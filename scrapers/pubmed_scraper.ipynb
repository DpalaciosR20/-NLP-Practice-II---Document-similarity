{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e88885",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import polars as pl\n",
    "\n",
    "PUBMED_TRENDING_URL = \"https://pubmed.ncbi.nlm.nih.gov/trending/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998be986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_nbib_data(nbib_text: str) -> dict | None:\n",
    "    \"\"\"\n",
    "    Analiza un bloque de texto en formato NBIB/MEDLINE, extrae los campos requeridos\n",
    "    y valida que todos estén presentes.\n",
    "    \"\"\"\n",
    "    # Mapeo de campos requeridos a sus etiquetas NBIB\n",
    "    nbib_map = {\n",
    "        'Title': 'TI',\n",
    "        'Authors': 'AU',\n",
    "        'Abstract': 'AB',\n",
    "        'Journal': 'JT',\n",
    "        'Date': 'DP',\n",
    "        'DOI': 'LID'\n",
    "    }\n",
    "    required_fields = list(nbib_map.keys())\n",
    "    \n",
    "    data = {}\n",
    "    authors = []\n",
    "    last_tag = None\n",
    "\n",
    "    for line in nbib_text.strip().split('\\n'):\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        match = re.match(r'^([A-Z]{2,4})\\s*-\\s*(.*)', line)\n",
    "        if match:\n",
    "            tag, value = match.groups()\n",
    "            last_tag = tag.strip()\n",
    "\n",
    "            # Solo captura el valor de LID si la línea contiene la etiqueta [doi]\n",
    "            if last_tag == nbib_map['DOI'] and '[doi]' in line:\n",
    "                data['DOI'] = value.split(' ')[0].strip()\n",
    "            \n",
    "            # Manejar autores (puede haber múltiples)\n",
    "            if last_tag == nbib_map['Authors']:\n",
    "                authors.append(value.strip())\n",
    "            # Manejar otros campos\n",
    "            elif last_tag in nbib_map.values():\n",
    "                field_name = [k for k, v in nbib_map.items() if v == last_tag][0]\n",
    "                if field_name not in data:\n",
    "                    data[field_name] = value.strip()\n",
    "        # Manejar campos multi-línea como el Abstract (AB)\n",
    "        elif last_tag and last_tag == nbib_map['Abstract'] and 'Abstract' in data:\n",
    "            data['Abstract'] += ' ' + line\n",
    "\n",
    "    if authors:\n",
    "        data['Authors'] = \", \".join(authors)\n",
    "\n",
    "    # Limpieza final y validación\n",
    "    if 'DOI' in data:\n",
    "        data['DOI'] = data['DOI'].split(' ')[0] # Extraer solo el DOI\n",
    "\n",
    "    for field in required_fields:\n",
    "        if field not in data or not data[field]:\n",
    "            print(f\"Artículo descartado. Campo requerido '{field}' no encontrado en el NBIB.\")\n",
    "            return None\n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabdcd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = webdriver.ChromeOptions()\n",
    "options.add_experimental_option(\"prefs\", {\"download.default_directory\": os.path.abspath(\".\")})\n",
    "# options.add_argument(\"--headless\")\n",
    "options.add_argument(\"--start-maximized\")\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "wait = WebDriverWait(driver, 10)\n",
    "\n",
    "driver.get(PUBMED_TRENDING_URL)\n",
    "actions = ActionChains(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492e31e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Mostrar primeros 300 registros ---\n",
    "# wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, 'button[data-ga-category=\"display_options\"]'))).click()\n",
    "# select_element = driver.find_element(By.ID, \"id_size\")\n",
    "# select_object = Select(select_element)\n",
    "# select_object.select_by_visible_text(\"100\")\n",
    "# wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, 'button[data-ga-category=\"display_options\"]'))).click()\n",
    "# for i in range (3):\n",
    "#     time.sleep(1)\n",
    "#     wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'button[data-ga-action=\"show_more\"]'))).click()\n",
    "# wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'button[data-ga-action=\"show_more\"]'))).click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004f13d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_data=[]\n",
    "reviewed=0\n",
    "\n",
    "while(len(article_data)<300):\n",
    "    article_urls = wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'a.docsum-title')))\n",
    "    # print(f\"article_urls={len(article_urls)}\")\n",
    "    for i in range(10):\n",
    "        if len(article_data)<300:\n",
    "            article_urls[reviewed].click()\n",
    "            # print(article_urls[reviewed].text)\n",
    "            time.sleep(1)\n",
    "            wait.until(EC.element_to_be_clickable((By.XPATH, '/html/body/div[5]/aside/div/div[2]/div/button[1]'))).click()\n",
    "            time.sleep(1)\n",
    "            file_name = ((wait.until(EC.visibility_of_element_located((By.XPATH, '/html/body/div[5]/div[2]/div/div[2]/div[2]/form'))).get_attribute(\"action\")).split(\"/\")[3] + \".nbib\")\n",
    "            # print(f\"file_name={file_name}\")\n",
    "            wait.until(EC.element_to_be_clickable((By.XPATH, '/html/body/div[5]/div[2]/div/div[2]/div[2]/form/button'))).click()\n",
    "            driver.execute_script(\"window.history.go(-1)\")\n",
    "            reviewed+=1\n",
    "\n",
    "            time.sleep(1)\n",
    "            contenido=\"\"\n",
    "            with open(file_name, 'r', encoding='utf-8') as f:\n",
    "                contenido = f.read()\n",
    "                # print(f\"Contenido del archivo {archivo_entrada} leído correctamente.\")\n",
    "            contenido_parseado = parse_nbib_data(contenido)\n",
    "            if contenido_parseado:\n",
    "                article_data.append(contenido_parseado)\n",
    "            os.remove(file_name)\n",
    "            # print(f\"reviewed={reviewed}, article_data={article_data}\")\n",
    "    if len(article_data)<300:\n",
    "        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'button[data-ga-action=\"show_more\"]'))).click()\n",
    "        # print(\"Showing more...\")\n",
    "    print(f\"len(article_data)={len(article_data)}\")\n",
    "    time.sleep(1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73a2a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Crear un DataFrame de Polars a partir de la lista de diccionarios\n",
    "df = pl.DataFrame(article_data)\n",
    "\n",
    "# 2. Seleccionar y ordenar las columnas según la especificación de la práctica\n",
    "column_order = [\"DOI\", \"Title\", \"Authors\", \"Abstract\", \"Journal\", \"Date\"]\n",
    "df = df.select(column_order)\n",
    "\n",
    "# 3. Guardar el DataFrame en un archivo CSV con separador de tabulación\n",
    "output_file = \"../pubmed_raw_corpus.csv\"\n",
    "df.write_csv(output_file, separator='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145a8329",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2cea375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2025/12/14'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def formatear_fecha(fecha: str):\n",
    "    mes_num = {\"Jan\": \"01\", \"Feb\": \"02\", \"Mar\": \"03\", \"Apr\": \"04\", \"May\": \"05\", \"Jun\": \"06\",\n",
    "           \"Jul\": \"07\", \"Aug\": \"08\", \"Sep\": \"09\", \"Oct\": \"10\", \"Nov\": \"11\", \"Dec\": \"12\"}\n",
    "    # Suponiendo que al menos el año está (YYYY MM DD, YYYY MM, YYYY)\n",
    "    # Formato original: YYYY MM DD\n",
    "    fecha_separada = fecha.split(\" \")\n",
    "    año = fecha_separada[0]\n",
    "    mes = fecha_separada[1].split(\"-\")[-1] if fecha_separada[1].split(\"-\") else fecha_separada[1] if len(fecha_separada) >= 2 else \"\"\n",
    "    dia = fecha_separada[2] if len(fecha_separada) == 3 else \"\"\n",
    "    return (año+\"/\"+mes_num[mes]+\"/\"+dia)   \n",
    "\n",
    "formatear_fecha(\"2025 Jan-Dec 14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1bb3a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "-NLP-Practice-II---Document-similarity",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
