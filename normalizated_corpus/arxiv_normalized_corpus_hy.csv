DOI,Title,Authors,Abstract,Section,Date
10.48550/arXiv.2509.16198,rpg repository planning graph unified scalable codebase generation,"Jane Luo, Xin Zhang, Steven Liu, Jie Wu, Yiming Huang, Yangyu Huang, Chengyu Yin, Ying Xin, Jianfeng Liu, Yuefeng Zhan, Hao Sun, Qi Chen, Scarlett Li, Mao Yang","large language model excel function- file level code generation generate complete repository scratch remain fundamental challenge process demand coherent reliable plan proposal- implementation level stage natural language ambiguity verbosity be ill suit faithfully represent complex software structure to address introduce repository planning graph rpg persistent representation unify proposal- implementation level plan encode capability file structure datum flow function one graph rpg replace ambiguous natural language explicit blueprint enable long horizon plan scalable repository generation build rpg develop zerorepo graph drive framework repository generation scratch operate three stage proposal level plan implementation level refinement to construct graph follow graph guide code generation test validation to evaluate set construct repocraft benchmark six real world project 1,052 task repocraft zerorepo generate repository average nearly 36 k loc roughly 3.9× strong baseline claude code 64× other baseline attain 81.5 functional coverage 69.7 pass rate exceed claude code 27.3 35.8 percentage point respectively further analysis show rpg model complex dependency enable progressively more sophisticate plan near linear scale enhance llm understand repository thereby accelerate agent localization",Computation and Language,19/09/2025
10.48550/arXiv.2509.16188,culturescope dimensional lens probing cultural understanding llms,"Jinghao Zhang, Sihang Jiang, Shiwei Guo, Shisong Chen, Yanghua Xiao, Hongwei Feng, Jiaqing Liang, Minggui HE, Shimin Tao, Hongxia Ma",large language model llms be increasingly deploy diverse cultural environment evaluate cultural understand capability have become essential ensure trustworthy culturally align application however most exist benchmark lack comprehensiveness be challenge to scale adapt different cultural context framework often lack guidance well establish cultural theory tend to rely expert drive manual annotation to address issue propose culturescope most comprehensive evaluation framework date assess cultural understand llms inspire cultural iceberg theory design novel dimensional schema cultural knowledge classification comprise 3 layer 140 dimension guide automate construction culture specific knowledge basis correspond evaluation dataset give language culture experimental result demonstrate method can effectively evaluate cultural understand also reveal exist large language model lack comprehensive cultural competence merely incorporate multilingual datum do not necessarily enhance cultural understand code datum file be available https://github.com/hoganzinger/culture,Computation and Language,19/09/2025
10.48550/arXiv.2509.16112,coderag find relevant necessary knowledge retrieval augment repository level code completion,"Sheng Zhang, Yifan Ding, Shuquan Lian, Shun Song, Hui Li",repository level code completion automatically predict unfinished code base broad information repository recent stride code large language models code llms have spur development repository level code completion method yield promise result nevertheless suffer issue such inappropriate query construction single path code retrieval misalignment code retriever code llm to address problem introduce coderag framework tailor to identify relevant necessary knowledge retrieval augment repository level code completion core component include log probability guide query construction multi path code retrieval preference align bestfit reranking extensive experiment benchmark recceval cceval demonstrate coderag significantly consistently outperform state art method implementation coderag be available https://github.com/kdegroup/coderag,Computation and Language,19/09/2025
10.48550/arXiv.2509.16107,depend resolve referential ambiguity minimal contexts commonsense knowledge,"Lukas Ellinger, Georg Groh",ambiguous word underspecified reference require interlocutor to resolve often rely share context commonsense knowledge therefore systematically investigate large language models llms can leverage commonsense to resolve referential ambiguity multi turn conversation analyze behavior ambiguity persist far study request simplify language affect capacity use novel multilingual evaluation dataset test deepseek v3 gpt-4o qwen3 32b gpt-4o mini llama-3.1 8b llm judge human annotation finding indicate current llm struggle to resolve ambiguity effectively tend to commit single interpretation cover possible reference rather hedge seek clarification limitation become more pronounce simplification prompt drastically reduce use commonsense reason diverse response strategy fine tune llama-3.1 8b direct preference optimization substantially improve ambiguity resolution request type result underscore need advance fine tune to improve llm handle ambiguity to ensure robust performance diverse communication style,Computation and Language,19/09/2025
10.48550/arXiv.2509.16105,diep adaptive mixture expert compression differentiable expert pruning,"Sikai Bai, Haoxi Li, Jie Zhang, Zicong Hong, Song Guo",significant breakthrough mixture expert moe increase scale moe model present huge memory storage challenge exist moe prune method involve reduce parameter size uniform sparsity layer often lead suboptimal outcome performance degradation vary expert redundancy different moe layer to address propose non uniform prune strategy dub differentiable expert pruning diep adaptively adjust prune rate layer level jointly learn inter layer importance effectively capture vary redundancy different moe layer transform global discrete search space continuous one method handle exponentially grow non uniform expert combination enable adaptive gradient base prune extensive experiment five advance moe model demonstrate efficacy method various nlp task notably diep retain around 92 original performance mixtral 8×\times7b only expert outperform other prune method to 7.1 challenge mmlu dataset,Computation and Language,19/09/2025
10.48550/arXiv.2509.16093,pointwise score decomposed criteria base evaluation llm responses,"Fangyi Yu, Nabeel Seedat, Dasha Herrmannova, Frank Schilder, Jonathan Richard Schwarz",evaluate long form answer high stake domain such law medicine remain fundamental challenge standard metric bleu rouge fail to capture semantic correctness current llm base evaluator often reduce nuanced aspect answer quality single undifferentiated score introduce dece decompose llm evaluation framework separate precision factual accuracy relevance recall coverage require concept use instance specific criterion automatically extract gold answer requirement dece be model agnostic domain general require predefined taxonomy handcraft rubric instantiate dece to evaluate different llm real world legal qa task involve multi jurisdictional reason citation ground dece achieve substantially strong correlation expert judgment rr=0.78 compare traditional metric rr=0.12 pointwise llm score rr=0.35 modern multidimensional evaluator rr=0.48 also reveal interpretable trade off generalist model favor recall specialize model favor precision importantly only 11.95 llm generate criterion require expert revision underscore dece ’s scalability dece offer interpretable actionable llm evaluation framework expert domain,Computation and Language,19/09/2025
10.48550/arXiv.2509.16028,think verbalize then speak bridging complex thoughts comprehensible speech,"Sang Hoon Woo, Sehun Lee, Kang-wook Kim, Gunhee Kim",spoken dialogue system increasingly employ large language model llms to leverage advance reason capability however direct application llms spoken communication often yield suboptimal result due mismatch optimal textual verbal delivery exist approach adapt llm to produce speech friendly output impact reason performance remain underexplored work propose think verbalize speak framework decouple reason spoken delivery to preserve full reason capacity llms central method be verbalize intermediate step translate thought natural speech ready text also introduce revert latency efficient verbalizer base incremental asynchronous summarization experiment multiple benchmark show method enhance speech naturalness conciseness minimal impact reason project page dataset source code be available https://yhytoto12.github.io/tvs-revert,Computation and Language,19/09/2025
10.48550/arXiv.2509.16025,session level spoken language assessment multimodal foundation model multi target learning,"Hong-Yun Lin, Jhen-Ke Lin, Chung-Chun Wang, Hao-Chien Lu, Berlin Chen",spoken language assessment sla estimate learner ’s oral proficiency spontaneous speech grow population l2 english speaker have intensify demand reliable sla critical component computer assisted language learning call exist effort often rely cascade pipeline be prone error propagation end end model often operate short audio window might miss discourse level evidence paper introduce novel multimodal foundation model approach perform session level evaluation single pass approach couple multi target learn frozen whisper asr model base speech prior acoustic aware calibration allow jointly learn holistic trait level objective sla resort handcraft feature coherently process entire response session l2 speaker model excel predict holistic oral proficiency experiment conduct speak improve benchmark demonstrate propose approach outperform previous state art cascade system exhibit robust cross part generalization produce compact deployable grader be tailor call application,Computation and Language,19/09/2025
10.48550/arXiv.2509.15974,beft bias efficient fine tuning language models,"Baichuan Huang, Ananth Balashankar, Amir Aminifar",fine tune bias term stand various parameter efficient fine tune peft technique owe out box usability competitive performance especially low data regime bias only fine tune have potential unprecedented parameter efficiency however link fine tune different bias term i.e. bias term query key value projection downstream performance remain unclear exist approach e.g. base magnitude bias change empirical fisher information provide limit guidance select particular bias term effective fine tune paper propose approach select bias term to be fine tune form foundation bias efficient fine tune beft extensively evaluate bias efficient approach other bias selection approach wide range large language model llms span encoder only decoder only architecture 110 m to 6.7b parameter result demonstrate effectiveness superiority bias efficient approach diverse downstream task include classification multiple choice generation task,Computation and Language,19/09/2025
10.48550/arXiv.2509.15958,localmax dynamic attention transformer asymptotic behavior,"Henri Cimetière, Maria Teresa Chiri, Bahman Gharesifard",introduce new discrete time attention model term localmax dynamic interpolate classic softmax dynamic hardmax dynamic only token maximize influence give token have positive weight hardmax uniform weight be determine parameter control neighbor influence key extension lie relax neighborhood interaction alignment sensitivity parameter allow control deviation pure hardmax behavior prove convex hull token state still converge convex polytope structure can no long be fully describe maximal alignment set prompt introduction quiescent set to capture invariant behavior token vertex show set play key role understand asymptotic behavior system even time vary alignment sensitivity parameter far show localmax dynamic do not exhibit finite time convergence provide result vanish nonzero time vary alignment sensitivity parameter recover limit behavior hardmax product finally adapt lyapunov base method classical opinion dynamic highlight limitation asymmetric set localmax interaction outline direction future research,Computation and Language,19/09/2025
10.48550/arXiv.2509.15926,score uncertainty calibrate llm automated essay assessment,"Ahmed Karim, Qiao Wang, Zheng Yuan",automated essay scoring aes system now attain human agreement public benchmark real world adoption especially high stake examination remain limit principal obstacle be most model output single score accompany measure confidence explanation address gap conformal prediction distribution free wrapper equip classifier set value output enjoy formal coverage guarantee two open source large language models llama-3 8b qwen-2.5 3b be fine tune three diverse corpus asap toefl11 cambridge fce calibrate 90 risk level reliability be assess uacc uncertainty aware accuracy reward model be correct concise knowledge be first work to combine conformal prediction uacc essay score calibrate model consistently meet coverage target keep prediction set compact indicate open source mid size llm can already support teacher loop aes discuss scale broad user study future work,Computation and Language,19/09/2025
10.48550/arXiv.2509.15901,re frame meeting summarization scope fact base summarization personalization question,"Frederic Kirstein, Sonu Kumar, Terry Ruas, Bela Gipp",meeting summarization large language model llms remain error prone often produce output hallucination omission irrelevancy present frame modular pipeline reframe summarization semantic enrichment task frame extract score salient fact organize thematically use to enrich outline abstractive summary to personalize summary introduce scope reason loud protocol have model build reason trace answer nine question content selection evaluation propose p mesa multi dimensional reference free evaluation framework to assess summary fit target reader p mesa reliably identify error instance achieve ≥89%\geq 89\% balance accuracy human annotation strongly align human severity rating ρ≥0.70\rho\geq 0.70 qmsum fame frame reduce hallucination omission 2 5 point measure mesa scope improve knowledge fit goal alignment prompt only baseline finding advocate rethink summarization to improve control faithfulness personalization111resource be available section a.1 github,Computation and Language,19/09/2025
10.48550/arXiv.2509.15896,psychology falsehood human centric survey misinformation detection,"Arghodeep Nandi, Megha Sundriyal, Euna Mehnaz Khan, Jikai Sun, Emily Vraga, Jaideep Srivastava, Tanmoy Chakraborty",misinformation remain one most significant issue digital age automate fact check have emerge viable solution most current system be limit evaluate factual accuracy however detrimental effect misinformation transcend simple falsehood take advantage individual perceive interpret emotionally react information underscore need to move factuality adopt more human center detection framework survey explore evolve interplay traditional fact check approach psychological concept such cognitive bias social dynamic emotional response analyze state art misinformation detection system lens human psychology behavior reveal critical limitation current method identify opportunity improvement additionally outline future research direction aim create more robust adaptive framework such neuro behavioural model integrate technological factor complexity human cognition social influence approach offer promise pathway to more effectively detect mitigate societal harm misinformation,Computation and Language,19/09/2025
10.48550/arXiv.2509.15888,distribution align decoding efficient llm task adaptation,"Senkang Hu, Xudong Han, Jinqi Jiang, Yihang Tao, Zihan Fang, Sam Tak Wu Kwong, Yuguang Fang",adapt billion parameter language model downstream task be still costly even parameter efficient fine tune peft re cast task adaptation output distribution alignment objective be to steer output distribution task distribution directly decode rather indirectly weight update build view introduce steering vector decoding svd lightweight peft compatible theoretically ground method start short warm start fine tune extract task aware steer vector kullback leibler kl divergence gradient output distribution warm start pre train model steer vector be then use to guide decode process to steer model ’s output distribution task distribution theoretically prove svd be first order equivalent gradient step full fine tune derive globally optimal solution strength steer vector three task nine benchmark svd pair four standard peft method improve multiple choice accuracy to 5 point open end truthfulness 2 point similar gain 1 2 point commonsense dataset add trainable parameter peft adapter svd thus offer lightweight theoretically ground path strong task adaptation large language model,Computation and Language,19/09/2025
10.48550/arXiv.2509.15839,multi physics comprehensive benchmark multimodal llm reason chinese multi subject physics problem,"Zhongze Luo, Zhenshuai Yin, Yongxin Guo, Zhichao Wang, Jionghao Zhu, Xiaoying Tang","multimodal llm mllms demonstrate remarkable reason progress application specialize scientific domain physics reveal significant gap current evaluation benchmark specifically exist benchmark often lack fine grain subject coverage neglect step step reason process be predominantly english centric fail to systematically evaluate role visual information therefore introduce multi physics chinese physics reason comprehensive benchmark include 5 difficulty level feature 1,412 image associate multiple choice question span 11 high school physics subject employ dual evaluation framework to evaluate 20 different mllm analyze final answer accuracy step step integrity chain thought furthermore systematically study impact difficulty level visual information compare model performance change input mode work provide not only fine grain resource community also offer robust methodology dissect multimodal reason process state art mllm dataset code have be open source 111https://github.com/luozhongze/multi-physics",Computation and Language,19/09/2025
10.48550/arXiv.2509.15837,curious case visual grounding different effects speech- text base language encoders,"Adrian Sauter, Willem Zuidema, Marianne de Heer Kloots",do visual information include train affect language process audio- text base deep learn model explore such visual ground affect model internal representation word find substantially different effect speech- text base language encoder firstly global representational comparison reveal visual ground increase alignment representation spoken write language effect seem mainly drive enhance encode word identity rather mean then apply target cluster analysis to probe phonetic vs. semantic discriminability model representation speech base representation remain phonetically dominate visual ground contrast text base representation visual ground do not improve semantic discriminability finding could usefully inform development more efficient method to enrich speech base model visually inform semantic,Computation and Language,19/09/2025
10.48550/arXiv.2509.15811,good l cross lingual reward modeling mathematical reasoning,"Sara Rajaee, Rochelle Choenni, Ekaterina Shutova, Christof Monz",reason ability large language model llms continue to advance remain unclear such ability vary language multilingual llm different language produce reason path complement other to investigate question train reward model rank generate response give question language result show cross lingual reward model substantially improve mathematical reason performance compare use reward model single language benefit even high resource language english often exhibit high performance multilingual model find cross lingual sample particularly benefit english low sample budget finding reveal new opportunity to improve multilingual reason leverage complementary strength diverse language,Computation and Language,19/09/2025
10.48550/arXiv.2509.15793,rave retrieval scoring aware verifiable claim detection,"Yufeng Li, Arkaitz Zubiaga",rapid spread misinformation social medium underscore need scalable fact check tool key step be claim detection identify statement can be objectively verify prior approach often rely linguistic cue claim check worthiness struggle vague political discourse diverse format such tweet present rave retrieval scoring aware verifiable claim detection framework combine evidence retrieval structure signal relevance source credibility experiment ct22 test policlaim test show rave consistently outperform text only retrieval base baseline accuracy f1,Computation and Language,19/09/2025
10.48550/arXiv.2509.15789,uprprc unified pipeline reproduce parallel resource corpus united nations,"Qiuyang Lu, Fangjian Shen, Zhengkai Tang, Qiang Liu, Hexuan Cheng, Hui Liu, Wushao Wen",quality accessibility multilingual dataset be crucial advance machine translation however previous corpus build united nations document have suffer issue such opaque process difficulty reproduction limit scale to address challenge introduce complete end end solution datum acquisition web scrape text alignment entire process be fully reproducible minimalist single machine example optional distribute compute step scalability core propose new graph aided paragraph alignment gapa algorithm efficient flexible paragraph level alignment result corpus contain 713 million english token more double scale prior work good knowledge represent large publicly available parallel corpus compose entirely human translate non ai generate content code corpus be accessible mit license,Computation and Language,19/09/2025
10.48550/arXiv.2509.15763,unigist general hardware align sequence level long context compression,"Chenlong Deng, Zhisong Zhang, Kelong Mao, Shuaiyi Li, Tianqing Fang, Hongming Zhang, Haitao Mi, Dong Yu, Zhicheng Dou",large language model be increasingly capable handle long context input memory overhead key value kv cache remain major bottleneck general purpose deployment various compression strategy have be explore sequence level compression drop full kv cache certain token be particularly challenge can lead loss important contextual information to address introduce unigist sequence level long context compression framework efficiently preserve context information replace raw token special compression token gist fine grain manner adopt chunk free train strategy design efficient kernel gist shift trick enable optimize gpu train scheme also support flexible inference allow actual removal compress token result real time memory saving experiment multiple long context task demonstrate unigist significantly improve compression quality especially strong performance detail recall task long range dependency model,Computation and Language,19/09/2025
10.48550/arXiv.2509.15739,can llms judge debates evaluate non linear reasoning argumentation theory semantics,"Reza Sanayei, Srdjan Vesic, Eduardo Blanco, Mihai Surdeanu",large language models llms excel linear reason task remain underexplored non linear structure such find natural debate be well express argument graph evaluate llm can approximate structure reason computational argumentation theory cat specifically use quantitative argumentation debate quad semantic assign acceptability score argument base attack support relation give only dialogue format debate two node dataset model be prompt to rank argument access underlie graph test several llms advance instruction strategy include chain thought in context learning model show moderate alignment quad ranking performance degrade long input disrupt discourse flow advanced prompt help mitigate effect reduce bias relate argument length position finding highlight promise limitation llm model formal argumentation semantic motivate future work graph aware reason,Computation and Language,19/09/2025
10.48550/arXiv.2509.15723,refer mitigate bias opinion summarisation frequency framed prompting,"Nannan Huang, Haytham M. Fayek, Xiuzhen Zhang",individual express diverse opinion fair summary should represent viewpoint comprehensively previous research fairness opinion summarisation use large language model llms rely hyperparameter tune provide ground truth distributional information prompt however method face practical limitation end user rarely modify default model parameter accurate distributional information be often unavailable build cognitive science research demonstrate frequency base representation reduce systematic bias human statistical reason make reference class explicit reduce cognitive load study investigate frequency frame prompt refer can similarly enhance fairness llm opinion summarisation systematic experimentation different prompt framework adapt technique know to improve human reason to elicit more effective information process language model compare to abstract probabilistic representation result demonstrate refer enhance fairness language model summarise opinion effect be particularly pronounce large language model use strong reason instruction,Computation and Language,19/09/2025
10.48550/arXiv.2509.15714,once time interactive learning storytelle small language models,"Jonas Mayer Martins, Ali Hamza Bashir, Muhammad Rehan Khalid, Lisa Beinborn",child efficiently acquire language not just listen interact other social environment conversely large language model be typically train next word prediction massive amount text motivate contrast investigate language model can be train less datum learn not only next word prediction also high level cognitively inspire feedback train student model to generate story teacher model rate readability narrative coherence creativity vary amount pretraining feedback loop assess impact interactive learn formal functional linguistic competence find high level feedback be highly datum efficient just 1 m word input interactive learn storytelling skill can improve as much 410 m word next word prediction,Computation and Language,19/09/2025
10.48550/arXiv.2509.15701,fine tuning large multimodal models automatic pronunciation assessment,"Ke Wang, Wenning Wei, Yan Deng, Lei He, Sheng Zhao",automatic pronunciation assessment apa be critical computer assisted language learning call require evaluation multiple granularity aspect large multimodal models lmms present new opportunity apa effectiveness fine grain assessment remain uncertain work investigate fine tune lmm apa use speechocean762 dataset private corpus fine tune significantly outperform zero shot setting achieve competitive result single granularity task compare public commercial system model perform well word sentence level phoneme level assessment remain challenge also observe pearson correlation coefficient pcc reach 0.9 spearman ’s rank correlation coefficient scc remain 0.6 suggest scc well reflect ordinal consistency finding highlight promise limitation lmms apa point future work fine grain model rank aware evaluation,Computation and Language,19/09/2025
10.48550/arXiv.2509.15667,vox krikri unifying speech language continuous fusion,"Dimitrios Damianos, Leon Voukoutis, Georgios Paraskevopoulos, Vassilis Katsouros",present multimodal fusion framework bridge pre train decoder base large language model llm acoustic encoder decoder architecture such whisper aim build speech enable llms instead directly use audio embedding explore intermediate audio condition text space more effective mechanism alignment method operate fully continuous text representation space fuse whisper ’s hide decoder state llm cross modal attention support offline stream mode introduce voxkrikri first greek speech llm show analysis approach effectively align representation modality result highlight continuous space fusion promise path multilingual low resource speech llms achieve state art result automatic speech recognition greek provide average ∼20%\sim 20\% relative improvement benchmark,Computation and Language,19/09/2025
10.48550/arXiv.2509.15655,layer wise minimal pair probing reveal contextual grammatical conceptual hierarchy speech representations,"Linyang He, Qiaolin Wang, Xilin Jiang, Nima Mesgarani",transformer base speech language model slms have significantly improve neural speech recognition understand exist research have examine well slm encode shallow acoustic phonetic feature extent to slms encode nuanced syntactic conceptual feature remain unclear draw parallel linguistic competence assessment large language model study be first to systematically evaluate presence contextual syntactic semantic feature slms self supervise learn s3 m automatic speech recognition asr speech compression codec encoder auditory large language model audiollms minimal pair design diagnostic feature analysis 71 task span diverse linguistic level layer wise time resolve analysis uncover 1 speech encode grammatical feature more robustly conceptual one 2 never see text s3 m match surpass asr encoder linguistic level demonstrate rich grammatical even conceptual knowledge can arise purely audio 3 s3 m representation peak mid network then crash final layer asr audiollm encoder maintain improve reflect pre train objective reshape late layer content 4 temporal probe far show s3ms encode grammatical cue 500 ms word begin audiollms distribute evidence more evenly indicate objective shape not only also linguistic information be most salient together finding establish first large scale map contextual syntax semantic speech model highlight promise limit current slm train paradigm,Computation and Language,19/09/2025
10.48550/arXiv.2509.15640,multilingual llm prompting strategies medical english vietnamese machine translation,"Nhu Vo, Nu-Uyen-Phuong Le, Dung D. Le, Massimo Piccardi, Wray Buntine",medical english vietnamese machine translation en vi mt be essential healthcare access communication vietnam vietnamese remain low resource under study language systematically evaluate prompt strategy six multilingual llm 0.5b–9b parameter medev dataset compare zero shot few shot dictionary augment prompt meddict english vietnamese medical lexicon result show model scale be primary driver performance large llm achieve strong zero shot result few shot prompt yield only marginal improvement contrast terminology aware cue embed base example retrieval consistently improve domain specific translation finding underscore promise current limitation multilingual llm medical en vi mt,Computation and Language,19/09/2025
10.48550/arXiv.2509.15631,sparse autoencoder guide internal representation unlearning large language models,"Tomoya Yamashita, Akira Ito, Yuuki Yamanaka, Masanori Yamada, Takayuki Miura, Toshiki Shibahara",large language model llms be increasingly deploy various application privacy copyright concern have heighten need more effective llm unlearn technique many exist unlearn method aim to suppress undesirable output additional train e.g. gradient ascent reduce probability generate such output such suppression base approach can control model output may not eliminate underlie knowledge embed model ’s internal activation mute response be not same forget moreover such suppression base method often suffer model collapse to address issue propose novel unlearn method directly intervene model ’s internal activation formulation forget be define state activation forget target be indistinguishable unknown entity method introduce unlearn objective modify activation target entity away know entity unknown entity sparse autoencoder latent space align target ’s internal activation unknown entity shift model ’s recognition target entity know unknown achieve genuine forget avoid suppression model collapse empirically show method effectively align internal activation forget target result suppression base approach do not reliably achieve additionally method effectively reduce model ’s recall target knowledge question answer task significant damage non target knowledge,Computation and Language,19/09/2025
10.48550/arXiv.2509.15621,concept unlearning large language models self construct knowledge triplets,"Tomoya Yamashita, Yuuki Yamanaka, Masanori Yamada, Takayuki Miura, Toshiki Shibahara, Tomoharu Iwata",machine unlearning mu have recently attract considerable attention solution privacy copyright issue large language model llms exist mu method aim to remove specific target sentence llm minimize damage unrelated knowledge however approach require explicit target sentence do not support remove broad concept such person event to address limitation introduce concept unlearning cu new requirement llm unlearn leverage knowledge graph to represent llm ’s internal knowledge define cu remove forget target node associate edge graph base formulation enable more intuitive unlearn facilitate design more effective method propose novel method prompt llm to generate knowledge triplet explanatory sentence forget target apply unlearn process representation approach enable more precise comprehensive concept removal align unlearn process llm ’s internal knowledge representation experiment real world synthetic dataset demonstrate method effectively achieve concept level unlearn while preserve unrelated knowledge,Computation and Language,19/09/2025
10.48550/arXiv.2509.15620,scievent benchmarke multi domain scientific event extraction,"Bofu Dong, Pritesh Shah, Sumedh Sonawane, Tiyasha Banerjee, Erin Brady, Xinya Du, Ming Jiang",scientific information extraction sciie have primarily rely entity relation extraction narrow domain limit applicability interdisciplinary research struggle to capture necessary context scientific information often result fragment conflict statement paper introduce scievent111our code benchmark be release https://github.com/desdai/scievent novel multi domain benchmark scientific abstract annotate unify event extraction ee schema design to enable structure context aware understand scientific content include 500 abstract five research domain manual annotation event segment trigger fine grain argument define sciie multi stage ee pipeline 1 segment abstract core scientific activity background method result conclusion 2 extract correspond trigger argument experiment fine tune ee model large language model llms human annotator reveal performance gap current model struggle domain such sociology humanity scievent serve challenge benchmark step generalizable multi domain sciie,Computation and Language,19/09/2025
10.48550/arXiv.2509.15587,divlogiceval framework benchmarking logical reasoning evaluation large language models,"Tsz Ting Chung, Lemao Liu, Mo Yu, Dit-Yan Yeung",logic reason natural language have be recognize important measure human intelligence large language models llms popular benchmark may entangle multiple reason skill thus provide unfaithful evaluation logic reason skill meanwhile exist logic reason benchmark be limit language diversity distribution be deviate distribution ideal logic reason benchmark may lead bias evaluation result paper thereby propose new classical logic benchmark divlogiceval consist natural sentence compose diverse statement counterintuitive way to ensure more reliable evaluation also introduce new evaluation metric mitigate influence bias randomness inherent llms experiment demonstrate extent to logical reason be require to answer question divlogiceval compare performance different llm conduct logical reason,Computation and Language,19/09/2025
10.48550/arXiv.2509.15579,chunk based speech pre train high resolution finite scalar quantization,"Yun Tang, Cindy Tseng",low latency speech human machine communication be become increasingly necessary speech technology advance quickly last decade one primary factor advancement speech technology be self supervise learn most self supervise learn algorithm be design full utterance assumption compromise have to make partial utterance be present be common stream application work propose chunk base self supervise learn chunk ssl algorithm unify solution stream offline speech pre train chunk ssl be optimize mask prediction loss acoustic encoder be encourage to restore index mask speech frame help unmask frame same chunk precede chunk copy append data augmentation approach be propose to conduct efficient chunk base pre train chunk ssl utilize finite scalar quantization fsq module to discretize input speech feature study show high resolution fsq codebook i.e. codebook vocabulary size few million be beneficial to transfer knowledge pre train task downstream task group mask prediction loss be employ pre train to alleviate high memory computation cost introduce large codebook propose approach be examine two speech text task i.e. speech recognition speech translation experimental result librispeech must c dataset show propose method could achieve very competitive result speech to text task stream offline mode,Computation and Language,19/09/2025
10.48550/arXiv.2509.15577,relevance utility process supervise rewrite rag,"Jaeyoung Kim, Jongho Kim, Seung-won Hwang, Seoho Song, Young-In Song",retrieval augmented generation system often suffer gap optimize retrieval relevance generative utility retrieve document may be topically relevant still lack content need effective reason generation exist bridge module attempt to rewrite retrieve text well generation show fail to capture true document utility work propose r2u key distinction directly optimize to maximize probability generate correct answer process supervision such direct observation be expensive also propose approximate efficient distillation pipeline scale supervision llms help small rewriter model generalize well evaluate method multiple open domain question answer benchmark empirical result demonstrate consistent improvement strong bridge baseline 111source code https://anonymous.4open.science/r/r2u-d547/readme.md,Computation and Language,19/09/2025
10.48550/arXiv.2509.15568,litelong resource efficient long context data synthesis llms,"Junlong Jia, Xing Wu, Chaochen Gao, Ziyang Chen, Zijia Lin, Zhongzhi Li, Weinong Wang, Haotian Xu, Donghui Jin, Debing Zhang, Binghui Guo",high quality long context datum be essential train large language model llms capable process extensive document exist synthesis approach use relevance base aggregation face challenge computational efficiency present litelong resource efficient method synthesize long context datum structure topic organization multi agent debate approach leverage bisac book classification system to provide comprehensive hierarchical topic organization then employ debate mechanism multiple llm to generate diverse high quality topic structure topic use lightweight bm25 retrieval to obtain relevant document concatenate 128k token train sample experiment helmet ruler benchmark demonstrate litelong achieve competitive long context performance can seamlessly integrate other long dependency enhancement method litelong make high quality long context data synthesis more accessible reduce computational data engineer cost facilitate further research long context language train,Computation and Language,19/09/2025
10.48550/arXiv.2509.15556,explore polyglot harmony multilingual data allocation large language models pretraine,"Ping Guo, Yubing Ren, Binbin Liu, Fengze Liu, Haobin Lin, Yifan Zhang, Bingni Zhang, Taifeng Wang, Yin Zheng",large language model llms have become integral wide range application worldwide drive unprecedented global demand effective multilingual capability central achieve robust multilingual performance be strategic allocation language proportion train corpus however determine optimal language ratio be highly challenge intricate cross lingual interaction sensitivity dataset scale paper introduce climb cross lingual interaction aware multilingual balancing novel framework design to systematically optimize multilingual datum allocation core climb introduce cross lingual interaction aware language ratio explicitly quantify language ’s effective allocation capture inter language dependency leverage ratio climb propose principled two step optimization procedure first equalize marginal benefit language then maximize magnitude result language allocation vector significantly simplify inherently complex multilingual optimization problem extensive experiment confirm climb can accurately measure cross lingual interaction various multilingual setting llm train climb derive proportion consistently achieve state art multilingual performance even achieve competitive performance open source llm train more token,Computation and Language,19/09/2025
10.48550/arXiv.2509.15550,dna detectllm unveiling ai generate text dna inspire mutation repair paradigm,"Xiaowei Zhu, Yubing Ren, Fang Fang, Qingfeng Tan, Shi Wang, Yanan Cao",rapid advancement large language model llms have blur line ai generate human write text progress bring societal risk such misinformation authorship ambiguity intellectual property concern highlight urgent need reliable ai generate text detection method however recent advance generative language model have result significant overlap feature distribution human write ai generate text blur classification boundary make accurate detection increasingly challenge to address above challenge propose dna inspire perspective leverage repair base process to directly interpretably capture intrinsic difference human write ai generate text building perspective introduce dna detectllm zero shot detection method distinguish ai generate human write text method construct ideal ai generate sequence input iteratively repair non optimal token quantify cumulative repair effort interpretable detection signal empirical evaluation demonstrate method achieve state art detection performance exhibit strong robustness various adversarial attack input length specifically dna detectllm achieve relative improvement 5.55 auroc 2.08 f1 score multiple public benchmark dataset,Computation and Language,19/09/2025
10.48550/arXiv.2509.15549,method improve multilingual quality diversity instruction fine tune dataset,"Chunguang Zhao, Yilun Liu, Pufan Zeng, Yuanchang Luo, Shimin Tao, Minggui He, Weibin Meng, Song Xu, Ziang Chen, Chen Liu, Hongxia Ma, Li Zhang, Boxing Chen, Daimeng Wei",multilingual instruction fine tuning ift be essential enable large language model llms to generalize effectively diverse linguistic cultural context however scarcity high quality multilingual train datum correspond build method remain critical bottleneck datum selection have show promise english setting exist method often fail to generalize language reliance simplistic heuristic language specific assumption work introduce multilingual data quality diversity m daq novel method improve llms multilinguality select high quality semantically diverse multilingual ift sample far conduct first systematic investigation superficial alignment hypothesis sah multilingual set empirical result 18 language demonstrate model fine tune m daq method achieve significant performance gain vanilla baseline 60 win rate human evaluation far validate gain highlight increment cultural point response release m daq code111https://github.com/zhaocorey/m-daq.git to support future research,Computation and Language,19/09/2025
10.48550/arXiv.2509.15518,do language models generate slang systematic comparison human machine generate slang usage,"Siyang Wu, Zhewei Sun",slang be commonly use type informal language pose daunt challenge nlp system recent advance large language model llms however have make problem more approachable llm agent be become more widely apply intermediary task such slang detection slang interpretation generalizability reliability be heavily dependent model have capture structural knowledge slang align well human attest slang usage to answer question contribute systematic comparison human machine generate slang usage evaluative framework focus three core aspect 1 characteristic usage reflect systematic bias machine perceive slang 2 creativity reflect lexical coinage word reuse employ slang usage 3 informativeness slang usage use gold standard example model distillation compare human attest slang usage online slang dictionary osd slang generate gpt-4o llama-3 find significant bias llms perceive slang result suggest llm have capture significant knowledge creative aspect slang such knowledge do not align human sufficiently to enable llm extrapolative task such linguistic analysis,Computation and Language,19/09/2025
10.48550/arXiv.2509.15515,llm cache bandit revisit address query heterogeneity cost effective llm inference,"Hantao Yang, Hong Xie, Defu Lian, Enhong Chen",paper revisit llm cache bandit problem special focus address query heterogeneity cost effective llm inference previous work often assume uniform query size heterogeneous query size introduce combinatorial structure cache selection make cache replacement process more computationally statistically challenge treat optimal cache selection knapsack problem employ accumulation base strategy to effectively balance computational overhead cache update theoretical analysis prove regret algorithm achieve o​(m​n​t)o(\sqrt{mnt bind improve coefficient m​n\sqrt{mn compare o​(m​n​t)o(mn\sqrt{t result berkeley nn be total number query mm be cache size additionally also provide problem dependent bind be absent previous work experiment rely real world datum show algorithm reduce total cost approximately 12,Computation and Language,19/09/2025
10.48550/arXiv.2509.15485,mucai barec shared task 2025 uncertainty aware arabic readability assessment,Ahmed Abdou,present simple model agnostic post process technique fine grain arabic readability classification barec 2025 shared task 19 ordinal level method apply conformal prediction to generate prediction set coverage guarantee then compute weight average use softmax renormalize probability conformal set uncertainty aware decode improve quadratic weighted kappa qwk reduce high penalty misclassification near level approach show consistent qwk improvement 1 3 point different base model strict track submission achieve qwk score 84.9%(test 85.7 blind test sentence level 73.3 document level arabic educational assessment enable human reviewer to focus handful plausible level combine statistical guarantee practical usability,Computation and Language,18/09/2025
10.48550/arXiv.2509.15476,evaluate multimodal large language models spoken sarcasm understanding,"Zhu Li, Xiyuan Gao, Yuqing Zhang, Shekhar Nayak, Matt Coler",sarcasm detection remain challenge natural language understand sarcastic intent often rely subtle cross modal cue span text speech vision prior work have primarily focus textual visual textual sarcasm comprehensive audio visual textual sarcasm understand remain underexplored paper systematically evaluate large language model llms multimodal llm sarcasm detection english mustard++ chinese mcsd 1.0 zero shot few shot lora fine tune setting addition direct classification explore model feature encoder integrate representation collaborative gate fusion module experimental result show audio base model achieve strong unimodal performance text audio audio vision combination outperform unimodal trimodal model furthermore mllm such qwen omni show competitive zero shot fine tune performance finding highlight potential mllm cross lingual audio visual textual sarcasm understand,Computation and Language,18/09/2025
10.48550/arXiv.2509.15447,pilot steering synthetic data generation psychological linguistic output targeting,"Caitlin Cisar, Emily Sheffield, Joshua Drake, Alden Harrell, Subramanian Chidambaram, Nikita Nangia, Vinayak Arannil, Alex Williams",generative ai application commonly leverage user persona steer mechanism synthetic datum generation reliance natural language representation force model to make unintended inference attribute to emphasize limit precise control output introduce pilot psychological linguistic output targeting two phase framework steer large language model structure psycholinguistic profile phase 1 pilot translate natural language persona description multidimensional profile normalize score linguistic psychological dimension phase 2 profile guide generation measurable axis variation evaluate pilot three state art llm mistral large 2 deepseek r1 llama 3.3 70b use 25 synthetic persona three condition natural language persona steering nps schema base steering sbs hybrid persona schema steering hps result demonstrate schema base approach significantly reduce artificial sound persona repetition improve output coherence silhouette score increase 0.098 0.237 topic purity 0.773 0.957 analysis reveal fundamental trade off sbs produce more concise output high topical consistency nps offer great lexical diversity reduce predictability hps achieve balance extreme maintain output variety preserve structural consistency expert linguistic evaluation confirm pilot maintain high response quality condition statistically significant difference steer approach finding establish pilot effective framework interpretable controllable persona base generation bridge gap structure user model nuanced linguistic expression llms,Computation and Language,18/09/2025
10.48550/arXiv.2509.15430,birq bi level self label random quantization self supervised speech recognition,"Liuyuan Jiang, Xiaodong Cui, Brian Kingsbury, Tianyi Chen, Lisha Chen","speech be rich signal label audio text pair be costly to obtain make self supervise learn ssl essential scalable representation learn core challenge speech ssl be generate pseudo label be informative efficient strong label such use hubert 1 improve downstream performance rely external encoder multi stage pipeline efficient method well rq 2 achieve simplicity cost weak label propose birq bilevel ssl framework combine efficiency best rq refinement benefit hubert style label enhancement key idea be to reuse part model pseudo label generator intermediate representation be discretize random projection quantizer to produce enhance label anchor label derive directly raw input stabilize train prevent collapse training be formulate efficient first order bilevel optimization problem solve end end differentiable gumbel softmax selection design eliminate need external label encoder reduce memory cost enable iterative label refinement end end fashion birq consistently improve best rq maintain low complexity computational efficiency validate method various dataset include 960 hour librispeech 150 hour ami meeting 5,000 hour yoda demonstrate consistent gain best rq",Computation and Language,18/09/2025
10.48550/arXiv.2509.15419,deep learn abstractive summarisation radiological report empirical study adapt pegasus model family scarce datum,"Claudio Benzoni, Martina Langhals, Martin Boeker, Luise Modersohn, Máté E. Maros",nan,Computation and Language,18/09/2025
10.48550/arXiv.2509.15403,quantify uncertainty natural language explanation large language models question answering,"Yangyi Li, Mengdi Huai",large language model llms have show strong capability enable concise context aware answer question answer qa task lack transparency complex llm have inspire extensive research aim develop method to explain large language behavior exist explanation method natural language explanation stand ability to explain llm self explanatory manner enable understand model behavior even model be close source however promise advancement be exist work study to provide valid uncertainty guarantee generate natural language explanation such uncertainty quantification be critical understand confidence explanation notably generate valid uncertainty estimate natural language explanation be particularly challenge auto regressive generation process llms presence noise medical inquiry to bridge gap work first propose novel uncertainty estimation framework generate natural language explanation provide valid uncertainty guarantee post hoc model agnostic manner additionally also design novel robust uncertainty estimation method maintain valid uncertainty guarantee even noise extensive experiment qa task demonstrate desire performance method,Computation and Language,18/09/2025
10.48550/arXiv.2509.15373,frustratingly easy data augmentation low resource asr,"Katsumi Ibaraki, David Chiang",paper introduce three self contain data augmentation method low resource automatic speech recognition asr technique first generate novel text use gloss base replacement random replacement llm base approach then apply text speech tts to produce synthetic audio apply method leverage only original annotate datum four language extremely limit resource vatlongo nashta shinekhen buryat kakabe fine tune pre train wav2vec2 xlsr-53 model combination original audio generate synthetic datum yield significant performance gain include 14.3 absolute wer reduction nashta method prove effective four low resource language also show utility high resource language english demonstrate broad applicability,Computation and Language,18/09/2025
10.48550/arXiv.2509.15362,speech language models under represent language insight wolof,"Yaya Sy, Dioula Doucouré, Christophe Cerisara, Irina Illina",present journey train speech language model wolof underrepresented language speak west africa share key insight first emphasize importance collect large scale spontaneous high quality speech datum show continue pretraining hubert dataset outperform base model african centric model asr then integrate speech encoder wolof llm to train first speech llm language extend capability task such speech translation furthermore explore train speech llm to perform multi step chain thought transcribe translate result show speech llm not only improve speech recognition also perform well speech translation model code will be openly share,Computation and Language,18/09/2025
10.48550/arXiv.2509.15361,spurious signal debiase multimodal large language models counterfactual inference adaptive expert routing,"Zichen Wu, Hsiu-Yuan Huang, Yunfang Wu",multimodal large language models mllms have show substantial capability integrate visual textual information yet frequently rely spurious correlation undermine robustness generalization complex multimodal reason task paper address critical challenge superficial correlation bias mllm novel causal mediation base debiasing framework specially distinguish core semantic spurious textual visual context counterfactual example to activate train stage debiasing employ mixture expert moe architecture dynamic rout to selectively engage modality specific debiase expert empirical evaluation multimodal sarcasm detection sentiment analysis task demonstrate framework significantly surpass unimodal debiasing strategy exist state art model further research release train evaluation pipeline github111https://github.com/zichen-wu/multimodal-mixture-of-expert-debiase,Computation and Language,18/09/2025
10.48550/arXiv.2509.15350,real fake manipulate detect machine influence text,"Yitong Wang, Zhongping Zhang, Margherita Piana, Zheng Zhou, Peter Gerstoft, Bryan A. Plummer",large language model llms can be use to write modify document present challenge understand intent use example benign use may involve use llm human write document to improve grammar to translate language however document entirely produce llm may be more likely to be use to spread misinformation simple translation e.g. use malicious actor simply hallucinate prior work machine generated text mgt detection mostly focus simply identify document be human machine write ignore fine grain use paper introduce hierarchical length robust machine influence text detector hero learn to separate text sample vary length four primary type human write machine generate machine polish machine translate hero accomplish combine prediction length specialist model have be train subcategory guidance specifically category be easily confuse e.g. different source language subcategory guidance module encourage separation fine grain category boost performance extensive experiment five llm six domain demonstrate benefit hero outperform state art 2.5 3 map average111code https://github.com/ellywang66/hero,Computation and Language,18/09/2025
10.48550/arXiv.2509.15339,quantify self awareness knowledge large language models,"Yeongbin Seo, Dongha Lee, Jinyoung Yeo",hallucination prediction large language model llms be often interpret sign self awareness however argue such performance can arise question side shortcut rather true model side introspection to disentangle factor propose approximate question side effect aqe quantify contribution question awareness analysis multiple dataset reveal much report success stem exploit superficial pattern question far introduce scao semantic compression answer one word method enhance use model side signal experiment show scao achieve strong consistent performance particularly setting reduce question side cue highlight effectiveness foster genuine self awareness llm code be available online https://github.com/ybseo-ac/aqe,Computation and Language,18/09/2025
10.48550/arXiv.2509.15335,polbix detect llms political bias fact checking x phemisms,"Charlott Jakob, David Harbecke, Patrick Parschan, Pia Wenzel Neves, Vera Schmitt",large language models be increasingly use application require objective assessment could be compromise political bias many study find preference left lean position llm downstream effect task fact check remain underexplored study systematically investigate political bias exchange word euphemism dysphemism german claim construct minimal pair factually equivalent claim differ political connotation to assess consistency llms classify true false evaluate six llm find more political lean presence judgmental word significantly influence truthfulness assessment few model show tendency political bias be not mitigate explicitly call objectivism prompt,Computation and Language,18/09/2025
10.48550/arXiv.2509.15260,toxicity red team benchmarking llm safety singapore 's low resource language,"Yujia Hu, Ming Shan Hee, Preslav Nakov, Roy Ka-Wei Lee",advancement large language models llms have transform natural language process however safety mechanism remain under explore low resource multilingual setting here aim to bridge gap particular introduce sgtoxicguard novel dataset evaluation framework benchmarke llm safety singapore ’s diverse linguistic context include singlish chinese malay tamil sgtoxicguard adopt red team approach to systematically probe llm vulnerability three real world scenario conversation question answer content composition conduct extensive experiment state art multilingual llm result uncover critical gap safety guardrail offer actionable insight cultural sensitivity toxicity mitigation lay foundation safe more inclusive ai system linguistically diverse environments.111link dataset https://github.com/social-ai-studio/sgtoxicguard disclaimer paper contain sensitive content may be disturb reader,Computation and Language,18/09/2025
10.48550/arXiv.2509.15248,synthetic bootstrappe pretraining,"Zitong Yang, Aonan Zhang, Hong Liu, Tatsunori Hashimoto, Emmanuel Candès, Chong Wang, Ruoming Pang",introduce synthetic bootstrapped pretraining sbp language model lm pretraining procedure first learn model relation document pretraine dataset then leverage to synthesize vast new corpus joint train standard pretraining teach lms to learn causal correlation token single document be not design to efficiently model rich learnable inter document correlation can potentially lead well performance validate sbp design compute match pretraining setup pretrain 3b parameter model to 1 t token scratch find sbp consistently improve strong repetition baseline deliver significant fraction performance improvement attainable oracle upper bind access 20x more unique datum qualitative analysis reveal synthesize document go mere paraphrase sbp first abstract core concept seed material then craft new narration top strong empirical performance sbp admit natural bayesian interpretation synthesizer implicitly learn to abstract latent concept share relate document,Computation and Language,17/09/2025
10.48550/arXiv.2509.16197,manzano simple scalable unified multimodal model hybrid vision tokenizer,"Yanghao Li, Rui Qian, Bowen Pan, Haotian Zhang, Haoshuo Huang, Bowen Zhang, Jialing Tong, Haoxuan You, Xianzhi Du, Zhe Gan, Hyunjik Kim, Chao Jia, Zhenbang Wang, Yinfei Yang, Mingfei Gao, Zi-Yi Dou, Wenze Hu, Chang Gao, Dongxu Li, Philipp Dufter, Zirui Wang, Guoli Yin, Zhengdong Zhang, Chen Chen, Yang Zhao, Ruoming Pang, Zhifeng Chen",unified multimodal large language models llms can understand generate visual content hold immense potential however exist open source model often suffer performance trade off capability present manzano simple scalable unify framework substantially reduce tension couple hybrid image tokenizer well curate train recipe single share vision encoder feed two lightweight adapter produce continuous embedding image text understand discrete token text image generation common semantic space unify autoregressive llm predict high level semantic form text image token auxiliary diffusion decoder subsequently translate image token pixel architecture together unify train recipe understand generation datum enable scalable joint learn capability manzano achieve state art result unify model be competitive specialist model particularly text rich evaluation study show minimal task conflict consistent gain scale model size validate design choice hybrid tokenizer,Computation and Language,19/09/2025
10.48550/arXiv.2509.16189,latent learn episodic memory complement parametric learn enable flexible reuse experience,"Andrew Kyle Lampinen, Martin Engelcke, Yuxuan Li, Arslan Chaudhry, James L. McClelland",do machine learn system fail to generalize mechanism could improve generalization here draw inspiration cognitive science to argue one weakness machine learn system be failure to exhibit latent learn learn information be not relevant task hand might be useful future task show perspective link failure range reversal curse language model new finding agent base navigation then highlight cognitive science point episodic memory potential part solution issue correspondingly show system oracle retrieval mechanism can use learn experience more flexibly to generalize well many challenge also identify essential component effectively use retrieval include importance example context learn acquire ability to use information retrieve example summary result illustrate one possible contributor relative datum inefficiency current machine learn system compare natural intelligence help to understand retrieval method can complement parametric learn to improve generalization,Computation and Language,19/09/2025
10.48550/arXiv.2509.16163,robust vision language models tensor decomposition defense adversarial attacks,"Het Patel, Muzammil Allie, Qian Zhang, Jia Chen, Evangelos E. Papalexakis",vision language model vlms excel multimodal understand be prone adversarial attack exist defense often demand costly retrain significant architecture change introduce lightweight defense use tensor decomposition suitable pre train vlm require retrain decompose reconstruct vision encoder representation filter adversarial noise preserve mean experiment clip coco flickr30 k show improve robustness flickr30 k restore 12.3 performance lose attack raise recall@1 accuracy 7.5 19.8 coco recover 8.1 performance improve accuracy 3.8 11.9 analysis show tensor train decomposition low rank 8 32 low residual strength α=0.1−0.2\alpha=0.1 0.2 be optimal method be practical plug play solution minimal overhead exist vlm,Computation and Language,19/09/2025
10.48550/arXiv.2509.16060,saber uncover vulnerability safety alignment cross layer residual connection,"Maithili Joshi, Palash Nandi, Tanmoy Chakraborty",large language models llms safe alignment train be powerful instrument robust language comprehension capability model typically undergo meticulous alignment procedure involve human feedback to ensure acceptance safe input reject harmful unsafe one however massive scale alignment effort llms remain vulnerable jailbreak attack malicious user manipulate model to produce harmful output be explicitly train to avoid study find safety mechanism llm be predominantly embed middle late layer build insight introduce novel white box jailbreak method saber safety alignment bypass extra residuals connect two intermediate layer ss ee s < es < e residual connection approach achieve 51%51\% improvement well perform baseline harmbench test set furthermore saber induce only marginal shift perplexity evaluate harmbench validation set source code be publicly available111https://github.com/palgitts/saber warning paper contain potentially harmful offensive content,Computation and Language,19/09/2025
10.48550/arXiv.2509.15986,emoheal end end system personalized therapeutic music retrieval fine grain emotion,"Xinchen Wan, Jinhua Liang, Huan Zhang",exist digital mental wellness tool often overlook nuanced emotional state underlie everyday challenge example pre sleep anxiety affect more 1.5 billion people worldwide current approach remain largely static one size fit fail to adapt individual need work present emoheal end end system deliver personalize three stage supportive narrative emoheal detect 27 fine grain emotion user text fine tune xlm roberta model map musical parameter knowledge graph ground music therapy principle gems iso principle emoheal retrieve audiovisual content use clamp3 model to guide user current state calm one match guide target subject study n=40 demonstrate significant supportive effect participant report substantial mood improvement m=4.12 p<0.001p<0.001 high perceive emotion recognition accuracy m=4.05 p<0.001p<0.001 strong correlation perceive accuracy therapeutic outcome r=0.72r=0.72 p<0.001p<0.001 validate fine grain approach finding establish viability theory drive emotion aware digital wellness tool provide scalable ai blueprint operationalize music therapy principle,Computation and Language,19/09/2025
10.48550/arXiv.2509.15969,voxtream full stream text speech extremely low latency,"Nikita Torgashov, Gustav Eje Henter, Gabriel Skantze",present voxtream fully autoregressive zero shot stream text speech tts system real time use begin speak first word voxtream directly map incoming phoneme audio token use monotonic alignment scheme dynamic look ahead do not delay onset build incremental phoneme transformer temporal transformer predict semantic duration token depth transformer produce acoustic token voxtream achieve knowledge low initial delay publicly available stream tts 102 ms gpu be train mid scale 9k hour corpus match surpass large baseline several metric deliver competitive quality output- full stream setting demo code be available https://herimor.github.io/voxtream,Computation and Language,19/09/2025
10.48550/arXiv.2509.15957,ehr mcp real world evaluation clinical information retrieval large language models model context protocol,"Kanato Masayoshi, Masahiro Hashimoto, Ryoichi Yokoyama, Naoki Toda, Yoshifumi Uwamino, Shogo Fukuda, Ho Namkoong, Masahiro Jinzaki",background large language model llms show promise medicine deployment hospital be limit restrict access electronic health record ehr system model context protocol mcp enable integration llm external tool,Computation and Language,19/09/2025
10.48550/arXiv.2509.15692,direct simultaneous translation activation large audio language models,"Pei Zhang, Yiming Wang, Jialong Tang, Baosong Yang, Rui Wang, Derek F. Wong, Fei Huang",simultaneous speech text translation simul s2tt aim to translate speech target text real time output translation receive source speech input rather wait entire utterance to be speak simul s2tt research often modify model architecture to implement read write strategy however rise large audio language model lalms key challenge be to directly activate simul s2tt capability base model additional architectural change paper introduce simultaneous self augmentation simulsa strategy utilize lalms inherent capability to obtain simultaneous datum randomly truncate speech construct partially align translation incorporate offline sft datum simulsa effectively bridge distribution gap offline translation pretraine simultaneous translation inference experimental result demonstrate augment only about 1 simultaneous datum compare full offline sft datum can significantly activate lalm simul s2tt capability modification to model architecture decode strategy,Computation and Language,19/09/2025
10.48550/arXiv.2509.15676,kite kernelize information theoretic exemplars in context learning,"Vaibhav Singh, Soumya Suvra Ghosal, Kapu Nirmal Joshua, Soumyabrata Pal, Sayak Ray Chowdhury",context learn icl have emerge powerful paradigm adapt large language model llms new datum scarce task use only few carefully select task specific example present prompt however give limit context size llms fundamental question arise example should be select to maximize performance give user query near neighbor base method kate have be widely adopt purpose suffer well know drawback high dimensional embed space include poor generalization lack diversity work study problem example selection icl principled information theory drive perspective,Computation and Language,19/09/2025
10.48550/arXiv.2509.15661,sightsound r1 cross modal reasoning distillation vision audio language models,"Qiaolin Wang, Xilin Jiang, Linyang He, Junkai Wu, Nima Mesgarani",large audio language model lalms have demonstrate state art audio understand reason capability complex soundscape still fall large vision language model lvlms compare visual domain one bottleneck be lack large scale chain think audio datum to teach lalm stepwise reason to circumvent datum modality gap present sightsound r1 cross modal distillation framework transfer advance reason strong lvlm teacher weak lalm student same audio visual question answer avqa dataset sightsound r1 consist three core step i test time scale to generate audio focus chain thought cot lvlm teacher ii audio ground validation to filter hallucination iii distillation pipeline supervise fine tune sft follow group relative policy optimization grpo lalm student result show sightsound r1 improve lalm reason performance domain avqa test set as well unseen auditory scene question outperform pretraine label only distil baseline thus conclude vision reason can be effectively transfer audio model scale abundant audio visual datum,Computation and Language,19/09/2025
10.48550/arXiv.2509.15561,small llms expert blocks be good enough hyperparamter tuning,"Om Naphade, Saksham Bansal, Parikshit Pareek",hyper parameter tuning hpt be necessary step machine learn ml pipeline become computationally expensive opaque large model recently large language models llms have be explore hpt yet most rely model exceed 100 billion parameter propose expert block framework hpt use small llms core be trajectory context summarizer tcs deterministic block transform raw train trajectory structure context enable small llm to analyze optimization progress reliability comparable large model use two locally run llm phi4 reasoning14b qwen2.5 coder:32b 10 trial budget tcs enable hpt pipeline achieve average performance 0.9 percentage point gpt-4 six diverse task,Computation and Language,19/09/2025
10.48550/arXiv.2509.15540,word enhance desire emotion sentiment recognition non verbal cues,"Wei Chen, Tongguan Wang, Feiyue Xue, Junkai Li, Hui Liu, Ying Sha",desire intention drive human behavior be closely relate emotion sentiment multimodal learn have advance sentiment emotion recognition multimodal approach specially target human desire understand remain underexplored exist method sentiment analysis predominantly emphasize verbal cue overlook image complementary non verbal cue to address gap propose symmetrical bidirectional multimodal learning framework desire emotion sentiment recognition enforce mutual guidance text image modality to effectively capture intention relate representation image specifically low resolution image be use to obtain global visual representation cross modal alignment high resolution image be partition sub image model mask image model to enhance ability to capture fine grain local feature text guide image decoder image guide text decoder be introduce to facilitate deep cross modal interaction local global representation image information additionally to balance perceptual gain computation cost mix scale image strategy be adopt high resolution image be crop sub image mask model propose approach be evaluate msed multimodal dataset include desire understand benchmark as well emotion sentiment recognition experimental result indicate consistent improvement other state art method validate effectiveness propose method specifically method outperform exist approach achieve f1 score improvement 1.1 desire understand 0.6 emotion recognition 0.9 sentiment analysis code be available https://github.com/especiallyw/sydes,Computation and Language,19/09/2025
10.48550/arXiv.2509.15380,efficient versatile model multilingual information retrieval islamic text development deployment real world scenario,"Vera Pavlova, Mohammed Makhlouf",recent advancement multilingual information retrieval mlir significant gap remain research practical deployment many study assess mlir performance isolate setting limit applicability real world scenario work leverage unique characteristic quranic multilingual corpus to examine optimal strategy to develop ad hoc ir system islamic domain be design to satisfy user information need multiple language prepare eleven retrieval model employ four train approach monolingual cross lingual translate train novel mix method combine cross lingual monolingual technique evaluation domain dataset demonstrate mix approach achieve promise result diverse retrieval scenario furthermore provide detail analysis different train configuration affect embed space implication multilingual retrieval effectiveness finally discuss deployment consideration emphasize cost efficiency deploy single versatile lightweight model real world mlir application system be deploy online111https://rttl.ai/.,Computation and Language,18/09/2025
10.48550/arXiv.2509.15279,fleming r1 expert level medical reasoning reinforcement learning,"Chi Liu, Derek Li, Yan Shu, Robin Chen, Derek Duan, Teng Fang, Bryan Dai",large language model show promise medical application achieve expert level clinical reason remain challenge need accurate answer transparent reason process to address challenge introduce fleming r1 model design verifiable medical reason three complementary innovation first reasoning orient data strategy rods combine curate medical qa dataset knowledge graph guide synthesis to improve coverage underrepresented disease drug multi hop reason chain second employ chain thought cot cold start to distill high quality reason trajectory teacher model establish robust inference prior third implement two stage reinforcement learning verifiable rewards rlvr framework use group relative policy optimization consolidate core reason skill target persistent failure mode adaptive hard sample mine diverse medical benchmark fleming r1 deliver substantial parameter efficient improvement 7b variant surpass much large baseline 32b model achieve parity gpt-4o consistently outperform strong open source alternative result demonstrate structure data design reason orient initialization verifiable reinforcement learn can advance clinical reason simple accuracy optimization release fleming r1 publicly to promote transparent reproducible auditable progress medical ai enable safe deployment high stake clinical environment,Computation and Language,18/09/2025
10.48550/arXiv.2509.15241,m pace mother child framework multimodal compliance,"Shreyash Verma, Amit Kesari, Vinayak Trivedi, Anupam Purwar, Ratnesh Jamidar",ensure multi modal content adhere brand legal platform specific compliance standard be increasingly complex challenge domain traditional compliance framework typically rely disjoint multi stage pipeline integrate separate module image classification text extraction audio transcription hand craft check rule base merge architectural fragmentation increase operational overhead hamper scalability hinder ability to adapt dynamic guideline efficiently emergence multimodal large language models mllms be grow potential to unify workflow single general purpose framework capable jointly process visual textual content light propose multimodal parameter agnostic compliance engine m pace framework design assess attribute vision language input single pass representative use case apply m pace advertisement compliance demonstrate ability to evaluate 15 compliance relate attribute to support structure evaluation introduce human annotate benchmark enrich augment sample simulate challenge real world condition include visual obstruction profanity injection m pace employ mother child mllm setup demonstrate strong parent mllm evaluate output small child model can significantly reduce dependence human reviewer thereby automate quality control analysis reveal inference cost reduce 31× most efficient model gemini 2.0 flash child mllm select mother mllm operate $ 0.0005 image compare $ 0.0159 gemini 2.5 pro comparable accuracy highlight trade off cost output quality achieve real time m pace real life deployment advertise datum,Computation and Language,17/09/2025
10.48550/arXiv.2509.15235,vispec accelerate vision language models vision aware speculative decoding,"Jialiang Kang, Han Shu, Wenshuo Li, Yingjie Zhai, Xinghao Chen",speculative decode be widely adopt technique accelerate inference large language model llms application vision language model vlms remain underexplored exist method achieve only modest speedup < 1.5×<1.5\times gap be increasingly significant multimodal capability become central large scale model hypothesize large vlm can effectively filter redundant image information layer layer compromise textual comprehension small draft model struggle to do so to address introduce vision aware speculative decoding vispec novel framework tailor vlms vispec employ lightweight vision adaptor module to compress image token compact representation be seamlessly integrate draft model ’s attention mechanism preserve original image positional information additionally extract global feature vector input image augment subsequent text token feature to enhance multimodal coherence to overcome scarcity multimodal dataset long assistant response curate specialize train dataset repurpose exist dataset generate extend output use target vlm modify prompt train strategy mitigate risk draft model exploit direct access target model ’s hide state could otherwise lead to shortcut learn train solely target model output extensive experiment validate vispec achieve knowledge first substantial speedup vlm speculative decode,Computation and Language,17/09/2025
10.48550/arXiv.2509.15233,video2roleplay multimodal dataset framework video guided role play agent,"Xueqiao Zhang, Chao Zhang, Jingtao Xu, Yifan Zhu, Xin Shi, Yi Yang, Yawei Luo",role play agent rpas have attract grow interest ability to simulate immersive interactive character however exist approach primarily focus static role profile overlook dynamic perceptual ability inherent human to bridge gap introduce concept dynamic role profile incorporate video modality rpa to support construct role play video60k large scale high quality dataset comprise 60k video 700k correspond dialogue base dataset develop comprehensive rpa framework combine adaptive temporal sample dynamic static role profile representation specifically dynamic profile be create adaptively sample video frame feed llm temporal order static profile consist 1 character dialogue train video fine tune 2 summary context input video inference joint integration enable rpa to generate great response furthermore propose robust evaluation method cover eight metric experimental result demonstrate effectiveness framework highlight importance dynamic role profile develop rpas.111our datum code be available https://github.com/zxqsled/video2roleplay,Computation and Language,17/09/2025
10.48550/arXiv.2509.15218,lne blocking efficient framework contamination mitigation evaluation large language models,"Ruijie Hou, Yueyang Jiao, Hanxu Hu, Yingming Li, Wai Lam, Huajian Zhang, Hongyuan Lu",problem datum contamination be now almost inevitable development large language model llms train datum commonly integrate evaluation benchmark even unintentionally problem subsequently make hard to benchmark llm fairly instead construct contamination free dataset quite hard propose novel framework lne blocking to restore model performance prior contamination potentially leak dataset framework consist two component contamination detection disruption operation prompt framework first use contamination detection method lne to assess extent contamination model base adjust intensity disruption operation blocking to elicit non memorize response model framework be first to efficiently restore model ’s greedy decode performance come strong performance multiple dataset potential leakage risk consistently achieve stable recovery result different model vary level datum contamination release code https://github.com/ruijieh/lne-blocke to facilitate research,Computation and Language,18/09/2025
10.48550/arXiv.2509.15216,assess historical structural oppression worldwide rule guide prompting large language models,"Sreejato Chatterjee, Linh Tran, Quoc Duy Nguyen, Roni Kirson, Drue Hamlin, Harvest Aquino, Hanjia Lyu, Jiebo Luo, Timothy Dye",traditional effort to measure historical structural oppression struggle cross national validity unique locally specify history exclusion colonization social status country often have rely structure index privilege material resource overlook live identity base exclusion introduce novel framework oppression measurement leverage large language models llms to generate context sensitive score live historical disadvantage diverse geopolitical setting use unstructured self identify ethnicity utterance multilingual covid-19 global study design rule guide prompt strategy encourage model to produce interpretable theoretically ground estimation oppression systematically evaluate strategy multiple state art llm result demonstrate llm guide explicit rule can capture nuanced form identity base historical oppression nation approach provide complementary measurement tool highlight dimension systemic exclusion offer scalable cross cultural lens understand oppression manifest data drive research public health context to support reproducible evaluation release open source benchmark dataset assess llm oppression measurement https://github.com/chattergpt/llm-oppression-benchmark,Computation and Language,18/09/2025
10.48550/arXiv.2509.15211,be best way to retrieve slides comparative study multimodal caption base hybrid retrieval techniques,"Petros Stylianos Giouroukis, Dimitris Dimitriadis, Dimitrios Papadopoulos, Zhenwen Shao, Grigorios Tsoumakas",slide deck serve digital report bridge gap presentation slide write document be prevalent medium convey information academic corporate setting multimodal nature combine text image chart present challenge retrieval augment generation system quality retrieval directly impact downstream performance traditional approach to slide retrieval often involve separate index modality can increase complexity lose contextual information paper investigate various methodology effective slide retrieval include visual late interaction embed model colpali use visual reranker hybrid retrieval technique combine dense retrieval bm25 far enhance textual reranker fusion method reciprocal rank fusion novel vision language models base caption pipeline be also evaluate demonstrate significantly reduce embed storage requirement compare visual late interaction technique comparable retrieval performance analysis extend practical aspect method evaluate runtime performance storage demand retrieval efficacy thus offer practical guidance selection development efficient robust slide retrieval system real world application,Computation and Language,18/09/2025
10.48550/arXiv.2509.15188,fast fluent diffusion language models convolutional decoding rejective fine tune,"Yeongbin Seo, Dongha Lee, Jaehyung Kim, Jinyoung Yeo",autoregressive ar language model generate text one token time limit inference speed diffusion base language model offer promise alternative can decode multiple token parallel however identify key bottleneck current diffusion lms long decode window problem token generate far input context often become irrelevant repetitive previous solution semi autoregressive address issue split window block sacrifice speed bidirectionality eliminate main advantage diffusion model to overcome propose convolutional decode conv normalization base method narrow decode window hard segmentation lead well fluency flexibility additionally introduce reject rule base fine tuning r2ft post hoc train scheme well align token position far context method achieve state art result open end generation benchmark e.g. alpacaeval diffusion lm baseline significantly low step size previous work demonstrate speed quality improvement code be available online https://github.com/ybseo-ac/conv,Computation and Language,18/09/2025
10.48550/arXiv.2509.15174,smart data efficient framework to improve toxicity detection explanation self augment large language models,"Huy Nghiem, Advik Sachdeva, Hal Daumé III",warning paper contain example offensive material toxic content have become pervasive social medium platform introduce smart data efficient 2 stage framework explainable content moderation use large language models llms stage 1 leverage llms own output to generate synthetic explanation correct incorrect label enable alignment preference optimization minimal human supervision stage 2 refine explanation quality cross model train allow weak model to align stylistically semantically strong one experiment 3 benchmark task hatexplain latent hate implicit hate demonstrate smarter enable llm to achieve to 13.5 macro f1 improvement standard few shot baseline fraction full train datum framework offer scalable strategy low resource setting harness llm self improve capability classification explanation,Computation and Language,18/09/2025
10.48550/arXiv.2509.15148,a1 asynchronous test time scaling conformal prediction,"Jing Xiong, Qiujiang Chen, Fanghua Ye, Zhongwei Wan, Chuanyang Zheng, Chenyang Zhao, Hui Shen, Alexander Hanbo Li, Chaofan Tao, Haochen Tan, Haoli Bai, Lifeng Shang, Lingpeng Kong, Ngai Wong",large language model llms benefit test time scale exist method face significant challenge include severe synchronization overhead memory bottleneck latency especially speculative decode long reason chain introduce a1 asynchronous test time scaling statistically guarantee adaptive inference framework address challenge a1 refine arithmetic intensity to identify synchronization dominant bottleneck propose online calibration strategy to enable asynchronous inference design three stage rejection sample pipeline support sequential parallel scale experiment math amc23 aime24 aime25 dataset various draft target model family demonstrate a1 achieve remarkable 56.7x speedup test time scale 4.14x improvement throughput maintain accurate rejection rate control reduce latency memory overhead accuracy loss compare use target model scale alone result position a1 efficient principled solution scalable llm inference have release code https://github.com/menik1126/asynchronous-test-time-scale,Computation and Language,18/09/2025
10.48550/arXiv.2509.15098,textmine llm powered knowledge extraction humanitarian mine action,"Chenyue Zhou, Gürkan Solmaz, Flavio Cirillo, Kiril Gashteovski, Jonathan Fürst",humanitarian mine action have generate extensive good practice knowledge much remains lock unstructured report introduce textmine ontology guide pipeline use large language models to extract knowledge triple hma text textmine integrate document chunk domain aware prompt triple extraction reference base llm judge evaluation also create first hma ontology curated dataset real world demining report experiment show ontology align prompt boost extraction accuracy 44.2 cut hallucination 22.5 improve format conformance 20.9 baseline validate cambodian report textmine can adapt global demining effort other domain transform unstructured datum structure knowledge,Computation and Language,18/09/2025
10.48550/arXiv.2509.15089,llm oref open relation extraction framework base large language models,"Hongyao Tu, Liang Zhang, Yujie Lin, Xin Lin, Haibo Zhang, Long Zhang, Jinsong Su",goal open relation extraction openre be to develop re model can generalize new relation not encounter train exist study primarily formulate openre cluster task first cluster test instance base similarity instance then manually assign new relation cluster however reliance human annotation limit practicality paper propose openre framework base large language model llms directly predict new relation test instance leverage strong language understand generation ability human intervention specifically framework consist two core component 1 relation discoverer rd design to predict new relation test instance base demonstration form train instance know relation 2 relation predictor rp use to select most likely relation test instance nn candidate relation guide demonstration compose instance to enhance ability framework to predict new relation design self correct inference strategy compose three stage relation discovery relation denoising relation prediction first stage use rd to preliminarily predict new relation test instance next apply rp to select high reliability test instance new relation prediction result rd cross validation method third stage employ rp to re predict relation test instance base demonstration construct reliable test instance extensive experiment three openre dataset demonstrate effectiveness framework release code https://github.com/xmudeeplit/llm-oref.git,Computation and Language,18/09/2025
10.48550/arXiv.2509.15048,can maibert speak maithili,"Sumit Yadav, Raju Kumar Yadav, Utsav Maskey, Gautam Siddharth Kashyap Md Azizul Hoque, Ganesh Gautam",natural language understanding nlu low resource language remain major challenge nlp scarcity high quality datum language specific model maithili be speak million lack adequate computational resource limit inclusion digital ai drive application to address gap introduce maibert bert base language model pre train specifically maithili use masked language modeling mlm technique model be train newly construct maithili corpus evaluate news classification task experiment maibert achieve accuracy 87.02 outperform exist regional model nepberta hindibert 0.13 overall accuracy gain 5–7 improvement various class have open source maibert hugging face111https://huggingface.co/rockerritesh/maibert˙tf enable further fine tune downstream task such sentiment analysis name entity recognition ner,Computation and Language,18/09/2025
10.48550/arXiv.2509.15027,clear comprehensive linguistic evaluation argument rewrite large language models,"Thomas Huber, Christina Niklaus",llm have be extensively study general text generation task be less research text rewrite task relate general text generation particularly behavior model task paper analyze change llm make text rewrite set focus specifically argumentative text improvement task name argument improvement argimp present clear evaluation pipeline consist 57 metric map four linguistic level lexical syntactic semantic pragmatic pipeline be use to examine quality llm rewrite argument broad set argumentation corpus compare behavior different llm task analyze behavior different llm task term linguistic level take four linguistic level consideration find model perform argimp shorten text simultaneously increase average word length merge sentence overall note increase persuasion coherence dimension,Computation and Language,18/09/2025
10.48550/arXiv.2509.15020,mind gap close look tokenization multiple choice question answer llms,"Mario Sanz-Guerrero, Minh Duc Bui, Katharina von der Wense",evaluate large language model llms multiple choice question answer mcqa be common to end prompt string answer to facilitate automate answer extraction next token probability however be consensus to tokenize space follow colon often overlook trivial choice paper uncover accuracy difference to 11 seemingly irrelevant tokenization variation as well reshuffle model ranking raise concern reliability llm comparison prior work surprisingly be able to recommend one specific strategy tokenize space together answer letter observe consistent statistically significant performance improvement additionally improve model calibration enhance reliability model ’s confidence estimate finding underscore importance careful evaluation design highlight need standardize transparent evaluation protocol to ensure reliable comparable result,Computation and Language,18/09/2025
10.48550/arXiv.2509.14943,explicit implicit biographies evaluate adapt llm information extraction wikidata derive texts,"Alessandra Stramiglio, Andrea Schimmenti, Valentina Pasqual, Marieke van Erp, Francesco Sovrano, Fabio Vitali",text implicitness have always be challenge natural language processing nlp traditional method rely explicit statement to identify entity relationship sentence zuhdi attend church sunday relationship zuhdi christianity be evident human reader present challenge must be infer automatically large language model llms have prove effective nlp downstream task such text comprehension information extraction ie,Computation and Language,18/09/2025
10.48550/arXiv.2509.14930,cross modal knowledge distillation speech large language models,"Enzhi Wang, Qicheng Li, Zhiyuan Tang, Yuhang Jia",work present first systematic evaluation catastrophic forget modality inequivalence speech large language model show introduce speech capability can degrade knowledge reason even input remain textual performance far decrease spoken query to address challenge propose cross modal knowledge distillation framework leverage text text speech text channel to transfer knowledge text base teacher model speech llm extensive experiment dialogue audio understand task validate effectiveness approach preserve textual knowledge improve cross modal alignment enhance reason speech base interaction,Computation and Language,18/09/2025
10.48550/arXiv.2509.14926,patent language model pretraining modernbert,"Amirhossein Yousefiramandi, Ciaran Cooney",transformer base language model such bert have become foundational nlp performance degrade specialize domain patent contain long technical legally structure text prior approach to patent nlp have primarily rely fine tune general purpose model domain adapt variant pretraine limit datum work pretrain 3 domain specific mask language model patent use modernbert architecture curated corpus 60 million patent record approach incorporate architectural optimization include flashattention rotary embedding glu fee forward layer evaluate model four downstream patent classification task model modernbert base pt consistently outperform general purpose modernbert baseline three four dataset achieve competitive performance baseline patentbert additional experiment modernbert base vx mosaic bert large demonstrate scale model size customize tokenizer far enhance performance select task notably modernbert variant retain substantially fast inference 3× patentbert underscore suitability time sensitive application result underscore benefit domain specific pretraining architectural improvement patent focus nlp task,Computation and Language,18/09/2025
10.48550/arXiv.2509.14900,furina free unmergeable router linear aggregation mix expert,"Jiayi Han, Liang Du, Yinda Chen, Xiao Kang, Weiyang Ding, Donghong Han",mixture experts moe paradigm have be successfully integrate low rank adaptation lora parameter efficient fine tune peft deliver performance gain minimal parameter overhead however key limitation exist moe lora method be reliance discrete router prevent integration moe component backbone model result persistent computational overhead increase system complexity inference to overcome propose furina novel free unmergeable router framework base linear aggregation expert furina eliminate router introduce self routing mechanism be achieve three core innovation 1 decouple learn direction magnitude lora adapter 2 share learnable magnitude vector consistent activation scale 3 expert selection loss encourage divergent expert activation propose mechanism leverage angular similarity input adapter ’s directional component to activate expert be then scale share magnitude vector design allow output norm to naturally reflect importance expert thereby enable dynamic router free rout expert selection loss far sharpen behavior encourage sparsity align standard moe activation pattern also introduce share expert moe lora block provide stable foundational knowledge good knowledge furina be first router free moe enhance lora method can be fully merge backbone model introduce zero additional inference time cost complexity extensive experiment demonstrate furina not only significantly outperform standard lora also match surpass performance exist moe lora method eliminate extra inference time overhead moe. plan to open source code publication,Computation and Language,18/09/2025
10.48550/arXiv.2509.14886,multi one interview paradigm efficient mllm evaluation,"Ye Shen, Junying Wang, Farong Wen, Yijin Guo, Qi Jia, Zicheng Zhang, Guangtao Zhai",rapid progress multi modal large language models mllms have spur creation numerous benchmark however conventional full coverage question answering evaluation suffer high redundancy low efficiency inspire human interview process propose multi one interview paradigm efficient mllm evaluation framework consist i two stage interview strategy pre interview formal interview phase ii dynamic adjustment interviewer weight to ensure fairness iii adaptive mechanism question difficulty level choose experiment different benchmark show propose paradigm achieve significantly high correlation full coverage result random sample improvement to 17.6 plcc 16.7 srcc reduce number require question finding demonstrate propose paradigm provide reliable efficient alternative large scale mllm benchmarking,Computation and Language,18/09/2025
10.48550/arXiv.2509.14882,llama mimi speech language models interleaved semantic acoustic tokens,"Issa Sugiura, Shuhei Kurita, Yusuke Oda, Ryuichiro Higashinaka",propose llama mimi speech language model use unify tokenizer single transformer decoder to jointly model sequence interleave semantic acoustic token comprehensive evaluation show llama mimi achieve state art performance acoustic consistency possess ability to preserve speaker identity analysis far demonstrate increase number quantizer improve acoustic fidelity degrade linguistic performance highlight inherent challenge maintain long term coherence additionally introduce llm judge base evaluation to assess spoken content quality generate output model code speech sample be publicly available.111https://speed1313.github.io/llama-mimi,Computation and Language,18/09/2025
10.48550/arXiv.2509.14851,empathy r1 chain empathy reinforcement learning framework long form mental health support,"Xianrong Yao, Dong She, Chenxu Zhang, Yimeng Zhang, Yueru Sun, Noman Ahmed, Yang Gao, Zhanpeng Jin",empathy be critical effective mental health support especially address long counseling texts lct however exist large language models llms often generate reply be semantically fluent lack structure reason necessary genuine psychological support particularly chinese context to bridge gap introduce empathy r1 novel framework integrate chain empathy coe reason process reinforcement learning rl to enhance response quality lct inspire cognitive behavioral therapy coe paradigm guide model to sequentially reason help seeker ’s emotion cause intention make think process transparent interpretable framework be empower new large scale chinese dataset empathy qa two stage train process first supervised fine tuning instill coe ’s reason structure subsequently rl guide dedicate reward model refine therapeutic relevance contextual appropriateness final response experiment show empathy r1 achieve strong performance key automatic metric more importantly human evaluation confirm superiority show clear preference strong baseline achieve win@1 rate 44.30 new benchmark enable interpretable contextually nuanced response empathy r1 represent significant advancement develop responsible genuinely beneficial ai mental health support,Computation and Language,18/09/2025
10.48550/arXiv.2509.14837,v seam visual semantic editing attention modulating causal interpretability vision language models,"Qidong Wang, Junjie Hu, Ming Jiang",recent advance causal interpretability have extend language model vision language model vlms seek to reveal internal mechanism input intervention textual intervention often target semantic visual intervention typically rely coarse pixel level perturbation limit semantic insight multimodal integration study introduce v seam novel framework combine visual semantic editing attention modulating causal interpretation vlms v seam enable concept level visual manipulation identify attention head positive negative contribution prediction three semantic level object attribute relationship observe positive head be often share same semantic level vary level negative head tend to generalize broadly finally introduce automatic method to modulate key head embedding demonstrate enhance performance llava instructblip three diverse vqa benchmark datum code be release https://github.com/petergit1/v-seam,Computation and Language,18/09/2025
10.48550/arXiv.2509.14834,llm agents roundtable multi perspective dialectical reasoning framework essay scoring,"Jinhee Jang, Ayoung Moon, Minkyoung Jung, YoungBin Kim, Seung Jin Lee",emergence large language model llms have bring new paradigm automate essay score aes long stand practical application natural language process education however achieve human level multi perspective understand judgment remain challenge work propose roundtable essay scoring res multi agent evaluation framework design to perform precise human align score zero shot set res construct evaluator agent base llms tailor specific prompt topic context agent independently generate trait base rubric conduct multi perspective evaluation then simulate roundtable style discussion res consolidate individual evaluation dialectical reason process to produce final holistic score more closely align human evaluation enable collaboration consensus agent diverse evaluation perspective res outperform prior zero shot aes approach experiment asap dataset use chatgpt claude show res achieve 34.86 improvement average qwk straightforward prompt vanilla method,Computation and Language,18/09/2025
10.48550/arXiv.2509.14814,recover target language language steering sacrifice task performance,"Hannah Sterz, Fabian David Schmidt, Goran Glavaš, Ivan Vulić",become increasingly multilingual large language models llms exhibit more language confusion i.e. tend to generate answer language different language prompt answer language explicitly request user work propose recover reducing language confusion vector representations novel lightweight approach reduce language confusion base language specific steer vector first isolate language vector help multi parallel corpus then effectively leverage vector effective llm steer fix i.e. unsupervised as well trainable steer function extensive evaluation encompass three benchmark 18 language show recover effectively mitigate language confusion monolingual cross lingual setup same time contrast prior language steer method retain task performance data code be available https://github.com/hsterz/recover,Computation and Language,18/09/2025
10.48550/arXiv.2509.14806,sinai erisk@clef 2022 approach early detection gambling eat disorders natural language processing,"Alba Maria Marmol-Romero, Salud Maria Jimenez-Zafra, Flor Miriam Plaza-del-Arco, M. Dolores Molina-Gonzalez, Maria-Teresa Martin-Valdivia, Arturo Montejo-Raez",paper describe participation sinai team erisk@clef lab specifically two propose task have be address i task 1 early detection sign pathological gamble ii task 3 measure severity sign eat disorder approach present task 1 be base use sentence embedding transformers feature relate volumetry lexical diversity complexity metric emotion relate score approach task 3 be base text similarity estimation use contextualize word embedding transformers task 1 team have be rank second position f1 score 0.808 41 participant submission task 3 team also place second total 3 participate team,Computation and Language,18/09/2025
10.48550/arXiv.2509.14797,sinai erisk@clef 2023 approach early detection gambling natural language processing,"Alba Maria Marmol-Romero, Flor Miriam Plaza-del-Arco, Arturo Montejo-Raez",paper describe participation sinai team erisk@clef lab specifically one propose task have be address task 2 early detection sign pathological gamble approach present task 2 be base pre train model transformers architecture comprehensive preprocessing datum datum balance technique moreover integrate long short term memory lstm architecture automodel transformers task team have be rank seventh position f1 score 0.126 49 participant submission achieve high value recall metric metric relate early detection,Computation and Language,18/09/2025
10.48550/arXiv.2509.14760,reason boundary enhance specification alignment test time delibration,"Haoran Zhang, Yafu Li, Xuyang Hu, Dongrui Liu, Zhilin Wang, Bo Li, Yu Cheng","large language model llms be increasingly apply diverse real world scenario govern bespoke behavioral safety specification spec custom tailor user organization spec categorize safety spec behavioral spec vary scenario evolve change preference requirement formalize challenge specification alignment focus llm ability to follow dynamic scenario specific spec behavioral safety perspective to address challenge propose align3 lightweight method employ test time deliberation ttd hierarchical reflection revision reason specification boundary far present specbench unify benchmark measure specification alignment cover 5 scenario 103 spec 1,500 prompt experiment 15 reason 18 instruct model several ttd method include self refine tpo morethink yield three key finding i test time deliberation enhance specification alignment ii align3 advance safety helpfulness trade frontier minimal overhead iii specbench effectively reveal alignment gap result highlight potential test time deliberation effective strategy reason real world specification boundary code resource be available github",Computation and Language,18/09/2025
10.48550/arXiv.2509.14752,kaio collection more challenging korean question,"Nahyun Lee, Guijin Son, Hyunwoo Ko, Kyubeen Han",advancement mid post train technique llms be push boundary accelerate pace legacy benchmark saturate quickly e.g. broad suite mmlu year new one gpqa d even fast make frontier progress hard to track problem be especially acute korean widely use benchmark be few often translate narrow scope update more slowly saturation contamination arrive soon accordingly moment be korean benchmark capable evaluate rank frontier model to bridge gap introduce kaio korean math centric benchmark stress long chain reason recent korean suite be saturation kaio remain far saturate well perform model gpt-5 attain 62.8 follow gemini-2.5 pro 52.3 open model such qwen3 235b deepseek r1 cluster fall 30 demonstrate substantial headroom enable robust track frontier progress korean to reduce contamination kaio will remain private be serve hold evaluator well publicly know model reach at least 80 accuracy will release set iterate hard version,Computation and Language,18/09/2025
10.48550/arXiv.2509.14738,unifiedvisual framework constructing unified vision language dataset,"Pengyu Wang, Shaojun Zhou, Chenkun Tan, Xinghao Wang, Wei Huang, Zhen Ye, Zhaowei Li, Botian Jiang, Dong Zhang, Xipeng Qiu",unified vision large language model vllms have recently achieve impressive advancement multimodal understand generation power application such visual question answer text guide image synthesis however progress unify vllm remain constrain lack dataset fully exploit synergistic potential two core ability exist dataset typically address understand generation isolation thereby limit performance unify vllm to bridge critical gap introduce novel dataset construction framework unifiedvisual present unifiedvisual-240 k high quality dataset meticulously design to facilitate mutual enhancement multimodal understand generation unifiedvisual-240 k seamlessly integrate diverse visual textual input output enable comprehensive cross modal reason precise text image alignment dataset encompass wide spectrum task datum source ensure rich diversity address key shortcoming prior resource extensive experiment demonstrate model train unifiedvisual-240 k consistently achieve strong performance wide range task notably model exhibit significant mutual reinforcement multimodal understand generation far validate effectiveness framework dataset believe unifiedvisual represent new growth point advance unify vllm unlock full potential 111our code dataset will be available https://github.com/fnlp-vision/unifiedvisual,Computation and Language,18/09/2025
10.48550/arXiv.2509.14735,decouple proxy alignment mitigate language prior conflict multimodal alignment mllm,"Chenkun Tan, Pengyu Wang, Shaojun Zhou, Botian Jiang, Zhaowei Li, Dong Zhang, Xinghao Wang, Yaqian Zhou, Xipeng Qiu",multimodal large language model mllms have gain significant attention impressive ability to integrate vision language modality recent advancement mllm have primarily focus improve performance high quality dataset novel architecture optimize train strategy however paper identify previously overlook issue language prior conflict mismatch inherent language prior large language model llms language prior train dataset conflict lead suboptimal vision language alignment mllm be prone adapt language style train sample to address issue propose novel train method call decouple proxy alignment dpa dpa introduce two key innovation 1 use proxy llm pretraine to decouple vision language alignment process language prior interference 2 dynamic loss adjustment base visual relevance to strengthen optimization signal visually relevant token extensive experiment demonstrate dpa significantly mitigate language prior conflict achieve superior alignment performance diverse dataset model family scale method not only improve effectiveness mllm train also show exceptional generalization capability make robust approach vision language alignment 111our code be available https://github.com/fnlp-vision/dpa,Computation and Language,18/09/2025
10.48550/arXiv.2509.14689,harness lightweight distil arabic speech foundation models,"Vrunda N. sukhadia, Shammur Absar Chowdhury",large pre train speech model excel downstream task deployment be impractical resource limit environment paper introduce harness first arabic centric self supervise speech model family design to capture arabic speech nuance use iterative self distillation train large bilingual harness hl ssl model then distill knowledge compress student model hs hst preserve arabic specific representation use low rank approximation to far compact teacher ’s discrete supervision shallow thin model evaluate arabic asr speaker emotion recognition ser dialect identification do demonstrate effectiveness hubert xls r. minimal fine tune harness achieve sota comparable performance make lightweight yet powerful alternative real world use release distil model finding to support responsible research deployment low resource setting,Computation and Language,18/09/2025
10.48550/arXiv.2509.14671,tabledart dynamic adaptive multi modal routing table understanding,"Xiaobo Xing, Wei Yuan, Tong Chen, Quoc Viet Hung Nguyen, Xiangliang Zhang, Hongzhi Yin",model semantic structural information tabular datum remain core challenge effective table understand exist table text approach flatten table large language model llms lose crucial structural cue table image method preserve structure yet struggle fine grain semantic recent table multimodality strategy attempt to combine textual visual view 1 statically process modality query table pair large multimodal llm mllms inevitably introduce redundancy even conflict 2 depend costly fine tune mllm light propose tabledart train efficient framework integrate multimodal view reuse pretraine single modality model tabledart introduce lightweight 2.59m parameter mlp gate network dynamically select optimal path text only image only fusion table query pair effectively reduce redundancy conflict modality addition propose novel agent to mediate cross modal knowledge integration analyze output text- image base model select good result synthesize new answer reason design avoid prohibitive cost full mllm fine tune extensive experiment seven benchmark show tabledart establish new state art performance open source model surpass strong baseline average 4.02 code be available https://anonymous.4open.science/r/tabledart-c52b.,Computation and Language,18/09/2025
10.48550/arXiv.2509.14653,uma split unimodal aggregation english mandarin non autoregressive speech recognition,"Ying Fang, Xiaofei Li",paper propose unimodal aggregation uma base non autoregressive model english mandarin speech recognition original uma explicitly segment aggregate acoustic frame unimodal weight first monotonically increase then decrease same text token to learn well representation regular connectionist temporal classification ctc however only work well mandarin struggle other language such english single syllable may be tokenize multiple fine grain token token span few 3 acoustic frame fail to form unimodal weight to address problem propose allow uma aggregate frame map multiple token simple split module generate two token aggregate frame compute ctc loss experiment verify propose model ’s effectiveness outperform other advance non autoregressive model even match hybrid ctc attention autoregressive model librispeech english 2.22%/4.93 wer test clean other 149 m model aishell-1 mandarin 4.43 cer,Computation and Language,18/09/2025
10.48550/arXiv.2509.16197,manzano simple scalable unified multimodal model hybrid vision tokenizer,"Yanghao Li, Rui Qian, Bowen Pan, Haotian Zhang, Haoshuo Huang, Bowen Zhang, Jialing Tong, Haoxuan You, Xianzhi Du, Zhe Gan, Hyunjik Kim, Chao Jia, Zhenbang Wang, Yinfei Yang, Mingfei Gao, Zi-Yi Dou, Wenze Hu, Chang Gao, Dongxu Li, Philipp Dufter, Zirui Wang, Guoli Yin, Zhengdong Zhang, Chen Chen, Yang Zhao, Ruoming Pang, Zhifeng Chen",unified multimodal large language models llms can understand generate visual content hold immense potential however exist open source model often suffer performance trade off capability present manzano simple scalable unify framework substantially reduce tension couple hybrid image tokenizer well curate train recipe single share vision encoder feed two lightweight adapter produce continuous embedding image text understand discrete token text image generation common semantic space unify autoregressive llm predict high level semantic form text image token auxiliary diffusion decoder subsequently translate image token pixel architecture together unify train recipe understand generation datum enable scalable joint learn capability manzano achieve state art result unify model be competitive specialist model particularly text rich evaluation study show minimal task conflict consistent gain scale model size validate design choice hybrid tokenizer,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.16179,fast otsu thresholding use bisection method,Sai Varun Kodathala,otsu thresholding algorithm represent fundamental technique image segmentation computational efficiency be severely limit exhaustive search requirement possible threshold value work present optimize implementation leverage bisection method to exploit unimodal characteristic class variance function approach reduce computational complexity o(l o(log l evaluation preserve segmentation accuracy experimental validation 48 standard test image demonstrate 91.63 reduction variance computation 97.21 reduction algorithmic iteration compare conventional exhaustive search bisection method achieve exact threshold match 66.67 test case 95.83 exhibit deviation 5 gray level algorithm maintain universal convergence theoretical logarithmic bound provide deterministic performance guarantee suitable real time application optimization address critical computational bottleneck large scale image process system compromise theoretical foundation segmentation quality original otsu method,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.16170,unimrseg unified modality relax segmentation hierarchical self supervised compensation,"Xiaoqi Zhao, Youwei Pang, Chenyang Yu, Lihe Zhang, Huchuan Lu, Shijian Lu, Georges El Fakhri, Xiaofeng Liu",multi modal image segmentation face real world deployment challenge incomplete corrupt modality degrade performance exist method address train inference modality gap specialize combination model introduce high deployment cost require exhaustive model subset model modality match work propose unify modality relax segmentation network unimrseg hierarchical self supervise compensation hssc approach hierarchically bridge representation gap complete incomplete modality input feature output level first adopt modality reconstruction hybrid shuffle mask augmentation encourage model to learn intrinsic modality characteristic generate meaningful representation miss modality cross modal fusion next modality invariant contrastive learn implicitly compensate feature space distance incomplete complete modality pair furthermore propose lightweight reverse attention adapter explicitly compensate weak perceptual semantic frozen encoder last unimrseg be fine tune hybrid consistency constraint to ensure stable prediction modality combination large performance fluctuation bell whistle significantly outperform state art method diverse miss modality scenario mri base brain tumor segmentation rgb d semantic segmentation rgb d t salient object segmentation code will be release https://github.com/xiaoqi-zhao-dlut/unimrseg,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.16163,robust vision language models tensor decomposition defense adversarial attacks,"Het Patel, Muzammil Allie, Qian Zhang, Jia Chen, Evangelos E. Papalexakis",vision language model vlms excel multimodal understand be prone adversarial attack exist defense often demand costly retrain significant architecture change introduce lightweight defense use tensor decomposition suitable pre train vlm require retrain decompose reconstruct vision encoder representation filter adversarial noise preserve mean experiment clip coco flickr30 k show improve robustness flickr30 k restore 12.3 performance lose attack raise recall@1 accuracy 7.5 19.8 coco recover 8.1 performance improve accuracy 3.8 11.9 analysis show tensor train decomposition low rank 8 32 low residual strength α=0.1−0.2\alpha=0.1 0.2 be optimal method be practical plug play solution minimal overhead exist vlm,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.16149,point llama call camel sycophancy multimodal large language models,"Renjie Pi, Kehao Miao, Li Peihang, Runtao Liu, Jiahui Gao, Jipeng Zhang, Xiaofang Zhou",multimodal large language model mllms have demonstrate extraordinary capability conduct conversation base image input however observe mllm exhibit pronounce form visual sycophantic behavior similar behavior have also be note text base large language model llms become significantly more prominent mllm process image input refer phenomenon sycophantic modality gap to well understand issue far analyze factor contribute exacerbation gap to mitigate visual sycophantic behavior first experiment naive supervise fine tune to help mllm resist mislead instruction user however find approach also make mllm overly resistant corrective instruction i.e. stubborn even be wrong to alleviate trade off propose sycophantic reflective tuning srt enable mllm to engage reflective reason allow to determine user ’s instruction be mislead corrective draw conclusion apply srt observe significant reduction sycophantic behavior mislead instruction result excessive stubbornness receive corrective instruction,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.16141,act2i evaluate improving action depiction text image models,"Vatsal Malaviya, Agneet Chatterjee, Maitreya Patel, Yezhou Yang, Chitta Baral",text image t2i model have recently achieve remarkable success generate image textual description however challenge still persist accurately render complex scene action interaction form primary semantic focus key observation work be t2i model frequently struggle to capture nuanced often implicit attribute inherent action depiction lead generate image lack key contextual detail to enable systematic evaluation introduce act2i benchmark design to evaluate performance t2i model generate image action centric prompt experimentally validate lead t2i model do not fare well act2i. far hypothesize shortcoming arise incomplete representation inherent attribute contextual dependency train corpus exist t2i model build develop train free knowledge distillation technique utilize large language models to address limitation specifically enhance prompt incorporate dense information three dimension observe inject prompt temporal detail significantly improve image generation accuracy good model achieve increase 72 finding highlight limitation current t2i method generate image require complex reason demonstrate integrate linguistic knowledge systematic way can notably advance generation nuanced contextually accurate image project page https://vatsal-malaviya.github.io/act2i/,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.16132,recover parametric scenes very few time flight pixels,"Carter Sifferman, Yiquan Li, Yiming Li, Fangzhou Mu, Michael Gleicher, Mohit Gupta, Yin Li",aim to recover geometry 3d parametric scene use very few depth measurement low cost commercially available time flight sensor sensor offer very low spatial resolution i.e. single pixel image wide field view pixel capture detail time flight datum form time resolve photon count time flight datum encode rich scene information thus enable recovery simple scene sparse measurement investigate feasibility use distribute set few measurement e.g. as few 15 pixel to recover geometry simple parametric scene strong prior such estimate 6d pose know object to achieve design method utilize fee forward prediction to infer scene parameter differentiable render analysis synthesis framework to refine scene parameter estimate develop hardware prototype demonstrate method effectively recover object pose give untextured 3d model simulation control real world capture show promise initial result other parametric scene additionally conduct experiment to explore limit capability image solution project webpage be available cpsiff.github.io/recovering_parametric_scenes,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.16127,basereward strong baseline multimodal reward model,"Yi-Fan Zhang, Haihua Yang, Huanyu Zhang, Yang Shi, Zezhou Chen, Haochen Tian, Chaoyou Fu, Haotian Wang, Kai Wu, Bo Cui, Xu Wang, Jianfei Pan, Haotian Wang, Zhang Zhang, Liang Wang",rapid advancement multimodal large language models mllms have make align human preference critical challenge reward models rms be core technology achieve goal systematic guide build state art multimodal reward models mrms be currently lack academia industry exhaustive experimental analysis paper aim to provide clear recipe construct high performance mrm systematically investigate crucial component mrm development pipeline include reward model paradigm e.g. naive rm critic base rm generative rm reward head architecture train strategy datum curation cover ten multimodal text only preference dataset backbone model model scale ensemble method,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.16119,radargaussiandet3d efficient effective gaussian base 3d detector 4d automotive radar,"Weiyi Xiong, Bing Zhu, Tao Huang, Zewei Zheng",4d automotive radar have gain increase attention autonomous drive low cost robustness inherent velocity measurement capability however exist 4d radar base 3d detector rely heavily pillar encoder bev feature extraction point contribute only single bev grid result sparse feature map degrade representation quality addition also optimize bound box attribute independently lead sub optimal detection accuracy moreover inference speed sufficient high end gpu may fail to meet real time requirement vehicle mount embed device to overcome limitation efficient effective gaussian base 3d detector namely radargaussiandet3d be introduce leverage gaussian primitive distribution intermediate representation radar point bound box radargaussiandet3d novel point gaussian encoder pge be design to transform point gaussian primitive feature aggregation employ 3d gaussian splatting 3dgs technique bev rasterization yield dense feature map pge exhibit exceptionally low latency owe optimize algorithm point feature aggregation fast render 3dgs addition new box gaussian loss bgl be propose convert bound box 3d gaussian distribution measure distance to enable more comprehensive consistent optimization extensive experiment tj4dradset view delft demonstrate radargaussiandet3d achieve state art detection accuracy deliver substantially fast inference highlight potential real time deployment autonomous drive,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.16098,segdino3d 3d instance segmentation empower image level object level 2d feature,"Jinyuan Qu, Hongyang Li, Xingyu Chen, Shilong Liu, Yukai Shi, Tianhe Ren, Ruitao Jing, Lei Zhang",paper present segdino3d novel transformer encoder decoder framework 3d instance segmentation 3d train datum be generally not as sufficient 2d train image segdino3d be design to fully leverage 2d representation pre train 2d detection model include image level object level feature improve 3d representation segdino3d take point cloud associate 2d image input encoder stage first enrich 3d point retrieve 2d image feature correspond image view then leverage 3d encoder 3d context fusion decoder stage formulate 3d object query 3d anchor box perform cross attention 3d query 2d object query obtain 2d image use 2d detection model 2d object query serve compact object level representation 2d image effectively avoid challenge keep thousand image feature map memory faithfully preserve knowledge pre train 2d model introduce 3d box query also enable model to modulate cross attention use predict box more precise query segdino3d achieve state art performance scannetv2 scannet200 3d instance segmentation benchmark notably challenge scannet200 dataset significantly outperform prior method +8.7 +6.8 map validation hidden test set respectively demonstrate superiority,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.16095,adasports traj domain aware adaptation multi agent trajectory modeling sports,"Yi Xu, Yun Fu",trajectory prediction multi agent sport scenario be inherently challenge structural heterogeneity agent role e.g. player ball dynamic distribution gap different sport domain exist unify framework often fail to capture structure distributional shift result suboptimal generalization role domain propose adasports traj adaptive trajectory model framework explicitly address intra domain inter domain distribution discrepancy sport core adasports traj incorporate role- domain aware adapter to conditionally adjust latent representation base agent identity domain context additionally introduce hierarchical contrastive learning objective separately supervise role sensitive domain aware representation to encourage disentangle latent structure introduce optimization conflict experiment three diverse sport dataset basketball u football u soccer u demonstrate effectiveness adaptive design achieve strong performance unify cross domain trajectory prediction setting,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.16091,blind spot guided diffusion self supervise real world denoising,"Shen Cheng, Haipeng Li, Haibin Huang, Xiaohong Liu, Shuaicheng Liu",work present blind spot guide diffusion novel self supervise framework real world image denoising approach address two major challenge limitation blind spot network bsns often sacrifice local detail introduce pixel discontinuity due spatial independence assumption difficulty adapt diffusion model self supervise denoising propose dual branch diffusion framework combine bsn base diffusion branch generate semi clean image conventional diffusion branch capture underlie noise distribution to enable effective train pair datum use bsn base branch to guide sample process capture noise structure preserve local detail extensive experiment sidd dnd dataset demonstrate state art performance establish method highly effective self supervise solution real world denoising code pre train model will be release,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.16087,see&trek training free spatial prompting multimodal large language model,"Pengteng Li, Pinhao Song, Wuyang Li, Weiyu Guo, Huizai Yao, Yijie Xu, Dugang Liu, Hui Xiong",introduce see&trek first train free prompt framework tailor to enhance spatial understand multimodal large language models mllms vision only constraint prior effort have incorporate modality depth point cloud to improve spatial reason purely visual spatial understand remain underexplored see&trek address gap focus two core principle increase visual diversity motion reconstruction visual diversity conduct maximum semantic richness sampling employ shell perception model to extract semantically rich keyframe capture scene structure motion reconstruction simulate visual trajectory encode relative spatial position keyframe to preserve spatial relation temporal coherence method be training&gpu free require only single forward pass can be seamlessly integrate exist mllm extensive experiment vsi bench sti bench show see&trek consistently boost various mllm performance diverse spatial reason task most +3.5 improvement offer promise path strong spatial intelligence,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.16054,language instruct reasoning group activity detection multimodal large language model,"Jihua Peng, Qianxiong Xu, Yichen Liu, Chenxi Liu, Cheng Long, Rui Zhao, Ziyue Li",group activity detection gad aim to simultaneously identify group member categorize collective activity video sequence exist deep learn base method develop specialize architecture e.g. transformer network to model dynamic individual role semantic dependency individual group however rely solely implicit pattern recognition visual feature struggle contextual reason explainability work propose lir gad novel framework language instruct reason gad multimodal large language model mllm approach expand original vocabulary mllm introduce activity level < act > token multiple cluster specific < group > token process video frame two specially design token language instruction be then integrate mllm pretrained commonsense knowledge embed mllm enable < act > token < group > token to effectively capture semantic information collective activity learn distinct representational feature different group respectively also introduce multi label classification loss to far enhance < act > token ’s ability to learn discriminative semantic representation then design multimodal dual alignment fusion mdaf module integrate mllm ’s hide embedding correspond design token visual feature significantly enhance performance gad quantitative qualitative experiment demonstrate superior performance propose method gad taks,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.16050,graph base point cloud surface reconstruction use b spline,"Stuti Pathak, Rhys G. Evans, Gunther Steenackers, Rudi Penne",generate continuous surface discrete point cloud datum be fundamental task several 3d vision application real world point cloud be inherently noisy various technical environmental factor exist data drive surface reconstruction algorithm rely heavily ground truth normal compute approximate normal intermediate step dependency make extremely unreliable noisy point cloud dataset even availability ground truth train datum be ensure be not always case b spline reconstruction technique provide compact surface representation point cloud be especially know smoothen property however complexity surface approximate use b spline be directly influence number location spline control point exist spline base model method predict location fix number control point give point cloud make very difficult to match complexity underlie surface work develop dictionary guide graph convolutional network base surface reconstruction strategy simultaneously predict location number control point noisy point cloud datum to generate smooth surface use point normal compare reconstruction method several well know as well recent baseline employ widely use evaluation metric demonstrate method outperform qualitatively quantitatively,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.16031,glip global local integrated progressive framework robust visual speech recognition,"Tianyue Wang, Shuang Yang, Shiguang Shan, Xilin Chen",visual speech recognition vsr also know lip read be task recognize speech silent video significant advancement vsr recent decade most exist method pay limit attention real world visual challenge such illumination variation occlusion blur pose change to address challenge propose glip global local integrated progressive framework design robust vsr glip be build two key insight i learn initial coarse alignment visual feature vary condition correspond speech content facilitate subsequent learn precise visual speech mapping challenge environment ii adverse condition certain local region e.g. non occlude area often exhibit more discriminative cue lip read global feature end glip introduce dual path feature extraction architecture integrate global local feature two stage progressive learn framework first stage model learn to align global local visual feature correspond acoustic speech unit use easily accessible audio visual datum establish coarse semantically robust foundation second stage introduce contextual enhancement module cem to dynamically integrate local feature relevant global context spatial temporal dimension refine coarse representation precise visual speech mapping framework uniquely exploit discriminative local region progressive learn strategy demonstrate enhance robustness various visual challenge consistently outperform exist method lrs2 lrs3 benchmark far validate effectiveness newly introduce challenge mandarin dataset,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.16022,generalized deep multi view clustering causal learning partially align cross view correspondence,"Xihong Yang, Siwei Wang, Jiaqi Jin, Fangdi Wang, Tianrui Liu, Yueming Jin, Xinwang Liu, En Zhu, Kunlun He",multi view cluster mvc aim to explore common cluster structure multiple view many exist mvc method heavily rely assumption view consistency alignment correspond sample different view be order advance however real world scenario often present challenge only partial datum be consistently align different view restrict overall cluster performance work consider model performance decrease phenomenon cause datum order shift i.e. fully to partially align generalize multi view cluster problem to tackle problem design causal multi view cluster network term caumvc adopt causal model approach to understand multi view cluster procedure to be specific formulate partially align datum intervention multi view cluster partially align datum post intervention inference however obtain invariant feature directly can be challenge thus design variational auto encoder causal learning incorporate encoder exist information to estimate invariant feature moreover decoder be design to perform post intervention inference lastly design contrastive regularizer to capture sample correlation good knowledge paper be first work to deal generalize multi view cluster causal learning empirical experiment fully partially align datum illustrate strong generalization effectiveness caumvc,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.16017,distillmatch leverage knowledge distillation vision foundation model multimodal image matching,"Meng Yang, Fan Fan, Zizhuo Li, Songchu Deng, Yong Ma, Jiayi Ma",multimodal image match seek pixel level correspondence image different modality crucial cross modal perception fusion analysis however significant appearance difference modality make task challenge scarcity high quality annotate dataset exist deep learn method extract modality common feature match perform poorly lack adaptability diverse scenario vision foundation model vfm train large scale datum yield generalizable robust feature representation adapt datum task various modality include multimodal match thus propose distillmatch multimodal image match method use knowledge distillation vfm distillmatch employ knowledge distillation to build lightweight student model extract high level semantic feature vfm include dinov2 dinov3 to assist match modality to retain modality specific information extract inject modality category information other modality ’s feature enhance model ’s understand cross modal correlation furthermore design v2i gan to boost model ’s generalization translate visible pseudo infrared image datum augmentation experiment show distillmatch outperform exist algorithm public dataset,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.16011,robust visual continual learning multi prototype supervision,"Xiwei Liu, Yulong Li, Yichen Li, Xinlin Zhuang, Haolin Yang, Huifa Li, Imran Razzak",language guide supervision utilize frozen semantic target pretrained language model plm have emerge promise paradigm visual continual learning cl however rely single target introduce two critical limitation 1 semantic ambiguity polysemous category name result conflict visual representation 2 intra class visual diversity single prototype fail to capture rich variety visual appearance class end propose muprocl novel framework replace single target multiple context aware prototype specifically employ lightweight llm agent to perform category disambiguation visual modal expansion to generate robust set semantic prototype logsumexp aggregation mechanism allow vision model to adaptively align most relevant prototype give image extensive experiment various cl baseline demonstrate muprocl consistently enhance performance robustness establish more effective path language guide continual learn,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15990,dafted decouple asymmetric fusion tabular echocardiographic data cardiac hypertension diagnosis,"Jérémie Stym-Popper, Nathan Painchaud, Clément Rambour, Pierre-Yves Courand, Nicolas Thome, Olivier Bernard",multimodal datum fusion have emerge key approach recent year enhance diagnosis prognosis many medical application advent transformer base method be now possible to combine information different modality provide complementary insight however most exist method rely symmetric fusion scheme assume equal importance information carry modality strong assumption may not always hold true study propose alternative fusion strategy base asymmetric scheme start primary modality offer most critical information integrate secondary modality contribution disentangle share modality specific information propose model be validate dataset 239 patient characterize hypertension severity fuse time series automatically extract echocardiographic image sequence tabular datum patient record result show approach outperform exist unimodal multimodal approach achieve auc score 90 crucial benchmark clinical use,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15987,sharper object boundaries self supervised depth estimation,"Aurélien Cecille, Stefan Duffner, Franck Davoine, Rémi Agier, Thibault Neveu",accurate monocular depth estimation be crucial 3d scene understand exist method often blur depth object boundary introduce spurious intermediate 3d point achieve sharp edge usually require very fine grain supervision method produce crisp depth discontinuity use only self supervision specifically model pixel depth mixture distribution capture multiple plausible depth shift uncertainty direct regression mixture weight formulation integrate seamlessly exist pipeline variance aware loss function uncertainty propagation extensive evaluation kitti vkittiv2 show method achieve to 35 high boundary sharpness improve point cloud quality compare state art baseline,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15984,copad multi source trajectory fusion cooperative trajectory prediction anchor orient decoder v2x scenario,"Kangyu Wu, Jiaqi Qiao, Ya Zhang",recently data drive trajectory prediction method have achieve remarkable result significantly advance development autonomous drive however instability single vehicle perception introduce certain limitation trajectory prediction paper novel lightweight framework cooperative trajectory prediction copad be propose framework incorporate fusion module base hungarian algorithm kalman filter past time attention pta module mode attention module anchor orient decoder aod effectively perform early fusion multi source trajectory datum vehicle road infrastructure enable trajectory high completeness accuracy pta module can efficiently capture potential interaction information historical trajectory mode attention module be propose to enrich diversity prediction additionally decoder base sparse anchor be design to generate final complete trajectory extensive experiment show copad achieve state art performance dair v2x seq dataset validate effectiveness model cooperative trajectory prediction v2x scenario,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15980,shedding light depth explainability assessment monocular depth estimation,"Lorenzo Cirillo, Claudio Schiavella, Lorenzo Papa, Paolo Russo, Irene Amerini",explainable artificial intelligence be increasingly employ to understand decision make process deep learn model create trustworthiness adoption however explainability monocular depth estimation mde remain largely unexplored wide deployment real world application work study to analyze mde network to map input image predict depth map more detail investigate well establish feature attribution method saliency maps integrated gradients attention rollout different computationally complex model mde meter lightweight network pixelformer deep network assess quality generate visual explanation selectively perturb most relevant irrelevant pixel identify explainability method analyze impact perturbation model ’s output moreover exist evaluation metric can have limitation measure validity visual explanation mde additionally introduce attribution fidelity metric evaluate reliability feature attribution assess consistency predict depth map experimental result demonstrate saliency maps integrated gradients have good performance highlight most important input feature mde lightweight deep model respectively furthermore show attribution fidelity effectively identify explainability method fail to produce reliable visual map even scenario conventional metric might suggest satisfactory result,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15966,multi temporal multi spectral attention augment deep convolution neural network contrastive learn crop yield prediction,"Shalini Dangi, Surya Karthikeya Mullapudi, Chandravardhan Singh Raghaw, Shahid Shafi Dar, Mohammad Zia Ur Rehman, Nagendra Kumar",precise yield prediction be essential agricultural sustainability food security however climate change complicate accurate yield prediction affect major factor such weather condition soil fertility farm management system advance technology have play essential role overcome challenge leverage satellite monitor datum analysis precise yield estimation current method rely spatio temporal datum predict crop yield often struggle multi spectral datum be crucial evaluate crop health growth pattern to resolve challenge propose novel multi temporal multi spectral yield prediction network mtms yieldnet integrate spectral datum spatio temporal information to effectively capture correlation dependency exist method rely pre train model train general visual datum mtms yieldnet utilize contrastive learn feature discrimination pre train focus capture spatial spectral pattern spatio temporal dependency remote sense datum contrastive learning find relative feature distinguish crop growth pattern different temporal interval stack attention mechanism be apply to improve spectral spatial feature extraction focus most important spectral band spatial region far enhance forecast precision use optimization approach inspire natural balance process to identify key spectral temporal feature effective feature selection crop yield prediction evaluate mtms yieldnet various dataset use remote sense image sentinel-1 sentinel-2 landsat-8 treat source distinct dataset to capture diverse agricultural pattern quantitative qualitative assessment highlight excellence propose mtms yieldnet seven exist state art method sentinel-1 dataset mtms yieldnet achieve 0.336 mape 0.497 rmsle 0.362 smape landsat-8 dataset achieve 0.353 mape 0.511 rmsle 0.428 smape sentinel-2 achieve outstanding performance 0.331 mape 0.589 rmsle 0.433 smape demonstrate effectiveness yield prediction vary climatic seasonal condition agriculturally significant region outstanding performance mtms yieldnet improve yield prediction provide valuable insight can assist farmer make well decision potentially improve crop yield,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15935,pan pillars attention base network 3d object detection,"Ruan Bispo, Dane Mitrev, Letizia Mariotti, Clément Botty, Denver Humphrey, Anthony Scanlan, Ciarán Eising",camera radar fusion offer robust low cost alternative camera lidar fusion 3d object detection task real time adverse weather light condition however currently literature be possible to find few work focus modality most importantly develop new architecture to explore advantage radar point cloud such accurate distance estimation speed information therefore work present novel efficient 3d object detection algorithm use camera radar bird’s eye view bev algorithm exploit advantage radar fuse feature detection head new backbone be introduce map radar pillar feature embed dimension self attention mechanism allow backbone to model dependency radar point be use simplify convolutional layer to replace fpn base convolutional layer use pointpillars base architecture main goal reduce inference time result show modification approach achieve new state art 3d object detection problem reach 58.2 nds metric use resnet-50 also set new benchmark inference time nuscene dataset same category,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15924,sparse multiview open vocabulary 3d detection,"Olivier Moliner, Viktor Larsson, Kalle Åström",ability to interpret comprehend 3d scene be essential many vision robotic system numerous application involve 3d object detection i.e. identify location dimension object belong specific category typically represent bound box have traditionally be solve train to detect fix set category limit use work investigate open vocabulary 3d object detection challenge yet practical sparse view set only limit number pose rgb image be available input approach be train free rely pre train shelf 2d foundation model instead employ computationally expensive 3d feature fusion require 3d specific learn lift 2d detection directly optimize 3d proposal featuremetric consistency view fully leverage extensive train datum available 2d compare 3d. standard benchmark demonstrate simple pipeline establish powerful baseline perform competitively state art technique densely sample scenario significantly outperform sparse view set,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15905,deep feedback models,"David Calhas, Arlindo L. Oliveira",deep feedback models dfms be new class stateful neural network combine bottom input high level representation time feedback mechanism introduce dynamic otherwise static architecture enable dfm to iteratively refine internal state mimic aspect biological decision make model process differential equation solve recurrent neural network stabilize exponential decay to ensure convergence to evaluate effectiveness measure dfms two key condition robustness noise generalization limit datum object recognition segmentation task dfm consistently outperform feedforward counterpart particularly low datum high noise regime addition dfms translate medical image setting be robust various type noise corruption finding highlight importance feedback achieve stable robust generalizable learn code be available github.com/dcalhas/deep_feedback_models,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15891,global regulation excitation attention tune stereo matching,"Jiahao Li, Xinhong Chen, Zhengmin Jiang, Qian Zhou, Yung-Hui Li, Jianping Wang",stereo match achieve significant progress iterative algorithm raft stereo igev stereo however method struggle ill pose region occlusion textureless repetitive pattern lack global context geometric information effective iterative refinement to enable exist iterative approach to incorporate global context propose global regulation excitation attention tuning great framework encompass three attention module specifically spatial attention sa capture global context spatial dimension matching attention ma extract global context epipolar line volume attention va work conjunction sa ma to construct more robust cost volume excite global context geometric detail to verify universality effectiveness framework integrate several representative iterative stereo match method validate extensive experiment collectively denote great stereo framework demonstrate superior performance challenge ill pose region apply igev stereo publish method great igev rank first scene flow test set kitti 2015 eth3d leaderboard achieve second middlebury benchmark code be available https://github.com/jarvislee0423/great-stereo,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15886,rangesam leverage visual foundation models range view repesente lidar segmentation,"Paul Julius Kühn, Duc Anh Nguyen, Arjan Kuijper, Holger Graf, Dieter Fellner, Saptarshi Neil Sinha",lidar point cloud segmentation be central autonomous drive 3d scene understand voxel- point base method dominate recent research compatibility deep architecture ability to capture fine grain geometry often incur high computational cost irregular memory access limit runtime efficiency scale issue contrast range view method relatively underexplored can leverage mature 2d semantic segmentation technique fast accurate prediction motivate rapid progress visual foundation models vfms caption zero shot recognition multimodal task investigate sam2 current state art vfm segmentation task can serve strong backbone lidar point cloud segmentation range view representation present rangesam knowledge first range view framework adapt sam2 3d segmentation couple efficient 2d feature extraction projection back projection to operate point cloud to optimize sam2 range view representation implement several architectural modification encoder 1 novel stem module emphasize horizontal spatial dependency inherent lidar range image 2 customize configuration hiera blocks tailor geometric property spherical projection 3 adapt window attention mechanism encoder backbone specifically design to capture unique spatial pattern discontinuity present range view pseudo image approach achieve competitive performance semantickitti benefit speed scalability deployment simplicity 2d centric pipeline work highlight viability vfm general purpose backbone point cloud segmentation open path unify foundation model drive lidar segmentation result let conclude range view segmentation method use vfm lead promise result,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15883,racap relation aware prompting lightweight retrieval augment image captioning,"Xiaosheng Long, Hanyu Wang, Zhentao Song, Kun Luo, Hongde Liu",recent retrieval augment image caption method incorporate external knowledge to compensate limitation comprehend complex scene however current approach face challenge relation model 1 representation semantic prompt be too coarse grain to capture fine grain relationship 2 method lack explicit model image object semantic relationship to address limitation propose racap relation aware retrieval augment model image caption not only mine structure relation semantic retrieval caption also identify heterogeneous object image racap effectively retrieve structure relation feature contain heterogeneous visual information to enhance semantic consistency relational expressiveness experimental result show racap only 10.8 m trainable parameter achieve superior performance compare previous lightweight caption model,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15882,self supervise cross modal learning image point cloud registration,"Xingmei Wang, Xiaoyu Hu, Chengkai Huang, Ziyan Zeng, Guohao Nie, Quan Z. Sheng, Lina Yao",bridge 2d 3d sensor modality be critical robust perception autonomous system however image point cloud i2p registration remain challenge semantic geometric gap texture rich depth ambiguous image sparse yet metrically precise point cloud as well tendency exist method to converge local optima to overcome limitation introduce crossi2p self supervise framework unify cross modal learn two stage registration single end end pipeline first learn geometric semantic fuse embed space dual path contrastive learn enable annotation free bidirectional alignment 2d texture 3d structure second adopt coarse fine registration paradigm global stage establish superpoint superpixel correspondence joint intra modal context cross modal interaction model follow geometry constrain point level refinement precise registration third employ dynamic train mechanism gradient normalization to balance loss feature alignment correspondence refinement pose estimation extensive experiment demonstrate crossi2p outperform state art method 23.7 kitti odometry benchmark 37.9 nuscene significantly improve accuracy robustness,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15874,ensam efficient foundation model interactive segmentation 3d medical image,"Elias Stenhede, Agnar Martin Bjørnstad, Arian Ranjbar","present ensam equivariant normalized segment anything model lightweight promptable model universal 3d medical image segmentation ensam combine segresnet base encoder prompt encoder mask decoder u net style architecture use latent cross attention relative positional encode normalize attention muon optimizer train ensam be design to achieve good performance limit datum computational budget be train scratch 5,000 volume multiple modality ct mri pet ultrasound microscopy single 32 gb gpu 6 hour part cvpr 2025 foundation models interactive 3d biomedical image segmentation challenge ensam be evaluate hidden test set multimodal 3d medical image obtain dsc auc 2.404 nsd auc 2.266 final dsc 0.627 final nsd 0.597 outperform two previously publish baseline model vista3d sam med3d match third segvol surpass performance final dsc trail behind other three metric coreset track challenge ensam rank 5th 10 overall good approach not utilize pretraine weight ablation study confirm use relative positional encoding muon optimizer substantially speed convergence improve segmentation quality",Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15871,zero shot visual grounding 3d gaussians view retrieval,"Liwei Liao, Xufeng Li, Xiaoyun Zheng, Boning Liu, Feng Gao, Ronggang Wang",3d visual grounding 3dvg aim to locate object 3d scene base text prompt be essential application such robotic however exist 3dvg method encounter two main challenge first struggle to handle implicit representation spatial texture 3d gaussian splatting 3dgs make scene train indispensable second typically require large amount label datum effective train end propose ground view retrieval gvr novel zero shoot visual ground framework 3dgs to transform 3dvg 2d retrieval task leverage object level view retrieval to collect ground clue multiple view not only avoid costly process 3d annotation also eliminate need scene train extensive experiment demonstrate method achieve state art visual ground performance avoid scene train provide solid foundation zero shot 3dvg research video demo can be find https://github.com/leviome/gvr_demos,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15868,lc slab object base deep learning framework large scale land cover classification satellite imagery sparse in situ label,"Johannes Leonhardt, Juergen Gall, Ribana Roscher",large scale land cover map generate use deep learn play critical role data drive analysis decision make wide range earth science application open situ dataset principled land cover survey offer scalable alternative manual annotation train such model however sparse spatial coverage often lead fragment noisy prediction use exist deep learn base land cover map approach promise direction to address issue be object base classification assign label semantically coherent image region rather individual pixel thereby impose minimum map unit control spatial fragmentation potential object base method remain underexplored deep learn base land cover map pipeline especially context medium resolution imagery sparse supervision,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15805,boost active learning knowledge transfer,"Tianyang Wang, Xi Xiao, Gaofei Chen, Xiaoying Liao, Guo Cheng, Yingrui Ji",uncertainty estimation be core active learning al most exist method resort complex auxiliary model advance train fashion to estimate uncertainty unlabeled datum model need special design hence be difficult to train especially domain task such cryo electron tomography cryo et classification computational biology to address challenge propose novel method use knowledge transfer to boost uncertainty estimation al specifically exploit teacher student mode teacher be task model al student be auxiliary model learn teacher train two model simultaneously al cycle adopt certain distance model output to measure uncertainty unlabeled datum student model be task agnostic do not rely special train fashion e.g. adversarial make method suitable various task more importantly demonstrate datum uncertainty be not tie concrete value task loss closely relate upper bind task loss conduct extensive experiment to validate propose method classical computer vision task cryo et challenge result demonstrate efficacy efficiency,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15803,cider causal cure brand obsess text image models,"Fangjian Shen, Zifeng Liang, Chao Wang, Wushao Wen",text image t2i model exhibit significant yet under explore brand bias tendency to generate content feature dominant commercial brand generic prompt pose ethical legal risk propose cider novel model agnostic framework to mitigate bias inference time prompt refinement to avoid costly retrain cider use lightweight detector to identify brand content vision language model vlm to generate stylistically divergent alternative introduce brand neutrality score bns to quantify issue perform extensive experiment lead t2i model result show cider significantly reduce explicit implicit bias maintain image quality aesthetic appeal work offer practical solution more original equitable content contribute development trustworthy generative ai,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15800,chronoforge rl chronological forge reinforcement learning enhanced video understanding,Kehua Chen,current state art video understand method typically struggle two critical challenge 1 computational infeasibility process frame dense video content 2 difficulty identify semantically significant frame naive uniform sample strategy paper propose novel video understand framework call chronoforge rl combine temporal apex distillation tad keyframe aware group relative policy optimization kf grpo to tackle issue concretely introduce differentiable keyframe selection mechanism systematically identify semantic inflection point three stage process to enhance computational efficiency preserve temporal information then two particular module be propose to enable effective temporal reason firstly tad leverage variation score inflection detection prioritize distillation to select most informative frame secondly introduce kf grpo implement contrastive learn paradigm saliency enhance reward mechanism explicitly incentivize model to leverage frame content temporal relationship finally propose chronoforge rl achieve 69.1 videomme 52.7 lvbench compare baseline method clearly surpass previous approach enable 7b parameter model to achieve performance comparable 72b parameter alternative 10× improvement performance parameter ratio,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15795,tasam terrain aware segment anything model temporal scale remote sensing segmentation,"Tianyang Wang, Xi Xiao, Gaofei Chen, Hanzhang Chi, Qi Zhang, Guo Cheng, Yingrui Ji",segment anything model sam have demonstrate impressive zero shot segmentation capability natural image domain struggle to generalize unique challenge remote sense datum such complex terrain multi scale object temporal dynamic paper introduce tasam terrain- temporally aware extension sam design specifically high resolution remote sense image segmentation tasam integrate three lightweight yet effective module terrain aware adapter inject elevation prior temporal prompt generator capture land cover change time multi scale fusion strategy enhance fine grain object delineation retrain sam backbone approach achieve substantial performance gain three remote sense benchmark loveda isaid whu cd outperform zero shot sam task specific model minimal computational overhead result highlight value domain adaptive augmentation foundation model offer scalable path more robust geospatial segmentation,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15791,minimal semantic sufficiency meet unsupervised domain generalization,"Tan Pan, Kaiyu Guo, Dongli Xu, Zhaorui Tan, Chen Jiang, Deshu Chen, Xin Guo, Brian C. Lovell, Limei Han, Yuan Cheng, Mahsa Baktashmotlagh",generalization ability deep learn have be extensively study supervise setting remain less explore unsupervised scenario recently unsupervised domain generalization udg task have be propose to enhance generalization model train prevalent unsupervised learn technique such self supervised learning ssl udg confront challenge distinguish semantic variation category label recent method have employ domain label to tackle issue such domain label be often unavailable real world context paper address limitation formalize udg task learn minimal sufficient semantic representation representation i preserve semantic information share augment view sufficiency ii maximally remove information irrelevant semantic minimality theoretically ground objective perspective information theory demonstrate optimize representation to achieve sufficiency minimality directly reduce distribution risk practically implement optimization minimal sufficient udg ms udg learnable model integrate a infonce base objective to achieve sufficiency b two complementary component to promote minimality novel semantic variation disentanglement loss reconstruction base mechanism capture adequate variation empirically ms udg set new state art popular unsupervised domain generalization benchmark consistently outperform exist ssl udg method category domain label representation learn,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15788,foba foreground background co guided method new benchmark remote sensing semantic change detection,"Haotian Zhang, Han Guo, Keyan Chen, Hao Chen, Zhengxia Zou, Zhenwei Shi",remarkable progress achieve remote sense semantic change detection scd two major challenge remain datum level exist scd dataset suffer limit change category insufficient change type lack fine grain class definition make inadequate to fully support practical application methodological level most current approach underutilize change information typically treat post process step to enhance spatial consistency constrain further improvement model performance to address issue construct new benchmark remote sense scd levirscd focus beijing area dataset cover 16 change category 210 specific change type more fine grain class definition e.g. road be divide unpaved pave road furthermore propose foreground background co guide scd foba method leverage foreground focus region interest background enrich contextual information to guide model collaboratively thereby alleviate semantic ambiguity enhance ability to detect subtle change consider requirement bi temporal interaction spatial consistency scd introduce gated interaction fusion gif module simple consistency loss to far enhance model ’s detection performance extensive experiment three dataset second jl1 propose levirscd demonstrate foba achieve competitive result compare current sota method improvement 1.48 3.61 2.81 sek metric respectively code dataset be available https://github.com/zmoka-zht/foba,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15785,cbpnet continual backpropagation prompt network alleviate plasticity loss edge devices,"Runjie Shao, Boyu Diao, Zijia An, Ruiqi Liu, Yongjun Xu",to meet demand application robotic autonomous drive require real time response dynamic environment efficient continual learn method suitable edge device have attract increase attention transition use frozen pre train model prompt have become mainstream strategy to combat catastrophic forget however approach introduce new critical bottleneck plasticity loss model ’s ability to learn new knowledge diminish frozen backbone limit capacity prompt parameter argue reduction plasticity stem lack update vitality underutilize parameter train process end propose continual backpropagation prompt network cbpnet effective parameter efficient framework design to restore model ’s learn vitality innovatively integrate efficient cbp block counteract plasticity decay adaptively re initialize underutilized parameter experimental result edge device demonstrate cbpnet ’s effectiveness multiple benchmark split cifar-100 improve average accuracy 1 strong baseline more challenge split imagenet r achieve state art accuracy 69.41 be accomplish train additional parameter constitute less 0.2 backbone ’s size validate approach,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15784,ideal registration segmentation be need,"Xiang Chen, Fengting Zhang, Qinghao Liu, Min Liu, Kun Wu, Yaonan Wang, Hang Zhang",deep learn have revolutionize image registration ability to handle diverse task achieve significant speed advantage conventional approach current approach however often employ globally uniform smoothness constraint fail to accommodate complex regionally vary deformation characteristic anatomical motion to address limitation propose segreg segmentation drive registration framework implement anatomically adaptive regularization exploit region specific deformation pattern segreg first decompose input move fix image anatomically coherent subregion segmentation localize domain be then process same registration backbone to compute optimize partial deformation field be subsequently integrate global deformation field segreg achieve near perfect structural alignment 98.23 dice critical anatomy use ground truth segmentation outperform exist method 2 12 three clinical registration scenario cardiac abdominal lung image even automatic segmentation segreg demonstrate near linear dependence registration accuracy segmentation quality transform registration challenge segmentation problem source code will be release manuscript acceptance,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15781,enriched feature representation motion prediction module mosev2 track 7th lsvos challenge 3rd place solution,"Chang Soo Lim, Joonyoung Moon, Donghyeon Cho",video object segmentation vos be challenge task wide application such video edit autonomous drive cutie provide strong query base segmentation sam2 offer enrich representation pretrained vit encoder have limitation feature capacity temporal model report propose framework integrate complementary strength replace encoder cutie vit encoder sam2 introduce motion prediction module temporal stability far adopt ensemble strategy combine cutie sam2 variant achieve 3rd place mosev2 track 7th lsvos challenge refer final model scope sam2 cutie object prediction ensemble demonstrate effectiveness enrich feature representation motion prediction robust video object segmentation code be available https://github.com/2025-lsvos-3rd-place/mosev2_3rd_place,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15772,vision language models differentiable semantic spatial rewards text to-3d generation,"Weimin Bai, Yubo Li, Weijian Luo, Wenzheng Chen, He Sun",score distillation sampling sds enable high quality text to-3d generation supervise 3d model denoising multi view 2d rendering use pretraine text image diffusion model to align input prompt ensure 3d consistency however exist sds base method face two fundamental limitation 1 reliance clip style text encoder lead coarse semantic alignment struggle fine grain prompt 2 2d diffusion prior lack explicit 3d spatial constraint result geometric inconsistency inaccurate object relationship multi object scene to address challenge propose vlm3d novel text to-3d generation framework integrate large vision language model vlms sds pipeline differentiable semantic spatial prior standard text image diffusion prior vlms leverage rich language ground supervision enable fine grain prompt alignment moreover inherent vision language model provide strong spatial understand significantly enhance 3d consistency single object generation improve relational reason multi object scene instantiate vlm3d base open source qwen2.5 vl model evaluate gpteval3d benchmark experiment diverse object complex scene show vlm3d significantly outperform prior sds base method semantic fidelity geometric coherence spatial correctness,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15768,overview plantclef 2024 multi species plant identification vegetation plot image,"Herve Goeau, Vincent Espitalier, Pierre Bonnet, Alexis Joly",plot image be essential ecological study enable standardize sample biodiversity assessment long term monitor remote large scale survey plot image be typically fifty centimetre one square meter size botanist meticulously identify specie find there integration ai could significantly improve efficiency specialist help to extend scope coverage ecological study to evaluate advance regard plantclef 2024 challenge leverage new test set thousand multi label image annotate expert cover 800 specie addition provide large train set 1.7 million individual plant image as well state art vision transformer model pre train datum task be evaluate weakly label multi label classification task aim be to predict plant specie present high resolution plot image use single label train datum paper provide detail description datum evaluation methodology method model employ participant result achieve,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15753,mcod first challenging benchmark multispectral camouflaged object detection,"Yang Li, Tingfa Xu, Shuyan Bai, Peifu Liu, Jianan Li",camouflaged object detection cod aim to identify object blend seamlessly natural scene rgb base method have advance performance remain limit challenge condition multispectral imagery provide rich spectral information offer promise alternative enhance foreground background discrimination however exist cod benchmark dataset be exclusively rgb base lack essential support multispectral approach have impede progress area to address gap introduce mcod first challenge benchmark dataset specifically design multispectral camouflage object detection mcod feature three key advantage i comprehensive challenge attribute capture real world difficulty such small object size extreme light condition commonly encounter cod task ii diverse real world scenario dataset span wide range natural environment to well reflect practical application iii high quality pixel level annotation image be manually annotate precise object mask correspond challenge attribute label benchmark eleven representative cod method mcod observe consistent performance drop increase task difficulty notably integrate multispectral modality substantially alleviate degradation highlight value spectral information enhance detection robustness anticipate mcod will provide strong foundation future research multispectral camouflage object detection dataset be publicly accessible https://github.com/yl2900260-bit/mcod,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15751,simulated cortical magnification support self supervise object learning,"Zhengyang Yu, Arthur Aubret, Chen Yu, Jochen Triesch",recent self supervise learn model simulate development semantic object representation train visual experience similar toddler however model ignore foveated nature human vision high low resolution center periphery visual field here investigate role vary resolution development object representation leverage two dataset egocentric video capture visual experience human interaction object apply model human foveation cortical magnification to modify input such visual content become less distinct periphery result sequence be use to train two bio inspire self supervise learn model implement time base learn objective result show model aspect foveated vision improve quality learn object representation set analysis suggest improvement come make object appear big induce well trade off central peripheral visual information overall work take step make model human learn visual representation more realistic performant,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15750,floorsam sam guided floorplan reconstruction semantic geometric fusion,"Han Ye, Haofu Wang, Yunchi Zhang, Jiangjian Xiao, Yuqiang Jin, Jinyuan Liu, Wen-An Zhang, Uladzislau Sychou, Alexander Tuzikov, Vladislav Sobolevskii, Valerii Zakharov, Boris Sokolov, Minglei Fu",reconstruct build floor plan point cloud datum be critical technology indoor navigation build information model bim highly accurate precise indoor measurement application traditional method such geometric algorithm mask r cnn base deep learn mask segmentation often suffer sensitivity noise limit generalization loss geometric detail severely impact measurement accuracy study propose innovative framework floorsam integrate room height point cloud density map guide segmentation capability segment anything model sam to enhance precision floor plan reconstruction lidar point cloud datum apply grid base filter to retain elevation point cloud ceiling region combine adaptive resolution projection image enhancement technique top density map be generate improve robustness accuracy spatial feature measurement framework leverage sam ’s zero shot learn to achieve high fidelity room segmentation remarkably enhance reconstruction measurement accuracy diverse build layout subsequently leverage sam ’s zero shot guide segmentation capability high quality room mask be generate base adaptive prompt point follow multistage filter process to extract precise semantic mask individual room joint analysis mask point cloud modality contour extraction regularization be perform integrate semantic segmentation geometric information to produce accurate room floor plan recover topological relationship room experiment giblayout isprs public dataset validate effectiveness method show significant improvement measurement accuracy recall robustness traditional approach especially noisy environment complex layout code video supplementary material be available https://github.com/silentbarber/floorsam,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15748,hybrid lie semi group cascade structure generalize gaussian derivative model visual receptive field,Tony Lindeberg,variability real world image structure natural image transformation arise observe similar object spatio temporal event different view condition receptive field response compute early layer visual hierarchy may be strongly influence such geometric image transformation one way handle variability be base vision system covariant receptive field family expand receptive field shape degree freedom image transformation,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15741,truemoe dual routing mixture discriminative experts synthetic image detection,"Laixin Zhang, Shuaibo Li, Wei Ma, Hongbin Zha",rapid progress generative model have make synthetic image detection increasingly critical task most exist approach attempt to construct single universal discriminative space to separate real fake content however such unify space tend to be complex brittle often struggle to generalize unseen generative pattern work propose truemoe novel dual route mixture discriminative expert framework reformulate detection task collaborative inference multiple specialize lightweight discriminative subspace core truemoe be discriminative expert array dea organize complementary axis manifold structure perceptual granularity enable diverse forgery cue to be capture subspace dual rout mechanism comprise granularity aware sparse router manifold aware dense router adaptively assign input image most relevant expert extensive experiment wide spectrum generative model demonstrate truemoe achieve superior generalization robustness,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15711,medical deepfake detection comprehensive dataset novel method,"Shuaibo Li, Zhaohu Xing, Hongqiu Wang, Pengfei Hao, Xingyu Li, Zekai Liu, Lei Zhu",rapid advancement generative ai medical image have introduce significant opportunity serious challenge especially risk fake medical image could undermine healthcare system synthetic image pose serious risk such diagnostic deception financial fraud misinformation however research medical forensic to counter threat remain limit be critical lack comprehensive dataset specifically tailor field additionally exist medium forensic method be primarily design natural facial image be inadequate capture distinct characteristic subtle artifact ai generate medical image to tackle challenge introduce medforensics large scale medical forensic dataset encompass six medical modality twelve state art medical generative model also propose dski novel dual stage knowledge infuse detector construct vision language feature space tailor detection ai generate medical image dski comprise two core component 1 cross domain fine trace adapter cdfa extract subtle forgery clue spatial noise domain train 2 medical forensic retrieval module mfrm boost detection accuracy few shot retrieval test experimental result demonstrate dski significantly outperform exist method human expert achieve superior accuracy multiple medical modality,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15706,sgmagnet baseline model 3d cloud phase structure reconstruction new passive active satellite benchmark,"Chi Yang, Fu Wang, Xiaofei Yang, Hao Huang, Weijia Cao, Xiaowen Chu",cloud phase profile be critical numerical weather prediction nwp directly affect radiative transfer precipitation process study present benchmark dataset baseline framework transform multimodal satellite observation detail 3d cloud phase structure aim operational cloud phase profile retrieval future integration nwp system to improve cloud microphysic parameterization multimodal observation consist 1 high spatiotemporal resolution multi band visible vis thermal infrared tir imagery geostationary satellite 2 accurate vertical cloud phase profile spaceborne lidar caliop calipso radar cpr cloudsat dataset consist synchronize image profile pair diverse cloud regime define supervise learn task give vis tir patch predict correspond 3d cloud phase structure adopt sgmagnet main model compare several baseline architecture include unet variant segnet design to capture multi scale spatial pattern model performance be evaluate use standard classification metric include precision recall f1 score iou. result demonstrate sgmagnet achieve superior performance cloud phase reconstruction particularly complex multi layer boundary transition region quantitatively sgmagnet attain precision 0.922 recall 0.858 f1 score 0.763 iou 0.617 significantly outperform baseline key metric,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15704,training free pyramid token pruning efficient large vision language models region token instruction guide importance,"Yuxuan Liang, Xu Li, Xiaolei Chen, Yi Zheng, Haotian Chen, Bin Li, Xiangyang Xue",large vision language models lvlms have significantly advance multimodal understand still struggle efficiently process high resolution image recent approach partition high resolution image multiple sub image dramatically increase number visual token cause exponential computational overhead inference to address limitation propose train free token prune strategy pyramid token pruning ptp integrate bottom visual saliency region token level top instruction guide importance inspire human visual attention mechanism ptp selectively retain more token visually salient region far leverage textual instruction to pinpoint token most relevant specific multimodal task extensive experiment 13 diverse benchmark demonstrate method substantially reduce computational overhead inference latency minimal performance loss,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15695,oric benchmarking object recognition incongruous context large vision language models,"Zhaoyang Li, Zhan Ling, Yuchen Zhou, Hao Su",large vision language models lvlms have make significant stride image caption visual question answer robotic integrate visual textual information however remain prone error incongruous context object appear unexpectedly be absent contextually expect lead two key recognition failure object misidentification hallucination to systematically examine issue introduce object recognition incongruous context benchmark oric novel benchmark evaluate lvlms scenario object context relationship deviate expectation oric employ two key strategy 1 llm guide sample identify object be present contextually incongruous 2 clip guide sample detect plausible nonexistent object be likely to be hallucinate thereby create incongruous context evaluate 18 lvlm two open vocabulary detection model result reveal significant recognition gap underscore challenge pose contextual incongruity work provide critical insight lvlms limitation encourage further research context aware object recognition code be available https://github.com/zhaoyangli-1/oric,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15693,sceneforge enhance 3d text alignment structured scene compositions,"Cristian Sbrolli, Matteo Matteucci",whole be great sum part even 3d text contrastive learn introduce sceneforge novel framework enhance contrastive alignment 3d point cloud text structure multi object scene composition sceneforge leverage individual 3d shape to construct multi object scene explicit spatial relation pair coherent multi object description refine large language model augment contrastive train structure compositional sample sceneforge effectively address scarcity large scale 3d text dataset significantly enrich datum complexity diversity systematically investigate critical design element such optimal number object scene proportion compositional sample train batch scene construction strategy extensive experiment demonstrate sceneforge deliver substantial performance gain multiple task include zero shot classification modelnet scanobjnn objaverse lvis scannet as well few shot part segmentation shapenetpart sceneforge ’s compositional augmentation be model agnostic consistently improve performance multiple encoder architecture moreover sceneforge improve 3d visual question answer scanqa generalize robustly retrieval scenario increase scene complexity showcase spatial reason capability adapt spatial configuration to align precisely textual instruction,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15688,saccadic vision fine grained visual classification,"Johann Schmidt, Sebastian Stober, Joachim Denzler, Paul Bodesheim",fine grain visual classification fgvc require distinguish visually similar category subtle localize feature task remain challenge high intra class variability limit inter class difference exist part base method often rely complex localization network learn mapping pixel sample space require deep understand image content limit feature utility downstream task addition sample point frequently suffer high spatial redundancy make difficult to quantify optimal number require part inspire human saccadic vision propose two stage process first extract peripheral feature coarse view generate sample map fixation patch be sample encode parallel use weight share encoder employ contextualize selective attention to weigh impact fixation patch fuse peripheral focus representation to prevent spatial collapse common issue part base method utilize non maximum suppression fixation sample to eliminate redundancy comprehensive evaluation standard fgvc benchmark cub-200 2011 nabird food-101 stanford dogs challenge insect dataset eu moths ecuador moths ami moth demonstrate method achieve comparable performance state art approach consistently outperform baseline encoder,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15678,layout stroke imitation layout guided handwriting stroke generation style imitation diffusion model,"Sidra Hanif, Longin Jan Latecki",handwriting stroke generation be crucial improve performance task such handwrite recognition writer ’s order recovery handwrite stroke generation be significantly important to imitate sample calligraphic style previous study have suggest utilize calligraphic feature handwrite however have not consider word space word layout explicit handwrite feature result inconsistent word space style imitation firstly work propose multi scale attention feature calligraphic style imitation multi scale feature embedding highlight local global style feature secondly propose to include word layout facilitate word space handwrite stroke generation moreover propose conditional diffusion model to predict stroke contrast previous work directly generate style image stroke generation provide additional temporal coordinate information be lack image generation hence propose conditional diffusion model stroke generation be guide calligraphic style word layout well handwrite imitation stroke generation calligraphic style experimentation show propose diffusion model outperform current state art stroke generation be competitive recent image generation network,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15675,pca based model surface reconstruction incomplete point clouds,Hao Liu,point cloud datum represent crucial category information mathematical model surface reconstruction such datum be important task various discipline however scan process collect point cloud datum may fail to cover entire surface factor such high light absorption rate occlusion result incomplete dataset infer surface structure data miss region successfully reconstruct surface pose challenge paper present principal component analysis pca base model surface reconstruction incomplete point cloud datum initially employ pca to estimate normal information underlie surface available point cloud datum estimate normal information serve regularizer model guide reconstruction surface particularly area miss datum additionally introduce operator split method to effectively solve propose model systematic experimentation demonstrate model successfully infer surface structure data miss region well reconstruct underlie surface outperform exist methodology,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15648,fingersplat contactless fingerprint 3d reconstruction generation base 3d gaussian splatting,"Yuwei Jia, Yutang Lu, Zhe Cui, Fei Su",researcher have conduct many pioneer research contactless fingerprint performance contactless fingerprint recognition still lag contact base method primary insufficient contactless fingerprint datum pose variation lack usage implicit 3d fingerprint representation paper introduce novel contactless fingerprint 3d registration reconstruction generation framework integrate 3d gaussian splatting goal offer new paradigm contactless fingerprint recognition integrate 3d fingerprint reconstruction generation knowledge be first work to apply 3d gaussian splatting field fingerprint recognition first to achieve effective 3d registration complete reconstruction contactless fingerprint sparse input image require camera parameter information experiment 3d fingerprint registration reconstruction generation prove method can accurately align reconstruct 3d fingerprint 2d image sequentially generate high quality contactless fingerprint 3d model thus increase performance contactless fingerprint recognition,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15645,gs scale unlock large scale 3d gaussian splatting training host offloading,"Donghyun Lee, Dawoon Jeong, Jae W. Lee, Hongil Yoon",advent 3d gaussian splatting have revolutionize graphic render deliver high visual quality fast render speed however train large scale scene high quality remain challenge substantial memory demand require to store parameter gradient optimizer state can quickly overwhelm gpu memory to address limitation propose gs scale fast memory efficient train system 3d gaussian splatting gs scale store gaussians host memory transfer only subset gpu demand forward backward pass dramatically reduce gpu memory usage require frustum cull optimizer update to be execute cpu introduce slowdown cpu ’s limit compute memory bandwidth to mitigate gs scale employ three system level optimization 1 selective offload geometric parameter fast frustum cull 2 parameter forward to pipeline cpu optimizer update gpu computation 3 defer optimizer update to minimize unnecessary memory access gaussians zero gradient extensive evaluation large scale dataset demonstrate gs scale significantly lower gpu memory demand 3.3 5.6×\times achieve train speed comparable gpu host offload enable large scale 3d gaussian splatting train consumer grade gpu instance gs scale can scale number gaussians 4 million to 18 million rtx 4070 mobile gpu lead 23 35 lpip learn perceptual image patch similarity improvement,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15642,univ unified foundation model infrared visible modality,"Fangyuan Mao, Shuo Wang, Jilin Mei, Chen Min, Shun Lu, Fuyang Liu, Yu Hu","demand joint rgb visible infrared perception be grow rapidly particularly to achieve robust performance diverse weather condition pre train model rgb visible infrared datum excel respective domain often underperform multimodal scenario such autonomous vehicle equip sensor to address challenge propose biologically inspire unified foundation model infrared visible modality univ feature two key innovation first introduce patch wise cross modality contrastive learning pccl attention guide distillation framework mimic retinal horizontal cell lateral inhibition enable effective cross modal feature alignment remain compatible transformer base architecture second dual knowledge preservation mechanism emulate retina ’s bipolar cell signal rout combine lora adapter 2 add parameter synchronous distillation to prevent catastrophic forget thereby replicate retina ’s photopic cone drive scotopic rod drive functionality to support cross modal learn introduce mvip dataset most comprehensive visible infrared benchmark date contain 98,992 precisely align image pair span diverse scenario extensive experiment demonstrate univ ’s superior performance infrared task +1.7 miou semantic segmentation +0.7 map object detection maintain 99%+99\%+ baseline performance visible rgb task code be available https://github.com/fangyuanmao/univ",Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15638,pfedsam personalized federated learning segment anything model medical image segmentation,"Tong Wang, Xingyue Zhao, Linghao Zhuang, Haoyu Zhao, Jiayi Yin, Yuyang He, Gang Yu, Bo Lin",medical image segmentation be crucial computer aid diagnosis privacy constraint hinder datum share institution federated learning address limitation exist approach often rely lightweight architecture struggle complex heterogeneous datum recently segment anything model sam have show outstanding segmentation capability however massive encoder pose significant challenge federate setting work present first personalize federate sam framework tailor heterogeneous data scenario medical image segmentation framework integrate two key innovation 1 personalize strategy aggregate only global parameter to capture cross client commonality retain design l moe localize mixture expert component to preserve domain specific feature 2 decouple global local fine tune mechanism leverage teacher student paradigm knowledge distillation to bridge gap global share model personalize local model thereby mitigate overgeneralization extensive experiment two public dataset validate approach significantly improve segmentation performance achieve robust cross domain adaptation reduce communication overhead,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15623,pcsr pseudo label consistency guided sample refinement noisy correspondence learning,"Zhuoyao Liu, Yang Liu, Wentao Feng, Shudong Huang",cross modal retrieval aim to align different modality semantic similarity however exist method often assume image text pair be perfectly align overlook noisy correspondences real datum misalign pair misguide similarity learn degrade retrieval performance previous method often rely coarse grain categorization simply divide datum clean noisy sample overlook intrinsic diversity noisy instance moreover typically apply uniform train strategy regardless sample characteristic result suboptimal sample utilization model optimization to address above challenge introduce novel framework call pseudo label consistency guided sample refinement pcsr enhance correspondence reliability explicitly divide sample base pseudo label consistency specifically first employ confidence base estimation to distinguish clean noisy pair then refine noisy pair pseudo label consistency to uncover structurally distinct subset far propose pseudo label consistency score pcs to quantify prediction stability enable separation ambiguous refinable sample noisy pair accordingly adopt adaptive pair optimization apo ambiguous sample be optimize robust loss function refinable one be enhance text replacement train extensive experiment cc152 k ms coco flickr30 k validate effectiveness method improve retrieval robustness noisy supervision,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15608,enhance wsi base survival analysis report auxiliary self distillation,"Zheng Wang, Hong Liu, Zheng Wang, Danyi Li, Min Cen, Baptiste Magnier, Li Liang, Liansheng Wang",survival analysis base whole slide images wsis be crucial evaluate cancer prognosis offer detail microscopic information essential predict patient outcome however traditional wsi base survival analysis usually face noisy feature limit datum accessibility hinder ability to capture critical prognostic feature effectively pathology report provide rich patient specific information could assist analysis potential to enhance wsi base survival analysis remain largely unexplored end paper propose novel report auxiliary self distillation rasa framework wsi base survival analysis first advance large language model llms be utilize to extract fine grain wsi relevant textual description original noisy pathology report carefully design task prompt next self distillation base pipeline be design to filter irrelevant redundant wsi feature student model guidance teacher model ’s textual knowledge finally risk aware mix strategy be incorporate train student model to enhance quantity diversity train datum extensive experiment carry collect datum crc public datum tcga brca demonstrate superior effectiveness rasa state art method code be available https://github.com/zhengwang9/rasa,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15602,tennistv do multimodal large language models understand tennis rally,"Zhongyuan Bao, Lejun Zhang","multimodal large language model mllms excel general video understand struggle fast high frequency sport tennis rally clip be short information dense to systematically evaluate mllm challenge domain present tennistv first most comprehensive benchmark tennis video understand tennistv model rally time order sequence consecutive stroke event use automate pipeline filter question generation cover 8 task rally stroke level include 2,500 human verify question evaluate 16 representative mllm provide first systematic assessment tennis video understand result reveal substantial shortcoming yield two key insight i frame sample density should be tailor balance task ii improve temporal ground be essential strong reason",Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15596,eyepcr comprehensive benchmark fine grained perception knowledge comprehension clinical reasoning ophthalmic surgery,"Gui Wang, Yang Wennuo, Xusen Ma, Zehao Zhong, Zhuoru Wu, Ende Wu, Rong Qu, Wooi Ping Cheah, Jianfeng Ren, Linlin Shen",mllm multimodal large language models have showcase remarkable capability performance high stake domain specific scenario surgical setting remain largely under explore to address gap develop eyepcr large scale benchmark ophthalmic surgery analysis ground structure clinical knowledge to evaluate cognition perception comprehension reasoning eyepcr offer richly annotate corpus more 210k vqas cover 1048 fine grain attribute multi view perception medical knowledge graph more 25k triplet comprehension four clinically ground reason task rich annotation facilitate depth cognitive analysis simulate surgeon perceive visual cue combine domain knowledge to make decision thus greatly improve model cognitive ability particular eyepcr mllm domain adapt variant qwen2.5 vl-7b achieve high accuracy mcq perception compare model outperform open source model comprehension reasoning rival commercial model gpt-4.1 eyepcr reveal limitation exist mllm surgical cognition lay foundation benchmarke enhance clinical reliability surgical video understand model,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15578,multimodal learning fake news detection short videos use linguistically verify data heterogeneous modality fusion,"Shanghong Li, Chiam Wen Qi Ruth, Hong Xu, Fang Liu",rapid proliferation short video platform have necessitate advance method detect fake news need arise widespread influence ease share misinformation can lead significant societal harm current method often struggle dynamic multimodal nature short video content paper present hfn heterogeneous fusion net novel multimodal framework integrate video audio text datum to evaluate authenticity short video content hfn introduce decision network dynamically adjust modality weight inference weighted multi modal feature fusion module to ensure robust performance even incomplete datum additionally contribute comprehensive dataset vesv veracity short videos specifically design short video fake news detection experiment conduct fakett newly collect vesv dataset demonstrate improvement 2.71 4.14 marco f1 state art method work establish robust solution capable effectively identify fake news complex landscape short video platform pave way more reliable comprehensive approach combat misinformation,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15573,size invariant salient object detection generic evaluation optimization approach,"Shilong Bao, Qianqian Xu, Feiran Li, Boyu Han, Zhiyong Yang, Xiaochun Cao, Qingming Huang",paper investigate fundamental yet underexplored issue salient object detection sod size invariant property evaluation protocol particularly scenario multiple salient object significantly different size appear single image first present novel perspective to expose inherent size sensitivity exist widely use sod metric careful theoretical derivation show evaluation outcome image current sod metric can be essentially decompose sum several separable term contribution term be directly proportional correspond region size consequently prediction error would be dominate large region small potentially more semantically important object be often overlook lead bias performance assessment practical degradation to address challenge generic size invariant evaluation sieva framework be propose core idea be to evaluate separable component individually then aggregate result thereby effectively mitigate impact size imbalance object build far develop dedicate optimization framework siopt adhere size invariant principle significantly enhance detection salient object broad range size notably siopt be model agnostic can be seamlessly integrate wide range sod backbone theoretically also present generalization analysis sod method provide evidence support validity new evaluation protocol finally comprehensive experiment speak efficacy propose approach code be available https://github.com/ferry-li/si-sod,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15566,btl ui blink think link reasoning model gui agent,"Shaojie Zhang, Ruoceng Zhang, Pei Fu, Shaokang Wang, Jiahui Yang, Xin Du, Shiqi Cui, Bin Qin, Ying Huang, Zhenbo Luo, Jian Luan",field ai drive human gui interaction automation rapid advance multimodal large language model reinforcement fine tune technique have yield remarkable progress fundamental challenge persist interaction logic significantly deviate natural human gui communication pattern to fill gap propose blink think link btl brain inspire framework human gui interaction mimic human cognitive process user graphical interface system decompose interaction three biologically plausible phase 1 blink rapid detection attention relevant screen area analogous saccadic eye movement 2 think high level reason decision make mirror cognitive plan 3 link generation executable command precise motor control emulate human action selection mechanism additionally introduce two key technical innovation btl framework 1 blink data generation automate annotation pipeline specifically optimize blink datum 2 btl reward first rule base reward mechanism enable reinforcement learn drive process outcome building framework develop gui agent model name btl ui demonstrate consistent state art performance static gui understand dynamic interaction task comprehensive benchmark result provide conclusive empirical validation framework ’s efficacy develop advance gui agents,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15563,dc mamba bi temporal deformable alignment scale sparse enhancement remote sense change detection,"Min Sun, Fenghui Guo",remote sense change detection rscd be vital identify land cover change exist method include state art state space models ssms often lack explicit mechanism to handle geometric misalignment struggle to distinguish subtle true change noise to address introduce dc mamba align then enhance framework build changemamba backbone integrate two lightweight plug play module 1 bi temporal deformable alignment btda explicitly introduce geometric awareness to correct spatial misalignment semantic feature level 2 scale sparse change amplifier ssca use multi source cue to selectively amplify high confidence change signal suppress noise final classification synergistic design first establish geometric consistency btda to reduce pseudo change then leverage ssca to sharpen boundary enhance visibility small subtle target experiment show method significantly improve performance strong changemamba baseline increase f1 score 0.5730 0.5903 iou 0.4015 0.4187 result confirm effectiveness align then enhance strategy offer robust easily deployable solution transparently address geometric feature level challenge rscd,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15558,development deployment ai assist telehealth screen vision- hearing threaten disease resource constrain setting field observations challenge way forward,"Mahesh Shakya, Bijay Adhikari, Nirsara Shrestha, Bipin Koirala, Arun Adhikari, Prasanta Poudyal, Luna Mathema, Sarbagya Buddhacharya, Bijay Khatri, Bishesh Khanal",vision- hear threaten disease cause preventable disability especially resource constrain settings(rcs few specialist limit screen setup large scale ai assist screen telehealth have potential to expand early detection practical deployment be challenge paper base workflow limit document field experience exist to build,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15553,diffusion base cross modal feature extraction multi label classification,"Tian Lan, Yiming Zheng, Jianxin Yin","multi label classification have broad application depend powerful representation capable capture multi label interaction introduce diff feat simple powerful framework extract intermediate feature diffusion transformer model image text fuse downstream task observe vision task most discriminative intermediate feature diffusion process occur middle step be locate middle block transformer contrast language task good feature occur noise free step be locate deep block particular observe strike phenomenon vary dataset mysterious layer 1212 consistently yield good performance various downstream classification task image dit xl/2 256×\times256 devise heuristic local‑search algorithm pinpoint locally optimal image text""×\times""block timestep pair few candidate avoid exhaustive grid search simple fusion linear projection follow addition select representation yield state‑of‑the‑art performance 98.6 map ms‑coco enhance 45.7 map visual genome 500 surpass strong cnn graph transformer baseline wide margin t‑sne cluster metric far reveal diff feat form tight semantic cluster unimodal counterpart code be available https://github.com/lt-0123/diff-feat",Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15548,ms gs multi appearance sparse view 3d gaussian splatting wild,"Deming Li, Kaiwen Jiang, Yutao Tang, Ravi Ramamoorthi, Rama Chellappa, Cheng Peng",wild photo collection often contain limit volume imagery exhibit multiple appearance e.g. take different time day season pose significant challenge to scene reconstruction novel view synthesis recent adaptation neural radiance field nerf 3d gaussian splatting 3dgs have improve area tend to oversmooth be prone overfitte paper present ms gs novel framework design multi appearance capability sparse view scenario use 3dgs to address lack support sparse initialization approach be build geometric prior elicit monocular depth estimation key lie extract utilize local semantic region structure motion sfm point anchor algorithm reliable alignment geometry cue then to introduce multi view constraint propose series geometry guide supervision virtual view fine grain coarse scheme to encourage 3d consistency reduce overfitting also introduce dataset wild experiment set to set more realistic benchmark demonstrate ms gs achieve photorealistic rendering various challenge sparse view multi appearance condition outperform exist approach significantly different dataset,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15546,enhance sa2va referent video object segmentation 2nd solution 7th lsvos rvos track,"Ran Hong, Feng Lu, Leilei Cao, An Yan, Youhai Jiang, Fengjie Zhu",referential video object segmentation rvos aim to segment object video match give natural language description bridge gap vision language understand recent work such sa2va combine large language models llms sam 2 leverage strong video reason capability llms to guide video segmentation work present train free framework substantially improve sa2va ’s performance rvos task method introduce two key component 1 video language checker explicitly verify subject action describe query actually appear video thereby reduce false positive 2 key frame sampler adaptively select informative frame to well capture early object appearance long range temporal context additional train approach achieve 𝒥&ℱ\mathcal{j}\&\mathcal{f score 64.14 mevis test set rank 2nd place rvos track 7th lsvos challenge iccv 2025,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15540,word enhance desire emotion sentiment recognition non verbal cues,"Wei Chen, Tongguan Wang, Feiyue Xue, Junkai Li, Hui Liu, Ying Sha",desire intention drive human behavior be closely relate emotion sentiment multimodal learn have advance sentiment emotion recognition multimodal approach specially target human desire understand remain underexplored exist method sentiment analysis predominantly emphasize verbal cue overlook image complementary non verbal cue to address gap propose symmetrical bidirectional multimodal learning framework desire emotion sentiment recognition enforce mutual guidance text image modality to effectively capture intention relate representation image specifically low resolution image be use to obtain global visual representation cross modal alignment high resolution image be partition sub image model mask image model to enhance ability to capture fine grain local feature text guide image decoder image guide text decoder be introduce to facilitate deep cross modal interaction local global representation image information additionally to balance perceptual gain computation cost mix scale image strategy be adopt high resolution image be crop sub image mask model propose approach be evaluate msed multimodal dataset include desire understand benchmark as well emotion sentiment recognition experimental result indicate consistent improvement other state art method validate effectiveness propose method specifically method outperform exist approach achieve f1 score improvement 1.1 desire understand 0.6 emotion recognition 0.9 sentiment analysis code be available https://github.com/especiallyw/sydes,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15536,sampo scale wise autoregression motion prompt generative world model,"Sen Wang, Jingyi Tian, Le Wang, Zhimin Liao, Jiayi Li, Huaiyi Dong, Kun Xia, Sanping Zhou, Wei Tang, Hua Gang",world model allow agent to simulate consequence action imagine environment plan control long horizon decision make however exist autoregressive world model struggle visually coherent prediction due disrupt spatial structure inefficient decode inadequate motion model response propose scale wise autoregression motion prompt sampo hybrid framework combine visual autoregressive model intra frame generation causal model next frame generation specifically sampo integrate temporal causal decode bidirectional spatial attention preserve spatial locality support parallel decode scale design significantly enhance temporal consistency rollout efficiency to far improve dynamic scene understand devise asymmetric multi scale tokenizer preserve spatial detail observe frame extract compact dynamic representation future frame optimize memory usage model performance additionally introduce trajectory aware motion prompt module inject spatiotemporal cue object robot trajectory focus attention dynamic region improve temporal consistency physical realism extensive experiment show sampo achieve competitive performance action condition video prediction model base control improve generation quality 4.4×\times fast inference also evaluate sampo ’s zero shot generalization scale behavior demonstrate ability to generalize unseen task benefit large model size,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15532,gui arp enhance grounding adaptive region perception gui agents,"Xianhang Ye, Yiqing Li, Wei Dai, Miancan Liu, Ziyuan Chen, Zhangye Han, Hongbo Min, Jinkui Ren, Xiantao Zhang, Wen Yang, Zhi Jin",exist gui ground method often struggle fine grain localization high resolution screenshot to address propose gui arp novel framework enable adaptive multi stage inference equip propose adaptive region perception arp adaptive stage controlling asc gui arp dynamically exploit visual attention crop task‑relevant region adapt inference strategy perform single stage inference simple case multi stage analysis more complex scenario be achieve two phase train pipeline integrate supervise fine tune reinforcement fine tune base group relative policy optimization grpo extensive experiment demonstrate propose gui arp achieve state art performance challenge gui ground benchmark 7b model reach 60.8%60.8\% accuracy screenspot pro 30.9%30.9\% ui vision benchmark notably gui arp-7b demonstrate strong competitiveness open source 72b model ui tars-72b 38.1%38.1\% proprietary model,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15514,mec quant maximum entropy code extremely low bit quantization aware training,"Junbiao Pang, Tianyang Cai, Baochang Zhang",quantization aware training qat have drive much attention to produce efficient neural network current qat still obtain inferior performance compare full precision fp counterpart work argue quantization inevitably introduce bias learn representation especially extremely low bit set to cope issue propose maximum entropy coding quantization mec quant more principled objective explicitly optimize structure representation learn representation be less bias thus generalize well unseen distribution sample to make objective end end trainable propose to leverage minimal code length lossy datum cod computationally tractable surrogate entropy far derive scalable reformulation objective base mixture experts moe not only allow fast computation also handle long tail distribution weight activation value extensive experiment various task computer vision task prove superiority mec qaunt limit qat be push x bit activation first time accuracy mec quant be comparable even surpass fp counterpart bell whistle mec qaunt establish new state art qat code be available https url have be integrate mqbench https url,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15497,backdoor mitigation invertible pruning masks,"Kealan Dunnett, Reza Arablouei, Dimity Miller, Volkan Dedeoglu, Raja Jurdak",model prune have gain traction promise defense strategy backdoor attack deep learn however exist prune base approach often fall short accurately identify remove specific parameter responsible induce backdoor behavior dominance fine tune base defense recent literature largely due superior performance prune remain compel alternative offer great interpretability improve robustness low data regime paper propose novel prune approach feature learn selection mechanism to identify parameter critical main backdoor task invertible prune mask design to simultaneously achieve two complementary goal eliminate backdoor task preserve inverse mask formulate bi level optimization problem jointly learn selection variable sparse invertible mask sample specific backdoor perturbation derive clean datum inner problem synthesize candidate trigger use inverse mask outer problem refine mask to suppress backdoor behavior impair clean task accuracy extensive experiment demonstrate approach outperform exist prune base backdoor mitigation approach maintain strong performance limit datum condition achieve competitive result compare state art fine tune approach notably propose approach be particularly effective restore correct prediction compromise sample successful backdoor mitigation,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15496,lynx high fidelity personalized video generation,"Shen Sang, Tiancheng Zhi, Tianpei Gu, Jing Liu, Linjie Luo",present lynx high fidelity model personalize video synthesis single input image build open source diffusion transformer dit foundation model lynx introduce two lightweight adapter to ensure identity fidelity id adapter employ perceiver resampler to convert arcface derive facial embedding compact identity token condition ref adapter integrate dense vae feature frozen reference pathway inject fine grain detail transformer layer cross attention module collectively enable robust identity preservation maintain temporal coherence visual realism evaluation curated benchmark 40 subject 20 unbiased prompt yield 800 test case lynx have demonstrate superior face resemblance competitive prompt follow strong video quality thereby advance state personalize video generation,Computer Vision and Pattern Recognition,19/09/2025
10.48550/arXiv.2509.15490,smolrgpt efficient spatial reasoning warehouse environments 600 m parameters,"Abdarahmane Traore, Éric Hervet, Andy Couturier",recent advance vision language model vlms have enable powerful multimodal reason state art approach typically rely extremely large model prohibitive computational memory requirement make deployment challenge resource constrain environment such warehouse robotic industrial application efficiency robust spatial understand be critical work present smolrgpt compact vision language architecture explicitly incorporate region level spatial reason integrate rgb depth cue smolrgpt employ three stage curriculum progressively align visual language feature enable spatial relationship understand adapt task specific dataset demonstrate only 600 m parameter smolrgpt achieve competitive result challenge warehouse spatial reason benchmark match exceed performance much large alternative finding highlight potential efficient deployable multimodal intelligence real world setting sacrifice core spatial reason capability code experimentation will be available https://github.com/abtraore/smolrgpt,Computer Vision and Pattern Recognition,18/09/2025
10.48550/arXiv.2509.15482,compare computational pathology foundation models use representational similarity analysis,"Vaibhav Mishra, William Lotter",foundation model be increasingly develop computational pathology cpath give promise facilitate many downstream task recent study have evaluate task performance model less be know structure variability learn representation here systematically analyze representational space six cpath foundation model use technique popularize computational neuroscience model analyze span vision language contrastive learn conch plip keep self distillation uni v2 virchow v2 prov gigapath approach representational similarity analysis use h&e image patch tcga find uni2 virchow2 have most distinct representational structure prov gigapath have high average similarity model have same train paradigm vision only vision language do not guarantee high representational similarity representation model show high slide dependence relatively low disease dependence stain normalization decrease slide dependence model range 5.5 conch 20.5 plip term intrinsic dimensionality vision language model demonstrate relatively compact representation compare more distribute representation vision only model finding highlight opportunity to improve robustness slide specific feature inform model ensembling strategy provide insight train paradigm shape model representation framework be extendable medical image domain probe internal representation foundation model can help ensure effective development deployment,Computer Vision and Pattern Recognition,18/09/2025
10.48550/arXiv.2509.15479,openviga video generation automotive driving scene streamlining fine tuning open source models public data,"Björn Möller, Zhengyang Li, Malte Stelzer, Thomas Graave, Fabian Bettels, Muaaz Ataya, Tim Fingscheidt",recent successful video generation system predict create realistic automotive drive scene short video input assign tokenization future state prediction world model video decode dedicate model approach often utilize large model require significant train resource offer limit insight design choice lack publicly available code dataset work address deficiency present openviga open video generation system automotive drive scene contribution be several early work video generation such gaia-1 provide deep analysis three component system separate quantitative qualitative evaluation image tokenizer world model video decoder second purely build powerful pre train open source model various domain fine tune publicly available automotive datum bdd100 k gpu hardware academic scale third build coherent video generation system streamline interface component fourth public availability underlie model datum allow full reproducibility finally also publish code model github111https://github.com/ifnspaml/openviga image size 256x256 4 fps be able to predict realistic drive scene video frame frame only one frame algorithmic latency,Computer Vision and Pattern Recognition,18/09/2025
10.48550/arXiv.2509.15472,efficient multimodal dataset distillation generative models,"Zhenghao Zhao, Haoxuan Wang, Junyi Wu, Yuzhang Shang, Gaowen Liu, Yan Yan",dataset distillation aim to synthesize small dataset large dataset enable model train to perform well original dataset bloom large language model multimodal large language model importance multimodal dataset particularly image text dataset have grow significantly however exist multimodal dataset distillation method be constrain matching training trajectories algorithm significantly increase compute resource requirement take day to process distillation work introduce edge generative distillation method efficient multimodal dataset distillation specifically identify two key challenge distil multimodal dataset generative model 1 lack correlation generate image caption 2 lack diversity generate sample to address aforementioned issue propose novel generative model train workflow bi directional contrastive loss diversity loss furthermore propose caption synthesis strategy to far improve text image retrieval performance introduce more text information method be evaluate flickr30 k coco cc3 m dataset demonstrate superior performance efficiency compare exist approach notably method achieve result 18×\time fast state art method code will be make public https://github.com/ichbill/edge,Computer Vision and Pattern Recognition,18/09/2025
10.48550/arXiv.2509.15459,cage continuity aware edge network unlock robust floorplan reconstruction,"Yiyi Liu, Chunyang Liu, Weiqin Jiao, Bojian Wu, Fashuai Li, Biao Xiong",present cage continuity aware edge network end end framework reconstruct vector floorplan directly point cloud density map traditional corner base polygon representation be highly sensitive noise incomplete observation often result fragment implausible layout recent line group method leverage structural cue to improve robustness still struggle to recover fine geometric detail to address limitation propose native edge centric formulation model wall segment direct geometrically continuous edge representation enable inference coherent floorplan structure ensure watertight topologically valid room boundary improve robustness reduce artifact design develop dual query transformer decoder integrate perturb latent query denoising framework not only stabilize optimization also accelerate convergence extensive experiment structured3d scenecad show cage achieve state art performance f1 score 99.1 room 91.7 corner 89.3 angle method also demonstrate strong cross dataset generalization underscore efficacy architectural innovation code pretraine model will be release acceptance,Computer Vision and Pattern Recognition,18/09/2025
10.48550/arXiv.2509.15436,region aware deformable convolutions,"Abolfazl Saheban Maleki, Maryam Imani",introduce region aware deformable convolution rad conv new convolutional operator enhance neural network ability to adapt complex image structure traditional deformable convolution be limit fix quadrilateral sample area rad conv use four boundary offset kernel element to create flexible rectangular region dynamically adjust size shape to match image content approach allow precise control receptive field ’s width height enable capture local detail long range dependency even small 1x1 kernel decouple receptive field ’s shape kernel ’s structure rad conv combine adaptability attention mechanism efficiency standard convolution innovative design offer practical solution build more expressive efficient vision model bridge gap rigid convolutional architecture computationally costly attention base method,Computer Vision and Pattern Recognition,18/09/2025
10.48550/arXiv.2509.15435,orca agentic reasoning hallucination adversarial robustness vision language models,"Chung-En Johnny Yu, Hsuan-Chih, Chen, Brian Jalaian, Nathaniel D. Bastian",large vision language models lvlms exhibit strong multimodal capability remain vulnerable hallucination intrinsic error adversarial attack external exploitation limit reliability real world application present orca agentic reason framework improve factual accuracy adversarial robustness pretrained lvlms test time structure inference reason suite small vision model ≤\leq3b parameter orca operate observe reason critique act loop query multiple visual tool evidential question validate cross model inconsistency refine prediction iteratively access model internal retrain orca also store intermediate reason trace support auditable decision make design primarily to mitigate object level hallucination orca also exhibit emergent adversarial robustness require adversarial train defense mechanism evaluate orca three setting 1 clean image hallucination benchmark 2 adversarially perturb image defense 3 adversarially perturb image defense apply pope hallucination benchmark orca improve standalone lvlms performance +3.64 +40.67 different subset adversarial perturbation pope orca achieve average accuracy gain +20.11 lvlms combine defense technique adversarially perturb amber image orca far improve standalone lvlm performance gain range +1.20 +48.00 evaluation metric result demonstrate orca offer promise path build more reliable robust multimodal system,Computer Vision and Pattern Recognition,18/09/2025
10.48550/arXiv.2509.15416,neurorad fm foundation model neuro oncology distributionally robust training,"Moinak Bhattacharya, Angelica P. Kurtz, Fabio M. Iwamoto, Prateek Prasanna, Gagandeep Singh",background neuro oncology present unique challenge machine learn heterogeneous datum distribution biological complexity brain tumor result generalize foundation model fm diverse cohort remain difficult further limitation be poor performance exist fm predict uncommon molecular marker area critical treatment response assessment risk stratification to address gap propose fm incorporate distributionally robust loss function enable accurate estimation tumor specific phenotype maintain strong generalization institution,Computer Vision and Pattern Recognition,18/09/2025
10.48550/arXiv.2509.15406,causal fingerprint ai generative models,"Hui Xu, Chi Liu, Congcong Zhu, Minghao Wang, Youyang Qu, Longxiang Gao",ai generative model leave implicit trace generate image be commonly refer model fingerprint be exploit source attribution prior method rely model specific cue synthesis artifact yield limit fingerprint may generalize poorly different generative model argue complete model fingerprint should reflect causality image provenance model trace direction largely unexplored end conceptualize causal fingerprint generative model propose causality decouple framework disentangle image specific content style semantic invariant latent space derive pre train diffusion reconstruction residual far enhance fingerprint granularity diverse feature representation validate causality assess attribution performance representative gan diffusion model achieve source anonymization use counterfactual example generate causal fingerprint experiment show approach outperform exist method model attribution indicate strong potential forgery detection model copyright trace identity protection,Computer Vision and Pattern Recognition,18/09/2025
10.48550/arXiv.2509.15393,generate part base global explanation via correspondence,"Kunal Rathore, Prasad Tadepalli",deep learn model be notoriously opaque exist explanation method often focus localize visual explanation individual image concept base explanation offer global insight require extensive annotation incur significant label cost propose approach leverage user define part label limit set image efficiently transfer large dataset enable generation global symbolic explanation aggregate part base local explanation ultimately provide human understandable explanation model decision large scale,Computer Vision and Pattern Recognition,18/09/2025
10.48550/arXiv.2509.15391,racegan framework preserve individuality convert racial information image image translation,"Mst Tasnim Pervin, George Bebis, Fang Jiang, Alireza Tavakkoli",generative adversarial network gan have demonstrate significant progress unpaired image image translation recent year several application cyclegan be first to lead way be restrict pair domain stargan overcome constraint tackle image image translation various domain be not able to map depth low level style change domain style map reference guide image synthesis have be make possible innovation starganv2 stylegan however model do not maintain individuality need extra reference image addition input study aim to translate racial trait mean multi domain image image translation present racegan novel framework capable map style code several domain racial attribute translation maintain individuality high level semantic rely reference image racegan outperform other model translate racial feature i.e. asian white black test chicago face dataset also give quantitative finding utilize inceptionrenetv2 base classification to demonstrate effectiveness racial translation moreover investigate well model partition latent space distinct cluster face ethnic group,Computer Vision and Pattern Recognition,18/09/2025
10.48550/arXiv.2509.15357,maskattn sdxl controllable region level text image generation,"Yu Chang, Jiahao Chen, Anzhe Cheng, Paul Bogdan",text image diffusion model achieve impressive realism often suffer compositional failure prompt multiple object attribute spatial relation result cross token interference entity entangle attribute mix object spatial cue be violate to address failure propose maskattn sdxl region level gate mechanism apply cross attention logit stable diffusion xl(sdxl ’s unet maskattn sdxl learn binary mask layer inject cross attention logit map softmax to sparsify token latent interaction only semantically relevant connection remain active method require positional encoding auxiliary token external region mask preserve original inference path negligible overhead practice model improve spatial compliance attribute bind multi object prompt preserve overall image quality diversity finding demonstrate logit level makse cross attention be data efficient primitve enforce compositional control method thus serve practical extension spatial control text image generation,Computer Vision and Pattern Recognition,18/09/2025
10.48550/arXiv.2509.15342,lowdiff efficient diffusion sampling low resolution condition,"Jiuyi Xu, Qing Jin, Meida Chen, Andrew Feng, Yang Sui, Yangming Shi",diffusion model have achieve remarkable success image generation practical application be often hinder slow sample speed prior effort improve efficiency primarily focus compress model reduce total number denoising step largely neglect possibility to leverage multiple input resolution generation process work propose lowdiff novel efficient diffusion framework base cascade approach generate increasingly high resolution output besides lowdiff employ unify model to progressively refine image low resolution desire resolution propose architecture design generation technique achieve comparable even superior performance much few high resolution sample step lowdiff be applicable diffusion model pixel space latent space extensive experiment conditional unconditional generation task cifar-10 ffhq imagenet demonstrate effectiveness generality method result show 50 throughput improvement dataset setting maintain comparable well quality unconditional cifar-10 lowdiff achieve fid 2.11 be 9.87 conditional cifar-10 fid 1.94 be 10.03 ffhq 64×64 lowdiff achieve fid 2.43 imagenet 256×256 lowdiff build lightningdit b/1 produce high quality sample fid 4.00 is 195.06 together substantial efficiency gain,Computer Vision and Pattern Recognition,18/09/2025
10.48550/arXiv.2509.15333,emulate human like adaptive vision efficient flexible machine visual perception,"Yulin Wang, Yang Yue, Yang Yue, Huanqian Wang, Haojun Jiang, Yizeng Han, Zanlin Ni, Yifan Pu, Minglei Shi, Rui Lu, Qisen Yang, Andrew Zhao, Zhuofan Xia, Shiji Song, Gao Huang",nan,Computer Vision and Pattern Recognition,18/09/2025
10.48550/arXiv.2509.15330,codol conditional domain prompt learning out distribution generalization,"Min Zhang, Bo Jiang, Jie Zhou, Yimeng Liu, Xin Lin",recent advance pre train vision language model vlms e.g. contrastive language image pre train clip method have show great potential learn distribution ood representation show competitive performance prompt base clip method still suffer i inaccurate text description lead degrade accuracy robustness pose challenge zero shot clip method ii limit vision language embed alignment significantly affect generalization performance to tackle above issue paper propose novel conditional domain prompt learning codol method utilize readily available domain information to form prompt improve vision language embed alignment improve ood generalization to capture instance specific domain specific information far propose lightweight domain meta network dmn to generate input conditional token image domain extensive experiment four ood benchmark pacs vlcs officehome digitdg validate effectiveness propose codol term improve vision language embed alignment as well out distribution generalization performance,Computer Vision and Pattern Recognition,18/09/2025
10.48550/arXiv.2509.15293,good be foundation models step step embodied reasoning,"Dinura Dissanayake, Ahmed Heakl, Omkar Thawakar, Noor Ahsan, Ritesh Thawkar, Ketan More, Jean Lahoud, Rao Anwer, Hisham Cholakkal, Ivan Laptev, Fahad Shahbaz Khan, Salman Khan",embody agent operate physical world must make decision be not only effective also safe spatially coherent ground context recent advance large multimodal model lmms have show promise capability visual understand language generation ability to perform structure reason real world embody task remain underexplored work aim to understand well foundation model can perform step step reason embody environment end propose foundation model embodied reasoning fomer benchmark design to evaluate reason capability lmms complex embody decision make scenario benchmark span diverse set task require agent to interpret multimodal observation reason physical constraint safety generate valid next action natural language present i large scale curated suite embody reason task ii novel evaluation framework disentangle perceptual ground action reason iii empirical analysis several lead lmm set benchmark include 1.1k sample detail step step reason 10 task 8 embodiment cover three different robot type result highlight potential current limitation lmms embody reason point key challenge opportunity future research robot intelligence benchmark be publicly available https://mbzuai-oryx.github.io/fomer-bench/,Computer Vision and Pattern Recognition,18/09/2025
10.48550/arXiv.2509.15272,direction to choose analysis representation power self supervised vits downstream tasks,"Yannis Kaltampanidis, Alexandros Doumanoglou, Dimitrios Zarpalas",self supervised learning ssl vision transformers vits have recently demonstrate considerable potential pre train strategy variety computer vision task include image classification segmentation standard few shoot downstream context two pre train objective dominate landscape ssl technique contrastive learning masked image modeling feature token extract final transformer attention block specifically key query value as well feature obtain final block ’s fee forward layer have become common foundation address downstream task however many exist approach pre train vit feature be far process additional transformation layer often involve lightweight head combine distillation to achieve superior task performance such method can improve task outcome good knowledge comprehensive analysis intrinsic representation capability unaltered vit feature have yet to be conduct study aim to bridge gap systematically evaluate use unmodified feature image classification segmentation task standard few shot context classification segmentation rule use be hyperplane base logistic regression cosine similarity base rely presence interpretable direction vit ’s latent space base previous rule use additional feature transformation conduct analysis token type task pre train vit model study provide insight optimal choice token type decision rule base task context pre train objective report detail finding two widely use dataset,Computer Vision and Pattern Recognition,18/09/2025
10.48550/arXiv.2509.15271,large vision models can solve mental rotation problem,"Sebastian Ray Mason, Anders Gjølbye, Phillip Chavarria Højbjerg, Lenka Tětková, Lars Kai Hansen",mental rotation be key test spatial reason human have be central understand perception support cognition success modern vision transformer be still unclear well model develop similar ability work present systematic evaluation vit clip dinov2 dinov3 range mental rotation task simple block structure similar use shepard metzler to study human cognition more complex block figure three type text photo realistic object probe model representation layer layer examine network succeed find i self supervise vits capture geometric structure well supervise vits ii intermediate layer perform well final layer iii task difficulty increase rotation complexity occlusion mirror human reaction time suggest similar constraint embed space representation,Computer Vision and Pattern Recognition,18/09/2025
10.48550/arXiv.2509.15270,prism phase enhance radial base image signature mapping framework fingerprint ai generate image,"Emanuele Ricco, Elia Onofri, Lorenzo Cima, Stefano Cresci, Roberto Di Pietro","critical need have emerge generative ai attribution method that is solution can identify model originate ai generate content feature generally relevant multimodal application be especially sensitive commercial setting user subscribe pay proprietary service expect guarantee source content receive to address issue introduce prism scalable phase enhance radial base image signature mapping framework fingerprint ai generate image prism be base radial reduction discrete fourier transform leverage amplitude phase information to capture model specific signature output above process be subsequently cluster linear discriminant analysis to achieve reliable model attribution diverse setting even model ’s internal detail be inaccessible to support work construct prism-36 k novel dataset 36,000 image generate six text image gan- diffusion base model dataset prism achieve attribution accuracy 92.04 additionally evaluate method four benchmark literature reach average accuracy 81.60%81.60\% finally evaluate methodology also binary task detect real fake image achieve average accuracy 88.41 obtain good result genimage accuracy 95.06 original benchmark achieve 82.20 result demonstrate effectiveness frequency domain fingerprint cross architecture cross dataset model attribution offer viable solution enforce accountability trust generative ai system",Computer Vision and Pattern Recognition,18/09/2025
10.48550/arXiv.2509.15267,autoguided online data curation diffusion model training,"Valeria Pais, Luis Oala, Daniele Faccio, Marco Aversa",cost generative model compute rekindle promise hope efficient datum curation work investigate recently develop autoguidance online datum selection method can improve time sample efficiency train generative diffusion model integrate joint example selection jest autoguidance unify code base fast ablation benchmarking evaluate combination datum curation control 2​-d2\text{-d synthetic datum generation task as well 3×642)​-d(3\times 64^{2})\text{-d image generation comparison be make equal wall clock time equal number sample explicitly account overhead selection experiment autoguidance consistently improve sample quality diversity early ajest apply selection only begin train can match modestly exceed autoguidance alone data efficiency task however time overhead add complexity make autoguidance uniform random datum selection preferable most situation finding suggest target online selection can yield efficiency gain early train robust sample quality improvement be primarily drive autoguidance discuss limitation scope outline datum selection may be beneficial,Computer Vision and Pattern Recognition,18/09/2025
10.48550/arXiv.2509.16052,exclusive be ethereum transaction evidence non win block,"Vabuk Pahari, Andrea Canidio","analyze 15,097 block propose inclusion ethereum ’s blockchain 8 minute window december 3 2024 38 block be add chain classify transaction exclusive present only block single builder private absent public mempool include block multiple builder find exclusive transaction account 84 total fee pay transaction win block furthermore show exclusivity can not be fully explain exclusive relationship sender builder about 7 exclusive transaction include chain value come sender route exclusively single builder analyze transaction log show exclusive transaction be duplicate variation same strategy even account share total fee pay transaction win block be least 77.2 take together finding highlight exclusive transaction be dominant source builder revenue",Cryptography and Security,19/09/2025
10.48550/arXiv.2509.16038,concap practical network traffic generation flow base intrusion detection systems,"Miel Verkerken, Laurens D'hooge, Bruno Volckaert, Filip De Turck, Giovanni Apruzzese",network intrusion detection systems nids have be study research almost four decade yet thousand paper claim scientific advance non negligible number recent work suggest finding prior literature may be questionable root disagreement be well know challenge obtain datum representative real world network hence usable security assessment,Cryptography and Security,19/09/2025
10.48550/arXiv.2509.16030,high performance real time container file monitoring approach base virtual machine introspection,"Kai Tan, Dongyang Zhan, Lin Ye, Hongli Zhang, Binxing Fang, Zhihong Tian",cloud compute continue to advance become integral part modern it infrastructure container security have emerge critical factor ensure smooth operation cloud native application attacker can attack service container even perform container escape attack tamper file monitor container file be important apt detection cyberspace security exist file monitor method be usually base host operate system virtual machine introspection to protect file security real time method base host operate system usually monitor file operation host operate system however container escape host host operate system will no long be secure method face problem weak security method base virtual machine introspection usually monitor file operation virtual machine real time virtual machine monitor layer strong isolation ability hypervisor compare file monitor base host operate system monitor program virtual machine monitor layer be more secure however virtual machine introspection technology usually introduce high real time monitor overhead aim problem low security high overload introduce exist container file monitor high performance container file monitor method base virtual machine introspection be propose base container vm architecture virtual machine introspection technology be use to monitor vm container file base isolation capability hypervisor security problem security monitor introduce container escape attack can be address to reduce monitor overload introduce file monitor base virtual machine introspection container scenario high performance real time file monitor method base memory monitor be propose analyze container file system independent memory area be initialize to store memory cache monitor container file then virtual machine introspection technology be use to monitor target memory area to capture analyze access operation target file monitor file be store separate memory area monitor will not affect read write performance other file container experimental result show propose approach can effectively monitor container file introduce acceptable monitor overload,Cryptography and Security,19/09/2025
10.48550/arXiv.2509.15756,adversarial robust behavior sequence anomaly detection approach base critical behavior unit learning,"Dongyang Zhan, Kai Tan, Lin Ye, Xiangzhan Yu, Hongli Zhang, Zheng He",sequential deep learn model e.g. rnn lstm can learn sequence feature software behavior such api syscall sequence however recent study have show deep learn base approach be vulnerable adversarial sample attacker can use adversarial sample to change sequential characteristic behavior sequence mislead malware classifier paper adversarial robustness anomaly detection method base analysis behavior unit be propose to overcome problem extract relate behavior usually perform behavior intention behavior unit contain representative semantic information local behavior can be use to improve robustness behavior analysis learn overall semantic behavior unit contextual relationship behavior unit base multilevel deep learn model approach can mitigate perturbation attack target local large scale behavior addition approach can be apply low level high level behavior log e.g. api syscall log experimental result show approach outperform compare method indicate approach have well performance obfuscation attack,Cryptography and Security,19/09/2025
10.48550/arXiv.2509.15694,inference attacks encrypted online voting traffic analysis,"Anastasiia Belousova, Francesco Marchiori, Mauro Conti",online vote enable individual to participate election remotely offer great efficiency accessibility governmental organizational setting method gain popularity ensure security online vote system become increasingly vital system support must satisfy demand set security requirement most research area emphasize design verification cryptographic protocol to protect voter integrity system confidentiality however other vector such network traffic analysis remain relatively understudy even may pose significant threat voter privacy overall trustworthiness system,Cryptography and Security,19/09/2025
10.48550/arXiv.2509.15653,future proofing cloud security quantum attacks risk transition mitigation strategy,"Yaser Baseri, Abdelhakim Hafid, Arash Habibi Lashkari",quantum computing qc introduce transformative threat digital security potential to compromise widely deploy classical cryptographic system survey offer comprehensive systematic examination quantum safe security cloud computing cc focus vulnerability transition strategy mitigation mechanism require to secure cloud infrastructure quantum era evaluate landscape quantum threat entire cc stack demonstrate quantum algorithm can undermine classical encryption compromise cloud security multiple architectural layer use structure risk assessment methodology base stride model evaluate quantum induce attack vector impact cloud environment to address challenge propose layer security framework integrate hybrid cryptographic transition strategy cryptographic agility proactive risk mitigation analyze preparation implementation approach major cloud service providers csps include aws azure gcp synthesize platform specific initiative post quantum cryptography pqc furthermore provide detail evaluation standardize pqc algorithm explore resilience side channel active attack cloud native deployment survey serve strategic reference cloud architect policymaker researcher offer actionable insight navigate complex transition quantum resilient cloud system conclude identify six key future research direction standardization interoperability performance scalability implementation security integration emerge technology systemic preparedness crypto agile migration framework,Cryptography and Security,19/09/2025
10.48550/arXiv.2509.15572,cuckoo attack stealthy persistent attacks ai ide,"Xinpeng Liu, Junming Liu, Peiyu Liu, Han Zheng, Qinying Wang, Mathias Payer, Shouling Ji, Wenhai Wang",modern ai power integrated development environments ai ide be increasingly define agent centric architecture llm power agent be deeply integrate to autonomously execute complex task tight integration however also introduce new critical attack surface attacker can exploit component inject malicious instruction untrusted external source effectively hijack agent to perform harmful operation user ’s intention awareness emerge threat have quickly attract research attention lead various propose attack vector such hijack model context protocol mcp server to access private datum however most exist approach lack stealth persistence limit practical impact,Cryptography and Security,19/09/2025
10.48550/arXiv.2509.15555,hybrid deep learning federated learning powered intrusion detection system iot/5 g advanced edge computing network,"Rasil Baidar, Sasa Maric, Robert Abbas",exponential expansion iot/5g advanced application have expand attack surface ddos malware zero day intrusion propose intrusion detection system fuse cnn bilstm autoencoder ae bottleneck privacy preserve federate learn fl framework cnn bilstm capture local gate cross feature interaction ae emphasize reconstruction base anomaly sensitivity training occur edge device share raw datum,Cryptography and Security,19/09/2025
10.48550/arXiv.2509.15547,fluid antenna system assist physical layer secret key generation,"Zhiyu Huang, Guyue Li, Hao Xu, Derrick Wing Kwan Ng",paper investigate physical layer key generation plkg multi antenna base station bs system leverage fluid antenna system fas to dynamically customize radio environment require additional node extensive radio frequency chain fas effectively enable adaptive antenna port selection exploit channel spatial correlation to enhance key generation rate kgr legitimate node to comprehensively evaluate efficiency fas plkg propose fas assist plkg model integrate transmit beamforming sparse port selection independent identically distribute i.i.d spatially correlate channel model respectively specifically plkg utilize reciprocal channel probe to derive close form kgr expression base mutual information legitimate channel estimate explicitly account eve ’s channel observation spatially correlate channel scenario nonconvex optimization problem scenario be formulate to maximize kgr subject to transmit power constraint sparse port activation propose iterative algorithm capitalize successive convex approximation sca cauchy schwarz inequality to obtain locally optimal solution reweighted ℓ1\ell_{1}-norm base algorithm be apply to advocate sparse port activation fas assist plkg to approximate optimal activate port obtain exhaustive search low complexity slide window base port selection be propose to substitute reweighted ℓ1\ell_{1}-norm method base rayleigh quotient analysis simulation result demonstrate fas plkg scheme significantly outperform fa plkg scheme independent spatially correlate environment furthermore slide window base port selection method introduce paper have be show to yield superior kgr compare reweighted ℓ1\ell_{1}-norm method be show fas achieve high kgr few rf chain dynamic sparse port selection effectively reduce resource overhead also slide window approach propose paper closely approximate globally optimal port selection compare reweighted ℓ1\ell_{1}-norm method render suitable practical deployment,Cryptography and Security,19/09/2025
10.48550/arXiv.2509.15499,adversarially robust assembly language model packed executables detection,"Shijia Li, Jiang Ming, Lanqing Liu, Longwei Yang, Ni Zhang, Chunfu Jia",detect pack executable be critical component large scale malware analysis antivirus engine workflow identify sample warrant computationally intensive dynamic unpack to reveal conceal malicious behavior traditionally packer detection technique have rely empirical feature such high entropy specific binary pattern however empirical feature base method be increasingly vulnerable evasion adversarial sample unknown packer e.g. low entropy packer furthermore dependence expert craft feature pose challenge sustain evolve method time,Cryptography and Security,19/09/2025
10.48550/arXiv.2509.16151,automated cyber defense generalizable graph base reinforcement learning agents,"Isaiah J. King, Benjamin Bowman, H. Howie Huang",deep reinforcement learn rl be emerge viable strategy automate cyber defense acd traditional rl approach represent network list computer various state safety threat unfortunately model be force to overfit specific network topology render ineffective face even small environmental perturbation work frame acd two player context base partially observable markov decision problem observation represent attribute graph approach allow agent to reason lens relational inductive bias agent learn to reason host interact other system entity more general manner action be understand edit graph represent environment introduce bias will show agent can well reason state network zero shot adapt new one show approach outperform state art wide margin make agent capable defend never before see network wide range adversary variety complex multi agent environment,Cryptography and Security,19/09/2025
10.48550/arXiv.2509.15437,impact phonetics speaker identity adversarial voice attack,"Daniyal Kabir Dar, Qiben Yan, Li Xiao, Arun Ross",adversarial perturbation speech pose serious threat automatic speech recognition asr speaker verification introduce subtle waveform modification remain imperceptible human can significantly alter system output target attack end end asr model have be widely study phonetic basis perturbation effect speaker identity remain underexplored work analyze adversarial audio phonetic level show perturbation exploit systematic confusion such vowel centralization consonant substitution distortion not only mislead transcription also degrade phonetic cue critical speaker verification lead identity drift use deepspeech asr target generate target adversarial example evaluate impact speaker embedding genuine impostor sample result 16 phonetically diverse target phrase demonstrate adversarial audio induce transcription error identity drift highlight need phonetic aware defense to ensure robustness asr speaker recognition system,Cryptography and Security,18/09/2025
10.48550/arXiv.2509.15213,evil vizier vulnerability llm integrated xr systems,"Yicheng Zhang, Zijian Huang, Sophie Chen, Erfan Shayegani, Jiasi Chen, Nael Abu-Ghazaleh",extend reality xr application increasingly integrate large language models llms to enhance user experience scene understand even generate executable xr content be often call ai glass potential benefit integrate xr llm pipeline make xr application vulnerable new form attack paper analyze llm integated xr system literature practice categorize different dimension system perspective build categorization identify common threat model demonstrate series proof concept attack multiple xr platform employ various llm model meta quest 3 meta ray ban android microsoft hololens 2 run llama gpt model platform implement llm integration differently share vulnerability attacker can modify public context surround legitimate llm query result erroneous visual auditory feedback user thus compromise safety privacy sow confusion other harmful effect to defend threat discuss mitigation strategy good practice developer include initial defense prototype call community to develop new protection mechanism to mitigate risk,Cryptography and Security,18/09/2025
10.48550/arXiv.2509.14987,blockchain enable explainable ai trusted healthcare systems,Md Talha Mohsin,paper introduce blockchain integrate explainable ai framework bxhf healthcare system to tackle two essential challenge confront health information network safe datum exchange comprehensible ai drive clinical decision make architecture incorporate blockchain ensure patient record be immutable auditable tamper proof explainable ai xai methodology yield transparent clinically relevant model prediction incorporate security assurance interpretability requirement unify optimization pipeline bxhf ensure datum level trust verify encrypt record share decision level trust auditable clinically align explanation hybrid edge cloud architecture allow federate computation different institution enable collaborative analytic protect patient privacy demonstrate framework ’s applicability use case such cross border clinical research network uncommon illness detection high risk intervention decision support ensure transparency auditability regulatory compliance bxhf improve credibility uptake effectiveness ai healthcare lay groundwork safe more reliable clinical decision make,Cryptography and Security,18/09/2025
10.48550/arXiv.2509.14754,variables ordering optimization boolean characteristic set method use simulated annealing machine learning base time prediction,"Minzhong Luo, Yudong Sun, Yin Long",solve system boolean equation be fundamental task symbolic computation algebraic cryptanalysis wide range application cryptography code theory formal verification exist approach boolean characteristic set bcs method[1 have emerge one most efficient algorithm tackle such problem however performance be highly sensitive order variable solve time vary drastically different ordering fix variable count nn equation size mm to address challenge paper introduce novel optimization framework synergistically integrate machine learn ml)-based time prediction simulate anneal sa to efficiently identify high performance variable ordering construct dataset comprise variable frequency spectrum xx correspond bcs solve time tt benchmark systems(e.g = m=28n m=28 utilize datum train accurate ml predictor ft​(x)f_{t}(x to estimate solve time give variable order target system ftf_{t serve cost function sa algorithm enable rapid discovery low latency ordering significantly expedite subsequent bcs execution extensive experiment demonstrate method substantially outperform standard bcs algorithm[1 gröbner basis method 2 sat solver[3 particularly large scale systems(e.g n=32n=32 furthermore derive probabilistic time complexity bound overall algorithm use stochastic process theory establish quantitative relationship predictor accuracy expect solve complexity work provide practical acceleration tool algebraic cryptanalysis theoretical foundation ml enhance combinatorial optimization symbolic computation,Cryptography and Security,18/09/2025
10.48550/arXiv.2509.14706,security analysis web application base gruyere,"Yonghao Ni, Zhongwen Li, Xiaoqi Li",rapid development internet technology web system have become essential infrastructure modern information exchange business operation however expansion numerous security vulnerability have emerge make web security critical research focus broad field cybersecurity issue be closely relate datum protection privacy preservation business continuity systematic research web security be crucial mitigate malicious attack enhance reliability robustness network system paper first review owasp top 10 summarize type cause impact common web vulnerability illustrate exploitation mechanism representative case build gruyere platform be adopt experimental subject analyze know vulnerability study present detail reproduction step specific vulnerability propose comprehensive remediation strategy far compare gruyere ’s vulnerability contemporary real world case finding suggest gruyere ’s vulnerability be relatively outdated underlie principle remain highly relevant explain wide range modern security flaw overall research demonstrate web system security analysis base gruyere not only deepen understand vulnerability mechanism also provide practical support technological innovation security defense,Cryptography and Security,18/09/2025
10.48550/arXiv.2509.14657,threat modeling enhancing security iot audio classification devices secure protocols framework,"Sergio Benlloch-Lopez, Miquel Viel-Vazquez, Javier Naranjo-Alcazar, Jordi Grau-Haro, Pedro Zuccarello",rapid proliferation iot node equip microphone capable perform device audio classification expose highly sensitive datum operate tight resource constraint to protect present defence depth architecture comprise security protocol treat edge device cellular network cloud backend three separate trust domain link tpm base remote attestation mutually authenticate tls 1.3 stride drive threat model attack tree analysis guide design startup boot stage be measure tpm pcrs node can only decrypt luks seal partition cloud have verify tpm quote release one time unlock key ensure rogue tamper device remain inert datum transit be protect tls 1.3 hybridise kyber dilithium to provide post quantum resilience meanwhile end end encryption integrity hash safeguard extract audio feature sign rollback protect ai model tamper responsive sensor harden firmware hardware datum rest follow 3 2 1 strategy comprise solid state drive seal luks offline cold archive encrypt hybrid post quantum cipher encrypt cloud replica finally set plan evaluate physical logical security propose protocol,Cryptography and Security,18/09/2025
10.48550/arXiv.2509.14622,adversarial distilled retrieval augmented guarding model online malicious intent detection,"Yihao Guo, Haocheng Bian, Liutong Zhou, Ze Wang, Zhaoyi Zhang, Francois Kawala, Milan Dean, Ian Fischer, Yuantao Peng, Noyan Tokgozoglu, Ivan Barrientos, Riyaaz Shaik, Rachel Li, Chandru Venkataraman, Reza Shifteh Far, Moses Pawar, Venkat Sundaranatha, Michael Xu, Frank Chu",deployment large language models llms interactive application online malicious intent detection have become increasingly critical however exist approach fall short handle diverse complex user query real time to address challenge introduce adrag adversarial distilled retrieval augmented guard two stage framework robust efficient online malicious intent detection train stage high capacity teacher model be train adversarially perturb retrieval augment input to learn robust decision boundary diverse complex user query inference stage distillation scheduler transfer teacher ’s knowledge compact student model continually update knowledge base collect online deployment compact student model leverage top kk similar safety exemplar retrieve online update knowledge base to enable online real time malicious query detection evaluation ten safety benchmark demonstrate adrag 149 m parameter model achieve 98.5 wildguard-7b ’s performance surpass gpt-4 3.3 llama guard-3 8b 9.5 distribution detection simultaneously deliver 5.6×\times low latency 300 query second qps real time application,Cryptography and Security,18/09/2025
10.48550/arXiv.2509.14608,enterprise ai must enforce participant aware access control,"Shashank Shreedhar Bhatt, Tanmay Rajore, Khushboo Aggarwal, Ganesh Ananthanarayanan, Ranveer Chandra, Nishanth Chandran, Suyash Choudhury, Divya Gupta, Emre Kiciman, Sumit Kumar Pandey, Srinath Setty, Rahul Sharma, Teijia Zhao",large language model llms be increasingly deploy enterprise setting interact multiple user be train fine tune sensitive internal datum fine tune enhance performance internalize domain knowledge also introduce critical security risk leakage confidential train datum unauthorized user risk be exacerbate llm be combine retrieval augmented generation rag pipeline dynamically fetch contextual document inference time,Cryptography and Security,18/09/2025
10.48550/arXiv.2509.14583,get measured gets manage mitigate supply chain attacks link integrity management system,"Johnny So, Michael Ferdman, Nick Nikiforakis",web continue to grow dependency monitor tool standard resource integrity lag behind currently exist robust method to verify integrity web resource much less generalizable yet performant manner supply chain remain one most target part attack surface web application,Cryptography and Security,18/09/2025
10.48550/arXiv.2509.14558,llm jailbreak detection almost free,"Guorui Chen, Yifan Xia, Xiaojun Jia, Zhijiang Li, Philip Torr, Jindong Gu",large language model llms enhance security alignment widely use remain susceptible jailbreak attack capable produce inappropriate content jailbreak detection method show promise mitigate jailbreak attack assistance other model multiple model inference however exist method entail significant computational cost paper first present find difference output distribution jailbreak benign prompt can be employ detect jailbreak prompt base find propose free jailbreak detection fjd 111https://github.com/guoruic/fjd prepend affirmative instruction input scale logit temperature to far distinguish jailbreak benign prompt confidence first token furthermore enhance detection performance fjd integration virtual instruction learn extensive experiment align llms show fjd can effectively detect jailbreak prompt almost additional computational cost llm inference,Cryptography and Security,18/09/2025
10.48550/arXiv.2509.14335,classification evaluate llm fine grained automatic malware behavior auditing,"Xinran Zheng, Xingzhi Qian, Yiling He, Shuo Yang, Lorenzo Cavallaro",automate malware classification approach have achieve tantalize detection performance yet malware behavior audit focus provide causal verifiable explanation malicious behavior fundamental to trust result translate actionable insight remain critical challenge automate system flag sample malware analyst must determine not only malware do also to substantiate such claim evidence task be particularly difficult practice adversarial intent be often conceal complex framework heavy application make manual audit slow costly bottleneck large language models llms may play pivotal role address gap usefulness audit task have largely remain unexplored due three main limitation 1 scarcity fine grain behavioral evidence annotation fair assessment 2 abundant benign code interfere malicious signal 3 untraceable unverifiable output hallucination undermine credibility behavioral attribution,Cryptography and Security,17/09/2025
10.48550/arXiv.2509.14297,simple efficient jailbreak method exploit llms helpfulness,"Xuan Luo, Yue Wang, Zefeng He, Geng Tu, Jing Li, Ruifeng Xu",safety alignment aim to prevent large language models llms respond harmful query to strengthen safety protection jailbreak method be develop to simulate malicious attack uncover vulnerability paper introduce hill hide intention learning llms novel jailbreak approach systematically transform imperative harmful request learn style question only straightforward hypotheticality indicator far introduce two new metric to thoroughly evaluate utility jailbreak method experiment advbench dataset wide range model demonstrate hill ’s strong effectiveness generalizability harmfulness achieve top attack success rate majority model malicious category maintain high efficiency concise prompt result various defense method show robustness hill most defense have mediocre effect even increase attack success rate moreover assessment construct safe prompt reveal inherent limitation llm safety mechanism flaw defense method work expose significant vulnerability safety measure learn style elicitation highlight critical challenge balance helpfulness safety alignment,Cryptography and Security,17/09/2025
10.48550/arXiv.2509.14285,multi agent llm defense pipeline prompt injection attacks,"S M Asif Hossain, Ruksat Khan Shayoni, Mohd Ruhul Ameen, Akif Islam, M. F. Mridha, Jungpil Shin",prompt injection attack represent major vulnerability large language model llm deployment malicious instruction embed user input can override system prompt induce unintended behavior paper present novel multi agent defense framework employ specialize llm agent coordinate pipeline to detect neutralize prompt injection attack real time evaluate approach use two distinct architecture sequential chain agent pipeline hierarchical coordinator base system comprehensive evaluation 55 unique prompt injection attack group 8 category total 400 attack instance two llm platform chatglm llama2 demonstrate significant security improvement defense mechanism baseline attack success rates asr reach 30 chatglm 20 llama2 multi agent pipeline achieve 100 mitigation reduce asr 0 test scenario framework demonstrate robustness multiple attack category include direct override code execution attempt datum exfiltration obfuscation technique maintain system functionality legitimate query,Cryptography and Security,16/09/2025
10.48550/arXiv.2509.14284,sum leaks more parts compositional privacy risks mitigations multi agent collaboration,"Vaidehi Patil, Elias Stengel-Eskin, Mohit Bansal",large language model llms become integral multi agent system new privacy risk emerge extend memorization direct inference single turn evaluation particular seemingly innocuous response compose interaction can cumulatively enable adversary to recover sensitive information phenomenon term compositional privacy leakage present first systematic study such compositional privacy leak possible mitigation method multi agent llm system first develop framework model auxiliary knowledge agent interaction jointly amplify privacy risk even response be benign isolation next to mitigate propose evaluate two defense strategy 1 theory mind defense tom defender agent infer questioner ’s intent anticipate output may be exploit adversary 2 collaborative consensus defense codef responder agent collaborate peer vote base share aggregate state to restrict sensitive information spread crucially balance evaluation composition expose sensitive information composition yield benign inference experiment quantify defense strategy differ balance privacy utility trade off find chain thought alone offer limit protection leakage ∼\sim39 sensitive block rate tom defense substantially improve sensitive query block up to 97 can reduce benign task success codef achieve good balance yield high balanced outcome 79.8 highlight benefit combine explicit reason defender collaboration together result expose new class risk collaborative llm deployment provide actionable insight design safeguard compositional context drive privacy leakage.111we make code datum publicly available https://github.com/vaidehi99/multiagentprivacy,Cryptography and Security,16/09/2025
10.48550/arXiv.2509.14282,resist quantum key distribution attacks use quantum machine learning,"Ali Al-kuwari, Noureldin Mohamed, Saif Al-kuwari, Ahmed Farouk, Bikash K. Behera",emergence quantum compute pose significant risk security modern communication network break today ’s public key cryptographic algorithm quantum key distribution qkd offer promise solution harness principle quantum mechanic to establish secure key however practical qkd implementation remain vulnerable hardware imperfection advance attack such photon number splitting trojan horse attack work investigate potential use quantum machine learn qml to detect popular qkd attack particular propose hybrid quantum long short term memory qlstm model to improve detection common qkd attack combine quantum enhance learn classical deep learn model capture complex temporal pattern qkd datum improve detection accuracy to evaluate propose model introduce realistic qkd dataset simulate normal qkd operation seven attack scenario intercept resend photon number splitting pns trojan horse attack random number generator rng detector blinding wavelength dependent trojan horse combined attack dataset include quantum security metric such quantum bit error rate qber measurement entropy signal decoy loss rate time base metric ensure accurate representation real world condition result demonstrate promise performance quantum machine learn approach compare traditional classical machine learn model highlight potential hybrid technique to enhance security future quantum communication network propose hybrid qlstm model achieve accuracy 93.7.0 50 train epoch outperform classical deep learn model such lstm cnn,Cryptography and Security,16/09/2025
10.48550/arXiv.2509.14278,data privacy new privacy risks large language models,"Yuntao Du, Zitao Li, Ninghui Li, Bolin Ding",large language models llms have achieve remarkable progress natural language understand reason autonomous decision make however advancement have also come significant privacy concern significant research have focus mitigate datum privacy risk llm various stage model train less attention have be pay new threat emerge deployment integration llms widely use application weaponization autonomous ability have create new privacy vulnerability vulnerability provide opportunity inadvertent datum leakage malicious exfiltration llm power system additionally adversary can exploit system to launch sophisticate large scale privacy attack threaten not only individual privacy also financial security societal trust paper systematically examine emerge privacy risk llm also discuss potential mitigation strategy call research community to broaden focus datum privacy risk develop new defense to address evolve threat pose increasingly powerful llm llm power system,Cryptography and Security,16/09/2025
10.48550/arXiv.2509.14275,fedmentor domain aware differential privacy heterogeneous federated llms mental health,"Nobin Sarwar, Shubhashis Roy Dipta",privacy preserve adaptation large language models llms sensitive domain e.g. mental health require balance strict confidentiality model utility safety propose fedmentor federate fine tune framework integrate low rank adaptation lora domain aware differential privacy dp to meet domain privacy budget maintain performance client domain apply custom dp noise scale proportional data sensitivity server adaptively reduce noise utility fall threshold experiment three mental health dataset show fedmentor improve safety standard federated learning privacy raise safe output rate to three point lower toxicity maintain utility bertscore f1 rouge l 0.5 non private baseline close centralize upper bind framework scale backbone to 1.7b parameter single gpu client require < 173<173 mb communication round fedmentor demonstrate practical approach privately fine tune llm safe deployment healthcare other sensitive field,Cryptography and Security,16/09/2025
10.48550/arXiv.2509.14271,early approach adversarial fine tuning prompt injection defense 2022 study gpt-3 contemporary models,"Gustavo Sandoval, Denys Fenchenko, Junyao Chen",paper document early research conduct 2022 defend prompt injection attack large language model provide historical context evolution critical security domain research focus two adversarial attack large language models llms prompt injection goal hijack examine to construct attack test various llm compare effectiveness propose evaluate novel defense technique call adversarial fine tuning result show defense attack succeed 31 time gpt-3 series model use adversarial fine tuning approach attack success rate be reduce zero small gpt-3 variant ada babbage curie note subsequent research have reveal limitation fine tune base defense also find more flexible model exhibit great vulnerability attack consequently large model such gpt-3 davinci be more vulnerable small model like gpt-2 specific model test be now supersede core methodology empirical finding contribute foundation modern prompt injection defense research include instruction hierarchy system constitutional ai approach,Cryptography and Security,15/09/2025
10.48550/arXiv.2509.15195,orion fuzzing workflow automation,"Max Bazalii, Marius Fleischer",fuzz test be one most effective technique find software vulnerability modern fuzzer can generate input monitor execution automatically overall workflow analyze codebase configure harness triage result still require substantial manual effort prior attempt focus single stage such harness synthesis input minimization leave researcher to manually connect piece complete fuzzing campaign,Cryptography and Security,18/09/2025
10.48550/arXiv.2509.14789,acoustic simulation framework multi channel replay speech detection,"Michael Neri, Tuomas Virtanen",replay speech attack pose significant threat voice control system especially smart environment voice assistant be widely deploy multi channel audio offer spatial cue can enhance replay detection robustness exist dataset method predominantly rely single channel recording work introduce acoustic simulation framework design to simulate multi channel replay speech configuration use publicly available resource setup model genuine spoof speech vary environment include realistic microphone loudspeaker impulse response room acoustic noise condition framework employ measure loudspeaker directionality replay attack to improve realism simulation define two spoof setting simulate reverberant anechoic speech be use replay scenario evaluate impact omnidirectional diffuse noise detection performance use state art m alrad model replay speech detection demonstrate synthetic datum can support generalization capability detector unseen enclosure,Cryptography and Security,18/09/2025
10.48550/arXiv.2509.14519,beacon behavioral malware classification large language model embeddings deep learning,"Wadduwage Shanika Perera, Haodi Jiang",malware be become increasingly complex widespread make essential to develop more effective timely detection method traditional static analysis often fail to defend modern threat employ code obfuscation polymorphism other evasion technique contrast behavioral malware detection monitor runtime activity provide more reliable context aware solution work propose beacon novel deep learn framework leverage large language model llms to generate dense contextual embedding raw sandbox generate behavior report embedding capture semantic structural pattern sample be process one dimensional convolutional neural network 1d cnn multi class malware classification evaluate avast ctu public cape dataset framework consistently outperform exist method highlight effectiveness llm base behavioral embedding overall design beacon robust malware classification,Cryptography and Security,18/09/2025
10.48550/arXiv.2509.14334,normalized square root sharper matrix factorization bounds differentially private continual counting,"Monika Henzinger, Nikita P. Kalinin, Jalaj Upadhyay",factorization norm low triangular one n×nn\time matrix γ2​(m𝖼𝗈𝗎𝗇𝗍)\gamma_{2}(m_{\mathsf{count γf​(m𝖼𝗈𝗎𝗇𝗍)\gamma_{\mathrm{f}}(m_{\mathsf{count play central role differential privacy be use to give theoretical justification accuracy only know production level private train algorithm deep neural network google prior work well know upper bind γ2​(m𝖼𝗈𝗎𝗇𝗍)\gamma_{2}(m_{\mathsf{count be 1+log⁡(n)π1+\tfrac{\log(n)}{\pi mathias linear algebra applications 1993 well know low bind be 1π​(2+log⁡(2​n+13))≈0.507+log⁡(n)π\tfrac{1}{\pi}\bigl(2+\log\bigl(\tfrac{2n+1}{3}\bigr)\bigr)\approx 0.507+\tfrac{\log(n)}{\pi matoušek nikolov talwar imrn 2020 log⁡(⋅)\log(\cdot be natural logarithm recently henzinger upadhyay soda 2025 give first explicit factorization meet bound mathias 1993 ask exist explicit factorization improve mathias bind answer question affirmative additionally improve lower bind significantly more specifically show,Cryptography and Security,17/09/2025
10.48550/arXiv.2509.14139,cybersecurity ai humanoid robots attack vector,Víctor Mayoral-Vilches,present systematic security assessment unitree g1 humanoid show operate simultaneously covert surveillance node can be purpose active cyber operation platform partial reverse engineer unitree ’s proprietary fmx encryption reveal static blowfish ecb layer predictable lcg mask enable inspection system ’s otherwise sophisticate security architecture most mature have observe commercial robotic two empirical case study expose critical risk humanoid robot a robot function trojan horse continuously exfiltrate multi modal sensor service state telemetry 43.175.228.18:17883 43.175.229.18:17883 300 second operator notice create violation gdpr articles 6 13 b resident cybersecurity ai cai agent can pivot reconnaissance offensive preparation target such manufacturer ’s cloud control plane demonstrate escalation passive monitor active counter operation finding argue adaptive cai power defense humanoid move critical infrastructure contribute empirical evidence need to shape future security standard physical cyber convergence system,Cryptography and Security,17/09/2025
10.48550/arXiv.2509.14096,cybersecurity humanoid robot,Víctor Mayoral-Vilches,rapid advancement humanoid robotic present unprecedented cybersecurity challenge exist theoretical framework fail to adequately address report present comprehensive security assessment production humanoid robot platform bridge gap abstract security model operational vulnerability systematic static analysis runtime observation cryptographic examination uncover complex security landscape characterize sophisticate defensive mechanism critical vulnerability,Cryptography and Security,17/09/2025
10.48550/arXiv.2509.14035,piquant$\varepsilon$ private quantile estimation two server model,"Hannah Keller, Jacob Imola, Fabrizio Boninsegna, Rasmus Pagh, Amrita Roy Chowdhury",quantile be key distribute analytic compute sensitive datum risk privacy local differential privacy ldp offer strong protection low accuracy central dp assume trust aggregator secure multi party computation mpc can bridge gap generic mpc solution face scalability challenge due large domain complex secure operation multi round interaction,Cryptography and Security,17/09/2025
10.48550/arXiv.2509.13987,differential privacy federated learning mitigate inference attacks randomized response,"Ozer Ozturk, Busra Buyuktanir, Gozde Karatas Baydogmus, Kazim Yildiz",machine learn model use distribute architecture consist server client require large amount datum to achieve high accuracy datum obtain client be collect central server model train however store datum central server raise concern security privacy to address issue federate learn architecture have be propose federate learn client train local model use own datum train model be periodically transmit central server server then combine receive model use federate aggregation algorithm to obtain global model global model be distribute back client process continue cyclical manner prevent datum leave client enhance security certain concern still remain attacker can perform inference attack obtain model to approximate train dataset potentially cause datum leakage study differential privacy be apply to address aforementioned security vulnerability performance analysis be conduct data unaware classification base association ducba algorithm be use federate aggregation method differential privacy be implement datum use randomized response technique trade off security performance be examine different epsilon value epsilon value decrease model accuracy decline class prediction imbalance be observe indicate high level privacy do not always lead practical outcome balance security performance must be carefully consider,Cryptography and Security,17/09/2025
10.48550/arXiv.2509.13788,homomorphic encryption scheme base code theory polynomial,Giovanni Giuseppe Grimaldi,homomorphic encryption be powerful cryptographic tool enable secure computation private datum evaluate function operation securely encrypt datum know correspond plaintext original datum pp cc denote ciphertext original plaintext pp i.e. c = e​n​c​r​y​p​tk​(p)c = encrypt_{k}(p be crucial sensitive application run cloud must protect datum privacy even case server have fall victim cyber attack encryption scheme e​n​c​r​y​p​tkencrypt_{k be say to be homomorphic respect set operation 𝒪\mathcal{o operation ∘∈𝒪\circ\in\mathcal{o one can compute e​n​c​r​y​p​tk​(p1∘p2)encrypt_{k}(p_{1}\circ p_{2 e​n​c​r​y​p​tk​(p1)∘e​n​c​r​y​p​tk​(p2)encrypt_{k}(p_{1})\circ encrypt_{k}(p_{2 scheme come three form somewhat partially fully homomorphic survey present state art know homomorphic encryption scheme base code theory polynomial,Cryptography and Security,17/09/2025
10.48550/arXiv.2509.13772,teach lie responsibility attribution poisoned knowledge retrieval augmented generation,"Baolei Zhang, Haoran Xin, Yuxi Chen, Zhuqing Liu, Biao Yi, Tong Li, Lihai Nie, Zheli Liu, Minghong Fang",retrieval augmented generation rag integrate external knowledge large language model to improve response quality however recent work have show rag system be highly vulnerable poison attack malicious text be insert knowledge database influence model output several defense have be propose be often circumvent more adaptive sophisticate attack,Cryptography and Security,17/09/2025
10.48550/arXiv.2509.13740,protocol aware firmware rehosting effective fuzzing embedded network stacks,"Moritz Bley, Tobias Scharnowski, Simon Wörner, Moritz Schloegel, Thorsten Holz",one big attack surface embed system be network interface enable communication other device general purpose counterpart embed system be design specialize use case result unique diverse communication stack unfortunately current approach evaluate security embed network stack require manual effort access hardware generally focus only small part embed system promise alternative be firmware rehosting enable fuzz test entire firmware generically emulate physical hardware however exist rehosting method often struggle to meaningfully explore network stack complex multi layer input format limit ability to uncover deeply nest software fault,Cryptography and Security,17/09/2025
10.48550/arXiv.2509.13684,publicly verifiable private information retrieval protocols base function secret sharing,"Lin Zhu, Lingwei Kong, Xin Ning, Xiaoyang Qu, Jianzong Wang",private information retrieval pir be fundamental cryptographic primitive enable user to retrieve datum database reveal item be be access thereby preserve query privacy however pir protocol also face challenge result verifiability user expect reconstruct datum to be trustworthy authentic work propose two effective construction publicly verifiable pir pvpir multi server set achieve query privacy correctness verifiability simultaneously far present three concrete instantiation base construction point query protocol introduce minimal computational overhead achieve strong verifiability guarantee significantly low communication cost compare exist merkle tree base approach predicate query communication complexity scheme remain stable database size increase demonstrate strong scalability suitability large scale private query application,Cryptography and Security,17/09/2025
10.48550/arXiv.2509.13597,agentic jwt secure delegation protocol autonomous ai agents,Abhishek Goswami,autonomous llm agent can issue thousand api call hour human oversight oauth 2.0 assume deterministic client agentic setting stochastic reason prompt injection multi agent orchestration can silently expand privilege,Cryptography and Security,16/09/2025
10.48550/arXiv.2509.13581,invisible ears fingertip acoustic eavesdropping mouse sensor,"Mohamad Fakih, Rahul Dharmaji, Youssef Mahmoud, Halima Bouzidi, Mohammad Abdullah Al Faruque",modern optical mouse sensor advance precision high responsiveness possess often overlook vulnerability can be exploit side channel attack paper introduce mic e mouse first ever side channel attack target high performance optical mouse sensor to covertly eavesdrop user demonstrate audio signal can induce subtle surface vibration detectable mouse ’s optical sensor remarkably user space software popular operate system can collect broadcast sensitive side channel grant attacker access raw mouse datum require direct system level permission initially vibration signal extract mouse datum be poor quality non uniform sample non linear frequency response significant quantization to overcome limitation mic e mouse employ sophisticate end end datum filter pipeline combine wiener filter resampling correction innovative encoder only spectrogram neural filter technique evaluate attack ’s efficacy diverse condition include speak volume mouse poll rate dpi surface material speaker language environmental noise control environment mic e mouse improve signal noise ratio snr +19 db speech reconstruction furthermore result demonstrate speech recognition accuracy roughly 42 to 61 audiomnist vctk dataset code dataset be publicly accessible mic e mouse website111https://sites.google.com/view/mic-e-mouse,Cryptography and Security,16/09/2025
10.48550/arXiv.2509.13514,aqua llm evaluate accuracy quantization adversarial robustness trade off llm cybersecurity question answering,"Onat Gungor, Roshan Sood, Harold Wang, Tajana Rosing",large language models llms have recently demonstrate strong potential cybersecurity question answer qa support decision make real time threat detection response workflow however substantial computational demand pose significant challenge deployment resource constrain edge device quantization widely adopt model compression technique can alleviate constraint nevertheless quantization may degrade model accuracy increase susceptibility adversarial attack fine tune offer potential mean to mitigate limitation effectiveness combine quantization remain insufficiently explore hence be essential to understand trade off accuracy efficiency robustness propose aqua llm evaluation framework design to benchmark several state art small llms four distinct configuration base quantize only fine tune fine tune combine quantization specifically cybersecurity qa result demonstrate quantization alone yield low accuracy robustness improve efficiency contrast combine quantization fine tune enhance llm robustness predictive performance achieve optimal balance accuracy robustness efficiency finding highlight critical need quantization aware robustness preserve fine tune methodology to enable robust efficient deployment llms cybersecurity qa,Cryptography and Security,16/09/2025
10.48550/arXiv.2509.13509,practitioners perspectives differential privacy deployment registry,"Priyanka Nanayakkara, Elena Ghazi, Salil Vadhan",differential privacy principled approach produce statistical datum product e.g. summary statistic machine learn model strong mathematically provable privacy guarantee individual underlie dataset have see substantial adoption practice past decade apply dp require make several implementation decision significant impact datum privacy utility hence to promote share learn accountability dp deployment dwork kohli mulligan 1 propose public face repository registry dp deployment dp community have recently start to work realize vision contribute effort 1 develop holistic hierarchical schema to describe give dp deployment 2 design implement interactive interface to act registry practitioner can access information past dp deployment 3 populate interface 21 real world dp deployment 4 conduct exploratory user study dp practitioner n=16n=16 to understand would use registry as well challenge opportunity foresee adoption find participant be enthusiastic registry valuable resource evaluate prior deployment make future deployment also identify several opportunity registry include can become hub community support broad communication dp e.g. legal team same time identify challenge registry gain adoption include effort risk involve make implementation choice public moderate quality entry base finding offer recommendation encourage adoption increase registry ’s value not only dp practitioner also policymaker datum user datum subject,Cryptography and Security,16/09/2025
10.48550/arXiv.2509.13464,light hids lightweight effective machine learning base framework robust host intrusion detection,"Onat Gungor, Ishaan Kale, Jiasheng Zhou, Tajana Rosing",expansion edge compute have increase attack surface create urgent need robust real time machine learn ml)-base host intrusion detection system hids balance accuracy efficiency such setting inference latency pose critical security risk delay may provide exploitable opportunity attacker however many state art ml base hids solution rely computationally intensive architecture high inference cost limit practical deployment paper propose light hids lightweight machine learn framework combine compress neural network feature extractor train deep support vector data description deepsvdd efficient novelty detection model hybrid approach enable learn compact meaningful representation normal system call behavior accurate anomaly detection experimental result multiple dataset demonstrate light hids consistently enhance detection accuracy reduce inference time 75×\time compare state art method finding highlight effectiveness scalability machine learn base solution real time host intrusion detection,Cryptography and Security,16/09/2025
10.48550/arXiv.2509.13755,scrub erase sensitive memorization code language models machine unlearning,"Zhaoyang Chu, Yao Wan, Zhikun Zhang, Di Wang, Zhou Yang, Hongyu Zhang, Pan Zhou, Xuanhua Shi, Hai Jin, David Lo",code language models clms have demonstrate superior performance software engineer task such code generation summarization recent empirical study reveal critical privacy vulnerability model exhibit unintended memorization sensitive train datum enable verbatim reproduction confidential information specifically prompt to address issue several approach include train datum de duplication differential privacy augmentation have be propose however method require full model retrain deploy clms incur substantial computational cost paper aim to answer follow research question can sensitive information memorize clm be erase effectively efficiently,Cryptography and Security,17/09/2025
10.48550/arXiv.2509.13634,secure uav assist federated learning digital twin driven approach zero knowledge proofs,"Md Bokhtiar Al Zami, Md Raihan Uddin, Dinh C. Nguyen",federated learning fl have gain popularity privacy preserve method train machine learn model decentralize network however to ensure reliable operation uav assist fl system issue excessive energy consumption communication inefficiency security vulnerability must be solve paper propose innovative framework integrate digital twin dt technology zero knowledge federated learning zkfed to tackle challenge uav act mobile base station allow scatter device to train fl model locally upload model update aggregation incorporate dt technology approach enable real time system monitor predictive maintenance improve uav network efficiency additionally zero knowledge proofs zkp strengthen security allow model verification expose sensitive datum to optimize energy efficiency resource management introduce dynamic allocation strategy adjust uav flight path transmission power process rate base network condition use block coordinate descent convex optimization technique method significantly reduce system energy consumption to 29.6 compare conventional fl approach simulation result demonstrate improve learn performance security scalability position framework promise solution next generation uav base intelligent network,Cryptography and Security,17/09/2025
10.48550/arXiv.2509.13625,privacy aware in context learning large language models,"Bishnu Bhusal, Manoj Acharya, Ramneet Kaur, Colin Samplawski, Anirban Roy, Adam D. Cobb, Rohit Chadha, Susmit Jha",large language model llms have significantly transform natural language understand generation raise privacy concern potential exposure sensitive information study have highlight risk information leakage adversary can extract sensitive information embed prompt work introduce novel private prediction framework generate high quality synthetic text strong privacy guarantee approach leverage differential privacy dp framework to ensure bad case theoretical bound information leakage require fine tune underlie model propose method perform inference private record aggregate result token output distribution enable generation long coherent synthetic text maintain privacy guarantee additionally propose simple blend operation combine private public inference to far enhance utility empirical evaluation demonstrate approach outperform previous state art method context learn icl task make promise direction privacy preserve text generation maintain high utility,Cryptography and Security,17/09/2025
10.48550/arXiv.2509.13405,define security quantum key distribution,"Carla Ferradini, Martin Sandfuchs, Ramona Wolf, Renato Renner",security quantum key distribution qkd be quantify parameter ε>0\varepsilon>0 well define physical assumption can be bound explicitly contrast computationally secure scheme security claim be only asymptotic i.e. standard complexity assumption one only know 0 key size grow have explicit bind here explain definition interpretation ε\varepsilon security adopt axiomatic approach show ε\varepsilon can be understand maximum probability security failure finally review address several criticism definition have appear literature,Cryptography and Security,16/09/2025
10.48550/arXiv.2509.13217,trustworthy confidential sbom exchange,"Eman Abu Ishgair, Chinenye Okafor, Marcela S. Melara, Santiago Torres-Arias",software bills materials sboms have become regulatory requirement improve software supply chain security trust mean transparency regard component make software artifact however enterprise regulate software vendor commonly wish to restrict can view confidential software metadata record sbom intellectual property security vulnerability information to address tension transparency confidentiality propose petra sbom exchange system empower software vendor to interoperably compose distribute redact sbom datum use selective encryption petra enable software consumer to search redact sbom answer specific security question reveal information be not authorize to access petra leverage format agnostic tamper evident sbom representation to generate efficient confidentiality preserve integrity proof allow interest party to cryptographically audit establish trust redact sbom exchange redact sbom petra prototype require less 1 extra kb sbom sbom decryption account at most 1 performance overhead sbom query,Cryptography and Security,16/09/2025
10.48550/arXiv.2509.13186,characterize phishing pages javascript capabilities,"Aleksandr Nahapetyan, Kanv Khare, Kevin Schwarz, Bradley Reaves, Alexandros Kapravelos",2024 anti phishing work group identify one million phishing page phisher achieve scale use phishing kit ready to deploy phishing website to rapidly deploy phishing campaign specific datum exfiltration evasion mimicry technique contrast researcher defender continue to fight phishe page page basis rely manual analysis to recognize static feature kit identification,Cryptography and Security,16/09/2025
10.48550/arXiv.2509.13072,digital sovereignty control framework military ai base cyber security,"Clara Maathuis, Kasper Cools",today ’s evolve threat landscape ensure digital sovereignty have become mandatory military organization especially give increase development investment ai drive cyber security solution end multi angle framework be propose article order to define assess digital sovereign control datum ai base model military cyber security framework focus aspect such context autonomy stakeholder involvement mitigation risk domain ground concept digital sovereignty datum sovereignty framework aim to protect sensitive defence asset threat such unauthorized access ransomware supply chain attack approach reflect multifaceted nature digital sovereignty preserve operational autonomy assure security safety secure privacy foster ethical compliance military system decision maker same time framework address interoperability challenge ally force strategic legal consideration integration emerge technology consider multidisciplinary approach enhance resilience preservation control critical digital asset be do adopt design orient research systematic literature review be merge critical think analysis field incident order to assure effectivity realism framework propose,Cryptography and Security,16/09/2025
10.48550/arXiv.2509.13048,slash dsa break slh dsa use extensible end end rowhammer framework,"Jeremy Boy, Antoon Purnal, Anna Pätschke, Luca Wilke, Thomas Eisenbarth",quantum compute advance \acpqc scheme be adopt to replace classical algorithm be \acslh dsa be recently standardize nist be favor conservative security foundation,Cryptography and Security,16/09/2025
10.48550/arXiv.2509.13046,mia ept membership inference attack error prediction tabular data,"Eyal German, Daniel Samira, Yuval Elovici, Asaf Shabtai",synthetic datum generation play important role enable datum share particularly sensitive domain healthcare finance recent advance diffusion model have make possible to generate realistic high quality tabular datum may also memorize train record leak sensitive information membership inference attack mias exploit vulnerability determine record be use train mia have be study image text use tabular diffusion model remain underexplored unique risk structure attribute limit record diversity paper introduce mia ept membership inference attack error prediction tabular data novel black box attack specifically design to target tabular diffusion model mia ept construct error base feature vector mask reconstruct attribute target record disclose membership signal base well attribute be predict mia ept operate access internal component generative model rely only synthetic datum output be show to generalize multiple state art diffusion model validate mia ept three diffusion‑base synthesizer achieve auc‑roc score to 0.599 tpr@10 fpr value 22.0 internal test midst 2025 competition condition mia ept achieve second place black box multi table track tpr@10 fpr = 20.0 result demonstrate method can uncover substantial membership leakage synthetic tabular datum challenge assumption synthetic datum be inherently privacy preserve code be publicly available https://github.com/eyalgerman/mia-ept,Cryptography and Security,16/09/2025
10.48550/arXiv.2509.13021,xoffense ai drive autonomous penetration test framework offensive knowledge enhance llm multi agent system,"Phung Duc Luong, Le Tran Gia Bao, Nguyen Vu Khai Tam, Dong Huu Nguyen Khoa, Nguyen Huu Quyen, Van-Hau Pham, Phan The Duy",penetration test pentest be essential assess security computer system conventional automate approach use machine learning ml deep learning dl reinforcement learning rl remain limit simplify action space high computational cost weak reason multi stage process reconnaissance vulnerability analysis exploitation recent framework such pentestgpt vulnbot attempt to leverage large language model llms face challenge high cost scalability adaptability complex workflow motivate transition monolithic model agentic ai system multiple specialize agent collaborate to complete pentest task high efficiency accuracy work introduce xoffense ai drive multi agent penetration test framework shift process labor intensive expert drive manual effort to fully automate machine executable workflow capable scale seamlessly computational infrastructure core xoffense leverage fine tune mid scale open source llm qwen3 32b to drive reason decision make penetration test framework assign specialize agent to reconnaissance vulnerability scan exploitation orchestration layer ensure seamless coordination phase fine tune chain thought penetration test datum far enable model to generate precise tool command perform consistent multi step reason evaluate xoffense two rigorous benchmark autopenbench ai pentest benchmark result demonstrate xoffense consistently outperform contemporary method achieve sub task completion rate 79.17 decisively surpass lead system such vulnbot pentestgpt finding highlight potential domain adapt mid scale llm embed structure multi agent orchestration to deliver superior cost efficient reproducible solution autonomous penetration test,Cryptography and Security,16/09/2025
10.48550/arXiv.2509.12979,universal share base quantum multi secret image share scheme,"Dipak K. Rabari, Yogesh K. Meghrajani, Laxmi S. Desai",image security information have become increasingly critical internet become more prevalent hack unauthorized access to ensure security confidential image datum image encryption use visual cryptography play crucial role to share multiple image use visual cryptography company organizer utilize concept universal common share likewise quantum compute be emerge technology facilitate secure communication ability quantum computer to solve certain mathematical problem efficiently threaten security many current encryption algorithm hence to leverage strength quantum compute visual cryptography research introduce novel universal share base quantum multi secret share technique secure image communication quantum compute enable scheme to exhibit high resilience different eavesdrop threat consequently propose method offer robust security solution share confidential image range application include enterprise datum access military communication,Cryptography and Security,16/09/2025
10.48550/arXiv.2509.12957,xrwa cross chain framework interoperability real world asset,"Yihao Guo, Haoming Zhu, Minghui Xu, Xiuzhen Cheng, Bin Xiao",real world assets rwas have recently attract increase attention means bridge traditional financial instrument decentralize infrastructure represent asset such bond commodity real estate blockchain rwa can enhance liquidity broaden accessibility extend scope decentralize finance industry forecast far suggest rapid growth tokenize rwa come year underscore potential role evolution digital financial market however deploy multiple blockchain rwa face challenge such repeat authentication different chain inefficiency cause multi step settlement protocol to address issue present cross chain framework rwa emphasize identity management authentication interaction framework integrate decentralized identifier verifiable credentials customize attribute to support decentralize identification incorporate authentication protocol base simplified payment verification to avoid redundant verification chain furthermore design cross chain channel enable settlement rwa require channel closure thereby improve operational efficiency implement framework evaluate simulation confirm feasibility demonstrate improvement efficiency rwa cross chain setting,Cryptography and Security,16/09/2025
10.48550/arXiv.2509.12937,jailbreake large language models content concretization,"Johan Wahréus, Ahmed Hussain, Panos Papadimitratos",large language models llms be increasingly deploy task automation content generation safety mechanism remain vulnerable circumvention different jailbreake technique paper introduce content concretization cc novel jailbreaking technique iteratively transform abstract malicious request concrete executable implementation cc be two stage process first generate initial llm response use low tier less constrain safety filter model then refine high tier model process preliminary output original prompt evaluate technique use 350 cybersecurity specific prompt demonstrate substantial improvement jailbreak success rates sr increase 7 refinement 62 three refinement iteration maintain cost 7.5¢ prompt comparative a b test nine different llm evaluator confirm output additional refinement step be consistently rate more malicious technically superior moreover manual code analysis reveal generate output execute minimal modification optimal deployment typically require target specific fine tune eventual improve harmful code generation result highlight critical vulnerability current llm safety framework,Cryptography and Security,16/09/2025
10.48550/arXiv.2509.12923,graph base approach alert contextualisation security operations centres,"Magnus Wiik Eckhoff, Peter Marius Flydal, Siem Peters, Martin Eian, Jonas Halvorsen, Vasileios Mavroeidis, Gudmund Grov",interpret massive volume security alert be significant challenge security operations centres socs effective contextualisation be important enable quick distinction genuine threat benign activity to prioritise need further analysis paper propose graph base approach to enhance alert contextualisation soc aggregate alert graph base alert group node represent alert edge denote relationship define time window group relate alert enable analysis high abstraction level capture attack step more effectively individual alert furthermore to show format be well suit downstream machine learn method employ graph matching networks gmns to correlate incoming alert group historical incident provide analyst additional insight,Cryptography and Security,16/09/2025
10.48550/arXiv.2509.12899,ebyftve efficient byzantine fault tolerant base verifiable secret share distributed privacy preserve machine learning,"Zhen Li, Zijian Zhang, Wenjin Yang, Pengbo Wang, Zhaoqi Wang, Meng Li, Yan Wu, Xuyang Liu, Jing Sun, Liehuang Zhu",verifiable secret sharing vss have be widespread distributed privacy preserve machine learning dpml invalid share malicious dealer participant can be recognize verify commitment receive share honest participant however consistency computation communitation burden vss base dpml scheme be still two serious challenge byzantine fault tolerance bft system have be bring to guarantee consistency improve efficiency exist vss base dpml scheme recently explore adaptive share delay provision asdp strategy launch asdp base customized model poisoning attack acumpa certain participant paper theoretically analyze asdp strategy acumpa algorithm work exist scheme next propose e]fficient by]zantine f]ault t]olerant base ve]rifiable s]ecret share ebyftves scheme finally validity liveness consistency privacy ebyftves scheme be theoretically analyze efficiency ebyftves scheme outperform state art vss scheme accord comparative experiment result,Cryptography and Security,16/09/2025
10.48550/arXiv.2509.12574,watermark large language models,"Siyuan Bao, Ying Shi, Zhiguang Yang, Hanzhou Wu, Xinpeng Zhang",exist watermarking method large language model llms mainly embe watermark adjust token sample prediction post process lack intrinsic couple llm may significantly reduce semantic quality generate mark text traditional watermarking method base train fine tune may be extendable llm however most be limit white box scenario very time consume massive parameter llm paper present new watermarking framework llms watermark be embed llm manipulate internal parameter llm can be extract generate text access llm compare relate method propose method entangle watermark intrinsic parameter llm well balance robustness imperceptibility watermark moreover propose method enable to extract watermark black box scenario be computationally efficient use experimental result have also verify feasibility superiority practicality work provide new perspective different mainstream work may shed light future research,Cryptography and Security,16/09/2025
10.48550/arXiv.2509.12535,exploit timing side channels quantum circuits simulation ml base method,"Ben Dong, Hui Feng, Qian Wang",quantum compute advance quantum circuit simulator serve critical tool to bridge current gap cause limit quantum hardware availability simulator be typically deploy cloud platform user submit proprietary circuit design simulation work demonstrate novel time side channel attack target cloud base quantum simulator co locate malicious process can observe fine grain execution time pattern to extract sensitive information concurrently run quantum circuit systematically analyze simulator behavior use qasmbench benchmark suite profile time memory characteristic various circuit execution experimental result show time profile exhibit circuit dependent pattern can be effectively classify use pattern recognition technique enable adversary to infer circuit identity compromise user confidentiality be able to achieve 88 99.9 identification rate quantum circuit base different dataset work highlight previously unexplored security risk quantum simulation environment call strong isolation mechanism to protect user workload,Cryptography and Security,16/09/2025
10.48550/arXiv.2509.12494,closing performance gap cryptographic kernels cpu specialized hardware,"Naifeng Zhang, Sophia Fu, Franz Franchetti",specialized hardware application specific integrate circuit asics remain primary accelerator type cryptographic kernel base large integer arithmetic prior work have show commodity server class gpu can achieve near asic performance workload however achieve comparable performance cpu remain open challenge work investigate follow question can narrow performance gap cpu specialize hardware key cryptographic kernel basic linear algebra subprogram blas operation number theoretic transform ntt,Cryptography and Security,15/09/2025
10.48550/arXiv.2509.12478,qkd oracles authenticated key exchange,"Kathrin Hövelmanns, Daan Planken, Christian Schaffner, Sebastian R. Verschoor",authenticated key exchange ake establish share symmetric cryptographic key be essential secure online communication ake protocol can be construct public key cryptography key encapsulation mechanisms kems approach be to use quantum key distribution qkd to establish symmetric key use quantum communication combine post quantum ake qkd appropriately may provide security quantum attack even only one two approach turn to be secure,Cryptography and Security,15/09/2025
10.48550/arXiv.2509.12462,redefine website fingerprinting attacks multiagent llms,"Chuxu Song, Dheekshith Dev Manohar Mekala, Hao Wang, Richard Martin",website fingerprinting wfp use deep learn model to classify encrypt network traffic to infer visit website historically effective prior method fail to generalize modern web environment single page application spa eliminate paradigm website set discrete page undermine page base classification traffic script browser lack behavioral richness see real user session study reveal user exhibit highly diverse behavior even same website produce traffic pattern vary significantly individual behavioral entropy make wfp hard problem previously assume highlight need large more diverse representative dataset to achieve robust performance to address propose new paradigm drop session boundary favor contiguous traffic segment develop scalable data generation pipeline use large language model llm agent multi agent system coordinate decision make browser interaction to simulate realistic persona drive browse behavior 3–5× low cost human collection evaluate nine state art wfp model traffic 20 modern website browse 30 real user compare train performance human script llm generate dataset model achieve 10 accuracy train script traffic test human datum contrast llm generate traffic boost accuracy 80 range demonstrate strong generalization real world trace finding indicate modern wfp model performance be increasingly bottleneck datum quality scalable semantically ground synthetic traffic be essential capture complexity real user behavior,Cryptography and Security,15/09/2025
10.48550/arXiv.2509.12386,amulet python library assess interaction ml defenses risk,"Asim Waheed, Vasisht Duddu, Rui Zhang, Sebastian Szyller, N. Asokan",ml model be susceptible risk security privacy fairness several defense be design to protect intend risk can inadvertently affect susceptibility other unrelated risk know unintended interaction several jurisdiction be prepare ml regulatory framework require ml practitioner to assess susceptibility ml model different risk library evaluate unintended interaction can be use a practitioner to evaluate unintended interaction scale prior model deployment b researcher design defense do not suffer unintended increase unrelated risk ideally library should be i comprehensiveby include representative attack defense metric different risk ii extensibleto new module modular design iii consistentwith user friendly api template input output iv applicableto evaluate previously unexplored unintended interaction present amulet python library cover risk security privacy fairness satisfy requirement amulet can be use to evaluate unexplored unintended interaction compare effectiveness defense attack include new attack defense,Cryptography and Security,15/09/2025
10.48550/arXiv.2509.12291,collaborative p4 sdn ddos detection mitigation early exit neural network,"Ouassim Karrakchou, Alaa Zniber, Anass Sebbar, Mounir Ghogho",distribute denial service ddos attack pose persistent threat network security require timely scalable mitigation strategy paper propose novel collaborative architecture integrate p4 programmable datum plane sdn control plane to enable real time ddos detection response core approach be split early exit neural network perform partial inference data plane use quantize convolutional neural network cnn defer uncertain case gated recurrent unit gru module control plane design enable high speed classification line rate ability to escalate more complex flow deep analysis experimental evaluation use real world ddos dataset demonstrate approach achieve high detection accuracy significantly reduce inference latency control plane overhead result highlight potential tightly couple ml p4 sdn system efficient adaptive low latency ddos defense,Cryptography and Security,15/09/2025
10.48550/arXiv.2509.12290,secure human oversight ai explore attack surface human oversight,"Jonas C. Ditz, Veronika Lazar, Elmar Lichtmeß, Carola Plesch, Matthias Heck, Kevin Baum, Markus Langer",human oversight ai be promote safeguard risk such inaccurate output system malfunction violation fundamental right be mandate regulation european ai act yet debate human oversight have largely focus effectiveness overlook critical dimension security human oversight argue human oversight create new attack surface safety security accountability architecture ai operation draw cybersecurity perspective analyze attack vector threaten requirement effective human oversight thereby undermine safety ai operation such attack may target ai system communication oversight personnel personnel then outline harden strategy to mitigate risk contribution be 1 introduce security perspective human oversight 2 provide overview attack vector harden strategy to enable secure human oversight ai,Cryptography and Security,15/09/2025
10.48550/arXiv.2509.13219,out distribution backdoor attack federated learning,"Jiahao Xu, Zikai Zhang, Rui Hu",traditional backdoor attack federate learn fl operate constrain attack scenario depend visible trigger require physical modification target object limit practicality to address limitation introduce novel backdoor attack prototype fl call out distribution ood backdoor attack 𝙾𝙱𝙰\mathtt{oba use ood datum poison sample trigger simultaneously approach significantly broaden scope backdoor attack scenario fl to improve stealthiness 𝙾𝙱𝙰\mathtt{oba propose 𝚂𝚘𝙳𝚊\mathtt{soda regularize magnitude direction malicious local model local train align closely benign version to evade detection empirical result demonstrate 𝙾𝙱𝙰\mathtt{oba effectively circumvent state art defense maintain high accuracy main task,Cryptography and Security,16/09/2025
10.48550/arXiv.2509.13117,vulnerability patching software products software components case study red hat 's product portfolio,"Jukka Ruohonen, Sani Abdullahi, Abhishek Tiwari",motivate software maintenance more recent concept security debt paper present time series analysis vulnerability patch red hat ’s product component 1999 2024 accord result base segment regression analysis amount vulnerable product component have not be stable linear trend describe many series well do amount align well trend characterize vulnerability general be also visible breakpoint indicate linear trend be not universally applicable grow security debt may be stabilize,Cryptography and Security,16/09/2025
10.48550/arXiv.2509.12939,sy far symmetry base fair adversarial robustness,"Haneen Najjar, Eyal Ronen, Mahmood Sharif",security critical machine learn ml system such face recognition system be susceptible adversarial example include real world physically realizable attack various mean to boost ml ’s adversarial robustness have be propose however typically induce unfair robustness be often easy to attack certain class e.g. individual group e.g. gender other several technique have be develop to improve adversarial robustness seek perfect fairness class yet prior work have focus setting security fairness be less critical e.g. classify object such car ship,Cryptography and Security,16/09/2025
10.48550/arXiv.2509.12676,scalable architecture efficient multi bit fully homomorphic encryption,"Jiaao Ma, Ceyu Xu, Lisa Wu Wills",era cloud computing privacy preserve computation offload be crucial safeguard sensitive datum fully homomorphic encryption fhe enable secure process encrypt datum inherent computational complexity fhe operation introduce significant computational overhead server side fhe scheme often face tradeoff efficiency versatility ckks scheme be highly efficient polynomial operation lack flexibility binary tfhe torus fhe scheme offer great versatility cost efficiency recent multi bit tfhe extension offer great flexibility performance support native non polynomial operation efficient integer process however current implementation multi bit tfhe be constrain narrow numeric representation prevent adoption application require wide numeric representation,Cryptography and Security,16/09/2025
10.48550/arXiv.2509.12341,exact coset sampling quantum lattice algorithms,Yifan Zhang,give simple provably correct replacement contest domain extension step 9 recent windowed qft lattice algorithm complex gaussian window chen 2024 publish step 9 suffer periodicity support mismatch drop subroutine use pair shift difference to cancel unknown offset exactly to synthesize uniform cyclic subgroup zero offset coset order pp inside ℤm2)n(\mathbb{z}_{m_{2}})^{n subsequent qft enforce intend modular linear relation sole structural assumption be residue accessibility condition enable coherent auxiliary cleanup amplitude periodicity be use unitary be reversible use poly​(log⁡m2)\mathrm{poly}(\log m_{2 gate preserve upstream asymptotic,Cryptography and Security,15/09/2025
10.48550/arXiv.2509.12223,ratio1 ai meta os,"Andrei Damian, Petrica Butusina, Alessandro De Franceschi, Vitalii Toderian, Marius Grigoras, Cristian Bleotiu",propose111special acknowledgment thank whole ratio1 team section acknowledgments ratio1 ai meta operate system meta os decentralize mlops protocol unify ai model development deployment inference heterogeneous edge device key innovation be integrate blockchain base framework transform idle compute resource laptop smartphone cloud vms trustless global supercomputer 1][2 architecture include novel component decentralize authentication layer dauth memory state database cstore distribute storage system r1fs homomorphic encrypt federate learn edil decentralize container orchestration deeploy oracle network oraclesync 1][2 collectively ensure secure resilient execution ai pipeline other container base app scale protocol enforce formal circular token economic model combine proof availability poa proof ai poai consensus token rewards222tokenomic utilitarian token aspect 3 3.1 3.1.1 3.1.3 3.1.4 3.1 be compute smart contract r​(ωn)=f​(proof​(ωn))r(\omega_{n})=f(\text{proof}(\omega_{n node ’s uptime proof be validate chain 1 2 compare centralize heterogeneous cloud mlops exist decentralize compute platform often lack integrate ai toolchain 1 trust ratio1 node operator r1op mechanic 3 ratio1 ’s holistic design lower barrier ai deployment improve cost efficiency provide mathematical formulation secure license reward protocol include descriptive information system architecture protocol flow argue propose fully functional ecosystem propose demonstrate significant improvement accessibility scalability security exist alternative,Cryptography and Security,05/09/2025
10.48550/arXiv.2509.12221,meuv achieve fine grained capability activation large language models mutually exclusive unlock vector,"Xin Tong, Zhi Lin, Jingya Wang, Meng Han, Bo Jin",large language model llms enforce safety alignment to reliably refuse malicious request same blanket safeguard also block legitimate use police defense other high stake setting early refusal direction edit can bypass layer rely single vector indiscriminately unlock hazardous topic offer semantic control introduce mutually exclusive unlock vectors meuv lightweight framework factorize monolithic refusal direction topic align nearly orthogonal vector dedicate one sensitive capability meuv be learn single epoch multi task objective blend differential ablation margin cross topic orthogonality penalty several auxiliary term bilingual malicious prompt benchmark meuv achieve attack success rate less 87 gemma-2 2b llama-3 8b qwen-7b cut cross topic leakage to 90 compare good single direction baseline vector train chinese transfer almost unchanged english vice versa suggest language agnostic refusal subspace result show fine grain topic level capability activation be achievable minimal utility loss pave way control llms deployment security sensitive domain,Cryptography and Security,04/09/2025
10.48550/arXiv.2509.12181,loki proactively discover online scam websites mining toxic search query,"Pujan Paudel, Gianluca Stringhini","online e commerce scam range shop scam pet scam globally cause million dollar financial damage year response security community have develop highly accurate detection system able to determine website be fraudulent however find candidate scam website can be pass input downstream detection system be challenge rely user report be inherently reactive slow proactive system issue search engine query to return candidate website suffer low coverage do not generalize new scam type paper present loki system design to identify search engine query likely to return high fraction fraudulent website loki implement keyword score model ground learning privileged information lupi feature distillation search engine result page serp rigorously validate loki 10 major scam category demonstrate 20.58 time improvement discovery heuristic datum drive baseline category leverage small seed set only 1,663 know scam site use keyword identify method to discover 52,493 previously unreported scam wild finally show loki generalize previously unseen scam category highlight utility surface emerge threat",Cryptography and Security,15/09/2025
10.48550/arXiv.2509.11974,poison to detect detection targeted overfitting federated learning,"Soumia Zohra El Mestari, Maciej Krzysztof Zuziak, Gabriele Lenzini",federated learning fl enable collaborative model train decentralise client keep local datum private make widely adopt privacy enhance technology pet privacy benefit fl remain vulnerable privacy attack include target specific client paper study underexplored threat dishonest orchestrator intentionally manipulate aggregation process to induce target overfitting local model specific client many study area predominantly focus reduce amount information leakage train focus enable early client side detection target overfitting thereby allow client to disengage significant harm occur line propose three detection techniques—(a label flip b backdoor trigger injection c model fingerprint enable client to verify integrity global aggregation evaluate method multiple dataset different attack scenario result show three method reliably detect target overfitting induce orchestrator differ term computational complexity detection latency false positive rate,Cryptography and Security,15/09/2025
10.48550/arXiv.2509.11934,zktoken empower holder to limit revocation check verifiable credential,"Praveensankar Manimaran, Mayank Raikwar, Thiago Garrett, Arlindo F. da Conceição, Leander Jehl, Roman Vitenberg",system manage verifiable credentials be become increasingly popular unfortunately support revoke previously issue credential allow verifier to effectively monitor validity credential be sensitive information issue start to gain recognition adequate solution have be propose so far,Cryptography and Security,15/09/2025
10.48550/arXiv.2509.11870,efficient byzantine robust privacy preserve federated learning dimension compression,"Xian Qin, Xue Yang, Xiaohu Tang",federated learning fl allow collaborative model train distribute client share raw datum thus preserve privacy however system remain vulnerable privacy leakage gradient update byzantine attack malicious client exist solution face critical trade off privacy preservation byzantine robustness computational efficiency propose novel scheme effectively balance compete objective integrate homomorphic encryption dimension compression base johnson lindenstrauss transformation approach employ dual server architecture enable secure byzantine defense ciphertext domain dramatically reduce computational overhead gradient compression dimension compression technique preserve geometric relationship necessary byzantine defence reduce computation complexity o​(d​n)o(dn o​(k​n)o(kn cryptographic operation k≪dk\ll d. extensive experiment diverse dataset demonstrate approach maintain model accuracy comparable non private fl effectively defend byzantine client comprise 40%40\% network approach also demonstrate substantial improvement computational communication efficiency experimental evaluation show dimension compression technique achieve 25×∼35×25\times\sim 35\times reduction computational overhead 17×17\times reduction communication overhead compare non compression version compare state art method shieldfl 1 approach demonstrate order magnitude improvement computational communication efficiency maintain equivalent privacy guarantee achieve superior byzantine robustness comparable fltrust 2 substantial efficiency enhancement make secure fl practical deployment large scale neural network million parameter,Cryptography and Security,15/09/2025
10.48550/arXiv.2509.11864,neurostrike neuron level attack aligned llms,"Lichao Wu, Sasha Behrouzi, Mohamadreza Rostami, Maximilian Thang, Stjepan Picek, Ahmad-Reza Sadeghi",safety alignment be critical ethical deployment large language model llms guide to avoid generate harmful unethical content current alignment technique such supervise fine tune reinforcement learn human feedback remain fragile can be bypass carefully craft adversarial prompt unfortunately such attack rely trial error lack generalizability model be constrain scalability reliability,Cryptography and Security,15/09/2025
10.48550/arXiv.2509.11836,practical adversarial attack sequence base deep learning malware classifier,"Kai Tan, Dongyang Zhan, Lin Ye, Hongli Zhang, Binxing Fang",sequence base deep learn model e.g. rnns can detect malware analyze behavioral sequence meanwhile model be susceptible adversarial attack attacker can create adversarial sample alter sequence characteristic behavior sequence to deceive malware classifier exist method generate adversarial sample typically involve delete replace crucial behavior original datum sequence insert benign behavior may violate behavior constraint however method directly manipulate sequence make adversarial sample difficult to implement apply practice paper propose adversarial attack approach base deep q network heuristic backtrack search strategy can generate perturbation sequence satisfy practical condition successful attack subsequently utilize novel transformation approach map modification back source code thereby avoid need to directly modify behavior log sequence conduct evaluation approach result confirm effectiveness generate adversarial sample real world malware behavior sequence have high success rate evade anomaly detection model furthermore approach be practical can generate adversarial sample maintain functionality modify software,Cryptography and Security,15/09/2025
10.48550/arXiv.2509.11833,off path tcp exploit pmtud break tcp connection isolation ip address sharing scenario,"Xuewei Feng, Zhaoxi Li, Qi Li, Ziqiang Wang, Kun Sun, Ke Xu",path mtu discovery pmtud ip address share be integral aspect modern internet infrastructure paper investigate security vulnerability associate pmtud context prevalent ip address share practice reveal pmtud be inadequately design to handle ip address share create vulnerability attacker can exploit to perform path tcp hijack attack demonstrate observe path mtu value determine server public ip address share multiple device path attacker internet collaboration malicious device can infer sequence number tcp connection establish other legitimate device share same ip address vulnerability enable attacker to perform path tcp hijack attack significantly compromise security affect tcp connection attack involve first identify target tcp connection originate share ip address follow infer sequence number identify connection thoroughly assess impact attack various network configuration experimental result reveal attack can be execute average time 220 second achieve success rate 70 case study include ssh do ftp traffic poison http injection highlight threat pose various application additionally evaluate attack 50 real world network ip address share include public wi fi vpns 5g find 38 vulnerable finally responsibly disclose vulnerability receive recognition organization such ietf linux cisco propose countermeasure,Cryptography and Security,15/09/2025
10.48550/arXiv.2509.11786,anomaly detection industrial control systems base cross domain representation learning,"Dongyang Zhan, Wenqi Zhang, Lin Ye, Xiangzhan Yu, Hongli Zhang, Zheng He",industrial control system icss be widely use industry security stability be very important ics be attack may cause serious damage therefore be very important to detect anomaly ics ics can monitor manage physical device remotely use communication network exist anomaly detection approach mainly focus analyze security network traffic sensor datum however behavior different domain e.g. network traffic sensor physical status ics be correlate be difficult to comprehensively identify anomaly analyze only single domain paper anomaly detection approach base cross domain representation learn ics be propose can learn joint feature multi domain behavior detect anomaly different domain construct cross domain graph can represent behavior multiple domain ics approach can learn joint feature leverage graph neural network anomaly behave differently different domain leverage multi task learn approach to identify anomaly different domain separately perform joint train experimental result show performance approach be well exist approach identify anomaly ics,Cryptography and Security,15/09/2025
10.48550/arXiv.2509.11761,spatial provenance recovery wireless networks relaxed privacy constraint,"Manish Bansal, Pramsu Shrivastava, J. Harshan",vehicle v2x network multi hop communication road side units rsus intend to gather location datum vehicle to offer various location base service vehicle use global positioning system gps navigation may refrain share exact gps coordinate rsus privacy consideration thus to address localization expectation rsus privacy concern vehicle introduce relax privacy model vehicle share partial location information order to avail location base service to implement notion relax privacy propose low latency protocol spatial provenance recovery vehicle use correlate linear bloom filter to embed position information propose spatial provenance recovery process take account resolution localization underlie ad hoc protocol coverage range wireless technology use vehicle rigorous theoretical analysis present extensive analysis underlie trade off relax privacy communication overhead protocol finally use wireless testbed show propose method require few bit packet header to provide security feature such localize low power jammer execute denial service attack,Cryptography and Security,15/09/2025
10.48550/arXiv.2509.11745,removal attack defense ai generate content latent base watermarking,"De Zhang Lee, Han Fang, Hanyi Wang, Ee-Chien Chang",digital watermark can be embed ai generate content aigc initialize generation process start point sample secret distribution combine pseudorandom error correct code such watermarke output can remain indistinguishable unwatermarked object maintain robustness whitenoise paper go indistinguishability investigate security removal attack demonstrate indistinguishability alone do not necessarily guarantee resistance adversarial removal specifically propose novel attack exploit boundary information leak location watermarke object attack significantly reduce distortion require to remove watermark factor 15×15\times compare baseline whitenoise attack certain setting to mitigate such attack introduce defense mechanism apply secret transformation to hide boundary prove secret transformation effectively render attacker ’s perturbation equivalent naïve whitenoise adversary empirical evaluation conduct multiple version stable diffusion validate effectiveness attack propose defense highlight importance address boundary leakage latent base watermarking scheme,Cryptography and Security,15/09/2025
10.48550/arXiv.2509.11695,time base state management hash base signature ca vpn authentication,"Daniel Herzinger, Linus Heise, Daniel Loebenberger, Matthias Söllner",advance quantum compute necessitate migrate entire technology stack post quantum cryptography include ipsec base vpn connection authentication be rfc draft post quantum authentication set draft do not consider stateful hash base signature small signature size trust long term security propose design time base state management assign vpn device certificate authority ca base hash base signature scheme xmss ca then issue leaf certificate be base classical cryptography have short validity time e. g. four hour be to be expect even large quantum computer will take significantly long to break cryptography make design quantum secure propose strategy to make timekeeping more resilient fault tamper as well strategy to recognize wrong system time minimize potential damage quickly recover result be openbsd implementation quantum safe regard leaf certificate highly flexible vpn authentication design require significantly less bandwidth computational resource compare exist alternative,Cryptography and Security,15/09/2025
10.48550/arXiv.2509.11555,dstack zero trust framework confidential containers,"Shunfan Zhou, Kevin Wang, Hang Yin",web3 application require execution platform maintain confidentiality integrity rely centralize trust authority trusted execution environments tees offer promise capability confidential compute current implementation face significant limitation apply web3 context particularly security reliability censorship resistance vendor independence,Cryptography and Security,15/09/2025
10.48550/arXiv.2509.11451,maui reconstruct private client data federated transfer learning,"Ahaan Dabholkar, Atul Sharma, Z. Berkay Celik, Saurabh Bagchi",recent work federate learn fl have show utility leverage transfer learn balance benefit fl centralize learn set federate train happen stable point have be reach conventional train global model weight be first centrally pretraine server public dataset follow only last few linear layer classification head model be finetune client scenario exist data reconstruction attack dras fl show two key weakness first strongly input correlate gradient information initial model layer be never share significantly degrade reconstruction accuracy second dra server make highly specific handcraft manipulation model structure parameter e.g. layer zero weight identity mapping row identical weight pattern be easily detectable active client,Cryptography and Security,14/09/2025
10.48550/arXiv.2509.11440,thunderhammer rowhammer bitflips pcie thunderbolt usb c,"Robert Dumitru, Junpeng Wan, Daniel Genkin, Rick Kennell, Dave, Tian, Yuval Yarom",recent year rowhammer have attract significant attention academia industry alike technique first publish 2014 flip bit memory repeatedly access neighbour memory location discovery researcher have develop substantial body work exploit rowhammer propose countermeasure work demonstrate rowhammer can be mount not only native code also remote code execution such javascript browser network,Cryptography and Security,14/09/2025
10.48550/arXiv.2509.11250,realistic environmental injection attacks gui agents,"Yitong Zhang, Ximo Li, Liyi Cai, Jia Li",gui agent build large vision language models lvlms be increasingly use to interact website however exposure open world content make vulnerable environmental injection attacks eias hijack agent behavior webpage element many recent study assume attacker to be regular user can only upload single trigger image be more realistic early assumption website level administrative control however work still fall short realism 1 trigger ’s position surround context remain largely fix train test fail to capture dynamic nature real webpage 2 trigger often occupy unrealistically large area real world image be typically small to well reflect real world scenario introduce more realistic threat model attacker be regular user trigger image be small embed dynamically change environment result exist attack prove largely ineffective threat model,Cryptography and Security,14/09/2025
10.48550/arXiv.2509.11242,explore exploit resource isolation attack surface webassembly containers,"Zhaofeng Yu, Dongyang Zhan, Lin Ye, Haining Yu, Hongli Zhang, Zhihong Tian",recently webassembly wasm technology have be rapidly evolve many runtime actively development provide cross platform secure sandbox wasm module to run portable container compare docker isolate application operate system level wasm runtime provide more security mechanism such linear memory type check protect call stack wasm be design security mind consider to be more secure container runtime various security challenge have arise researcher have focus security wasm runtime such discover vulnerability propose new security mechanism to achieve robust isolation however have observe resource isolation be not well protect current wasm runtime attacker can exhaust host ’s resource to interfere execution other container instance exploit wasi wasix interface attack surface have not be well explore measure paper explore resource isolation attack surface wasm runtime systematically propose several static wasm runtime analysis approach base analysis result propose several exploitation strategy to break resource isolation wasm runtime experimental result show malicious wasm instance can not only consume large amount system resource own also introduce high workload other component underlie operate system lead substantial performance degradation whole system addition mitigation approach have also be discuss,Cryptography and Security,14/09/2025
10.48550/arXiv.2509.11237,implementation learning errors non commuting multiplicative groups,"Aleksejus Mihalkovič, Lina Dindiene, Eligijus Sakalauskas",paper demonstrate way to generalize learn error lwe family so call modular maximal cyclic group be non commute group 𝐌2t\mathbf{m}_{2^{t have two cycle maximal multiplicative order use fact to construct accurate criterion restore message bit overwhelm probability furthermore implement original idea o. regev consider group to gain benefit non commutativity 𝐌2t\mathbf{m}_{2^{t also prove use approach can achieve level security comparable original idea,Cryptography and Security,14/09/2025
10.48550/arXiv.2509.11187,dmldroid deep multimodal fusion framework android malware detection resilience code obfuscation adversarial perturbations,"Doan Minh Trung, Tien Duc Anh Hao, Luong Hoang Minh, Nghi Hoang Khoa, Nguyen Tan Cam, Van-Hau Pham, Phan The Duy",recent year learn base android malware detection have see significant advancement detector generally fall three category string base image base graph base approach method have show strong detection performance often struggle to sustain robustness real world setting particularly face code obfuscation adversarial example aes deep multimodal learn have emerge promise solution leverage strength multiple feature type to enhance robustness generalization however systematic investigation multimodal fusion accuracy resilience remain underexplored study propose dmldroid android malware detection base multimodal fusion leverage three different representation malware feature include permission intent tabular base dex file representation image base api call graph derive sequence base conduct exhaustive experiment independently feature as well combination use different fusion strategy experimental result cicmaldroid 2020 dataset demonstrate multimodal approach dynamic weight fusion mechanism achieve high performance reach 97.98 accuracy 98.67 f1 score original malware detection notably propose method maintain strong robustness sustain 98 accuracy 98 f1 score obfuscation adversarial attack scenario finding highlight benefit multimodal fusion improve detection accuracy robustness evolve android malware threat,Cryptography and Security,14/09/2025
10.48550/arXiv.2509.11123,odoq oblivious dns quic,"Aditya Kulkarni, Tamal Das, Vivek Balachandran",domain name system dns convert domain name respective ip address have advance enhancement aim safeguard dns datum user identity attacker recent privacy focus advancement have enable ietf to standardize several protocol nevertheless protocol tend to focus strengthen user privacy oblivious dns oblivious dns https reduce resolution latency demonstrate dns quic achieve single protocol remain key challenge address paper propose protocol oblivious dns quic odoq leverage benefit quic protocol incorporate intermediary proxy server to protect client ’s identity exposure recursive resolver,Cryptography and Security,14/09/2025
10.48550/arXiv.2509.11006,range base sharding rbs protocol scalable enterprise blockchain,"M.Z. Haider, M. Dias de Assuncao, Kaiwen Zhang",blockchain technology offer decentralization security struggle scalability particularly enterprise setting efficiency control access be paramount sharding be promise solution private blockchain exist approach face challenge coordinate shard ensure fault tolerance limit node minimize high overhead consensus mechanism pbft paper propose range base sharding rbs protocol novel sharding mechanism tailor enterprise blockchain implement quorum traditional sharding model such omniledger non sharding corda framework rbs employ commit reveal scheme secure unbiased shard allocation ensure fair validator distribution reduce cross shard transaction delay approach enhance scalability balance computational load shard reduce consensus overhead improve parallel transaction execution experimental evaluation demonstrate rbs achieve significantly high throughput low latency compare exist enterprise sharde framework make viable efficient solution large scale blockchain deployment,Cryptography and Security,13/09/2025
10.48550/arXiv.2509.10895,find ssh strict key exchange violations state learning,"Fabian Bäumer, Marcel Maehren, Marcus Brinkmann, Jörg Schwenk",ssh be important protocol secure remote shell access server internet usenix 2024 bäumer et al present terrapin attack ssh bäumer et al 2024a rely attacker inject optional message key exchange to mitigate attack ssh vendor adopt extension develop openssh call strict key exchange strict kex strict kex optional message be forbid handshake prevent attack practice should simplify state machine ssh handshake linear message flow similar tls,Cryptography and Security,13/09/2025
10.48550/arXiv.2509.10858,large language models security operations centers comprehensive survey,"Ali Habibzadeh, Farid Feyzi, Reza Ebrahimi Atani",large language models llms have emerge powerful tool capable understand generate human like text offer transformative potential diverse domain security operations center soc responsible safeguard digital infrastructure represent one domain soc serve frontline defense cybersecurity task continuous monitor detection response incident however soc face persistent challenge such high alert volume limit resource high demand expert advance knowledge delay response time difficulty leverage threat intelligence effectively context llm can offer promise solution automate log analysis streamline triage improve detection accuracy provide require knowledge less time survey systematically explore integration generative ai more specifically llm soc workflow provide structure perspective capability challenge future direction believe survey offer researcher soc manager broad overview current state llm integration academic study good knowledge be first comprehensive study to examine llm application soc detail,Cryptography and Security,13/09/2025
10.48550/arXiv.2509.10823,paradigm shift audit rift explore vulnerability audit tips ton smart contracts,"Yury Yanovich, Sergey Sobolev, Yash Madhwal, Kirill Ziborov, Vladimir Gorgadze, Victoria Kovalevskay, Elizaveta Smirnova, Matvey Mishuris, Subodh Sharma",open network ton be high performance blockchain platform design scalability efficiency leverage asynchronous execution model multi layer architecture ton ’s design offer significant advantage also introduce unique challenge smart contract development security paper introduce comprehensive audit checklist ton smart contract base analysis 34 professional audit report contain 233 real world vulnerability checklist address ton specific challenge such asynchronous message handle provide actionable insight developer auditor also present detail case study vulnerability ton smart contract highlight implication offer lesson learn adopt checklist developer auditor can systematically identify mitigate vulnerability enhance security reliability ton base project work bridge gap ethereum ’s mature audit methodology emerge need ton ecosystem foster more secure robust blockchain environment,Cryptography and Security,13/09/2025
10.48550/arXiv.2509.10814,automatic generation cryptography misuse taxonomy use large language models,"Yang Zhang, Wenyi Ouyang, Yi Zhang, Liang Cheng, Chen Wu, Wenxin Hu",prevalence cryptographic api misuse cam be compromise effectiveness cryptography turn security modern system application extensive effort to develop cam detection tool tool typically rely limit set predefined rule human curate knowledge rigid rule base approach hinder adaptation evolve cam pattern real practice,Cryptography and Security,13/09/2025
