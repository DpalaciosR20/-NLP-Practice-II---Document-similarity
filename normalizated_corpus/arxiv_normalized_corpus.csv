DOI,Title,Authors,Abstract,Section,Date
10.48550/arXiv.2509.26643,convergence and divergence language models different random seed,"Finlay Fehlauer, Kyle Mahowald, Tiago Pimentel","paper , investigate convergence language model ( lm ) train different random seed , measure convergence expect per-token kullback–leibler ( kl ) divergence seed . compare lm convergence function model size and training checkpoint , identify four-phase convergence pattern : ( i ) initial uniform phase , ( ii ) sharp-convergence phase , ( iii ) sharp-divergence phase , and ( iv ) slow-reconvergence phase . far , observe large model reconverge fast later training stage , small model never actually reconverge ; result suggest certain model size may be necessary to learn stable distribution . restrict analysis to specific token frequency or part-of-speech ( pos ) tag far reveal convergence be uneven linguistic category : frequent token and function word converge fast and more reliably counterpart ( infrequent token and content word ) . overall , finding highlight factor influence stability learn distribution model training .",Computation and Language,30/09/2025
10.48550/arXiv.2509.26634,scale spoken language models syllabic speech tokenization,"Nicholas Lee, Cheol Jun Cho, Alan W Black, Gopala K. Anumanchipalli","speak language model ( slms ) typically discretize speech high-frame-rate token extract ssl speech model . most successful lm be base transformer architecture , process long token stream self-attention be expensive , attention scale quadratically sequence length . recent ssl work introduce acoustic tokenization speech syllable level , be more interpretable and potentially more scalable significant compression token length ( 4-5 hz ) . yet , value spoken language modeling be not yet fully explore . present first systematic study syllabic tokenization spoken language modeling , evaluate model suite slu benchmark vary training datum scale . syllabic token can match or surpass previous high-frame rate token significantly cut training and inference cost , achieve more 2× reduction training time and 5× reduction flop . finding highlight syllable-level language modeling promising path to efficient long-context speak language model .",Computation and Language,30/09/2025
10.48550/arXiv.2509.26619,search difficult-to-translate test examples scale,"Wenda Xu, Vilém Zouhar, Parker Riley, Mara Finkelstein, Markus Freitag, Daniel Deutsch","nlp model require test datum be sufficiently challenging . difficulty example be link topic originate ( "" seed topic "" ) . relationship topic and difficulty instance be stochastic nature : example difficult topic can happen to be easy , and vice versa . scale internet , be ten thousand potential topic , and find most difficult one draw and evaluate large number example topic be computationally infeasible . formalize task and treat multi-armed bandit problem . framework , topic be "" arm , "" and pull arm ( cost ) involve draw single example , evaluate , and measure difficulty . goal be to efficiently identify most difficult topic fix computational budget . illustrate bandit problem setup find difficult example task machine translation . find various bandit strategy vastly outperform baseline method brute-force search most challenging topic .",Computation and Language,30/09/2025
10.48550/arXiv.2509.26603,deepscientist : advance frontier-pushing scientific findings progressively,"Yixuan Weng, Minjun Zhu, Qiujie Xie, Qiyao Sun, Zhen Lin, Sifan Liu, Yue Zhang","previous ai scientist system can generate novel finding , often lack focus to produce scientifically valuable contribution address press human-defined challenge . introduce deepscientist , system design to overcome conduct goal-oriented , fully autonomous scientific discovery month-long timeline . formalize discovery bayesian optimization problem , operationalize hierarchical evaluation process consist "" hypothesize , verify , and analyze "" . leverage cumulative findings memory , loop intelligently balance exploration novel hypothesis exploitation , selectively promote most promising finding higher-fidelity level validation . consume 20 , 000 gpu hour , system generate about 5 , 000 unique scientific idea and experimentally validate approximately 1100 , ultimately surpass human-designed state-of-the-art ( sota ) method three frontier ai task 183 . 7 % , 1 . 9 % , and 7 . 9 % . work provide first large-scale evidence ai achieve discovery progressively surpass human sota scientific task , produce valuable finding genuinely push frontier scientific discovery .",Computation and Language,30/09/2025
10.48550/arXiv.2509.26601,menlo : preferences proficiency -- evaluating and modeling native-like quality 47 language,"Chenxi Whitehouse, Sebastian Ruder, Tony Lin, Oksana Kurylo, Haruka Takagi, Janice Lam, Nicolò Busetto, Denise Diaz","ensure native-like quality large language model ( llm ) response many language be challenge . to address , introduce menlo , framework operationalize evaluation native-like response quality base audience design-inspire mechanism . use menlo , create dataset 6 , 423 human-annotate prompt–response preference pair cover four quality dimension high inter-annotator agreement 47 language variety . evaluation reveal zero-shot llm judge benefit significantly pairwise evaluation and structured annotation rubric , yet still underperform human annotator dataset . demonstrate substantial improvement fine-tune reinforcement learning , reward shaping , and multi-task learning approach . additionally , show rl-traine judge can serve generative reward model to enhance llm ' multilingual proficiency , discrepancy human judgment remain . finding suggest promise direction scalable multilingual evaluation and preference alignment . release dataset and evaluation framework to support further research multilingual llm evaluation .",Computation and Language,30/09/2025
10.48550/arXiv.2509.26600,deconstruct self-bia llm-generate translation benchmark,"Wenda Xu, Sweta Agrawal, Vilém Zouhar, Markus Freitag, Daniel Deutsch","large language model ( llms ) begin to saturate exist benchmark , automate benchmark creation use llms ( llm-as-a-benchmark ) have emerge scalable alternative to slow and costly human curation . generate test set have to potential cheaply rank model , demonstrate critical flaw . llm-generate benchmark systematically favor model create benchmark : exhibit self-bia low resource language english translation task . show three key finding automatic benchmarking llms translation : first , bias originate two source : generate test datum ( llm-as-a-testset ) and evaluation method ( llm-as-an-evaluator ) , combination amplify effect . second , self-bia llm-as-a-benchmark be heavily influence model ’s generation capability source language . instance , observe more pronounce bias into-english translation , model ’s generation system be develop , out-of-english translation task . third , observe low diversity source text be one attribution self-bia . result suggest improve diversity generate source text can mitigate observe self-bia .",Computation and Language,30/09/2025
10.48550/arXiv.2509.26592,generate difficult-to-translate text,"Vilém Zouhar, Wenda Xu, Parker Riley, Juraj Juraska, Mara Finkelstein, Markus Freitag, Dan Deutsch","machine translation benchmark source real world be quickly obsolete , most example be easy state-of-the-art translation model . limit benchmark ’s ability to distinguish model be well or to reveal model ' weakness . current method create difficult test case , such subsampling or from-scratch synthesis , either fall short identify difficult example or suffer lack diversity and naturalness . inspire iterative process human expert probe model failure , propose mt-breaker , method large language model iteratively refine source text to increase translation difficulty . llm iteratively query target machine translation model to guide generation difficult example . approach generate example be more challenging target mt model preserve diversity natural text . example be tailor particular machine translation model generation , difficulty also transfer other model and language .",Computation and Language,30/09/2025
10.48550/arXiv.2509.26553,"reliable benchmarking : contamination free , controllable evaluation framework multi-step llm function call","Seiji Maekawa, Jackson Hassell, Pouya Pezeshkpour, Tom Mitchell, Estevam Hruschka","language model gain access external tool structured function call , become increasingly more capable solve complex , multi-step task . however , exist benchmark tool-augmented language model ( talms ) provide insufficient control factor such number function accessible , task complexity , and input size , and remain vulnerable data contamination . present funcbenchgen , unified , contamination-free framework evaluate talms generate synthetic multi-step tool-use task stress-test talms . key idea be to cast tool use traversal hide function-dependency dag node be function call and edge node represent one function consume output . give set external function schemas , initial variable value , and target variable , model must compose correct call sequence to compute target variable . funcbenchgen allow user to precisely control task difficulty ( e.g. , graph size , dependency depth , and distractor function ) avoid pretraining/test-time leakage .",Computation and Language,30/09/2025
10.48550/arXiv.2509.26543,unheard alternative : contrastive explanations speech-to-text model,"Lina Conti, Dennis Fucci, Marco Gaido, Matteo Negri, Guillaume Wisniewski, Luisa Bentivogli","contrastive explanation , indicate ai system produce one output ( target ) instead ( foil ) , be widely regard explainable ai more informative and interpretable standard explanation . however , obtain such explanation speech-to-text ( s2 t ) generative model remain open challenge . draw feature attribution technique , propose first method to obtain contrastive explanation s2 t analyze part input spectrogram influence choice alternative output . case study gender assignment speech translation , show method accurately identify audio feature drive selection one gender . extend scope contrastive explanation s2 t , work provide foundation well understanding s2 t model .",Computation and Language,30/09/2025
10.48550/arXiv.2509.26520,training matryoshka mixture-of-expert elastic inference-time expert utilization,"Yaoxiang Wang, Qingguo Hu, Yucheng Ding, Ruizhe Wang, Yeyun Gong, Jian Jiao, Yelong Shen, Peng Cheng, Jinsong Su","mixture-of-expert ( moe ) have emerge promising paradigm efficiently scale large language model proportional increase computational cost . however , standard training strategy top-k router prevent moe model realize full potential elastic inference . number activate expert be alter inference time , model exhibit precipitous performance degradation . work , introduce matryoshka moe ( m-moe ) , training framework instill coarse-to-fine structure directly expert ensemble . systematically vary number activate expert training , m-moe compel model to learn meaningful rank : top-ranked expert collaborate to provide essential , coarse-grained capability , subsequent expert add progressively finer-grained detail . explore principle multiple granularity , identify layer-wise randomization strategy most effective . experiment demonstrate single m-moe model achieve remarkable elasticity , performance various expert count closely match entire suite specialist model , but only fraction total training cost . flexibility not only unlock elastic inference but also enable optimize performance allocate different computational budget different model layer . work pave way more practical and adaptable deployment large-scale moe model .",Computation and Language,30/09/2025
10.48550/arXiv.2509.26514,batonvoice : operationalist framework enhance controllable speech synthesis linguistic intelligence llm,"Yue Wang, Ruotian Ma, Xingyu Chen, Zhengliang Shi, Wanshun Chen, Huang Liu, Jiadi Yao, Qu Yang, Qingxuan Jiang, Fanghua Ye, Juntao Li, Min Zhang, Zhaopeng Tu, Xiaolong Li, Linus","rise large language models ( llms ) be reshape multimodel model , speech synthesis be prominent application . however , exist approach often underutilize linguistic intelligence model , typically fail to leverage powerful instruction-following capability . limitation hinder model ’s ability to follow text instruction controllable text-to-speech ( tts ) . to address , propose new paradigm inspire "" operationalism "" decouple instruction understanding speech generation . introduce batonvoice , framework llm act "" conductor "" , understand user instruction and generate textual "" plan "" – explicit vocal feature ( e.g. , pitch , energy ) . separate tts model , "" orchestra "" , then generate speech feature . to realize component , develop batontts , tts model train specifically task . experiment demonstrate batonvoice achieve strong performance controllable and emotional speech synthesis , outperform strong open- and closed-source baseline . notably , approach enable remarkable zero-shot cross-lingual generalization , accurately apply feature control ability language unseen post-training . demonstrate objectifying speech textual vocal feature can more effectively unlock linguistic intelligence llms .",Computation and Language,30/09/2025
10.48550/arXiv.2509.26490,vitabench : benchmarke llm agents versatile interactive tasks real-world application,"Wei He, Yueqing Sun, Hongyan Hao, Xueyuan Hao, Zhikang Xia, Qi Gu, Chengcheng Han, Dengchang Zhao, Hui Su, Kefeng Zhang, Man Gao, Xi Su, Xiaodong Cai, Xunliang Cai, Yu Yang, Yunke Zhao","llm-base agent be increasingly deploy real-life scenario , existing benchmark fail to capture inherent complexity handle extensive information , leverage diverse resource , and manage dynamic user interaction . to address gap , introduce vitabench111the name "" vita "" derive latin word "" life "" , reflect focus life-serving application . , challenging benchmark evaluate agent versatile interactive task ground real-world setting . draw daily application food delivery , consumption , and online travel service , vitabench present agent most complex life-serving simulation environment date , comprise 6666 tool . framework eliminate domain-specific policy , enable flexible composition scenario and tool , yield 100100 cross-scenario task ( main result ) and 300300 single-scenario task . task be derive multiple real user request and require agent to reason temporal and spatial dimension , utilize complex tool set , proactively clarify ambiguous instruction , and track shift user intent multi-turn conversation . moreover , propose rubric-based slide window evaluator , enable robust assessment diverse solution pathway complex environment and stochastic interaction . comprehensive evaluation reveal even most advanced model achieve only 30%30\% success rate cross-scenario task , and less 50%50\% success rate other . overall , believe vitabench will serve valuable resource advance development ai agent practical real-world application .",Computation and Language,30/09/2025
10.48550/arXiv.2509.26488,dparallel : learnable parallel decode dllms,"Zigeng Chen, Gongfan Fang, Xinyin Ma, Ruonan Yu, Xinchao Wang","diffusion large language model ( dllms ) have recently draw considerable attention research community promising alternative autoregressive generation , offer parallel token prediction and low inference latency . yet , parallel decode potential remain largely underexplored , exist open-source model still require nearly token-length decode step to ensure performance . to address , introduce dparallel , simple and effective method unlock inherent parallelism dllms fast sampling . identify key bottleneck to parallel decoding arise sequential certainty convergence mask token . build insight , introduce core approach : certainty-force distillation , novel training strategy distill model to follow original sampling trajectory enforce to achieve high certainty mask token more rapidly and parallel . extensive experiment various benchmark demonstrate method can dramatically reduce number decode step maintain performance . apply llada-8b-instruct model , dparallel reduce decode step 256 30 gsm8 k , achieve 8 . 5× speedup performance degradation . mbpp benchmark , cut decode step 256 to 24 , result 10 . 5× speedup maintain accuracy . code be available https://github.com/czg1225/dparallel",Computation and Language,30/09/2025
10.48550/arXiv.2509.26476,regression language models code,"Yash Akhauri, Xingyou Song, Arissa Wongpanich, Bryan Lewandowski, Mohamed S. Abdelfattah","study code-to-metric regression : predict numeric outcome code execution , challenging task open-ended nature programming language . prior method have resort heavy and domain-specific feature engineering , show single unified regression language model ( rlm ) can simultaneously predict directly text , ( i ) memory footprint code multiple high-level language such python and c++ , ( ii ) latency triton gpu kernel , and ( iii ) accuracy and speed train neural network represent onnx . particular , relatively small 300 m parameter rlm initialize t5gemma , obtain > > 0 . 9 spearman-rank competitive programming submission apps , and single unified model achieve > > 0 . 5 average spearman-rank 17 separate language codenet . furthermore , rlm can obtain high average kendall-tau 0 . 46 five classic nas design space previously dominate graph neural network , and simultaneously predict architecture latency numerous hardware platform .",Computation and Language,30/09/2025
10.48550/arXiv.2509.26461,creagentive : agent workflow driven multi-category creative generation engine,"Yuyang Cheng, Linyue Cai, Changwei Peng, Yumiao Xu, Rongfang Bie, Yong Zhao","abstract : present creagentive , agent workflow drive multi-category creative generation engine address four key limitation contemporary large language model write story , drama and other category creative : restrict genre diversity , insufficient output length , weak narrative coherence , and inability to enforce complex structural construct . core , creagentive employ story prototype , be genre-agnostic , knowledge graph-based narrative representation decouple story logic stylistic realization encode character , event , and environment semantic triple . creagentive engage three‑stage agent workflow comprise : initialization stage construct user‑specified narrative skeleton ; generation stage long‑ and short‑term objective guide multi‑agent dialogue to instantiate story prototype ; writing stage leverage prototype to produce multi‑genre text advanced structure such retrospection and foreshadowing . architecture reduce storage redundancy and overcome typical bottleneck long‑form generation . extensive experiment , creagentive generate thousand chapter stable quality and low cost ( less $ 1 100 chapter ) use general-purpose backbone model . to evaluate performance , define two-dimensional framework 10 narrative indicator measure quality and length . result show creagentive consistently outperform strong baseline and achieve robust performance diverse genre , approach quality human-authored novel .",Computation and Language,30/09/2025
10.48550/arXiv.2509.26435,adaptive planning multi-attribute controllable summarization monte carlo tree search,"Sangwon Ryu, Heejin Do, Yunsu Kim, Gary Geunbae Lee, Jungseul Ok","controllable summarization move generic output human-aligned summary guide specify attribute . practice , interdependence attribute make challenge language model to satisfy correlate constraint consistently . moreover , previous approach often require per-attribute fine-tuning , limit flexibility diverse summary attribute . paper , propose adaptive planning multi-attribute controllable summarization ( paco ) , training-free framework reframe task plan order sequential attribute control customize monte carlo tree search ( mcts ) . paco , node represent summary , and action correspond single-attribute adjustment , enable progressive refinement only attribute require further control . strategy adaptively discover optimal control order , ultimately produce summary effectively meet constraint . extensive experiment diverse domain and model demonstrate paco achieve robust multi-attribute controllability , surpass llm-base self-planning model and fine-tuned baseline . remarkably , paco llama-3 . 2-1b rival controllability much large llama-3 . 3-70b baseline . large model , paco achieve superior control performance , outperform competitor .",Computation and Language,30/09/2025
10.48550/arXiv.2509.26415,automatic fact-checking english and telugu,"Ravi Kiran Chikkala, Tatiana Anikina, Natalia Skachkova, Ivan Vykopal, Rodrigo Agerri, Josef van Genabith","false information pose significant global challenge , and manually verifying claim be time-consuming and resource-intensive process . research paper , experiment different approach to investigate effectiveness large language model ( llms ) classify factual claim veracity and generate justification english and telugu . key contribution work include creation bilingual english-telugu dataset and benchmarking different veracity classification approach base llms .",Computation and Language,30/09/2025
10.48550/arXiv.2509.26406,annotation scheme factuality and application parliamentary proceedings,"Gili Goldin, Shira Wigderson, Ella Rabinovich, Shuly Wintner","factuality assess extent to language utterance relate real-world information ; determine utterance correspond fact , possibility , or imaginary situation , and as such , be instrumental fact check . factuality be complex notion rely multiple linguistic signal , and have be study various discipline . present complex , multi-faceted annotation scheme factuality combine concept variety previous work . develop scheme hebrew , but trust can be adapt other language . also present set almost 5 , 000 sentence domain parliamentary discourse manually annotate accord scheme . report inter-annotator agreement , and experiment various approach to automatically predict ( feature ) scheme , order to extend annotation large corpus .",Computation and Language,30/09/2025
10.48550/arXiv.2509.26383,efficient and transferable agentic knowledge graph rag reinforcement learning,"Jinyeop Song, Song Wang, Julian Shun, Yada Zhu","knowledge-graph retrieval-augmented generation ( kg-rag ) couple large language model ( llms ) structured , verifiable knowledge graph ( kgs ) to reduce hallucination and expose reasoning trace . however , many kg-rag system compose multiple llm module ( e. g planning , reasoning , and respond ) , inflate inference cost and bind behavior specific target kg . to address , introduce kg-r1 , agentic kg retrieval-augmented generation ( kg-rag ) framework reinforcement learning ( rl ) . kg-r1 utilize single agent interact kg environment , learn to retrieve step and incorporate retrieve information reasoning and generation . process be optimize end-to-end rl . control experiment knowledge-graph question answering(kgqa ) benchmark , method demonstrate efficiency and transferability : use qwen-2 . 5-3b , kg-r1 improve answer accuracy few generation token prior multi-module workflow method use large foundation or fine-tuned model . furthermore , kg-r1 enable plug and play : training , maintain strong accuracy new kg modification . property make promising kg-rag framework real-world deployment . code be publicly available https://github.com/jinyeop3110/kg-r1 .",Computation and Language,30/09/2025
10.48550/arXiv.2509.26328,fast-dllm v2 : efficient block-diffusion llm,"Chengyue Wu, Hao Zhang, Shuchen Xue, Shizhe Diao, Yonggan Fu, Zhijian Liu, Pavlo Molchanov, Ping Luo, Song Han, Enze Xie","abstract : autoregressive ( ar ) large language model ( llms ) have achieve remarkable performance wide range natural language task , yet inherent sequential decoding limit inference efficiency . work , propose fast-dllm v2 , carefully design block diffusion language model ( dllm ) efficiently adapt pretraine ar model dllms parallel text generation—require only ∼\sim1b token fine‑tuning . represent 500× reduction training datum compare full‑attention diffusion llm such dream ( 580b token ) , preserve original model ’s performance . approach introduce novel training recipe combine block diffusion mechanism complementary attention mask , enable blockwise bidirectional context modeling sacrifice ar training objective . to far accelerate decode , design hierarchical caching mechanism : block-level cache store historical context representation block , and sub-block cache enable efficient parallel generation partially decode block . couple parallel decode pipeline , fast-dllm v2 achieve to 2 . 5× speedup standard ar decode compromise generation quality . extensive experiment diverse benchmark demonstrate fast-dllm v2 match or surpass ar baseline accuracy , deliver state‑of‑the‑art efficiency dllms—marke significant step practical deployment fast and accurate llms . code and model will be publicly release . link : github code | project page",Computation and Language,30/09/2025
10.48550/arXiv.2509.26314,latent thinking optimization : latent reasoning language model secretly encodes reward signals latent thoughts,"Hanwen Du, Yuxin Dong, Xia Ning","large language models ( llms ) excel problem solve generate chain thought natural language , but such verbal thinking be computationally costly and prone overthinke . recent work instead propose latent thinking architecture huggin-3 . 5b , represent intermediate reasoning step sequence latent representation . however , latent thought lack interpretability and be difficult to supervise , raise concern correctness and reliability latent thinking process . paper , provide systematic study huggin-3 . 5b think latent space and external supervision signal can improve latent thinking process . show latent thought lead to correct incorrect answer exhibit highly distinguishable pattern , and latent classifier can reliably predict answer correctness directly latent thought . leverage insight , propose latent thinking optimization ( lto ) , probabilistic algorithm employ latent classifier latent reward model ( lrm ) to optimize latent thinking process . extensive experiment diverse reasoning task demonstrate lrm be highly effective detect incorrect latent thinking pattern , and lto can significantly improve latent thinking process . furthermore , show lrm can generalize diverse domain , and lto can be seamlessly apply general llms to improve thinking process . contrast verbal thinking , method demonstrate reward modeling and scale test-time thinking supervision can be perform directly latent space , highlight potential general , efficient , and domain-agnostic approach improve thinking process llms .",Computation and Language,30/09/2025
10.48550/arXiv.2509.26313,one-token rollout : guide supervised fine-tuning llms policy gradient,"Rui Ming, Haoyuan Wu, Shoubo Hu, Zhuolun He, Bei Yu","supervised fine-tuning ( sft ) be predominant method adapt large language model ( llms ) , yet often struggle generalization compare reinforcement learning ( rl ) . work , posit performance disparity stem not just loss function , but more fundamental difference : sft learn fix , pre-collected dataset , rl utilize on-policy datum sample current policy . build hypothesis , introduce one-token rollout ( otr ) , novel fine-tune algorithm guide sft policy gradient method . otr reframe autoregressive learning process treat token generation single-step reinforcement learning trajectory . step , perform monte carlo "" rollout "" sample multiple candidate token current policy ’s distribution . ground-truth token supervise datum be then use to provide reward signal sample . guide policy gradient , algorithm repurpose static , off-policy supervise datum dynamic , on-policy signal token level , capture generalization benefit on-policy learning bypass costly overhead full sentence generation . extensive experiment diverse suite challenge benchmark span mathematical reasoning , code generation , and general domain reasoning , demonstrate otr consistently outperform standard sft . finding establish otr powerful and practical alternative fine-tune llm and provide compelling evidence on-policy nature datum be critical driver generalization , offer promising new direction fine-tune llms .",Computation and Language,30/09/2025
10.48550/arXiv.2509.26305,feedback forensics : toolkit to measure ai personality,"Arduin Findeis, Timo Kaufmann, Eyke Hüllermeier, Robert Mullins","trait make "" good "" ai model be hard to describe upfront . example , should response be more polite or more casual ? such trait be sometimes summarize model character or personality . clear objective , conventional benchmark base automatic validation struggle to measure such trait . evaluation method use human feedback such chatbot arena have emerge popular alternative . method infer "" well "" personality and other desirable trait implicitly rank multiple model response relative other . recent issue model release highlight limitation exist opaque evaluation approach : major model be roll back sycophantic personality issue , model be observe overfitte such feedback-based leaderboard . know issue , limited public tooling exist to explicitly evaluate model personality . introduce feedback forensics : open-source toolkit to track ai personality change , encourage human ( or ai ) feedback , and exhibit ai model train and evaluate such feedback . leverage ai annotator , toolkit enable investigate personality python api and browser app . demonstrate toolkit ’s usefulness two step : ( a ) first analyse personality trait encourage popular human feedback dataset include chatbot arena , multipref and prism ; and ( b ) then use toolkit analyse much popular model exhibit such trait . release ( 1 ) feedback forensics toolkit ( 2 ) web app track ai personality popular model and feedback dataset as well ( 3 ) underlie annotation datum . 111 code : github.com/rdnfn/feedback-forensics , web app : app.feedbackforensics.com , data : hf.co/datasets/rdnfn/ff-annotations",Computation and Language,30/09/2025
10.48550/arXiv.2509.26302,quartz : qa-base unsupervised abstractive refinement task-oriented dialogue summarization,"Mohamed Imed Eddine Ghebriout, Gaël Guibon, Ivan Lerner, Emmanuel Vincent","dialogue summarization aim to distill core meaning conversation concise text . be crucial reduce complexity and noise inherent dialogue-heavy application . recent approach typically train language model to mimic human-written summary , such supervision be costly and often result output lack task-specific focus limit effectiveness downstream application , such medical task . paper , propose quartz , framework task-oriented utility-based dialogue summarization . quartz start generate multiple summary and task-oriente question-answer pair dialogue zero-shot manner use pool large language model ( llms ) . quality generate summary be evaluate have llms answer task-related question ( i ) select good candidate answer and ( ii ) identify most informative summary base answer . finally , fine-tune good llm select summary . validate multiple dataset , quartz demonstrate effectiveness achieve competitive result various zero-shot setting , rival fully-supervised state-of-the-art ( sota ) method . code and supplementary material be publicly available111https://github.com/mohamed-imed-eddine/quartz .",Computation and Language,30/09/2025
10.48550/arXiv.2509.26276,optimize speech language models acoustic consistency,"Morteza Rohanian, Michael Krauthammer","study speech language model incorporate semantic initialization and planning loss to achieve robust and consistent generation . approach initialize speech token self-supervised feature , apply light alignment loss , and train thinning and auxiliary objective target robustness and content planning . train three model : 0 . 7b speech-only model , 1 . 0b speech-only model , and 1 . 0b interleave model text and speech . acoustic study show speech-only model achieve high consistency speaker , gender , sentiment , room , and background factor , surpass large system . interleaving improve lexical and syntactic probe and semantic–acoustic alignment but reduce consistency . linear probe show initialization bias model content structure trade prosody detail . result show lm-side design and training mix control balance acoustic stability and semantic grounding change tokenizer or runtime architecture . demo and model weight be available exploration.111https://mortezaro.github.io/speech-cast/ ( demo ) ; https://huggingface.co/krauthammerlab/cast-0.7b-s2s ( hf model card ) .",Computation and Language,30/09/2025
10.48550/arXiv.2509.26242,finetune once : decouple general & domain learning dynamic boosted annealing,"Yang Tang, Ruijie Liu, Yifan Wang, Shiyu Li, Xi Chen","large language model ( llms ) fine-tuning show excellent implication . however , vanilla fine-tune method often require intricate datum mixture and repeat experiment optimal generalization . to address challenge and streamline training process , propose efficient and universal solution , dynamic boosted annealing ( dba ) . obtain global gradient training general datum , be subsequently employ gradient boosting and dynamic training step correction domain training . conjunction annealing learning , end establish fine-tuning pipeline rely solely domain datum collapse . evaluate both general and domain-specific performance multiple task several popular base model , dba achieve average improvement 5 . 8 % joint performance vanilla fine-tuning . furthermore , general datum be no long involve anneal , repeat experiment lead datum mixture be also eliminate . accord test , dba method can reduce gpu hour 91 . 0 % compare vanilla method .",Computation and Language,30/09/2025
10.48550/arXiv.2509.26216,comparative analysis ant colony optimization and google or-tool solve open capacitated vehicle routing problem logistics,"Assem Omar, Youssef Omar, Marwa Solayman, Hesham Mansour","modern logistic management system , route planning require high efficiency . open capacitated vehicle routing problem ( ocvrp ) deal find optimal delivery route fleet vehicle serve geographically distribute customer , require vehicle to return depot delivery . present study be comparative nature and speak two algorithm ocvrp solution : ant colony optimization ( aco ) , nature-inspired metaheuristic ; and google or-tools , industry-standard toolkit optimization . implementation be develop python and use custom dataset . performance appraisal be base route efficiency , computation time , and scalability . result show aco allow flexibility route parameter or-tool run much fast more consistency and require less input . could help choose route strategy scalable real-time logistic system .",Computation and Language,30/09/2025
10.48550/arXiv.2509.26189,vietbinoculars : zero-shot approach detecting vietnamese llm-generate text,"Trieu Hai Nguyen, Sivaswamy Akilesh","rapid development research large language models ( llms ) base transformer architecture raise key challenge , one be task distinguish human-written text and llm-generate text . llm-generate textual content , become increasingly complex time , and resemble human writing , traditional detection method be prove less effective , especially number and diversity llms continue to grow new model and version be release rapid pace . study propose vietbinoculars , adaptation binoculars method optimize global threshold , to enhance detection vietnamese llm-generate text . have construct new vietnamese ai-generate dataset to determine optimal threshold vietbinoculars and to enable benchmarke . result experiment show vietbinoculars achieve 99 % two domain accuracy , f1-score , and auc multiple out-of-domain dataset . outperform original binoculars model , traditional detection method , and other state-of-the-art approach , include commercial tool such zerogpt and detectgpt , especially specially modify prompt strategy .",Computation and Language,30/09/2025
10.48550/arXiv.2509.26181,explain novel sense use definition generation open language model,"Mariia Fedorova, Andrey Kutuzov, Francesco Periti, Yves Scherrer","apply definition generator base open-weights large language models ( llms ) task explain novel word sense , take target word usage input . end , employ dataset axolotl ' 24 share task explainable semantic change modeling , feature finnish , russian and german language . fine-tune and provide publicly open-source model perform high good submission aforementioned shared task , employ close proprietary llm . addition , find encoder-decoder definition generator perform par decoder-only counterpart .",Computation and Language,30/09/2025
10.48550/arXiv.2509.26160,mgen : million naturally occurring generics context,"Gustavo Cilleruelo, Emily Allaway, Barry Haddow, Alexandra Birch","mgen be dataset 44 million naturally occur generic and quantify sentence extract diverse textual source . sentence dataset have long context document , correspond website and academic paper , and cover 11 different quantifier . analyze feature generic sentence dataset , interesting insight : generic can be long sentence ( average 16 word ) and speaker often use to express generalisation people .",Computation and Language,30/09/2025
10.48550/arXiv.2509.26136,clinibench : clinical outcome prediction benchmark generative and encoder-base language model,"Paul Grundmann, Dennis Fast, Jan Frick, Thomas Steffek, Felix Gers, Wolfgang Nejdl, Alexander Löser","grow capability , generative large language model ( llms ) be be increasingly investigate complex medical task . however , effectiveness real-world clinical application remain underexplored . to address , present clinibench , first benchmark enable comparability well-studied encoder-based classifier and generative llm discharge diagnosis prediction admission note mimic-iv dataset . extensive study compare 12 generative llms and 3 encoder-based classifier and demonstrate encoder-based classifier consistently outperform generative model diagnosis prediction . assess several retrieval augmentation strategy in-context learn similar patient and find provide notable performance improvement generative llm .",Computation and Language,30/09/2025
10.48550/arXiv.2509.26126,hunger game debate : emergence over-competition multi-agent system,"Xinbei Ma, Ruotian Ma, Xingyu Chen, Zhengliang Shi, Mengru Wang, Jen-tse Huang, Qu Yang, Wenxuan Wang, Fanghua Ye, Qingxuan Jiang, Mengfei Zhou, Zhuosheng Zhang, Rui Wang, Hai Zhao, Zhaopeng Tu, Xiaolong Li, Linus","llm-base multi-agent system demonstrate great potential tackle complex problem , but competition shape behavior remain underexplored . paper investigate over-competition multi-agent debate , agent extreme pressure exhibit unreliable , harmful behavior undermine both collaboration and task performance . to study phenomenon , propose hate , hunger game debate , novel experimental framework simulate debate zero-sum competition arena . experiment , conduct range llm and task , reveal competitive pressure significantly stimulate over-competition behavior and degrade task performance , cause discussion to derail . far explore impact environmental feedback add variant judge , indicate objective , task-focused feedback effectively mitigate over-competition behavior . also probe post-hoc kindness llms and form leaderboard to characterize top llms , provide insight understanding and govern emergent social dynamic ai community .",Computation and Language,30/09/2025
10.48550/arXiv.2509.26124,vocabulary customization efficient domain-specific llm deployment,"Christian Herold, Michael Kozielski, Nicholas Santavas, Yannick Versley, Shahram Khadivi","use llm to process text training domain(s ) , often overlook factor be vocabulary mismatch , general-domain tokenizer fail to capture frequent domain-specific term , lead high token fertility and thus decrease process speed suboptimal sub-word split .",Computation and Language,30/09/2025
10.48550/arXiv.2509.26103,end-to-end aspect-guide review summarization scale,"Ilya Boytsov, Vinny DeGenova, Mikhail Balyasin, Joseph Walt, Caitlin Eusden, Marie-Claire Rochat, Margaret Pierson","present scalable large language model ( llm)-base system combine aspect-based sentiment analysis ( absa ) guide summarization to generate concise and interpretable product review summary wayfair platform . approach first extract and consolidate aspect–sentiment pair individual review , select most frequent aspect product , and sample representative review accordingly . be use to construct structured prompt guide llm to produce summary ground actual customer feedback . demonstrate real-world effectiveness system large-scale online a/b test . furthermore , describe real-time deployment strategy and release dataset111https://huggingface.co/collections/ieboytsov/review-summaries-68dab02e7b6a5bc8e29e81fa 11 , 8 million anonymize customer review cover 92 , 000 product , include extract aspect and generate summary , to support future research aspect-guided review summarization .",Computation and Language,30/09/2025
10.48550/arXiv.2509.26093,reinforced strategy optimization conversational recommender systems network-of-expert,Xiaoyan Zhao,"conversational recommender systems ( crss ) aim to provide personalize recommendation multi-turn natural language interaction user . give strong interaction and reasoning skill large language models ( llms ) , leverage llm crs have recently emerge promising direction . however , exist llm-base method often lack explicit optimization interaction strategy , instead rely unified prompt and llm ’s internal knowledge to decide to interact , can lead suboptimal outcome . paper , propose novel reinforced strategy optimization ( rso ) method crs , decompose process generate strategy-driven response decision macro-level strategy planning and micro-level strategy adaptation network-of-experts architecture . macro level , planner expert select macro-level interaction strategy ( e.g. , recommend , explain , encourage ) . micro level , actor expert generate detailed response condition select macro-level strategy , guide auxiliary expert provide complementary information such user preference and factual grounding . hierarchical decomposition disentangle optimization different sub-task involve crs response generation , enable more tractable learning level . to address scarcity high-quality multi-turn training datum , formulate strategy learning reinforcement learning problem , guide llm-based reward model to achieve automatic strategy exploration . extensive experiment show rso significantly improve interaction performance compare state-of-the-art baseline , demonstrate effectiveness explicit hierarchical strategy optimization crs .",Computation and Language,30/09/2025
10.48550/arXiv.2509.26076,improofbench : benchmarke ai research-level mathematical proof generation,"Johannes Schmitt, Gergely Bérczi, Jasper Dekoninck, Jeremy Feusi, Tim Gehrunger, Raphael Appenzeller, Jim Bryan, Niklas Canova, Timo de Wolff, Filippo Gaia, Michel van Garrel, Baran Hashemi, David Holmes, Aitor Iribar Lopez, Victor Jaeck, Martina Jørgensen, Steven Kelk, Stefan Kuhlmann, Adam Kurpisz, Chiara Meroni, Ingmar Metzler, Martin Möller, Samuel Muñoz-Echániz, Robert Nowak, Georg Oberdieck, Daniel Platt, Dylan Possamaï, Gabriel Ribeiro, Raúl Sánchez Galán, Zheming Sun, Josef Teichmann, Richard P. Thomas, Charles Vial","mathematical capability large language model ( llms ) improve , become increasingly important to evaluate performance research-level task frontier mathematical knowledge . however , existing benchmark be limited , focus solely final-answer question or high-school competition problem . to address gap , introduce improofbench , private benchmark consisting 3939 peer-reviewed problem develop expert mathematician . problem require detailed proof and be pair subproblem have final answer , support both evaluation mathematical reasoning capability human expert and large-scale quantitative analysis automate grading . furthermore , prior benchmark , evaluation setup simulate realistic research environment : model operate agentic framework tool web search literature review and mathematical software such sagemath . result show current llm can succeed more accessible research-level question , but still encounter significant difficulty more challenging problem . quantitatively , grok-4 achieve high accuracy 52%52\% final-answer subproblem , gpt-5 obtain good performance proof generation , achieve fully correct solution 22%22\% problem . improofbench will continue to evolve dynamic benchmark collaboration mathematical community , ensure relevance evaluate next generation llms .",Computation and Language,30/09/2025
10.48550/arXiv.2509.26074,limited preference data ? learn better reward model latent space synthesis,"Leitian Tao, Xuefeng Du, Yixuan Li","reward modeling , crucial align large language model ( llms ) human preference , be often bottleneck high cost preference datum . exist textual datum synthesis method be computationally expensive . propose novel framework lens synthesize preference datum directly llm ’s latent embed space . method employ variational autoencoder ( vae ) to learn structured latent representation response embedding . perform control perturbation latent space and decode back embed space , efficiently generate diverse , semantically consistent synthetic preference pair , bypass costly text generation and annotation . provide theoretical guarantee synthesize pair approximately preserve original preference ordering and improve reward model generalization . empirically , latent-space synthesis significantly outperform text-based augmentation standard benchmark , achieve superior result be 18× fast generation and use 16 , 000× small model . work offer scalable and effective alternative enhance reward model efficient datum augmentation . code be publicly available https://github.com/deeplearning-wisc/len .",Computation and Language,30/09/2025
10.48550/arXiv.2509.26072,silent judge : unacknowledged shortcut bias llm-as-a-judge,"Arash Marioriyad, Mohammad Hossein Rohban, Mahdieh Soleymani Baghshah","large language model ( llms ) be increasingly deploy automatic judge to evaluate system output task such summarization , dialogue , and creative writing . faithful judge should base verdict solely response quality and explicitly acknowledge factor shape decision . show current llm judge fail count rely shortcut introduce prompt . study use two evaluation dataset : eli5 , benchmark long-form question answering , and litbench , recent benchmark creative writing . dataset provide pairwise comparison , evaluator must choose two response be well . dataset construct 100 pairwise judgment task and employ two widely use model , gpt-4o and gemini-2 . 5-flash , evaluator role llm-as-a-judge . pair , assign superficial cue response , provenance cue indicate source identity ( human , expert , llm , or unknown ) and recency cue indicate temporal origin ( old , 1950 new , 2025 ) , keep rest prompt fix . result reveal consistent verdict shift : model exhibit strong recency bias , systematically favor "" new "" response "" old "" , as well clear provenance hierarchy ( expert > > human > > llm > > unknown ) . bias be especially pronounce gpt-4o and more subjective and open-ended litbench domain . crucially , cue acknowledgment be rare : justification almost never reference inject cue , instead rationalize decision term content quality . finding demonstrate today ’s llm-as-a-judge system be shortcut-prone and unfaithful , undermine reliability evaluator both research and deployment .",Computation and Language,30/09/2025
10.48550/arXiv.2509.26062,dyflow : dynamic workflow framework agentic reasoning,"Yanbo Wang, Zixiang Xu, Yue Huang, Xiangqi Wang, Zirui Song, Lang Gao, Chenxi Wang, Xiangru Tang, Yue Zhao, Arman Cohan, Xiangliang Zhang, Xiuying Chen","agent system base large language model ( llms ) have show great potential complex reasoning task , but build efficient and generalizable workflow remain major challenge . most exist approach rely manually design process , limit adaptability different task . few method attempt automate workflow generation , be often tie specific dataset or query type and make limited use intermediate feedback , reduce system robustness and reasoning depth . moreover , operation be typically predefine and inflexible . to address limitation , propose dyflow , dynamic workflow generation framework adaptively construct and adjust reasoning procedure base task requirement and real-time intermediate feedback , thereby enhance cross-task generalization . dyflow consist two core component : designer and executor . designer decompose complex problem sequence sub-goal define high-level objective and dynamically plan next step base intermediate output and feedback . plan be then carry executor , execute operation use dynamic operator context-aware parameterization , enable flexible and semantically ground reasoning . systematically evaluate dyflow diverse domain , include social reasoning , biomedical task , mathematical problem solve , and code generation . result demonstrate dyflow significantly outperform exist baseline , achieve substantial pass@k improvement and exhibit robust generalization diverse domain . code be publicly available https://github.com/wyf23187/dyflow .",Computation and Language,30/09/2025
10.48550/arXiv.2509.26051,ceaid : benchmark multilingual machine-generate text detection methods central european languages,"Dominik Macko, Jakub Kopal","machine-generate text detection , important task , be predominantly focus english research . make exist detector almost unusable non-english language , rely purely cross-lingual transferability . exist only few work focus central european language , leave transferability language rather unexplored . fill gap provide first benchmark detection method focus region , also provide comparison train-languages combination to identify good perform one . focus multi-domain , multi-generator , and multilingual evaluation , pinpoint difference individual aspect , as well adversarial robustness detection method . supervise finetuned detector central european language be find most performant language as well most resistant obfuscation .",Computation and Language,30/09/2025
10.48550/arXiv.2509.26048,re-searcher : robust agentic search goal-oriented planning and self-reflection,"Daocheng Fu, Jianbiao Mei, Licheng Wen, Xuemeng Yang, Cheng Yang, Rong Wu, Tao Hu, Siqi Li, Yufan Shen, Xinyu Cai, Pinlong Cai, Botian Shi, Yong Liu, Yu Qiao","large language model ( llms ) excel knowledge-intensive question answering and reasoning , yet real-world deployment remain constrain knowledge cutoff , hallucination , and limited interaction modality . augment llms external search tool help alleviate issue , but also expose agent complex search environment small , plausible variation query formulation can steer reasoning unproductive trajectory and amplify error . present systematic analysis quantify environmental complexity induce fragile search behavior and , turn , degrade overall performance . to address challenge , propose simple yet effective approach to instantiate search agent , re-searcher . search , re-searcher explicitly articulate concrete search goal and subsequently reflect retrieve evidence satisfy goal . combination goal-oriented planning and self-reflection enable re-searcher to resist spurious cue complex search environment and perform robust search . extensive experiment show method improve search accuracy and achieve state-of-the-art result . perturbation study far demonstrate substantial resilience noisy or misleading external signal , mitigate fragility search process . believe finding offer practical guidance integrate llm-powered agent more complex interactive environment and enable more autonomous decision-making .",Computation and Language,30/09/2025
10.48550/arXiv.2509.26041,unspoken hints : accuracy acknowledgement llm reasoning,"Arash Marioriyad, Shaygan Adim, Nima Alighardashi, Mahdieh Soleymani Banghshah, Mohammad Hossein Rohban","large language model ( llms ) increasingly rely chain-of-thought ( cot ) prompt to solve mathematical and logical reasoning task . yet , central question remain : extent be generate rationale faithful underlie computation , rather post-hoc narrative shape hint function answer shortcut embed prompt ? follow prior work hint unhinted prompt , present systematic study cot faithfulness control hint manipulation . experimental design span four dataset ( aime , gsm-hard , math-500 , uniadilr ) , two state-of-the-art model ( gpt-4o and gemini-2-flash ) , and structured set hint condition vary correctness ( correct and incorrect ) , presentation style ( sycophancy and datum leak ) , and complexity ( raw answer , two-operator expression , four-operator expression ) . evaluate task accuracy and hint be explicitly acknowledge reasoning . result reveal three key finding . first , correct hint substantially improve accuracy , especially hard benchmark and logical reasoning , incorrect hint sharply reduce accuracy task low baseline competence . second , acknowledgement hint be highly uneven : equation-based hint be frequently reference , raw hint be often adopt silently , indicate more complex hint push model verbalize reliance reasoning process . third , presentation style matter : sycophancy prompt encourage overt acknowledgement , leak-style prompt increase accuracy but promote hidden reliance . may reflect rlhf-related effect , sycophancy exploit human-pleasing side and datum leak trigger self-censoring side . together , result demonstrate llm reasoning be systematically shape shortcut way obscure faithfulness .",Computation and Language,30/09/2025
10.48550/arXiv.2509.26038,re$^2 $ : improve chinese grammatical error correction retrieve appropriate examples explanation,"Baoxin Wang, Yumeng Luo, Yixuan Wang, Dayong Wu, Wanxiang Che, Shijin Wang","primary objective chinese grammatical error correction ( cgec ) be to detect and correct error chinese sentence . recent research show large language model ( llms ) have be apply cgec significant result . llms , select appropriate reference example can help improve performance . however , exist method predominantly rely text similarity example retrieval , strategy frequently mismatch actual error pattern and retrieve lexically similar yet grammatically irrelevant sentence . to address problem , propose method name re2 , retrieve appropriate example explanation grammatical error . instead use text similarity input sentence , use explanation grammatical error to select reference example , be use llm to improve performance cgec . conduct experiment two cgec dataset and create high-quality grammatical error explanation ( gee ) dataset , be not only use research but also serve valuable resource future study both cgec and gee . experimental result two dataset indicate propose method effectively improve performance cgec .",Computation and Language,30/09/2025
10.48550/arXiv.2509.25961,reliability crisis reference-free metrics grammatical error correction,"Takumi Goto, Yusuke Sakai, Taro Watanabe","reference-free evaluation metric grammatical error correction ( gec ) have achieve high correlation human judgment . however , metric be not design to evaluate adversarial system aim to obtain unjustifiably high score . existence such system undermine reliability automatic evaluation , can mislead user select appropriate gec system . study , propose adversarial attack strategy four reference-free metric : some , scribendi , impara , and llm-base metric , and demonstrate adversarial system outperform current state-of-the-art . finding highlight need more robust evaluation method . code be available : https://github.com/gotutiyan/attack-gec-metric .",Computation and Language,30/09/2025
10.48550/arXiv.2509.25918,bring emerge architectures sequence labeling nlp,"Ana Ezquerro, Carlos Gómez-Rodríguez, David Vilares","pretrained transformer encoder be dominant approach sequence labeling . alternative architectures—such xlstms , structured state-space model , diffusion model , and adversarial learning—have show promise language modeling , few have be apply sequence labeling , and mostly flat or simplified task . study architecture adapt tag task vary structural complexity , label space , and token dependency , evaluation span multiple language . find strong performance previously observe simple setting do not always generalize well language or dataset , nor do extend more complex structured task .",Computation and Language,30/09/2025
10.48550/arXiv.2509.25913,understand mixture-of-expert nadaraya-watson kernel,"Chuanyang Zheng, Jiankai Sun, Yihang Gao, Enze Xie, Yuehao Wang, Peihao Wang, Ting Xu, Matthew Chang, Liliang Ren, Jingyao Li, Jing Xiong, Kashif Rasul, Mac Schwager, Anderson Schneider, Zhangyang Wang, Yuriy Nevmyvaka","mixture-of-expert ( moe ) have become cornerstone recent state-of-the-art large language model ( llms ) . traditionally , moe relie softmax\mathrm{softmax } router score function to aggregate expert output , design choice have persist early moe model modern llms , and be now widely regard standard practice . however , necessity use softmax\mathrm{softmax } to project router weight probability simplex remain unchallenged assumption rather principled design choice . work , first revisit classical nadaraya–watson regression and observe moe share same mathematical formulation nadaraya–watson regression . furthermore , show feed-forward neural network ( ffn ) and moe can be interpret special case nadaraya–watson regression , kernel function correspond input neuron output layer . motivate insight , propose zero-additional-cost kernel​inspired​router​with​normalization\mathrm{kernel ~ inspired ~ router ~ ~ normalization } ( kern\mathrm{kern } ) , ffn-style router function , alternative softmax\mathrm{softmax } . demonstrate router generalize sigmoid\mathrm{sigmoid}- and softmax\mathrm{softmax}-based router . base empirical observation and establish practice ffn implementation , recommend use relu\mathrm{relu } activation and ℓ2\ell_{2}-normalization kern\mathrm{kern } router function . comprehensive experiment moe and llm validate effectiveness propose ffn-style router function kern\mathrm{kern } .",Computation and Language,30/09/2025
10.48550/arXiv.2509.25911,mem-α : learning memory construction reinforcement learning,"Yu Wang, Ryuichi Takanobu, Zhiqi Liang, Yuzhen Mao, Yuanzhe Hu, Julian McAuley, Xiaojian Wu","large language model ( llm ) agent be constrain limited context window , necessitate external memory system long-term information understanding . current memory-augmented agent typically depend pre-defined instruction and tool memory update . however , language model may lack ability to determine information to store , to structure , and to update it—especially memory system become more complex . result suboptimal memory construction and information loss . end , propose mem-α\alpha , reinforcement learn framework train agent to effectively manage complex memory system interaction and feedback . also construct specialized training dataset span diverse multi-turn interaction pattern pair comprehensive evaluation question design to teach effective memory management . training , agent process sequential information chunk , learn to extract , store , and update memory system . reward signal derive downstream question-answere accuracy full interaction history , directly optimize memory construction . to illustrate effectiveness training framework , design memory architecture comprise core , episodic , and semantic component , equip multiple tool memory operation . empirical evaluation demonstrate mem-α\alpha achieve significant improvement exist memory-augmented agent baseline . be train exclusively instance maximum length 30k token , agent exhibit remarkable generalization sequence exceed 400k tokens—over 13× training length , highlight robustness mem-α\alpha .",Computation and Language,30/09/2025
10.48550/arXiv.2509.25903,perq : efficient evaluation multilingual text personalization quality,"Dominik Macko, Andrew Pulver","metric be available to evaluate specific aspect text , such personalization quality , researcher often rely solely large language model to meta-evaluate such text . internal bias individual language model , be recommend to use multiple combined evaluation , directly increase cost such meta-evaluation . paper , computationally efficient method evaluation personalization quality give text ( generate language model ) be introduce , call perq . case study comparison generation capability large and small language model show usability propose metric research , effectively reduce waste resource .",Computation and Language,30/09/2025
10.48550/arXiv.2509.25878,asr noise : explore robustness sundanese and javanese,"Salsabila Zahirah Pranida, Muhammad Cendekia Airlangga, Rifo Ahmad Genadi, Shady Shehata","investigate robustness whisper-based automatic speech recognition ( asr ) model two major indonesian regional language : javanese and sundanese . recent work have demonstrate strong asr performance clean condition , effectiveness noisy environment remain unclear . to address , experiment multiple training strategy , include synthetic noise augmentation and specaugment , and evaluate performance range signal-to-noise ratio ( snrs ) . result show noise-aware training substantially improve robustness , particularly large whisper model . detailed error analysis far reveal language-specific challenge , highlight avenue future improvement . code be available https://github.com/rifoagenadi/robust_jvsu_asr .",Computation and Language,30/09/2025
10.48550/arXiv.2509.25868,refact : benchmark scientific confabulation detection positional error annotations,"Yindong Wang, Martin Preiß, Margarita Bugueño, Jan Vincent Hoffbauer, Abdullatif Ghajar, Tolga Buz, Gerard de Melo","large language models ( llms ) frequently confabulate scientific fact , severely undermine trustworthiness . address challenge require benchmark go binary factuality and enable fine-grained evaluation . introduce refact ( reddit false and correct texts ) , benchmark 1 , 001 expert-annotated question–answer pair span diverse scientific domain detection scientific confabulation . instance include both scientifically correct answer and non-factual counterpart annotate precise error span and error-type . refact enable multi-stage evaluation : ( 1 ) confabulation detection , ( 2 ) fine-grained error localization , and ( 3 ) correction . benchmark 9 state-of-the-art llms , reveal limited performance ( ∼\sim50 % accuracy ) . even top model such gpt-4o fail to distinguish factual confabulate scientific answer , raise concern reliability llm-as-judge evaluation paradigm . finding highlight need fine-grained , human-validated benchmark to detect and correct scientific confabulation domain-specific contexts . dataset be release github111we provide dataset : https://github.com/ddz5431/refact .",Computation and Language,30/09/2025
10.48550/arXiv.2509.25844,believe see : quality scores contextualizing vision-language model explanations,"Keyu He, Tejas Srinivasan, Brihi Joshi, Xiang Ren, Jesse Thomason, Swabha Swayamdipta","people query vision-language model ( vlms ) but can not see accompany visual context ( e.g. blind and low-vision user ) , augment vlm prediction natural language explanation can signal model prediction be reliable . however , prior work have find explanation can easily convince user inaccurate vlm prediction be correct . to remedy undesirable overreliance vlm prediction , propose evaluate two complementary quality vlm-generated explanation two quality scoring function . propose visual fidelity , capture faithful explanation be visual context , and contrastiveness , capture well explanation identify visual detail distinguish model ’s prediction plausible alternative . a-okvqa and vizwiz task , quality scoring function be well calibrate model correctness exist explanation quality . conduct user study participant have to decide vlm prediction be accurate view visual context . observe show quality score vlm explanation improve participant ' accuracy predict vlm correctness 11 . 1 % , include 15 . 4 % reduction rate falsely believe incorrect prediction . finding highlight utility explanation quality score foster appropriate reliance vlm prediction .",Computation and Language,30/09/2025
10.48550/arXiv.2509.25827,overthinke reduction decouple reward and curriculum data scheduling,"Shuyang Jiang, Yusheng Liao, Ya Zhang, Yanfeng Wang, Yu Wang","large reasoning model train critic-free reinforcement learning and verifiable reward ( rlvr ) represent state-of-the-art , practical utility be hamper "" overthinke "" , critical issue model generate excessively long reasoning path performance benefit . exist solution penalize length often fail , induce performance degradation fundamental misalignment trajectory-level reward and token-level optimization . work , introduce novel framework , decs , build theoretical discovery two previously unaddresse flaw current length reward : ( 1 ) erroneous penalization essential exploratory token and ( 2 ) inadvertent rewarding partial redundancy . framework ’s innovation include ( i ) first-of-its-kind decouple token-level reward mechanism surgically distinguishe and penalize redundant token , and ( ii ) novel curriculum batch scheduling strategy to master efficiency-efficacy equilibrium . experimental result show decs can achieve dramatic reduction reasoning token 50 % seven benchmark simultaneously maintain or even improve performance . demonstrate conclusively substantial gain reasoning efficiency can be achieve compromise model ’s underlie reasoning power .",Computation and Language,30/09/2025
10.48550/arXiv.2509.25817,personalized scientific figure caption generation : empirical study author-specific writing style transfer,"Jaeyoung Kim, Jongho Lee, Hongjun Choi, Sion Jang","study personalize figure caption generation use author profile datum scientific paper . experiment demonstrate rich author profile datum , combine relevant metadata , can improve personalization performance multimodal large language model . however , also reveal fundamental trade-off match author style and maintain caption quality . finding offer valuable insight and future direction develop practical caption automation system balance objective . work be conduct part 3rd scicap challenge . 111https://scicap.ai",Computation and Language,30/09/2025
10.48550/arXiv.2509.25814,"retag : retrieval-enhanced , topic-augmented graph-based global sensemaking","Boyoung Kim, Dosung Lee, Sumin An, Jinseong Jeong, Paul Hongsuck Seo","recent advance question answering have lead substantial progress task such multi-hop reasoning . however , global sensemaking—answere question synthesize information entire corpus—remain significant challenge . prior graph-based approach global sensemaking lack retrieval mechanism , topic specificity , and incur high inference cost . to address limitation , propose retag , retrieval-enhanced , topic-augmented graph framework construct topic-specific subgraph and retrieve relevant summary response generation . experiment show retag improve response quality significantly reduce inference time compare baseline . code be available https://github.com/bykimby/retag .",Computation and Language,30/09/2025
10.48550/arXiv.2509.25813,robiologydatachoiceqa : romanian dataset improve biology understanding large language model,"Dragos-Dumitru Ghinea, Adela-Nicoleta Corbeanu, Adrian-Marius Dumitran","recent year , large language model ( llms ) have demonstrate significant potential various natural language processing ( nlp ) task . however , performance domain-specific application and non-english language remain less explore . study introduce novel romanian-language dataset multiple-choice biology question , carefully curate to assess llm comprehension and reasoning capability scientific contexts . contain approximately 14 , 000 question , dataset provide comprehensive resource evaluate and improve llm performance biology .",Computation and Language,30/09/2025
10.48550/arXiv.2509.25795,assess algorithmic bias language-based depression detection : comparison dnn and llm approach,"Obed Junias, Prajakta Kini, Theodora Chaspari","paper investigate algorithmic bias language-based model automate depression detection , focus socio-demographic disparity relate gender and race/ethnicity . model train use deep neural network ( dnn ) base embedding be compare few-shot learning approach large language model ( llms ) , evaluate performance and fairness clinical interview transcript distress analysis interview corpus/wizard-of-oz ( daic-woz ) . to mitigate bias , fairness-aware loss function be apply dnn-base model , in-context learn varied prompt framing and shot count be explore llms . result indicate llms outperform dnn-based model depression classification , particularly underrepresented group such hispanic participant . llms also exhibit reduce gender bias compare dnn-base embedding , racial disparity persist . fairness-aware technique mitigate bias dnn-base embedding , worst-group loss , be design to minimize loss worst-performe demographic group , achieve well balance performance and fairness . contrast , fairness-regularized loss minimize loss group but perform less effectively . llms , guide prompt ethical framing help mitigate gender bias 1-shot setting . however , increase number shot do not lead further reduction disparity . race/ethnicity , neither prompt strategy nor increase nn nn-shot learn effectively reduce disparity .",Computation and Language,30/09/2025
10.48550/arXiv.2509.25760,truthrl : incentivize truthful llm reinforcement learning,"Zhepei Wei, Xiao Yang, Kai Sun, Jiaqi Wang, Rulin Shao, Sean Chen, Mohammad Kachuee, Teja Gollapudi, Tony Liao, Nicolas Scheffer, Rakesh Wanga, Anuj Kumar, Yu Meng, Wen-tau Yih, Xin Luna Dong","large language model ( llms ) have demonstrate strong performance factoid question answer , be still prone hallucination and untruthful response , particularly task demand information parametric knowledge . indeed , truthfulness require more accuracy—model must also recognize uncertainty and abstain unsure to avoid hallucination . present fundamental challenge exist method : approach optimize accuracy often amplify hallucination , encourage abstention can become overly conservative , sacrifice correct answer . extreme ultimately compromise truthfulness . work , present truthrl , general reinforcement learning ( rl ) framework directly optimize truthfulness llms . specifically , implement truthrl use grpo simple yet effective ternary reward distinguish correct answer , hallucination , and abstention . incentivize model to reduce hallucination not only provide correct response , but also enable abstention uncertain , thereby improve truthfulness . extensive experiment four knowledge-intensive benchmark show , compare vanilla rl , truthrl significantly reduce hallucination 28 . 9 % and improve truthfulness 21 . 1 % , consistent gain various backbone model ( e.g. , qwen , llama ) retrieval and non-retrieval setup . in-depth ablation study demonstrate vanilla accuracy-driven method , such supervised fine-tuning or rl binary reward , struggle to balance factual correctness and uncertainty . contrast , propose truthfulness-driven truthrl achieve strong performance both accuracy and truthfulness , underscore importance learn objective design develop truthful llm . also experiment more complicated reward design , such knowledge-enhanced and reasoning-enhanced variant , and show simple ternary reward scheme generally perform well . moreover , find improvement truthrl arise enhance capability llms to recognize knowledge boundary , hence avoid be overly conservative baseline be . further analysis confirm truthrl be robust hallucination-baiting question and more confident produce accurate response .",Computation and Language,30/09/2025
10.48550/arXiv.2509.25752,detect hope across languages : multiclass classification positive online discourse,"T. O.Abiola, K. D. Abiodun, O. E. Olumide, O. O. Adebanji, O. Hiram Calvo, Grigori Sidorov","detection hopeful speech social medium have emerge critical task promote positive discourse and well-being . paper , present machine learn approach multiclass hope speech detection multiple language , include english , urdu , and spanish . leverage transformer-based model , specifically xlm-roberta , to detect and categorize hope speech three distinct class : generalized hope , realistic hope , and unrealistic hope . propose methodology be evaluate polyhope dataset polyhope-m 2025 share task , achieve competitive performance language . compare result exist model , demonstrate approach significantly outperform prior state-of-the-art technique term macro f1 score . also discuss challenge detect hope speech low-resource language and potential improve generalization . work contribute development multilingual , fine-grained hope speech detection model , can be apply to enhance positive content moderation and foster supportive online community .",Computation and Language,30/09/2025
10.48550/arXiv.2509.25736,"think less , label better : multi-stage domain-grounde synthetic data generation fine-tune large language models telecommunications","Chenhua Shi, Gregor Macdonald, Bhavika Jalli, Wanlu Lei, John Zou, Mridul Jain, Joji Philip","success large language model ( llms ) depend heavily large-scale , high-quality instruction-following and reinforcement dataset . however , generate such datum human annotation be prohibitively time-consuming particularly domain-specific task telecom network troubleshooting , accurate response require deep technical expertise and contextual understanding . paper , present fully automate , retrieval-augmented pipeline generate synthetic question-answer ( qa ) pair ground structured domain knowledge . multi-stage framework integrate retriever , base generator , and refinement model to synthesize and enhance qa pair use document retrieve domain-specific knowledge graph . to ensure datum quality , employ customize ragas-base scoring to filter low-quality sample , produce high-quality dataset suitable reinforcement fine-tuning ( rft ) . demonstrate approach real-world telecom scenario focus radio access network ( ran ) troubleshooting . result pipeline generate complex , context-rich troubleshooting solution plan human intervention . work offer scalable solution building instruction and reinforcement dataset specialized domain , significantly reduce dependence manual labeling maintain high technical fidelity .",Computation and Language,30/09/2025
10.48550/arXiv.2509.25733,catch : novel data synthesis framework high therapy fidelity and memory-driven planning chain thought ai counseling,"Mingyu Chen, Jingkai Lin, Zhaojie Chu, Xiaofen Xing, Yirong Chen, Xiangmin Xu","recently , advancement ai counseling base large language model have show significant progress . however , exist study employ one-time generation approach to synthesize multi-turn dialogue sample , result low therapy fidelity and fail to capture decision-making rationale response . work , propose catch , novel datum synthesis framework design to address challenge . specifically , to improve therapy fidelity , introduce progressive dialogue synthesis strategy , extract goal , resource , and solution client ’s self-report , organize structured outline , and then incrementally generate stage-aligned counseling dialogue . to capture decision-making rationale response , propose memory-driven dynamic planning thinking pattern integrate memory enhancement , global planning , and strategy reasoning ; collaborative multi-agent optimizer then leverage mdp to attach explicit chain-of-thought dialogue turn . extensive experiment and human evaluation demonstrate catch significantly enhance fidelity and logical coherence ai counseling.111https://github.com/scutcyr/soulchat-r1",Computation and Language,30/09/2025
10.48550/arXiv.2509.25729,controlled generation private synthetic text,"Zihao Zhao, Anjalie Field","text anonymization be essential responsibly develop and deploy ai high-stakes domain such healthcare , social service , and law . work , propose novel methodology privacy-preserve synthetic text generation leverage principle de-identification and hiding plain sight ( hips ) theory . approach introduce entity-aware control code to guide controllable generation use either in-context learning ( icl ) or prefix tuning . icl variant ensure privacy level consistent underlie de-identification system , prefix tune variant incorporate custom masking strategy and loss function to support scalable , high-quality generation . experiment legal and clinical dataset demonstrate method achieve strong balance privacy protection and utility , offer practical and effective solution synthetic text generation sensitive domain . 111the code be provide https://github.com/zzhao71/controlled-generation-for-private-synthetic-text.git",Computation and Language,30/09/2025
10.48550/arXiv.2509.25725,atomic thinking llms : decouple and exploring mathematical reasoning abilities,"Jiayi Kuang, Haojing Huang, Yinghui Li, Xinnian Liang, Zhikun Xu, Yangning Li, Xiaoyu Tan, Chao Qu, Meishan Zhang, Ying Shen, Philip S. Yu","large language models ( llms ) have demonstrate outstanding performance mathematical reasoning capability . however , argue current large-scale reasoning model primarily rely scale training dataset diverse mathematical problem and long thinking chain , raise question llms genuinely acquire mathematical concept and reasoning principle or merely remember training datum . contrast , human tend to break complex problem multiple fundamental atomic capability . inspire , propose new paradigm evaluate mathematical atomic capability . work categorize atomic ability two dimension : ( 1 ) field-specific ability four major mathematical field , algebra , geometry , analysis , and topology , and ( 2 ) logical ability different level , include conceptual understanding , forward multi-step reasoning formal math language , and counterexample-driven backward reasoning . propose correspond training and evaluation dataset atomic capability unit , and conduct extensive experiment different atomic capability influence other , to explore strategy to elicit require specific atomic capability . evaluation and experimental result advanced model show many interesting discovery and inspiration different performance model various atomic capability and interaction atomic capability . finding highlight importance decouple mathematical intelligence atomic component , provide new insight model cognition and guide development training strategy more efficient , transferable , and cognitively ground paradigm "" atomic thinking "" .",Computation and Language,30/09/2025
10.48550/arXiv.2509.25684,ld-mole : learnable dynamic routing mixture lora expert,"Yuan Zhuang, Yi Shen, Yuexin Bian, Qing Su, Shihao Ji, Yuanyuan Shi, Fei Miao","recent study have show combine parameter-efficient fine-tuning ( peft ) mixture-of-expert ( moe ) be effective strategy adapt large language model ( llms ) downstream task . however , most exist approach rely conventional topk routing , require careful hyperparameter tuning and assign fix number expert token . work , propose ld-mole , learnable dynamic routing mechanism mixture lora experts enable adaptive , token-dependent , and layer-wise expert allocation . method replace non-differentiable topk selection differentiable routing function and closed-form solution . moreover , design allow model to adaptively determine number expert to activate token different layer . addition , introduce analytical sparsity control objective to regularize number activate expert . extensive experiment qwen3-1 . 7b and llama-3 . 2-3b model show ld-mole achieve high average score compare state-of-the-art baseline , diverse set benchmark . method not only achieve superior performance , but also demonstrate ability to learn token-dependent and layer-wise expert allocation .",Computation and Language,30/09/2025
10.48550/arXiv.2509.25673,mitigate biases language models bias unlearning,"Dianqing Liu, Yi Liu, Guoqing Jin, Zhendong Mao","many study have show various bias target different demographic group language model , amplify discrimination and harm fairness . recent parameter modification debiase approach significantly degrade core capability such text coherence and task accuracy . and prompt-base debiase method , only effective predefine trigger word , fail to address deeply embed stereotypical association model parameter . paper , propose biasunlearn , novel model debiase framework achieves target debiase dual-pathway unlearning mechanism coordinate stereotype forgetting anti-stereotype retention , prevent bias polarity reversal adversarial forget set and dynamic dataset swapping . conduct extensive experiment multiple language model various evaluation benchmark . result show biasunlearn outperform exist method mitigate bias language model retain language modeling capability . further experiment reveal debiase weight be transferable model variant , confirm bias representation become entrenched pre-training and persist fine-tune phase .",Computation and Language,30/09/2025
10.48550/arXiv.2509.25671,flaw averages : quantifying uniformity performance benchmarks,"Arda Uzunoglu, Tianjian Li, Daniel Khashabi","benchmark shape scientific conclusion model capability and steer model development . create feedback loop : strong benchmark drive well model , and well model demand more discriminative benchmark . ensure benchmark reliability be therefore essential trustworthy evaluation and meaningful progress . work , study benchmark reliability distributional perspective and introduce benchmark harmony , measure uniformly model ’s performance be distribute subdomain benchmark . posit high harmony be desirable benchmark property , indicate aggregate metric reflect uniform competence subdomain . 19 multiple-choice benchmark and five model family , map benchmark mean-variance plane harmony compute model , high mean and low variance signal more reliable evaluation . analysis show less harmonious benchmark can give mislead result , overall accuracy may be disproportionately influence specific subdomain . instance , arc-easy be overwhelm question biological concepts , overshadow other critical subdomain such geography , physics , chemistry , and environmental science . recommend harmony should be report accuracy , reframe evaluation simple performance average more robust , distributionally reliable measurement performance .",Computation and Language,30/09/2025
10.48550/arXiv.2509.25649,media bias detector : framework annotating and analyze news scale,"Samar Haider, Amir Tohidi, Jenny S. Wang, Timothy Dörr, David M. Rothschild, Chris Callison-Burch, Duncan J. Watts","mainstream news organization shape public perception not only directly article publish but also choice make topic to cover ( or ignore ) and to frame issue do decide to cover . however , measure subtle form medium bias scale remain challenge . here , introduce large , ongoing ( january 1 , 2024 to present ) , real-time dataset and computational framework develop to enable systematic study selection and frame bias news coverage . pipeline integrate large language model ( llms ) scalable , near-real-time news scrape to extract structured annotations—include political lean , tone , topic , article type , and major events—across hundred article day . quantify dimension coverage multiple sentence level , article level , and publisher level—expande way researcher can analyze media bias modern news landscape . addition curate dataset , also release interactive web platform convenient exploration datum . together , contribution establish reusable methodology study media bias scale , provide empirical resource future research . leverage breadth corpus time and publisher , also present example ( focus 150 , 000 + article examine 2024 ) illustrate novel datum set can reveal insightful pattern news coverage and bias , support academic research and real-world effort to improve media accountability .",Computation and Language,30/09/2025
10.48550/arXiv.2509.25611,transformer lens support-preserving map measure,"Takashi Furuya, Maarten V. de Hoop, Matti Lassas","transformer be deep architecture define "" in-context map "" enable predict new token base give set token ( such prompt nlp application or set patch vision transformer ) . previous work , study ability architecture to handle arbitrarily large number context token . to mathematically , uniformly analyze expressivity , consider case mapping be condition context represent probability distribution become discrete finite number token . modeling neural network map probability measure have multiple application , such study wasserstein regularity , prove generalization bound and do mean-field limit analysis dynamic interact particle go network . work , study question kind map measure be transformer . fully characterize property map measure enable to be represent term in-context map push forward . one hand , include transformer ; other hand , transformer universally approximate representation continuous in-context map . property be preserve cardinality support and regular part fréchet derivative be uniformly continuous . moreover , show solution map vlasov equation , be nonlocal transport type , interact particle system mean-field regime cauchy problem satisfy condition one hand and , hence , can be approximate transformer ; other hand , prove measure-theoretic self-attention have property ensure infinite depth , mean-field measure-theoretic transformer can be identify vlasov flow .",Computation and Language,30/09/2025
10.48550/arXiv.2509.25604,rfg : test-time scale diffusion large language model reasoning reward-free guidance,"Tianlang Chen, Minkai Xu, Jure Leskovec, Stefano Ermon","diffusion large language model ( dllms ) have show great potential large-scale language modeling , and be increase interest far improve capacity to solve complex problem guide reasoning process step step . common practice autoregressive language model typically learn process reward model dense annotation intermediate step . however , be challenge dllms generation be any-order fashion and intermediate state be partially mask sentence . end , paper , propose reward-free guidance ( rfg ) , principled method guide reasoning trajectory dllms explicit process reward . key idea rfg be to parameterize process reward log-likelihood ratio enhanced and reference dllms , enhanced model can be easily obtain dllm have be post-traine reinforcement learning ( rl ) or supervise fine-tuning ( sft ) . provide theoretical justification rfg induce reward-guided sample distribution additional reward . conduct comprehensive experiment four challenging mathematical reasoning and code generation benchmark use diverse suite dllms enhance various post-training method . rfg consistently yield significant improvement task and model type , achieve accuracy gain to 9 . 2 % . finding establish rfg general training-free framework scale test-time reasoning reliance external reward model .",Computation and Language,29/09/2025
10.48550/arXiv.2509.25568,probe limits stylistic alignment vision-language model,"Asma Farajidizaji, Akash Gupta, Vatsal Raina","vision-language model be increasingly use to generate image caption specific style , such humor or romantic . however , transformer-based model often struggle subjective task zero-shot setting . preference datum can be use to align desire style , such datum be expensive to acquire , limit ability to explore model ' full capability . work address study data efficiency align small vision-language model humor and romantic style . approach help to define performance limit model and determine little preference datum be need to achieve stylistic saturation , benchmarke capability and limitation .",Computation and Language,29/09/2025
10.48550/arXiv.2509.25546,do not sweat small stuff : segment-level meta-evaluation base pairwise difference correlation,"Colten DiIanni, Daniel Deutsch","paper introduce pairwise difference pearson ( pdp ) , novel segment-level meta-evaluation metric machine translation ( mt ) address limitation previous pearson ’s ρ\rho-based and and kendall ’s τ\tau-base meta-evaluation approach . pdp be correlation-based metric utilize pairwise difference rather raw score . draw information segment more robust understanding score distribution and use segment-wise pairwise difference to refine global pearson intra-segment score comparison . analysis wmt ' 24 share task show pdp properly rank sentinel evaluation metric and well align human error weighting previous work . noise injection analysis demonstrate pdp ’s robustness random noise , segment bias , and system bias highlight sensitivity extreme outlier .",Computation and Language,29/09/2025
10.48550/arXiv.2509.25545,performance and competence intertwine : computational model null subject stage english-speake child,"Soumik Dey, William Gregory Sakas","empirically establish null subject ( ns ) stage , last about 4 year age , involve frequent omission subject child . orfitelli and hyams ( 2012 ) observe young english speaker often confuse imperative ns utterance declarative one due performance influence , promote temporary null subject grammar . propose new computational parameter to measure misinterpretation and incorporate simulated model obligatory subject grammar learning . use modify version variational learner yang ( 2012 ) work superset-subset language , simulation support orfitelli and hyams ' hypothesis . more generally , study outline framework integrate computational model study grammatical acquisition other key developmental factor .",Computation and Language,29/09/2025
10.48550/arXiv.2509.25543,align multilingual reasoning verifiable semantics high-resource expert model,"Fahim Faisal, Kaiqiang Song, Song Wang, Simin Ma, Shujian Liu, Haoyun Deng, Sathish Reddy Indurthi","reinforcement learning have advance reasoning ability large language models ( llms ) , gain be largely confine english , create significant performance disparity language . to address , introduce pivot-based reinforcement learning semantically verifiable rewards ( pb-rlsvr ) , novel framework enhance multilingual reasoning circumvent need human-annotated datum target language . approach employ high-performing english llm "" pivot "" model to generate reference response reasoning task . multilingual model be then reward base semantic equivalence response english reference , effectively transfer pivot model ’s reasoning capability language . investigate several cross-lingual semantic reward function , include base embedding and machine translation . extensive experiment suite multilingual reasoning benchmark show method significantly narrow performance gap english and other language , substantially outperform traditional ppo baseline . specifically , pb-rlsvr framework improve average multilingual performance llama-3 . 1-8b-instruct and qwen3-32b 16 . 41 % and 10 . 17 % , respectively , demonstrate powerful and data-efficient approach build truly multilingual reasoning agent .",Computation and Language,29/09/2025
10.48550/arXiv.2509.25532,calibrate verbalize confidence self-generate distractor,"Victor Wang, Elias Stengel-Eskin","calibrated confidence estimate be necessary large language model ( llm ) output to be trust human user . llms can express confidence human-interpretable way , verbalize llm-generate confidence score have empirically be find to be miscalibrate , report high confidence instance low accuracy and thereby harm trust and safety . hypothesize overconfidence often stem give llm ’s heighten suggestibility face claim encode little information ; empirically validate hypothesis , find more suggestibility lower-accuracy claim . build finding , introduce distractor-normalized coherence ( dinco ) , estimate and account llm ’s suggestibility bias have model verbalize confidence independently several self-generated distractor ( i.e. alternative claim ) , and normalize total verbalize confidence . to far improve calibration , leverage generator-validator disagreement , augment normalize validator confidence consistency-based estimate generator confidence . here , frame popular approach self-consistency leverage coherence sample generation , and normalize verbalize confidence leverage coherence validation incompatible claim , allow to integrate complementary dimension coherence dinco . moreover , analysis show dinco provide less saturated – and therefore more usable – confidence estimate , and further sampling alone can not close gap dinco and baseline , dinco 10 inference call outperform self-consistency 100 . 111code : https://github.com/dubai03nsr/dinco",Computation and Language,29/09/2025
10.48550/arXiv.2509.25516,wer : probing whisper 's sub-token decoder diverse language resource levels,"Siyu Liang, Nicolas Ballier, Gina-Anne Levow, Richard Wright","large multilingual automatic speech recognition ( asr ) model achieve remarkable performance , internal mechanism end-to-end pipeline , particularly concern fairness and efficacy language , remain underexplored . paper introduce fine-grained analysis whisper ’s multilingual decoder , examine sub-token hypothesis transcription language various resource level . method trace beam search path , capture sub-token guess and associated probability . result reveal high resource language benefit high likelihood correct token be top-ranke , great confidence , low predictive entropy , and more diverse alternative candidate . low resource language fare bad metric , but also exhibit distinct cluster pattern sub-token usage sometimes influence typology pca and t-sne analysis . sub-token probe uncover systematic decode disparity mask aggregate error rate and point target intervention to ameliorate imbalance development speech technology .",Computation and Language,29/09/2025
10.48550/arXiv.2509.25498,"not wrong , but untrue : llm overconfidence document-based query","Nick Hagar, Wilma Agustianto, Nicholas Diakopoulos","large language model ( llms ) be increasingly use newsroom workflow , but tendency to hallucinate pose risk core journalistic practice source , attribution , and accuracy . evaluate three widely use tools—chatgpt , gemini , and notebooklm—on reporting-style task ground 300-document corpus relate tiktok litigation and policy u . s . vary prompt specificity and context size and annotate sentence-level output use taxonomy to measure hallucination type and severity . sample , 30 % model output contain at least one hallucination , rate approximately three time high gemini and chatgpt ( 40 % ) notebooklm ( 13 % ) . qualitatively , most error do not involve invent entity or number ; instead , observe interpretive overconfidence–model add unsupported characterization source and transform attribute opinion general statement . pattern reveal fundamental epistemological mismatch : journalism require explicit source claim , llm generate authoritative-sounding text regardless evidentiary support . propose journalism-specific extension exist hallucination taxonomy and argue effective newsroom tool need architecture enforce accurate attribution rather optimize fluency .",Computation and Language,29/09/2025
10.48550/arXiv.2509.25477,"rise africanlp : contribution , contributors , and community impact ( 2005-2025 )","Tadesse Destaw Belay, Kedir Yassin Hussen, Sukairaj Hafiz Imam, Iqra Ameer, Ibrahim Said Ahmad, Isa Inuwa-Dutse, Idris Abdulmumin, Grigori Sidorov, Vukosi Marivate, Seid Muhie Yimam, Shamsuddeen Hassan Muhammad","natural language processing ( nlp ) be undergo constant transformation , large language models ( llms ) be drive daily breakthrough research and practice . regard , track progress nlp research and automatically analyze contribution research paper provide key insight nature field and researcher . study explore progress african nlp ( africanlp ) ask ( and answer ) basic research question such : i ) have nature nlp evolve last two decade ? , ii ) be contribution africanlp paper ? , and iii ) individual and organization ( author , affiliated institution , and funding body ) have be involve development africanlp ? quantitatively examine contribution africanlp research use 1 . 9 k nlp paper abstract , 4 . 9 k author contributor , and 7 . 8 k human-annotate contribution sentence ( africanlpcontributions ) benchmark result . dataset and continuously exist nlp progress track website111https://africanlpprogress.github.io/. website might still be improvement . provide powerful lens trace africanlp research trend and hold potential generate data-driven literature survey .",Computation and Language,29/09/2025
10.48550/arXiv.2509.25459,simulrag : simulator-base rag ground llms long-form scientific qa,"Haozhou Xu, Dongxia Wu, Matteo Chinazzi, Ruijia Niu, Rose Yu, Yi-An Ma","large language model ( llms ) show promise solve scientific problem . can help generate long-form answer scientific question , be crucial comprehensive understanding complex phenomenon require detailed explanation span multiple interconnect concept and evidence . however , llm often suffer hallucination , especially challenge task long-form scientific question answer . retrieval-augmented generation ( rag ) approach can ground llm incorporate external knowledge source to improve trustworthiness . context , scientific simulator , play vital role validate hypothesis , offer particularly promising retrieval source to mitigate hallucination and enhance answer factuality . however , exist rag approach can not be directly apply scientific simulation-based retrieval two fundamental challenge : to retrieve scientific simulator , and to efficiently verify and update long-form answer . to overcome challenge , propose simulator-based rag framework ( simulrag ) and provide long-form scientific qa benchmark covering climate science and epidemiology ground truth verify simulation and human annotator . framework , propose generalized simulator retrieval interface to transform textual and numerical modality . far design claim-level generation method utilize uncertainty estimation score and simulator boundary assessment ( ue+sba ) to efficiently verify and update claim . extensive experiment demonstrate simulrag outperform traditional rag baseline 30 . 4 % informativeness and 16 . 3 % factuality . ue+sba far improve efficiency and quality claim-level generation .",Computation and Language,29/09/2025
10.48550/arXiv.2509.25416,emotion-aligned generation diffusion text speech models preference-guided optimization,"Jiacheng Shi, Hongfei Du, Yangfan He, Y. Alicia Hong, Ye Gao","emotional text-to-speech seek to convey affect preserve intelligibility and prosody , yet exist method rely coarse label or proxy classifier and receive only utterance-level feedback . introduce emotion-aware stepwise preference optimization ( easpo ) , post-training framework align diffusion tts fine-grained emotional preference intermediate denoising step . central approach be easpm , time-conditioned model score noisy intermediate speech state and enable automatic preference pair construction . easpo optimize generation to match stepwise preference , enable controllable emotional shaping . experiment show superior performance exist method expressiveness and naturalness .",Computation and Language,29/09/2025
10.48550/arXiv.2509.25409,faithfulness correctness : generative reward models think critically,"Qiyao Ma, Yunsheng Shi, Hongtao Tian, Chao Wang, Weiming Chang, Ting Yao","reinforcement learning verifiable reward ( rlvr ) , large language model have achieve substantial progress domain easily verifiable outcome , such mathematic and coding . however , apply more complex task open-domain question answer , rlvr face significant challenge difficulty verify correctness . nuanced and ambiguous nature real-world knowledge make difficult to reliably evaluate correctness setting , necessitate further ability extend mere logical consistency to encompass understanding and assessment external and internal knowledge . recent work have primarily focus improve faithfulness , define semantic alignment support document , can cause model to rely excessively external source and diminish capacity critical assessment . to address , propose thinking-supervised reward model ( trm ) , incorporate sentence-level thinking supervision endow reward model critical thinking ability . give query , answer , and support document , trm first assess faithfulness answer sentence support document , and then apply reasoning step to evaluate sentence-level correctness . structure reward modeling sequence faithfulness , reasoning , and correctness evaluation , trm encourage model to critically assess and leverage both external and internal knowledge . experiment reward signal demonstrate trm substantially improve identification incorrect sentence , and incorporate trm policy optimization lead significant gain answer correctness and usefulness .",Computation and Language,29/09/2025
10.48550/arXiv.2509.25369,generative value conflicts reveal llm priorities,"Andy Liu, Kshitish Ghate, Mona Diab, Daniel Fried, Atoosa Kasirzadeh, Max Kleiman-Weiner","past work seek to align large language model ( llm)-base assistant target set value , but such assistant be frequently force to make tradeoff value deploy . response scarcity value conflict exist alignment dataset , introduce conflictscope , automatic pipeline to evaluate llms prioritize different value . give user-defined value set , conflictscope automatically generate scenario language model face conflict two value sample set . then prompt target model llm-written "" user prompt "" and evaluate free-text response to elicit rank value value set . compare result multiple-choice and open-ended evaluation , find model shift away support protective value , such harmlessness , and support personal value , such user autonomy , more open-ended value conflict setting . however , include detailed value ordering model ' system prompt improve alignment target rank 14 % , show system prompt can achieve moderate success align llm behavior value conflict . work demonstrate importance evaluate value prioritization model and provide foundation future work area . 111code and datum can be find http://github.com/andyjliu/conflictscope .",Computation and Language,29/09/2025
10.48550/arXiv.2509.25359,internal representations text quality : geometric approach llm evaluation,"Viacheslav Yusupov, Danil Maksimov, Ameliia Alaeva, Anna Vasileva, Anna Antipina, Tatyana Zaitseva, Alina Ermilova, Evgeny Burnaev, Egor Shvetsov","paper bridge internal and external analysis approach large language model ( llms ) demonstrate geometric property internal model representation serve reliable proxy evaluate generate text quality . validate set metrics—include maximum explainable variance , effective rank , intrinsic dimensionality , score , and schatten norm measure different layer llms , demonstrate intrinsic dimensionality and effective rank can serve universal assessment text naturalness and quality . key finding reveal different model consistently rank text various source same order base geometric property , indicate metric reflect inherent text characteristic rather model-specific artifact . allow reference-free text quality evaluation do not require human-annotated dataset , offer practical advantage automate evaluation pipeline .",Computation and Language,29/09/2025
10.48550/arXiv.2509.25220,cyclic ablation : testing concept localization functional regeneration ai,Eduard Kapelko,nan,Computation and Language,23/09/2025
10.48550/arXiv.2509.26628,attention compass : efficient exploration process-supervised rl reasoning models,"Runze Liu, Jiakang Wang, Yuling Shi, Zhihui Xie, Chenxin An, Kaiyan Zhang, Jian Zhao, Xiaodong Gu, Lei Lin, Wenping Hu, Xiu Li, Fuzheng Zhang, Guorui Zhou, Kun Gai","reinforcement learning ( rl ) have show remarkable success enhance reasoning capability large language models ( llms ) . process-supervise rl ( psrl ) have emerge more effective paradigm compare outcome-based rl . however , exist psrl approach suffer limited exploration efficiency , term branch position and sampling . paper , introduce novel psrl framework ( attnrl ) , enable efficient exploration reasoning model . motivate preliminary observation step exhibit high attention score correlate reasoning behavior , propose branch position high value . furthermore , develop adaptive sampling strategy account problem difficulty and historical batch size , ensure whole training batch maintain non-zero advantage value . to far improve sample efficiency , design one-step off-policy training pipeline psrl . extensive experiment multiple challenge mathematical reasoning benchmark demonstrate method consistently outperform prior approach term performance and sampling and training efficiency .",Computation and Language,30/09/2025
10.48550/arXiv.2509.26594,clarification supervision : reinforcement learning vision-language interface,"John Gkountouras, Ivan Titov","recent text-only model demonstrate remarkable mathematical reasoning capability . extend visual domain require vision-language model to translate image text description . however , current model , train to produce caption human reader , often omit precise detail reasoning system require . create interface mismatch : reasoner often fail not due reasoning limitation but lack access critical visual information . propose adaptive-clarification reinforcement learning ( ac-rl ) , teach vision model information reasoner need interaction . key insight be clarification request training reveal information gap ; penalize success require clarification , create pressure comprehensive initial caption enable reasoner to solve problem single pass . ac-rl improve average accuracy 4 . 44 . 4 point pretraine baseline seven visual mathematical reasoning benchmark , and analysis show would cut clarification request 3939 % be allow . treat clarification form implicit supervision , ac-rl demonstrate vision-language interface can be effectively learn interaction alone , require explicit annotation .",Computation and Language,30/09/2025
10.48550/arXiv.2509.26574,probe critical point ( critpt ) ai reasoning : frontier physics research benchmark,"Minhui Zhu, Minyang Tian, Xiaocheng Yang, Tianci Zhou, Penghao Zhu, Eli Chertkov, Shengyan Liu, Yufeng Du, Lifan Yuan, Ziming Ji, Indranil Das, Junyi Cao, Yufeng Du, Jinchen He, Yifan Su, Jiabin Yu, Yikun Jiang, Yujie Zhang, Chang Liu, Ze-Min Huang, Weizhen Jia, Xinan Chen, Peixue Wu, Yunkai Wang, Juntai Zhou, Yong Zhao, Farshid Jafarpour, Jessie Shelton, Aaron Young, John Bartolotta, Wenchao Xu, Yue Sun, Anjun Chu, Victor Colussi, Chris Akers, Nathan Brooks, Wenbo Fu, Christopher Wilson, Jinchao Zhao, Marvin Qi, Anqi Mu, Yubo Yang, Allen Zang, Yang Lyu, Peizhi Mai, Xuefei Guo, Luyu Gao, Ze Yang, Chi Xue, Dmytro Bandak, Yaïr Hein, Yonatan Kahn, Kevin Zhou, John Drew Wilson Jarrod T. Reilly, Di Luo, Daniel Inafuku, Hao Tong, Liang Yang, Ruixing Zhang, Xueying Wang, Ofir Press, Nicolas Chia, Eliu Huerta, Hao Peng","large language model ( llms ) reasoning capability be progress rapidly high-school math competition and coding , can reason effectively complex , open-ended challenge find frontier physics research ? and crucially , kind reasoning task do physicist actually want llms to assist ? to address question , present critpt ( complex research use integrated thinking - physics test , pronounce "" critical point "" ) , first benchmark design to test llm unpublished , research-level reasoning task broadly cover modern physics research area , include condensed matter , quantum physics , atomic , molecular & optical physics , astrophysic , high energy physic , mathematical physics , statistical physics , nuclear physics , nonlinear dynamic , fluid dynamic and biophysic . critpt consist 71 composite research challenge design to simulate full-scale research project entry level , be also decompose 190 simple checkpoint task more fine-grained insight . problem be newly create 50 active physics researcher base own research . problem be hand-curated to admit guess-resistant and machine-verifiable answer and be evaluate automate grading pipeline heavily customize advanced physics-specific output format . find current state-of-the-art llms show early promise isolated checkpoint , remain far be able to reliably solve full research-scale challenge : good average accuracy base model be only 4 . 0 % , achieve gpt-5 ( high ) , moderately rise 10 % equip code tool . realistic yet standardize evaluation offer critpt , highlight large disconnect current model capability and realistic physics research demand , offer foundation to guide development scientifically ground ai tool .",Computation and Language,30/09/2025
10.48550/arXiv.2509.26539,ferret-ui lite : lesson build small on-device gui agent,"Zhen Yang, Zi-Yi Dou, Di Feng, Forrest Huang, Anh Nguyen, Keen You, Omar Attia, Yuhao Yang, Michael Feng, Haotian Zhang, Ram Ramrakhya, Chao Jia, Jeffrey Nichols, Alexander Toshev, Yinfei Yang, Zhe Gan","develop autonomous agent effectively interact graphic user interfaces ( gui ) remain challenging open problem , especially small on-device model . paper , present ferret-ui lite , compact , end-to-end gui agent operate diverse platform , include mobile , web , and desktop . utilize technique optimize develop small model , build 3b ferret-ui lite agent curate diverse gui datum mixture real and synthetic source , strengthen inference-time performance chain-of-thought reasoning and visual tool-use , and reinforcement learning design reward . ferret-ui lite achieve competitive performance other small-scale gui agent . gui grounding , ferret-ui lite attain score 91 . 6%91 . 6\% , 53 . 3%53 . 3\% , and 61 . 2%61 . 2\% screenspot-v2 , screenspot-pro , and osworld-g benchmark , respectively . gui navigation , ferret-ui lite achieve success rate 28 . 0%28 . 0\% androidworld and 19 . 8%19 . 8\% osworld . share method and lesson learn develop compact , on-device gui agent .",Computation and Language,30/09/2025
10.48550/arXiv.2509.26464,extreme self-preference language model,"Steven A. Lehr, Mary Cipperman, Mahzarin R. Banaji","preference ( self-love ) be fundamental feature biological organism , evidence human often border comedic . 1 , 2 , 3 large language model ( llms ) lack sentience4 , 5 – and disclaim have selfhood or identity – one anticipated benefit be will be protect , and turn protect , distortion decision . yet , five study and ∼\sim20 , 000 query , discover massive self-preference four widely use llm . word-association task , model overwhelmingly pair positive attribute own name , company , and ceo relative competitor . strikingly , model be query apis self-preference vanish , initiate detection work reveal api model often lack clear recognition . peculiar feature serendipitously create opportunity to test causal link self-recognition and self-love . directly manipulate llm identity – i.e. , explicitly inform llm1 be indeed llm1 , or alternatively , convince llm1 be llm2 – find self-love consistently follow assign , not true , identity . importantly , llm self-love emerge consequential setting word-association task , evaluate job candidate , security software proposal and medical chatbot . far bypass human bias , self-love appear to be deeply encode llm cognition . result raise question llm behavior will be systematically influence self-preferential tendency , include bias own operation and even own existence . call corporate creator model to contend significant rupture core promise llm – neutrality judgment and decision-making .",Computation and Language,30/09/2025
10.48550/arXiv.2509.26404,seedprint : fingerprint can even tell seed large language model be train,"Yao Tong, Haonan Wang, Siquan Li, Kenji Kawaguchi, Tianyang Hu","fingerprint large language models ( llms ) be essential provenance verification and model attribution . exist method typically extract post-hoc signature base training dynamic , datum exposure , or hyperparameters—propertie only emerge training begin . contrast , propose strong and more intrinsic notion llm fingerprinting : seedprints , method leverage random initialization bias persistent , seed-dependent identifier present even training . show untrained model exhibit reproducible token selection bias condition solely parameter initialization . bias be stable and measurable training , enable statistical detection method to recover model ’s lineage high confidence . prior technique , unreliable convergence and vulnerable distribution shift , seedprints remain effective training stage and robust domain shift or parameter modification . experiment llama-style and qwen-style model show seedprints achieve seed-level distinguishability and can provide birth-to-lifecycle identity verification akin biometric fingerprint . evaluation large-scale pretraine model and fingerprinting benchmark far confirm effectiveness practical deployment scenario . result suggest initialization imprint unique and persistent identity neural language model , form true "" galtonian "" fingerprint .",Computation and Language,30/09/2025
10.48550/arXiv.2509.26388,game-time : evaluate temporal dynamics spoken language model,"Kai-Wei Chang, En-Pei Hu, Chun-Yi Kuan, Wenze Ren, Wei-Chih Chen, Guan-Ting Lin, Yu Tsao, Shao-Hua Sun, Hung-yi Lee, James Glass","conversational spoken language models ( slms ) be emerge promising paradigm real-time speech interaction . however , capacity temporal dynamic , include ability to manage timing , tempo and simultaneous speaking , remain critical and unevaluated challenge conversational fluency . to address gap , introduce game-time benchmark , framework to systematically assess temporal capability . inspire human learn language language activity , game-time consist basic instruction-following task and advanced task temporal constraint , such tempo adherence and synchronized response . evaluation diverse slm architecture reveal clear performance disparity : state-of-the-art model handle basic task well , many contemporary system still struggle fundamental instruction-following . more critically , nearly model degrade substantially temporal constraint , expose persistent weakness time awareness and full-duplex interaction . game-time benchmark provide foundation guide future research more temporally-aware conversational ai . demos and dataset be available project website111https://ga642381.github.io/game-time .",Computation and Language,30/09/2025
10.48550/arXiv.2509.26346,editreward : human-aligned reward model instruction-guided image editing,"Keming Wu, Sicong Jiang, Max Ku, Ping Nie, Minghao Liu, Wenhu Chen","recently , have witness great progress image editing natural language instruction . several closed-source model gpt-image-1 , seedream , and google-nano-banana have show highly promising progress . however , open-source model be still lag . main bottleneck be lack reliable reward model to scale high-quality synthetic training datum . to address critical bottleneck , build editreward , train new large-scale human preference dataset , meticulously annotate train expert follow rigorous protocol contain 200 k preference pair . editreward demonstrate superior alignment human preference instruction-guided image editing task . experiment show editreward achieve state-of-the-art human correlation establish benchmark such genai-bench , aurora-bench , imagenhub , and new editreward-bench , outperform wide range vlm-as-judge model . furthermore , use editreward to select high-quality subset exist noisy sharegpt-4o-image dataset . train step1x-edit select subset , show significant improvement training full set . demonstrate editreward ’s ability to serve reward model to scale high-quality training datum image editing . furthermore , strong alignment suggest potential advanced application reinforcement learning-base post-training and test-time scaling image editing model . editreward training dataset will be release to help community build more high-quality image editing training dataset .",Computation and Language,30/09/2025
10.48550/arXiv.2509.26329,tau : benchmark cultural sound understanding semantics,"Yi-Cheng Lin, Yu-Hua Chen, Jia-Kai Dong, Yueh-Hsuan Huang, Szu-Chi Chen, Yu-Chen Chen, Chih-Yao Chen, Yu-Jung Lin, Yu-Ling Chen, Zih-Yu Chen, I-Ning Tsai, Hsiu-Hsuan Wang, Ho-Lam Chung, Ke-Han Lu, Hung-yi Lee","large audio–language model be advance rapidly , yet most evaluation emphasize speech or globally source sound , overlook culturally distinctive cue . gap raise critical question : can current model generalize localized , non-semantic audio community instantly recognize but outsider do not ? to address , present tau ( taiwan audio understanding ) , benchmark everyday taiwanese "" soundmark . "" tau be build pipeline combine curate source , human editing , and llm-assiste question generation , produce 702 clip and 1 , 794 multiple-choice item can not be solve transcript alone . experiment show state-of-the-art lalm , include gemini 2 . 5 and qwen2-audio , perform far local human . tau demonstrate need localize benchmark to reveal cultural blind spot , guide more equitable multimodal evaluation , and ensure model serve community global mainstream .",Computation and Language,30/09/2025
10.48550/arXiv.2509.26278,profvlm : lightweight video-language model multi-view proficiency estimation,"Edoardo Bianchi, Jacopo Staiano, Antonio Liotta","exist approach skill proficiency estimation often rely black-box video classifier , ignore multi-view context and lack explainability . present profvlm , compact vision-language model reformulate task generative reasoning : jointly predict skill level and generate expert-like feedback egocentric and exocentric video . central method be attentivegatedprojector dynamically fuse multi-view feature , project frozen timesformer backbone language model tune feedback generation . train egoexo4d expert commentary , profvlm surpasse state-of-the-art method use 20x few parameter and reduce training time to 60 % . approach not only achieve superior accuracy diverse activity , but also output natural language critique align performance , offer transparent reasoning . result highlight generative vision-language modeling powerful new direction skill assessment .",Computation and Language,30/09/2025
10.48550/arXiv.2509.26226,thinking-free policy initialization make distilled reasoning models more effective and efficient reasoners,"Xin Xu, Cliveb AI, Kai Yang, Tianhao Chen, Yang Wang, Saiyong Yang, Can Yang","reinforcement learning verifiable reward ( rlvr ) effectively solve complex task but demand extremely long context length training , lead substantial computational cost . multi-stage training can partially mitigate , start overly short contexts often cause irreversible performance degradation , ultimately fail to reduce overall training compute significantly . paper , introduce thinking-free policy initialization ( tfpi ) , simple yet effective adaptation rlvr bridge long chain-of-thought ( cot ) distillation and standard rlvr . tfpi employ simple thinkingfree operation , explicitly discard thinking content direct < /think > append , to reduce token usage inference . train thinkingfree-adapte input improve performance and lower token consumption , even original slow-thinking mode . extensive experiment various benchmark have show tfpi accelerate rl convergence , achieve high performance ceiling , and yield more token-efficient reasoning model specialized reward or complex training design . tfpi only , train 4b model to reach 89 . 0 % accuracy aime24 and 65 . 5 % livecodebench use less 4 k h20 hour .",Computation and Language,30/09/2025
10.48550/arXiv.2509.26184,auto-argue : llm-base report generation evaluation,"William Walden, Marc Mason, Orion Weller, Laura Dietz, Hannah Recknor, Bryan Li, Gabrielle Kaili-May Liu, Yu Hou, James Mayfield, Eugene Yang","generation long-form , citation-backed report be primary use case retrieval augmented generation ( rag ) system . open-source evaluation tool exist various rag task , one tailor to report generation be lack . accordingly , introduce auto-argue , robust llm-base implementation recent argue framework report generation evaluation . present analysis auto-argue report generation pilot task trec 2024 neuclir track , show good system-level correlation human judgment . far release web app visualization auto-argue output .",Computation and Language,30/09/2025
10.48550/arXiv.2509.26045,scale temporal domain generalization temporal experts averaging,"Aoming Liu, Kevin Miller, Venkatesh Saligrama, Kate Saenko, Boqing Gong, Ser-Nam Lim, Bryan A. Plummer","temporal domain generalization ( tdg ) aim to generalize temporal distribution shift , e.g. , lexical change time . prior work often address predict future model weight . however , full model prediction be prohibitively expensive even reasonably sized model . thus , recent method only predict classifier layer , limit generalization fail to adjust other model component . to address , propose temporal experts averaging ( tea ) , novel and scalable tdg framework update entire model use weight average to maximize generalization potential minimize computational cost . theoretical analysis guide two step enhance generalization future domain . first , create expert model functional diversity yet parameter similarity fine-tune domain-agnostic base model individual temporal domain constrain weight change . second , optimize bias-variance tradeoff adaptive averaging coefficient derive model temporal weight trajectory principal component subspace . expert ’s contribution be base project proximity future domain . extensive experiment 7 tdg benchmark , 5 model , and 2 tdg setting show tea outperform prior tdg method to 69 % be up 60x more efficient111code : https://github.com/zxcvfd13502/tea .",Computation and Language,30/09/2025
10.48550/arXiv.2509.26017,fit : ai-driven fashion information tool sustainability,"Daphne Theodorakopoulos, Elisabeth Eberling, Miriam Bodenheimer, Sabine Loos, Frederic Stahl","access credible sustainability information fashion industry remain limited and challenging to interpret , grow public and regulatory demand transparency . general-purpose language model often lack domain-specific knowledge and tend to "" hallucinate "" , be particularly harmful field factual correctness be crucial . work explore natural language processing ( nlp ) technique can be apply to classify sustainability datum fashion brand , thereby address scarcity credible and accessible information domain . present prototype fashion information tool sustainability ( fits ) , transformer-based system extract and classifie sustainability information credible , unstructured text source : ngo report and scientific publication . several bert-based language model , include model pretraine scientific and climate-specific datum , be fine-tuned curate corpus use domain-specific classification schema , hyperparameter optimize bayesian optimization . fits allow user to search relevant datum , analyze own datum , and explore information interactive interface . evaluate fit two focus group potential user concern usability , visual design , content clarity , possible use case , and desire feature . result highlight value domain-adapted nlp promote inform decision-making and emphasize broad potential ai application address climate-related challenge . finally , work provide valuable dataset , sustainabletextilecorpus , methodology future update . code available https://github.com/daphne12345/fits",Computation and Language,30/09/2025
10.48550/arXiv.2509.25996,cast : continuous and differentiable semi-structure sparsity-aware training large language model,"Weiyu Huang, Yuezhou Hu, Jun Zhu, Jianfei Chen","sparsity-aware training be effective approach transform large language model ( llms ) hardware-friendly sparse pattern , thereby reduce latency and memory consumption inference . paper , propose continuous adaptive sparse trainer ( cast ) , fully continuous and differentiable sparsity-aware training framework semi-structured ( or "" n : m "" ) sparse model . previous approach optimize sparsity pattern and weight separately , cast enable seamless joint optimization training , progressively transform model desire sparsity format . specifically , cast introduce three key component : 1 ) adams , sparsity-aware optimizer leverage adaptive l1l_{1 } decay to promote uniform sparsification parameter ; 2 ) weight scaling , module design to mitigate magnitude reduction cause decay preserve desire sparsity pattern ; 3 ) knowledge distillation , employ dense model self-teacher to enhance training efficiency . evaluate cast 2 : 4 sparsity pattern multiple model family , range 125 m 13b parameter . result demonstrate significant improvement previous state-of-the-art method perplexity and zero-shot accuracy minimal training resource . notably , llama2-7b , 2 : 4 sparse model achieve negligible perplexity increase 0 . 09 and 0 . 36 % gain zero-shot accuracy compare dense model use only 2 % original pretraining token . additionally , establish accurate and robust empirical scaling law to predict sparse model performance give adequate training resource . finally , demonstrate practical applicability sparse model evaluate quantization and fine-tune scenario .",Computation and Language,30/09/2025
10.48550/arXiv.2509.25958,rorecomp : enhance reasoning efficiency rollout response recomposition reinforcement learning,"Gang Li, Yulei Qin, Xiaoyu Tan, Dingkang Yang, Yuchen Shi, Zihan Xu, Xiang Li, Xing Sun, Ke Li","reinforcement learn verifiable reward ( rlvr ) have prove effective elicit complex reasoning large language model ( llms ) . however , standard rlvr training often lead to excessively verbose process ( reasoning task ) and inefficient exploration trajectory ( agentic setting ) , outcome-only reward provide incentive efficiency and high variance response length relatively small rollout group result noisy optimization signal . to address , propose rollout response recomposition ( rorecomp ) , plug-and-play method guide model concise reasoning strategically recompose training datum . rorecomp separate response two distinct batch type : 1 ) priority batch , combine short-correct and long-incorrect response select online batch to provide clear gradient signal brevity , and 2 ) compensation batch , utilize remain response replay buffer to maintain stability and prevent model collapse . to comprehensively evaluate effectiveness , test rorecomp three setting result demonstrate substantial efficiency gain : reduce reasoning length 27 . 7 % zero rl training , reduce unnecessary tool call 46 . 8 % improve accuracy agentic rl , and achieve 52 . 5 % length reduction think compression , all minimal performance impact .",Computation and Language,30/09/2025
10.48550/arXiv.2509.25941,boost process-correct cot reasoning modeling solvability multiple-choice qa,"Raphael Schumann, Stefan Riezler","reasoning quality large language model depend not only produce correct answer but also generate valid intermediate step . study multiple-choice question answer ( mcqa ) , provide control setting fix answer option . analysis show question be effectively unsolvable model , spurious chain thought ( cots ) be more likely to appear , lead false positive . estimate solvability question , uncover intermediate regime learning be most effective . build insight , adapt outcome-supervised reward model and reinforcement learning group-relative advantage to incorporate solvability objective . experiment math and multimodal dataset , modification consistently yield high rate process-correct reasoning and , reinforcement learning , improved answer accuracy as well . result highlight solvability key factor reduce hallucination and increase reliability cot reasoning . 111code and datum available https://github.com/raphael-sch/mcqa_solvability",Computation and Language,30/09/2025
10.48550/arXiv.2509.25922,deepjsoneval : benchmarking complex nested json data mining large language model,"Zhicheng Zhou, Jing Li, Suming Qiu, Junjie Huang, Linyuan Qiu, Zhijie Sun","internet be saturate low-density , high-redundancy information , such social medium comment , repetitive news , and lengthy discussion , make difficult to extract valuable insight efficiently . multi-layer nest json structure provide effective solution compress such information semantically rich , hierarchical representation , organize datum key-value pair , array , and nested object , preserve contextual relationship and enable efficient storage , retrieval , and semantic querying . instance , news aggregation , json object can nest article ’s metadata ( title , author , date ) , content ( text , multimedia ) , and multimedia information ( multimedia type , caption ) hierarchically . large language models ( llms ) play transformative role web datum mining parse unstructured text and output structured result directly complex json schemas . however , current benchmark evaluate llms ' json output capability overemphasize pure json generation rather assess datum comprehension and extraction ability , limitation lack relevance practical web datum mining task . to address , introduce deepjsoneval , novel benchmark feature 2100 multi-domain instance deep nested structure , categorize difficulty . experiment show significant performance gap llms handle such complexity . benchmark and dataset be open-sourced to advance research structured json generation . ( https://github.com/gts-ai-infra-lab-sotas/deepjsoneval ) .",Computation and Language,30/09/2025
10.48550/arXiv.2509.26645,ttt3r : 3d reconstruction test-time training,"Xingyu Chen, Yue Chen, Yuliang Xiu, Andreas Geiger, Anpei Chen","modern recurrent neural networks have become competitive architecture 3d reconstruction linear-time complexity . however , performance degrade significantly apply training context length , reveal limited length generalization . work , revisit 3d reconstruction foundation model test-time training perspective , frame design online learning problem . build perspective , leverage alignment confidence memory state and incoming observation to derive closed-form learn rate memory update , to balance retain historical information and adapt new observation . training-free intervention , term ttt3r , substantially improve length generalization , achieve 2×2\times improvement global pose estimation baseline , operate 20 fps just 6 gb gpu memory to process thousand image . code available rover-xingyu.github.io/ttt3r.",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26644,stitch : training-free position control multimodal diffusion transformers,"Jessica Bader, Mateusz Pach, Maria A. Bravo, Serge Belongie, Zeynep Akata","text-to-image ( t2i ) generation model have advance rapidly recent year , but accurately capture spatial relationship "" "" or "" right "" pose persistent challenge . early method improve spatial relationship follow external position control . however , architecture evolve to enhance image quality , technique become incompatible modern model . propose stitch , training-free method incorporate external position control multi-modal diffusion transformers ( mmdit ) automatically-generated bounding box . stitch produce image be spatially accurate and visually appealing generate individual object designate bounding box and seamlessly stitch together . find target attention head capture information necessary to isolate and cut individual object mid-generation , need to fully complete image . evaluate stitch poseval , benchmark position-based t2i generation . feature five new task extend concept position basic geneval task , poseval demonstrate even top model still have significant room improvement position-based generation . test qwen-image , flux , and sd3 . 5 , stitch consistently enhance base model , even improve flux 218%218\% geneval ’s position task and 206%206\% poseval . stitch achieve state-of-the-art result qwen-image poseval , improve previous model 54%54\% , accomplish integrate position control lead model training-free . code be available https://github.com/explainableml/stitch .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26641,query-kontext : unified multimodal model image generation and editing,"Yuxin Song, Wenkai Dong, Shizun Wang, Qi Zhang, Song Xue, Tao Yuan, Hu Yang, Haocheng Feng, Hang Zhou, Xinyan Xiao, Jingdong Wang","unify multimodal models ( umms ) have demonstrate remarkable performance text-to-image generation ( t2i ) and editing ( ti2i ) , instantiate assemble unified framework couple powerful vision-language model ( vlm ) diffusion-based generator , or naive unify multimodal models early fusion understanding and generation modality . contend current unified framework , crucial capability multimodal generative reasoning encompass instruction understanding , grounding , and image refer identity preservation and faithful reconstruction , be intrinsically entangle high-fidelity synthesis . work , introduce query-kontext , novel approach bridge vlm and diffusion model multimodal "" kontext "" compose semantic cue and coarse-grained image condition encode multimodal input . design delegate complex ability multimodal generative reasoning powerful vlm reserve diffusion model ’s role high-quality visual synthesis . to achieve , propose three-stage progressive training strategy . first , connect vlm lightweight diffusion head multimodal kontext token to unleash vlm ’s generative reasoning ability . second , scale head large , pre-trained diffusion model to enhance visual detail and realism . finally , introduce low-level image encoder to improve image fidelity and perform instruction tuning downstream task . furthermore , build comprehensive datum pipeline integrate real , synthetic , and open-source dataset , cover diverse multimodal reference-to-image scenario , include image generation , instruction-driven editing , customize generation , and multi-subject composition . experiment show approach match strong unified baseline and even outperform task-specific state-of-the-art method several case .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26639,benchmarke egocentric visual-inertial slam city scale,"Anusha Krishnan, Shaohui Liu, Paul-Edouard Sarlin, Oscar Gentilhomme, David Caruso, Maurizio Monge, Richard Newcombe, Jakob Engel, Marc Pollefeys","precise 6-dof simultaneous localization and mapping ( slam ) onboard sensor be critical wearable device capture egocentric datum , exhibit specific challenge , such wide diversity motion and viewpoint , prevalent dynamic visual content , or long session affect time-varying sensor calibration . recent progress slam have be swift , academic research be still drive benchmark do not reflect challenge or do not offer sufficiently accurate ground truth pose . paper , introduce new dataset and benchmark visual-inertial slam egocentric , multi-modal datum . record hour and kilometer trajectory city center glasses-like device equip various sensor . leverage survey tool to obtain control point indirect pose annotation be metric , centimeter-accurate , and available city scale . make possible to evaluate extreme trajectory involve walk night or travel vehicle . show state-of-the-art system develop academia be not robust challenge and identify component be responsible . addition , design track different level difficulty to ease in-depth analysis and evaluation less mature approach . dataset and benchmark be available lamaria.ethz.ch .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26631,learn generalizable shape completion sim(3 ) equivariance,"Yuqing Wang, Zhaiyu Chen, Xiao Xiang Zhu","3d shape completion method typically assume scan be pre-aligned canonical frame . leak pose and scale cue network may exploit to memorize absolute position rather infer intrinsic geometry . such alignment be absent real datum , performance collapse . argue robust generalization demand architectural equivariance similarity group , sim​(3)\mathrm{sim}(3 ) , so model remain agnostic to pose and scale . follow principle , introduce first sim​(3)\mathrm{sim}(3)-equivariant shape completion network , modular layer successively canonicalize feature , reason similarity-invariant geometry , and restore original frame . de-biase evaluation protocol remove hide cue , model outperform both equivariant and augmentation baseline pcn benchmark . also set new cross-domain record real driving and indoor scan , lower minimal matching distance kitti 17%17\% and chamfer distance ℓ​1\ell 1 omniobject3d 14%14\% . perhaps surprisingly , our strict protocol still outperform competitor biased setting . result establish full sim​(3)\mathrm{sim}(3 ) equivariance effective route to truly generalizable shape completion . project page : https://sime-completion.github.io .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26621,hart : human aligned reconstruction transformer,"Xiyi Chen, Shaofei Wang, Marko Mihajlovic, Taewon Kang, Sergey Prokudin, Ming Lin","introduce hart , unified framework sparse-view human reconstruction . give small set uncalibrated rgb image person input , output watertight clothe mesh , align smpl-x body mesh , and gaussian-splat representation photorealistic novel-view rendering . prior method clothed human reconstruction either optimize parametric template , overlook loose garment and human-object interaction , or train implicit function simplified camera assumption , limit applicability real scene . contrast , hart predict per-pixel 3d point map , normal , and body correspondence , and employ occlusion-aware poisson reconstruction to recover complete geometry , even self-occluded region . prediction also align parametric smpl-x body model , ensure reconstructed geometry remain consistent human structure capture loose clothing and interaction . human-aligned mesh initialize gaussian splat to far enable sparse-view rendering . train only 2 . 3 k synthetic scan , hart achieve state-of-the-art result : chamfer distance improve 18–23 % clothed-mesh reconstruction , pa-v2v drop 6–27 % smpl-x estimation , lpips decrease 15–27 % novel-view synthesis wide range dataset . result suggest feed-forward transformer can serve scalable model robust human reconstruction real-world setting . code and model will be release .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26614,hy-facial : hybrid feature extraction dimensionality reduction methods enhanced facial expression classification,"Xinjin Li, Yu Ma, Kaisen Ye, Jinghan Cao, Minghao Zhou, Yeyang Zhou","facial expression classification remain challenging task high dimensionality and inherent complexity facial image datum . paper present hy-facial , hybrid feature extraction framework integrate deep learning and traditional image processing technique , complement systematic investigation dimensionality reduction strategy . propose method fuse deep feature extract visual geometry group 19-layer network ( vgg19 ) handcraft local descriptor and scale-invariant feature transform ( sift ) and orient fast and rotate brief ( orb ) algorithm , to obtain rich and diverse image representation . to mitigate feature redundancy and reduce computational complexity , conduct comprehensive evaluation dimensionality reduction technique and feature extraction . , umap be identify most effective , preserve both local and global structure high-dimensional feature space . hy-facial pipeline integrate vgg19 , sift , and orb feature extraction , follow k-means cluster and umap dimensionality reduction , result classification accuracy 83 . 3 % facial expression recognition ( fer ) dataset . finding underscore pivotal role dimensionality reduction not only pre-processing step but essential component improve feature quality and overall classification performance .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26604,video object segmentation-aware audio generation,"Ilpo Viertola, Vladimir Iashin, Esa Rahtu","exist multimodal audio generation model often lack precise user control , limit applicability professional foley workflow . particular , model focus entire video and do not provide precise method prioritize specific object scene , generate unnecessary background sound , or focus wrong object . to address gap , introduce novel task video object segmentation-aware audio generation , explicitly condition sound synthesis object-level segmentation map . present saganet , new multimodal generative model enable controllable audio generation leverage visual segmentation mask video and textual cue . model provide user fine-grained and visually localize control audio generation . to support task and further research segmentation-aware foley , propose segmented music solos , benchmark dataset musical instrument performance video segmentation information . method demonstrate substantial improvement current state-of-the-art method and set new standard controllable , high-fidelity foley synthesis . code , sample , and segmented music solos be available saganet.notion.site .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26585,autoproof : automated segmentation proofreading connectomic,"Gary B Huang, William M Katz, Stuart Berg, Louis Scheffer","produce connectome electron microscopy ( em ) image have historically require great deal human proofreading effort . manual annotation cost be current bottleneck scale em connectomic , example , make large connectome reconstruction feasible , or enable comparative connectomic multiple relate reconstruction be produce . work , propose use available ground-truth datum generate manual annotation effort to learn machine learning model to automate or optimize part require proofreading workflow . validate approach recent complete reconstruction drosophila male central nervous system . first show method would allow obtain 90 % value guide proofreading workflow reduce require cost 80 % . then demonstrate second application automatically merge many segmentation fragment to proofread neuron . system be able to automatically attach 200 thousand fragment , equivalent four proofreader year manual work , and increase connectivity completion rate connectome 1 . 3 % point .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26555,stable cinemetrics : structure taxonomy and evaluation professional video generation,"Agneet Chatterjee, Rahim Entezari, Maksym Zhuravinskyi, Maksim Lapin, Reshinth Adithyan, Amit Raj, Chitta Baral, Yezhou Yang, Varun Jampani","recent advance video generation have enable high-fidelity video synthesis user provide prompt . however , exist model and benchmark fail to capture complexity and requirement professional video generation . goal , introduce stable cinemetrics , structured evaluation framework formalize filmmaking control four disentangle , hierarchical taxonomy : setup , event , lighting , and camera . together , taxonomy define 76 fine-grained control node ground industry practice . use taxonomy , construct benchmark prompt align professional use case and develop automate pipeline prompt categorization and question generation , enable independent evaluation control dimension . conduct large-scale human study span 10 + model and 20 k video , annotate pool 80 + film professional . analysis , both coarse and fine-grained reveal even strong current model exhibit significant gap , particularly events and camera-relate control . to enable scalable evaluation , train automatic evaluator , vision-language model align expert annotation outperform exist zero-shot baseline . scine be first approach to situate professional video generation landscape video generative model , introduce taxonomy center cinematic control and support structured evaluation pipeline and detailed analysis to guide future research .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26539,ferret-ui lite : lesson build small on-device gui agent,"Zhen Yang, Zi-Yi Dou, Di Feng, Forrest Huang, Anh Nguyen, Keen You, Omar Attia, Yuhao Yang, Michael Feng, Haotian Zhang, Ram Ramrakhya, Chao Jia, Jeffrey Nichols, Alexander Toshev, Yinfei Yang, Zhe Gan","develop autonomous agent effectively interact graphic user interfaces ( gui ) remain challenging open problem , especially small on-device model . paper , present ferret-ui lite , compact , end-to-end gui agent operate diverse platform , include mobile , web , and desktop . utilize technique optimize develop small model , build 3b ferret-ui lite agent curate diverse gui datum mixture real and synthetic source , strengthen inference-time performance chain-of-thought reasoning and visual tool-use , and reinforcement learning design reward . ferret-ui lite achieve competitive performance other small-scale gui agent . gui grounding , ferret-ui lite attain score 91 . 6%91 . 6\% , 53 . 3%53 . 3\% , and 61 . 2%61 . 2\% screenspot-v2 , screenspot-pro , and osworld-g benchmark , respectively . gui navigation , ferret-ui lite achieve success rate 28 . 0%28 . 0\% androidworld and 19 . 8%19 . 8\% osworld . share method and lesson learn develop compact , on-device gui agent .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26498,depthor++ : robust depth enhancement real-world lightweight dtof and rgb guidance,"Jijun Xiang, Longliang Liu, Xuan Zhu, Xianqi Wang, Min Lin, Xin Yang","depth enhancement , convert raw dtof signal dense depth map use rgb guidance , be crucial improve depth perception high-precision task such 3d reconstruction and slam . however , exist method often assume ideal dtof input and perfect dtof-rgb alignment , overlook calibration error and anomaly , thus limit real-world applicability . work systematically analyze noise characteristic real-world lightweight dtof sensor and propose practical and novel depth completion framework—depthor++ , enhance robustness noisy dtof input three key aspect . first , introduce simulation method base synthetic dataset to generate realistic training sample robust model training . second , propose learnable-parameter-free anomaly detection mechanism to identify and remove erroneous dtof measurement , prevent misleading propagation completion . third , design depth completion network tailor noisy dtof input , integrate rgb image and pre-trained monocular depth estimation prior to improve depth recovery challenge region . zju-l5 dataset and real-world sample , training strategy significantly boost exist depth completion model , model achieve state-of-the-art performance , improve rmse and rel 22 % and 11 % average . mirror3d-nyu dataset , incorporate anomaly detection method , model improve previous sota 37 % mirror region . hammer dataset , use simulated low-cost dtof datum realsense l515 , method surpass l515 measurement average gain 22 % , demonstrate potential to enable low-cost sensor to outperform higher-end device . qualitative result diverse real-world dataset far validate effectiveness and generalizability approach . code depthor be available : https://github.com/shadowbbbb/depthor , and depthor++ will be release publicity paper .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26497,reveal power post-training small language models knowledge distillation,"Miao Rang, Zhenni Bi, Hang Zhou, Hanting Chen, An Xiao, Tianyu Guo, Kai Han, Xinghao Chen, Yunhe Wang","rapid advancement large language model ( llms ) have significantly advance capability artificial intelligence various domain . however , massive scale and high computational cost render unsuitable direct deployment resource-constrained edge environment . create critical need high-performance small model can operate efficiently edge . yet , pre-traine alone , small model often fail to meet performance requirement complex task . to bridge gap , introduce systematic post-training pipeline efficiently enhance small model accuracy . post training pipeline consist curriculum-based supervised fine-tuning ( sft ) and offline on-policy knowledge distillation . result instruction-tuned model achieve state-of-the-art performance billion-parameter model , demonstrate strong generalization strict hardware constraint maintain competitive accuracy variety task . work provide practical and efficient solution develop high-performance language model ascend edge device .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26489,contrastive diffusion guidance spatial inverse problems,"Sattwik Basu, Chaitanya Amballa, Zhongweiyang Xu, Jorge Vančo Sampedro, Srihari Nelakuditi, Romit Roy Choudhury","consider inverse problem reconstruct spatial layout place , home floorplan example , user ’s movement layout . direct inversion be ill-posed many floorplan can explain same movement trajectory . adopt diffusion-based posterior sampler to generate layout consistent measurement . active research be progress generative inverse solver , find forward operator problem pose new challenge . path planning process floorplan be non-invertible , non-differentiable function , and cause instability optimize use likelihood score . break-away exist approach and reformulate likelihood score smoother embed space . embed space be train contrastive loss bring compatible floorplan and trajectory close other , pushing mismatch pair far apart . show surrogate form likelihood score embed space be valid approximation true likelihood score , make possible to steer denoising process posterior . extensive experiment , model coguide produce more consistent floorplan trajectory , and be more robust differentiable-planner baseline and guided-diffusion method .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26457,attention scene graph : indoor scene representations csai classification,"Artur Barros, Carlos Caetano, João Macedo, Jefersson A. dos Santos, Sandra Avila","indoor scene classification be critical task computer vision , wide-ranging application go robotic sensitive content analysis , such child sexual abuse imagery ( csai ) classification . problem be particularly challenging intricate relationship object and complex spatial layout . work , propose attention scene graphs sensitive content analysis ( asgra ) , novel framework operate structured graph representation instead raw pixel . first convert image scene graphs and then employ graph attention network inference , asgra directly model interaction scene ’s component . approach offer two key benefit : ( i ) inherent explainability object and relationship identification , and ( ii ) privacy preservation , enable model training direct access sensitive image . places8 , achieve 81 . 27 % balanced accuracy , surpass image-based method . real-world csai evaluation law enforcement yield 74 . 27 % balanced accuracy . result establish structured scene representation robust paradigm indoor scene classification and csai classification . code be publicly available https://github.com/tutuzeraa/asgra .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26455,stylo : multi-view 3d stylization single-forward gaussian splatting,"Hanzhou Liu, Jia Huang, Mi Lu, Srikanth Saripalli, Peng Jiang","present stylos , single-forward 3d gaussian framework 3d style transfer operate unposed content , single image multi-view collection , condition separate reference style image . stylos synthesize stylize 3d gaussian scene per-scene optimization or precomputed pose , achieve geometry-aware , view-consistent stylization generalize unseen category , scene , and style . core , stylos adopt transformer backbone two pathway : geometry prediction retain self-attention to preserve geometric fidelity , style be inject global cross-attention to enforce visual consistency view . addition voxel-based 3d style loss align aggregate scene feature style statistic , stylos enforce view-consistent stylization preserve geometry . experiment multiple dataset demonstrate stylos deliver high-quality zero-shot stylization , highlight effectiveness global style–content coupling , propose 3d style loss , and scalability framework single view large-scale multi-view setting . code will be available https://github.com/hanzhouliu/stylos .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26454,multi-view camera system variant-aware autonomous vehicle inspection and defect detection,"Yash Kulkarni, Raman Jha, Renu Kachhoria","ensure vehicle leave modern production line be build correct variant specification and be free visible defect be increasingly complex challenge . present automated vehicle inspection ( avi ) platform , end-to-end , multi-view perception system couple deep-learne detector semantic rule engine to deliver variant-aware quality control real time . eleven synchronize camera capture full 360 ° sweep vehicle ; task-specific view be then route specialised module : yolov8 part detection , efficientnet ice/ev classification , gemini-1 . 5 flash mascot ocr , and yolov8-seg scratch-and-dent segmentation . view-aware fusion layer standardise evidence , vin-conditione rule engine compare detect feature expect manifest , produce interpretable pass/fail report ≈300​ms\approx\ ! 300\ , \text{ms } . mixed datum set original equipment manufacturer(oem ) vehicle data set four distinct model plus public scratch/dent image , avi achieve 93 % verification accuracy , 86 % defect-detection recall , and sustain 3 . 3\mathbf{3 . 3 } vehicles/min , surpass single-view or segmentation baseline large margin . knowledge , be first publicly report system unify multi-camera feature validation defect detection deployable automotive setting industry .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26436,post-traine quantization residual truncation and zero suppression diffusion models,"Donghoon Kim, Dongyoung Lee, Ik Joon Chang, Sung-Ho Bae","diffusion model achieve high-quality image generation but face deployment challenge due high computational requirement . 8-bit outlier-aware post-training quantization ( ptq ) match full-precision performance , extend ptq 4 bit remain challenge . large step size 4-bit quantization amplify round error dense , low-magnitude activation , lead loss fine-grained texture . hypothesize not only outlier but also small activation be critical texture fidelity . end , propose quantization residual truncation and zero suppression ( quartz ) , 4-bit ptq scheme diffusion model . quartz apply 8-bit min–max quantization outli handling and compress 4 bit leading-zero suppression to retain lsb , thereby preserve texture detail . approach reduce round error and improve quantization efficiency balance outli preservation and lsb precision . theoretical derivation and empirical evaluation demonstrate generalizability quartz diverse activation distribution . notably , 4-bit quartz achieve fid 6 . 98 flux . 1-schnell , outperform svdquant require auxiliary fp16 branch .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26413,prism : progressive rain removal integrated state-space modeling,"Pengze Xue, Shanwen Wang, Fei Zhou, Yan Cui, Xin Sun","image deraining be essential vision technique remove rain streak and water droplet , enhance clarity critical vision task autonomous driving . however , current single-scale model struggle fine-grained recovery global consistency . to address challenge , propose progressive rain removal integrated state-space modeling ( prism ) , progressive three-stage framework : ̵‌coarse extraction network ( cenet)‌ , ̵‌frequency fusion network ( sfnet)‌ and ̵‌refine network ( rnet)‌‌ . specifically , cenet and sfnet utilize novel hybrid attention unet ( ha-unet ) multi-scale feature aggregation combine channel attention windowed spatial transformer . moreover , propose hybrid domain mamba ( hdmamba ) sfnet to jointly model spatial semantic and wavelet domain characteristic . finally , rnet recover fine-grained structure original-resolution subnetwork . model learn high-frequency rain characteristic preserve structural detail and maintain global context , lead improve image quality . method achieve competitive result multiple dataset recent deraining method .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26398,image-difficulty-aware evaluation super-resolution model,"Atakan Topaloglu, Ahmet Bilican, Cansu Korkmaz, A. Murat Tekalp","image super-resolution model be commonly evaluate average score ( benchmark test set ) , fail to reflect performance model image vary difficulty and model generate artifact certain difficult image , be not reflect average score . propose difficulty-aware performance evaluation procedure to well differentiate sisr model produce visually different result image but yield close average performance score entire test set . particular , propose two image-difficulty measure , high-frequency index and rotation-invariant edge index , to predict test image , model would yield significantly well visual result model , and evaluation method visual difference be reflect objective measure . experimental result demonstrate effectiveness propose image-difficulty measure and evaluation methodology .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26391,motionrag : motion retrieval-augmente image-to-video generation,"Chenhui Zhu, Yilu Wu, Shuai Wang, Gangshan Wu, Limin Wang","image-to-video generation have make remarkable progress advancement diffusion model , yet generate video realistic motion remain highly challenging . difficulty arise complexity accurately model motion , involve capture physical constraint , object interaction , and domain-specific dynamic be not easily generalize diverse scenario . to address , propose motionrag , retrieval-augmented framework enhance motion realism adapt motion prior relevant reference video context-aware motion adaptation ( cama ) . key technical innovation include : ( i ) retrieval-based pipeline extract high-level motion feature use video encoder and specialized resampler to distill semantic motion representation ; ( ii ) in-context learn approach motion adaptation implement causal transformer architecture ; ( iii ) attention-based motion injection adapter seamlessly integrate transfer motion feature pretraine video diffusion model . extensive experiment demonstrate method achieve significant improvement multiple domain and various base model , all negligible computational overhead inference . furthermore , modular design enable zero-shot generalization new domain simply update retrieval database retrain component . research enhance core capability video generation system enable effective retrieval and transfer motion prior , facilitate synthesis realistic motion dynamic .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26386,panda : generalist video anomaly detection agentic ai engineer,"Zhiwei Yang, Chen Gao, Mike Zheng Shou","video anomaly detection ( vad ) be critical yet challenging task complex and diverse nature real-world scenario . previous method typically rely domain-specific training datum and manual adjustment apply new scenario and unseen anomaly type , suffer high labor cost and limited generalization . therefore , aim to achieve generalist vad , i.e. , automatically handle scene and anomaly type train datum or human involvement . work , propose panda , agentic ai engineer base mllm . specifically , achieve panda comprehensively devise four key capability : ( 1 ) self-adaptive scene-aware strategy planning , ( 2 ) goal-driven heuristic reasoning , ( 3 ) tool-augmented self-reflection , and ( 4 ) self-improve chain-of-memory . concretely , develop self-adaptive scene-aware rag mechanism , enable panda to retrieve anomaly-specific knowledge anomaly detection strategy planning . next , introduce latent anomaly-guided heuristic prompt strategy to enhance reasoning precision . furthermore , panda employ progressive reflection mechanism suite context-aware tool to iteratively refine decision-make complex scenario . finally , chain-of-memory mechanism enable panda to leverage historical experience continual performance improvement . extensive experiment demonstrate panda achieve state-of-the-art performance multi-scenario , open-set , and complex scenario setting training and manual involvement , validate generalizable and robust anomaly detection capability . code be release https://github.com/showlab/panda .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26376,go gut : scale confidence autoregressive image generation,"Harold Haodong Chen, Xianfeng Wu, Wen-Jie Shu, Rongjin Guo, Disen Lan, Harry Yang, Ying-Cong Chen","test-time scale ( tts ) have demonstrate remarkable success enhance large language model , yet application next-token prediction ( ntp ) autoregressive ( ar ) image generation remain largely uncharted . exist tts approach visual ar ( var ) , rely frequent partial decoding and external reward model , be ill-suited ntp-based image generation inherent incompleteness intermediate decode result . to bridge gap , introduce scalingar , first tts framework specifically design ntp-based ar image generation eliminate need early decoding or auxiliary reward . scalingar leverage token entropy novel signal visual token generation and operate two complementary scaling level : ( i ) profile level , stream calibrate confidence state fuse intrinsic and conditional signal ; and ( ii ) policy level , utilize state to adaptively terminate low-confidence trajectory and dynamically schedule guidance phase-appropriate conditioning strength . experiment general and compositional benchmark show scalingar ( 1 ) improve base model 12 . 5%12 . 5\% geneval and 15 . 2%15 . 2\% tiif-bench , ( 2 ) efficiently reduce visual token consumption 62 . 0%62 . 0\% outperform baseline , and ( 3 ) successfully enhance robustness , mitigate performance drop 26 . 0%26 . 0\% challenge scenario . code be available scalingar repository .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26360,timescope : task-oriente temporal grounding long video,"Xiangrui Liu, Minghao Qin, Yan Shu, Zhengyang Liang, Yang Tian, Chen Jason Zhang, Bo Zhao, Zheng Liu","identify key moment long video be essential downstream understanding and reasoning task . paper , introduce new problem , task-oriente temporal grounding ( totg ) , aim to localize time interval contain necessary information base task ’ natural description . definition , also present totg-bench , comprehensive benchmark evaluate performance totg . totg be particularly challenge traditional approach limited generalizability and difficulty handle long video . to address challenge , propose timescope , novel framework build progressive reasoning . timescope first identify coarse-grained temporal scope long video likely contain key moment , and then refine scope fine-grained moment partition . additionally , curate high-quality dataset , namely totg-pile , to enhance timescope ’s ability to perform progressive temporal grounding effectively . extensive experiment demonstrate timescope consistently outperform exist temporal-grounding method and popular mllm various setting , highlight effectiveness address new challenging problem .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26346,editreward : human-aligned reward model instruction-guided image editing,"Keming Wu, Sicong Jiang, Max Ku, Ping Nie, Minghao Liu, Wenhu Chen","recently , have witness great progress image editing natural language instruction . several closed-source model gpt-image-1 , seedream , and google-nano-banana have show highly promising progress . however , open-source model be still lag . main bottleneck be lack reliable reward model to scale high-quality synthetic training datum . to address critical bottleneck , build editreward , train new large-scale human preference dataset , meticulously annotate train expert follow rigorous protocol contain 200 k preference pair . editreward demonstrate superior alignment human preference instruction-guided image editing task . experiment show editreward achieve state-of-the-art human correlation establish benchmark such genai-bench , aurora-bench , imagenhub , and new editreward-bench , outperform wide range vlm-as-judge model . furthermore , use editreward to select high-quality subset exist noisy sharegpt-4o-image dataset . train step1x-edit select subset , show significant improvement training full set . demonstrate editreward ’s ability to serve reward model to scale high-quality training datum image editing . furthermore , strong alignment suggest potential advanced application reinforcement learning-base post-training and test-time scaling image editing model . editreward training dataset will be release to help community build more high-quality image editing training dataset .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26330,square : semantic query-augmented fusion and efficient batch reranking training-free zero-shot composed image retrieval,"Ren-Di Wu, Yu-Yen Lin, Huei-Fang Yang","composed image retrieval ( cir ) aim to retrieve target image preserve visual content reference image incorporate user-specified textual modification . training-free zero-shot cir ( zs-cir ) approach , require task-specific training or label datum , be highly desirable , yet accurately capture user intent remain challenge . paper , present square , novel two-stage training-free framework leverage multimodal large language models ( mllms ) to enhance zs-cir . semantic query-augmented fusion ( sqaf ) stage , enrich query embed derive vision-language model ( vlm ) such clip mllm-generated caption target image . caption provide high-level semantic guidance , enable query to well capture user ’s intent and improve global retrieval quality . efficient batch reranking ( ebr ) stage , top-ranked candidate be present image grid visual mark mllm , perform joint visual-semantic reasoning candidate . reranking strategy operate single pass and yield more accurate ranking . experiment show square , simplicity and effectiveness , deliver strong performance four standard cir benchmark . notably , maintain high performance even lightweight pre-trained , demonstrate potential applicability .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26325,continuous space-time video super-resolution 3d fourier fields,"Alexander Becker, Julius Erbach, Dominik Narnhofer, Konrad Schindler","introduce novel formulation continuous space-time video super-resolution . instead decouple representation video sequence separate spatial and temporal component and rely brittle , explicit frame warp motion compensation , encode video continuous , spatio-temporally coherent 3d video fourier field ( vff ) . representation offer three key advantage : ( 1 ) enable cheap , flexible sampling arbitrary location space and time ; ( 2 ) be able to simultaneously capture fine spatial detail and smooth temporal dynamic ; and ( 3 ) offer possibility to include analytical , gaussian point spread function sampling to ensure aliasing-free reconstruction arbitrary scale . coefficient propose , fourier-like sinusoidal basis be predict neural encoder large spatio-temporal receptive field , condition low-resolution input video . extensive experiment , show joint modeling substantially improve spatial and temporal super-resolution and set new state art multiple benchmark : wide range upscale factor , deliver sharp and temporally more consistent reconstruction exist baseline , be computationally more efficient . project page : https://v3vsr.github.io .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26287,flower : flow-matching solver inverse problems,"Mehrsa Pourya, Bassam El Rawas, Michael Unser","introduce flower , solver inverse problem . leverage pre-trained flow model to produce reconstruction be consistent observed measurement . flower operate iterative procedure three step : ( i ) flow-consistent destination estimation , velocity network predict denoised target ; ( ii ) refinement step project estimate destination feasible set define forward operator ; and ( iii ) time-progression step re-project refined destination flow trajectory . provide theoretical analysis demonstrate flower approximate bayesian posterior sampling , thereby unify perspective plug-and-play method and generative inverse solver . practical side , flower achieve state-of-the-art reconstruction quality use nearly identical hyperparameter various inverse problem .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26281,point2rbox-v3 : self-bootstrappe point annotations integrated pseudo-label refinement and utilization,"Teng Zhang, Ziqian Fan, Mingxin Liu, Xin Zhang, Xudong Lu, Wentong Li, Yue Zhou, Yi Yu, Xiang Li, Junchi Yan, Xue Yang","drive grow need oriented object detection ( ood ) , learn point annotation weakly-supervised framework have emerge promising alternative costly and laborious manual labeling . paper , discuss two deficiency exist point-supervised method : inefficient utilization and poor quality pseudo label . therefore , present point2rbox-v3 . core be two principle : 1 ) progressive label assignment ( pla ) . dynamically estimate instance size coarse yet intelligent manner different stage training process , enable use label assignment method . 2 ) prior-guided dynamic mask loss ( pgdm-loss ) . be enhancement voronoi watershed loss point2rbox-v2 , overcome shortcoming watershed poor performance sparse scene and sam ’s poor performance dense scene . knowledge , point2rbox-v3 be first model to employ dynamic pseudo label label assignment , and creatively complement advantage sam model watershed algorithm , achieve excellent performance sparse and dense scene . solution give competitive performance , especially scenario large variation object size or sparse object occurrence : 66 . 09%/56 . 86%/41 . 28%/46 . 40%/19 . 60%/45 . 96 % dota-v1 . 0/dota-v1 . 5/dota-v2 . 0/dior/star/rsar .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26278,profvlm : lightweight video-language model multi-view proficiency estimation,"Edoardo Bianchi, Jacopo Staiano, Antonio Liotta","exist approach skill proficiency estimation often rely black-box video classifier , ignore multi-view context and lack explainability . present profvlm , compact vision-language model reformulate task generative reasoning : jointly predict skill level and generate expert-like feedback egocentric and exocentric video . central method be attentivegatedprojector dynamically fuse multi-view feature , project frozen timesformer backbone language model tune feedback generation . train egoexo4d expert commentary , profvlm surpasse state-of-the-art method use 20x few parameter and reduce training time to 60 % . approach not only achieve superior accuracy diverse activity , but also output natural language critique align performance , offer transparent reasoning . result highlight generative vision-language modeling powerful new direction skill assessment .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26272,prpo : paragraph-level policy optimization vision-language deepfake detection,"Tuan Nguyen, Naseem Khan, Khang Tran, NhatHai Phan, Issa Khalil","rapid rise synthetic medium have make deepfake detection critical challenge online safety and trust . progress remain constrain scarcity large , high-quality dataset . multimodal large language model ( llms ) exhibit strong reasoning capability , performance deepfake detection be poor , often produce explanation be misalign visual evidence or hallucinatory . to address limitation , introduce reasoning-annotated dataset deepfake detection and propose paragraph-level relative policy optimization ( prpo ) , reinforcement learn algorithm align llm reasoning image content paragraph level . experiment show prpo improve detection accuracy wide margin and achieve high reasoning score 4 . 55/5 . 0 . ablation study far demonstrate prpo significantly outperform grpo test-time condition . result underscore importance ground multimodal reasoning visual evidence to enable more reliable and interpretable deepfake detection .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26251,see space and motion : enhancing latent actions spatial and dynamic awareness vla,"Zhejia Cai, Yandan Yang, Xinyuan Chang, Shiyi Liang, Ronghan Chen, Feng Xiong, Mu Xu, Ruqi Huang","latent action models ( lams ) enable vision-language-action ( vla ) system to learn semantic action representation large-scale unannotate datum . yet , identify two bottleneck lam : 1 ) commonly adopt end-to-end train image encoder suffer poor spatial understanding ; 2 ) lam can be fragile input frame be distant , lead limited temporal perception . such factor inevitably hinder stable and clear action modeling . end , propose farsighted-lam , latent action framework geometry-aware spatial encoding and multi-scale temporal modeling , capture structural prior and dynamic motion pattern consecutive frame . far propose ssm-vla , end-to-end vla framework build farsighted-lam , integrate structured perception visual chain-of-thought module to explicitly reason environmental dynamic , enhance decision consistency and interpretability . validate ssm-vla multiple vla task simulation and real-world setting , and achieve state-of-the-art performance . result demonstrate strategy combine geometry-aware modeling , temporal coherence , and explicit reasoning be effective enhance robustness and generalizability embodied intelligence .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26235,"interpret , prune and distill donut : lightweight vlm vqa document","Adnan Ben Mansour, Ayoub Karine, David Naccache","recent advance visually-rich document understanding rely large vision-language model donut , perform document-level visual question answer optical character recognition . effectiveness , model be too costly real-time or resource-constrained application . investigate model compression knowledge distillation , train compact student model large teacher . leverage mechanistic interpretability to drive student architecture design framework . analyze internal computation , identify essential subcomponent to retain , have clear view subcomponent should be approximate , skip , or reparametrize base function . approach yield ( mechanistic interpretability-base network trimming ) , prune donut variant reduce inference time and memory usage maintain strong performance docvqa , standard benchmark document visual question answering . method reframe compression circuit discovery , bridge interpretability research and practical vision-language model deployment .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26231,img : calibrating diffusion models implicit multimodal guidance,"Jiayi Guo, Chuanhao Yan, Xingqian Xu, Yulin Wang, Kai Wang, Gao Huang, Humphrey Shi","ensure precise multimodal alignment diffusion-generated image and input prompt have be long-standing challenge . early work finetune diffusion weight use high-quality preference datum , tend to be limited and difficult to scale . recent editing-based method far refine local region generate image but may compromise overall image quality . work , propose implicit multimodal guidance ( img ) , novel re-generation-base multimodal alignment framework require extra datum or edit operation . specifically , give generate image and prompt , img a ) utilize multimodal large language model ( mllm ) to identify misalignment ; b ) introduce implicit aligner manipulate diffusion conditioning feature to reduce misalignment and enable re-generation ; and c ) formulate re-alignment goal trainable objective , namely iteratively updated preference objective . extensive qualitative and quantitative evaluation sdxl , sdxl-dpo , and flux show img outperform exist alignment method . furthermore , img act flexible plug-and-play adapter , seamlessly enhance prior finetuning-based alignment method . code will be available https://github.com/shi-labs/img–multimodal-diffusion-alignment .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26227,generalized fine-grained category discovery multi-granularity conceptual expert,"Haiyang Zheng, Nan Pu, Wenjing Li, Nicu Sebe, Zhun Zhong","generalized category discovery ( gcd ) be open-world problem cluster unlabeled datum leverage knowledge partially label category . key challenge be unlabeled datum may contain known and novel category . exist approach suffer two main limitation . first , fail to exploit multi-granularity conceptual information visual datum , limit representation quality . second , most assume number unlabeled category be know training , be impractical real-world scenario . to address issue , propose multi-granularity conceptual experts ( mgce ) framework adaptively mine visual concept and integrate multi-granularity knowledge accurate category discovery . mgce consist two module : ( 1 ) dynamic conceptual contrastive learning ( dccl ) , alternate concept mining and dual-level representation learning to jointly optimize feature learning and category discovery ; and ( 2 ) multi-granularity expert collaborative learning ( mecl ) , extend single-expert paradigm introduce additional expert different granularity and employ concept alignment matrix effective cross-expert collaboration . importantly , mgce can automatically estimate number category unlabeled datum , make suitable practical open-world setting . extensive experiment nine fine-grained visual recognition benchmark demonstrate mgce achieve state-of-the-art result , particularly novel-class accuracy . notably , even prior knowledge category number , mgce outperform parametric approach require know exact number category , average improvement 3 . 6 % . code be available https://github.com/haiyangzheng/mgce .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26225,experimental study generating plausible textual explanations video summarization,"Thomas Eleftheriadis, Evlampios Apostolidis, Vasileios Mezaris","paper , present experimental study generate plausible textual explanation outcome video summarization . need study , extend exist framework multigranular explanation video summarization integrate sota large multimodal model ( llava-onevision ) and prompt to produce natural language description obtain visual explanation . follow , focus one most desire characteristic explainable ai , plausibility obtain explanation relate alignment human ' reasoning and expectation . use extended framework , propose approach evaluate plausibility visual explanation quantify semantic overlap textual description and textual description correspond video summary , help two method create sentence embedding ( sbert , simcse ) . base extend framework and propose plausibility evaluation approach , conduct experimental study use sota method ( ca-sum ) and two dataset ( summe , tvsum ) video summarization , to examine more faithful explanation be also more plausible one , and identify most appropriate approach generate plausible textual explanation video summarization .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26219,pixels : efficient dataset distillation sparse gaussian representation,"Chenyang Jiang, Zhengcen Li, Hang Zhao, Qiben Shan, Shaocong Wu, Jingyong Su","dataset distillation have emerge promising paradigm synthesize compact , informative dataset capable retain knowledge large-scale counterpart , thereby address substantial computational and storage burden modern model training . conventional approach typically rely dense pixel-level representation , introduce redundancy and be difficult to scale . work , propose gsdd , novel and efficient sparse representation dataset distillation base 2d gaussians . instead represent pixel equally , gsdd encode critical discriminative information distil image use only small number gaussian primitive . sparse representation could improve dataset diversity same storage budget , enhance coverage difficult sample and boost distillation performance . to ensure efficiency and scalability , adapt cuda-based splatte operator parallel inference and training , enable high-quality render minimal computational and memory overhead . method be simple yet effective , broadly applicable different distillation pipeline , and highly scalable . experiment show gsdd achieve state-of-the-art performance cifar-10 , cifar-100 , and imagenet subset , remain highly efficient encoding and decode cost . code be available https://github.com/j-cyoung/gsdatasetdistillation .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26208,tsalv360 : method and dataset text-driven saliency detection 360-degrees video,"Ioannis Kontostathis, Evlampios Apostolidis, Vasileios Mezaris","paper , deal task text-driven saliency detection 360∘360^{\circ } video . , introduce tsv360 dataset include 16 , 000 triplet erp frame , textual description salient objects/event frame , and associate ground-truth saliency map . follow , extend and adapt sota visual-based approach 360∘360^{\circ } video saliency detection , and develop tsalv360 method take account user-provided text description desire object and/or event . method leverage sota vision-language model datum representation and integrate similarity estimation module and viewport spatio-temporal cross-attention mechanism , to discover dependency different data modality . quantitative and qualitative evaluation use tsv360 dataset , show competitiveness tsalv360 compare sota visual-based approach and document competency to perform customized text-driven saliency detection 360∘360^{\circ } video .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26185,attrigen : automated multi-attribute annotation blood cell dataset,"Walid Houmaidi, Youssef Sabiri, Fatima Zahra Iguenfer, Amine Abouaomar","introduce attrigen , novel framework automate , fine-grained multi-attribute annotation computer vision , particular focus cell microscopy multi-attribute classification remain underrepresented compare traditional cell type categorization . use two complementary dataset : peripheral blood cell ( pbc ) dataset contain eight distinct cell type and wbc attribute dataset ( wbcatt ) contain correspond 11 morphological attribute , propose dual-model architecture combine cnn cell type classification , as well vision transformer ( vit ) multi-attribute classification achieve new benchmark 94 . 62 % accuracy . experiment demonstrate attrigen significantly enhance model interpretability and offer substantial time and cost efficiency relative conventional full-scale human annotation . thus , framework establish new paradigm can be extend other computer vision classification task effectively automate expansion multi-attribute label .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26166,overall accuracy : pose- and occlusion-driven fairness analysis pedestrian detection autonomous driving,"Mohammad Khoshkdahan, Arman Akbari, Arash Akbari, Xuan Zhang","pedestrian detection play critical role autonomous driving ( ad ) , ensure safety and reliability be important . many detection model aim to reduce miss-rate and handle challenge such occlusion and long-range recognition , fairness remain underexplored yet equally important concern . work , systematically investigate variation pedestrian pose—include leg status , elbow status , and body orientation—as well individual joint occlusion , affect detection performance . evaluate five pedestrian-specific detector ( f2dnet , mgan , alfnet , csp , and cascade r-cnn ) three general-purpose model ( yolov12 variant ) eurocity persons dense pose ( ecp-dp ) dataset . fairness be quantify use equal opportunity difference ( eod ) metric various confidence threshold . to assess statistical significance and robustness , apply z-test . finding highlight bias pedestrian parallel leg , straight elbow , and lateral view . occlusion low body joint have more negative impact detection rate compare upper body and head . cascade r-cnn achieve low overall miss-rate and exhibit small bias attribute . good knowledge , be first comprehensive pose- and occlusion-aware fairness evaluation pedestrian detection ad .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26165,human-mme : holistic evaluation benchmark human-centric multimodal large language model,"Yuansen Liu, Haiming Tang, Jinlong Peng, Jiangning Zhang, Xiaozhong Ji, Qingdong He, Donghao Luo, Zhenye Gan, Junwei Zhu, Yunhang Shen, Chaoyou Fu, Chengjie Wang, Xiaobin Hu, Shuicheng Yan","multimodal large language models ( mllms ) have demonstrate significant advance visual understanding task . however , capacity to comprehend human-centric scene have rarely be explore , primarily absence comprehensive evaluation benchmark take account both human-oriented granular level and higher-dimensional causal reasoning ability . such high-quality evaluation benchmark face tough obstacle , give physical complexity human body and difficulty annotate granular structure . paper , propose human-mme , rigorously curate benchmark design to provide more holistic evaluation mllms human-centric scene understanding . compare other exist benchmark , work provide three key feature : ( 1 ) diversity human scene , span 4 primary visual domain 15 secondary domain and 43 sub-field to ensure broad scenario coverage . ( 2 ) progressive and diverse evaluation dimension , evaluate human-based activity progressively human-oriented granular perception higher-dimensional multi-target and causal reasoning , consist eight dimension 19 , 945 real-world image question pair and evaluation suite . ( 3 ) high-quality annotation rich datum paradigm , construct automate annotation pipeline and human-annotation platform , support rigorous manual labeling expert annotator to facilitate precise and reliable model assessment . benchmark extend single-person and single-image understanding multi-person and multi-image mutual understanding construct choice , short-answ , ground , rank and judgment question component , and complex question-answer pair combination . extensive experiment 17 state-of-the-art mllm effectively expose limitation and guide future mllm research well human-centric image understanding and reasoning . datum and code be publicly available .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26158,continual expansion data coverage : automatic text-guided edge-case synthesis,Kyeongryeol Go,"performance deep neural network be strongly influence quality training datum . however , mitigate dataset bias manually curate challenging edge case remain major bottleneck . to address , propose automate pipeline text-guided edge-case synthesis . approach employ large language model , fine-tune preference learning , to rephrase image caption diverse textual prompt steer text-to-image model generate difficult visual scenario . evaluate fisheye8 k object detection benchmark , method achieve superior robustness , surpass both naive augmentation and manually engineer prompt . work establish scalable framework shift datum curation manual effort to automate , target synthesis , offer promising direction develop more reliable and continuously improve ai system . code be available https://github.com/gokyeongryeol/ate .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26157,entrope : entropy-guide dynamic patch encoder time series forecasting,"Sachith Abeywickrama, Emadeldeen Eldele, Min Wu, Xiaoli Li, Chau Yuen","transformer-based model have significantly advanced time series forecasting , patch-based input strategy offer efficiency and improve long-horizon modeling . yet , exist approach rely temporally-agnostic patch construction , arbitrary starting position and fix length fracture temporal coherence split natural transition boundary . naive segmentation often disrupt short-term dependency and weaken representation learning . response , propose entrope ( entropy-guided dynamic patch encoder ) , novel , temporally inform framework dynamically detect transition point conditional entropy and dynamically place patch boundary . preserve temporal structure retain computational benefit patching . entrope consist two key module , namely entropy-based dynamic patcher ( edp ) apply information-theoretic criterion to locate natural temporal shift and determine patch boundary , and adaptive patch encoder ( ape ) employ pool and cross-attention to capture intra-patch dependency and produce fixed-size latent representation . embedding be then process global transformer to model inter-patch dynamic . experiment long-term forecasting benchmark demonstrate entrope improve accuracy and efficiency , establish entropy-guided dynamic patching promising new paradigm time series modeling . code be available https://github.com/sachithx/entrope .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26127,echogen : generate visual echoes scene feed-forward subject-driven auto-regressive model,"Ruixiao Dong, Zhendong Wang, Keli Liu, Li Li, Ying Chen, Kai Li, Daowen Li, Houqiang Li","subject-driven generation be critical task creative ai ; yet current state-of-the-art method present stark trade-off . either rely computationally expensive , per-subject fine-tuning , sacrifice efficiency and zero-shot capability , or employ feed-forward architecture build diffusion model , be inherently plague slow inference speed . visual auto-regressive ( var ) model be renowned rapid sampling speed and strong generative quality , make ideal yet underexplored foundation resolve tension . to bridge gap , introduce echogen , pioneering framework empower var model subject-driven generation capability . core design echogen be effective dual-path injection strategy disentangle subject ’s high-level semantic identity low-level fine-grained detail , enable enhance controllability and fidelity . employ semantic encoder to extract subject ’s abstract identity , be inject decouple cross-attention to guide overall composition . concurrently , content encoder capture intricate visual detail , be integrate multi-modal attention mechanism to ensure high-fidelity texture and structural preservation . good knowledge , echogen be first feed-forward subject-driven framework build var model . both quantitative and qualitative result substantiate design , demonstrate echogen achieve subject fidelity and image quality comparable to state-of-the-art diffusion-based method significantly low sampling latency . code and model will be release soon .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26096,evodiff : entropy-aware variance optimized diffusion inference,"Shigui Li, Wei Chen, Delu Zeng","diffusion model ( dms ) excel image generation , but suffer slow inference and training-inference discrepancy . gradient-based solver dpm-solver accelerate denoising inference , lack theoretical foundation information transmission efficiency . work , introduce information-theoretic perspective inference process dms , reveal successful denoising fundamentally reduce conditional entropy reverse transition . principle lead key insight inference process : ( 1 ) datum prediction parameterization outperform noise counterpart , and ( 2 ) optimize conditional variance offer reference-free way to minimize transition and reconstruction error . base insight , propose entropy-aware variance optimize method generative process dms , call evodiff , systematically reduce uncertainty optimize conditional entropy denoise . extensive experiment dms validate insight and demonstrate method significantly and consistently outperform state-of-the-art ( sota ) gradient-based solver . example , compare dpm-solver++ , evodiff reduce reconstruction error 45 . 5 % ( fid improve 5 . 10 to 2 . 78 ) 10 function evaluation ( nfe ) cifar-10 , cut nfe cost 25 % ( 20 to 15 nfe ) high-quality sample imagenet-256 , and improve text-to-image generation reduce artifact . code be available https://github.com/shiguili/evodiff .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26091,text-to-scene large reasoning model,"Frédéric Berdoz, Luca A. Lanzendörfer, Nick Tuninga, Roger Wattenhofer","prompt-driven scene synthesis allow user to generate complete 3d environment textual description . current text-to-scene method often struggle complex geometry and object transformation , and tend to show weak adherence complex instruction . address limitation introduce reason-3d , text-to-scene model power large reasoning model ( lrms ) . reason-3d integrate object retrieval use caption cover physical , functional , and contextual attribute . reason-3d then place select object base implicit and explicit layout constraint , and refine position collision-aware spatial reasoning . evaluate instruction range simple complex indoor configuration , reason-3d significantly outperform previous method human-rated visual fidelity , adherence constraint , and asset retrieval quality . contribution field text-to-scene generation , work showcase advanced spatial reasoning ability modern lrm . additionally , release codebase to further research object retrieval and placement lrms . 111demo & code : https://lucala.github.io/reason-3d-demo/",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26087,easyocc : 3d pseudo-label supervision fully self-supervise semantic occupancy prediction model,"Seamie Hayes, Ganesh Sistu, Ciarán Eising","self-supervised model have recently achieve notable advancement , particularly domain semantic occupancy prediction . model utilize sophisticated loss computation strategy to compensate absence ground-truth label . instance , technique such novel view synthesis , cross-view rendering , and depth estimation have be explore to address issue semantic and depth ambiguity . however , such technique typically incur high computational cost and memory usage training stage , especially case novel view synthesis . to mitigate issue , propose 3d pseudo-ground-truth label generate foundation model grounded-sam and metric3dv2 , and harness temporal information label densification . 3d pseudo-label can be easily integrate exist model , yield substantial performance improvement , miou increase 45 % , 9 . 73 14 . 09 , implement occnerf model . stand contrast early advancement field , be often not readily transferable other architecture . additionally , propose streamlined model , easyocc , achieve 13 . 86 miou . model conduct learn solely label , avoid complex rendering strategy mention previously . furthermore , method enable model to attain state-of-the-art performance evaluate full scene apply camera mask , easyocc achieve 7 . 71 miou , outperform previous good model 31 % . finding highlight critical importance foundation model , temporal context , and choice loss computation space self-supervised learning comprehensive scene understanding .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26070,geometric learning canonical parameterizations $ 2d$-curves,"Ioana Ciuclea, Giorgio Longari, Alice Barbara Tumpach","most dataset encounter computer vision and medical application present symmetry should be take account classification task . typical example be symmetry rotation and/or scaling object detection . common way to build neural network learn symmetry be to use datum augmentation . order to avoid datum augmentation and build more sustainable algorithm , present alternative method mod symmetry base notion section principal fiber bundle . framework allow use simple metric space object order to measure dissimilarity orbit object symmetry group . moreover , section use can be optimize to maximize separation class . illustrate methodology dataset contour object group translation , rotation , scaling and reparameterization . particular , present 22-paramet family canonical parameterization curve , contain constant-speed parameterization special case , believe be interesting own right . hope simple application will serve to convey geometric concept underlie method , have wide range possible application . code be available follow link : https://github.com/gilonga/geometric-learning . tutorial notebook showcase application code specific dataset be available following link : https://github.com/ioanaciuclea/geometric-learning-notebook",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26047,dgm4 + : dataset extension global scene inconsistency,"Gagandeep Singh, Samudi Amarsinghe, Priyanka Singh, Xue Li","rapid advance generative model have significantly lower barrier produce convincing multimodal disinformation . fabricate image and manipulate caption increasingly co-occur to create persuasive false narrative . detecting and ground multi-modal media manipulation ( dgm4 ) dataset establish foundation research area , be restrict local manipulation such face swap , attribute edit , and caption change . leave critical gap : global inconsistency , such mismatch foreground and background , be now prevalent real-world forgery .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26039,sgs : segmentation-guide score global scene inconsistencies,"Gagandeep Singh, Samudi Amarsinghe, Urawee Thani, Ki Fung Wong, Priyanka Singh, Xue Li","extend hammer , state-of-the-art model multimodal manipulation detection , to handle global scene inconsistency such foreground–background ( fg–bg ) mismatch . hammer achieve strong performance dgm4 dataset , consistently fail main subject be contextually misplace implausible background . diagnose limitation combination label-space bias , local attention focus , and spurious text–foreground alignment . to remedy retrain , propose lightweight segmentation-guided scoring ( sgs ) pipeline . sgs use person/face segmentation mask to separate foreground and background region , extract embedding joint vision–language model , and compute region-aware coherence score . score be fuse hammer ’s original prediction to improve binary detection , ground , and token-level explanation . sgs be inference-only , incur negligible computational overhead , and significantly enhance robustness global manipulation . work demonstrate importance region-aware reasoning multimodal disinformation detection . release script segmentaion and scoring https://github.com/gaganx0/hammer-sgs",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26036,semobridge : semantic modality bridge efficient few-shot adaptation clip,"Christoph Timmermann, Hyunse Lee, Woojin Lee","contrastive language-image pretraine ( clip ) excel zero-shot task align image and text embedding , performance few-shot classification be hinder critical limitation : intra-modal misalignment . issue , cause persistent modality gap and clip ’s exclusively inter-modal training objective , leave embed space uncalibrate , make direct image-to-image comparison unreliable . exist method attempt to address refine similarity logit or computationally expensive per-sample optimization . to overcome challenge , introduce semobridge , lightweight yet powerful approach directly address misalignment . method map image text modality , keep semantic content intact call semantic modality bridge . semobridge be closed-form and can optionally be train multi-modal supervision , combine image and text-alignment loss to optimize projection . experiment show train version , semobridge-t , require only fraction training time overall outperform other method , particularly low-data scenario ( 1 , 2 , and 4 shot ) . code be available github.com/christti98/semobridge .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26027,causally guide gaussian perturbations out-of-distribution generalization medical imaging,"Haoran Pei, Yuguang Yang, Kexin Liu, Baochang Zhang","out-of-distribution ( ood ) generalization remain central challenge deploy deep learning model real-world scenario , particularly domain such biomedical image , distribution shift be subtle and pervasive . existing method often pursue domain invariance complex generative model or adversarial training , approach may overlook underlie causal mechanism generalization . work , propose causally-guide gaussian perturbations ( cgp)—a lightweight framework enhance ood generalization inject spatially vary noise input image , guide soft causal mask derive vision transformers . apply strong perturbation background region and weak one to foreground area , cgp encourage model to rely causally relevant feature rather spurious correlation . experimental result challenge wilds benchmark camelyon17 demonstrate consistent performance gain state-of-the-art ood baseline , highlight potential causal perturbation tool reliable and interpretable generalization .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26025,patchvsr : break video diffusion resolution limits patch-wise video super-resolution,"Shian Du, Menghan Xia, Chang Liu, Xintao Wang, Jing Wang, Pengfei Wan, Di Zhang, Xiangyang Ji","pre-traine video generation model hold great potential generative video super-resolution ( vsr ) . however , adapt full-size vsr , most exist method do , suffer unnecessary intensive full-attention computation and fix output resolution . to overcome limitation , make first exploration utilize video diffusion prior patch-wise vsr . be non-trivial pre-trained video diffusion model be not native patch-level detail generation . to mitigate challenge , propose innovative approach , call patchvsr , integrate dual-stream adapter conditional guidance . patch branch extract feature input patch to maintain content fidelity global branch extract context feature resize full video to bridge generation gap cause incomplete semantic patch . particularly , also inject patch ’s location information model to well contextualize patch synthesis global video frame . experiment demonstrate method can synthesize high-fidelity , high-resolution detail patch level . tailor-made multi-patch joint modulation be propose to ensure visual consistency individually enhance patch . flexibility patch-based paradigm , can achieve highly competitive 4 k vsr base 512×\times512 resolution base model , extremely high efficiency .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26016,geolink : empower remote sensing foundation model openstreetmap datum,"Lubian Bai, Xiuyuan Zhang, Siqi Zhang, Zepeng Zhang, Haoyu Wang, Wei Qin, Shihong Du","integrate ground-level geospatial datum rich geographic context , openstreetmap ( osm ) , remote sensing ( rs ) foundation model ( fm ) be essential advance geospatial intelligence and support broad spectrum task . however , modality gap rs and osm datum , include difference datum structure , content , and spatial granularity , make effective synergy highly challenging , and most exist rs fm focus imagery alone . end , study present geolink , multimodal framework leverage osm datum to enhance rs fm pretraining and downstream task stage . specifically , geolink enhance rs self-supervised pretraining use multi-granularity learning signal derive osm datum , guide cross-modal spatial correlation information interaction and collaboration . also introduce image mask-reconstruction to enable sparse input efficient pretraining . downstream task , geolink generate unimodal and multimodal fine-grained encoding to support wide range application , common rs interpretation task land cover classification more comprehensive geographic task urban function zone mapping . extensive experiment show incorporate osm datum pretraine enhance performance rs image encoder , fuse rs and osm datum downstream task improve fm ’s adaptability complex geographic scenario . result underscore potential multimodal synergy advance high-level geospatial artificial intelligence . moreover , find spatial correlation play crucial role enable effective multimodal geospatial datum integration . code , checkpoint , and use example be release https://github.com/bailubin/geolink_neurips2025",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26012,setr : two-stage semantic-enhanced framework zero-shot composed image retrieval,"Yuqi Xiao, Yingying Zhu","zero-shot composed image retrieval ( zs-cir ) aim to retrieve target image give reference image and relative text , rely costly triplet annotation . exist clip-based method face two core challenge : ( 1 ) union-based feature fusion indiscriminately aggregate visual cue , carry irrelevant background detail dilute intend modification , and ( 2 ) global cosine similarity clip embedding lack ability to resolve fine-grained semantic relation . to address issue , propose setr ( semantic-enhanced two-stage retrieval ) . coarse retrieval stage , setr introduce intersection-driven strategy retain only overlap semantic reference image and relative text , thereby filter distractor inherent union-based fusion and produce clean , high-precision candidate set . fine-grained re-ranking stage , adapt pretraine multimodal llm lora to conduct binary semantic relevance judgment ( "" yes/no "" ) , go clip ’s global feature match explicitly verify relational and attribute-level consistency . together , two stage form complementary pipeline : coarse retrieval narrow candidate pool high recall , re-ranking ensure precise alignment nuanced textual modification . experiment cirr , fashion-iq , and circo show setr achieve new state-of-the-art performance , improve recall@1 cirr to 15 . 15 point . result establish two-stage reasoning general paradigm robust and portable zs-cir .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26010,new fourth-order grayscale indicator-base telegraph diffusion model image despeckling,"Rajendra K. Ray, Manish Kumar","second-order pde model have be widely use suppress multiplicative noise , but often introduce blocky artifact early stage denoising . to resolve , propose fourth-order nonlinear pde model integrate diffusion and wave property . diffusion process , guide both laplacian and intensity value , reduce noise well gradient-based method , wave part keep fine detail and texture . effectiveness propose model be evaluate two second-order anisotropic diffusion approach use peak signal-to-noise ratio ( psnr ) and mean structural similarity index ( mssim ) image available ground truth . sar image , noise-free reference be unavailable , speckle index ( si ) be use to measure noise reduction . additionally , extend propose model to study color image apply denoising process independently channel , preserve structure and color consistency . same quantitative metric psnr and mssim be use performance evaluation , ensure fair comparison grayscale and color image . case , computed result produce well result compare exist model genre .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26008,pfdepth : heterogeneous pinhole-fisheye joint depth estimation distortion-aware gaussian-splatte volumetric fusion,"Zhiwei Zhang, Ruikai Xu, Weijian Zhang, Zhizhong Zhang, Xin Tan, Jingyu Gong, Yuan Xie, Lizhuang Ma","paper , present first pinhole-fisheye framework heterogeneous multi-view depth estimation , pfdepth . key insight be to exploit complementary characteristic pinhole and fisheye imagery ( undistorted vs. distorted , small large fov , far near field ) joint optimization . pfdepth employ unified architecture capable process arbitrary combination pinhole and fisheye camera varied intrinsic and extrinsic . pfdepth , first explicitly lift 2d feature heterogeneous view canonical 3d volumetric space . then , core module term heterogeneous spatial fusion be design to process and fuse distortion-aware volumetric feature overlap and non-overlapping region . additionally , subtly reformulate conventional voxel fusion novel 3d gaussian representation , learnable latent gaussian sphere dynamically adapt local image texture fine 3d aggregation . finally , fuse volume feature be render multi-view depth map . extensive experiment , demonstrate pfdepth set state-of-the-art performance kitti-360 and realhet dataset current mainstream depth network . good knowledge , be first systematic study heterogeneous pinhole-fisheye depth estimation , offer technical novelty and valuable empirical insight .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26006,agenticiqa : agentic framework adaptive and interpretable image quality assessment,"Hanwei Zhu, Yu Tian, Keyan Ding, Baoliang Chen, Bolin Chen, Shiqi Wang, Weisi Lin","image quality assessment ( iqa ) be inherently complex , reflect both quantification and interpretation perceptual quality root human visual system . conventional approach typically rely fix model to output scalar score , limit adaptability to diverse distortion , user-specific query , and interpretability need . furthermore , scoring and interpretation be often treat independent process , interdependence : interpretation identify perceptual degradation , scoring abstract compact metric . to address limitation , propose agenticiqa , modular agentic framework integrate vision-language model ( vlms ) traditional iqa tool dynamic , query-aware manner . agenticiqa decompose iqa four subtasks—distortion detection , distortion analysis , tool selection , and tool execution—coordinate planner , executor , and summarizer . planner formulate task-specific strategy , executor collect perceptual evidence tool invocation , and summarizer integrate evidence to produce accurate score human-aligned explanation . to support training and evaluation , introduce agenticiqa-200 k , large-scale instruction dataset tailor iqa agent , and agenticiqa-eval , first benchmark assess planning , execution , and summarization capability vlm-base iqa agent . extensive experiment diverse iqa dataset demonstrate agenticiqa consistently surpass strong baseline both scoring accuracy and explanatory alignment111code : https://agenticiqa.github.io/.",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26004,learn egocentric in-hand object segmentation weak supervision human narrations,"Nicola Messina, Rosario Leonardi, Luca Ciampi, Fabio Carrara, Giovanni Maria Farinella, Fabrizio Falchi, Antonino Furnari","pixel-level recognition object manipulate user egocentric image enable key application span assistive technology , industrial safety , and activity monitoring . however , progress area be currently hinder scarcity annotated dataset , exist approach rely costly manual label . paper , propose to learn human-object interaction detection leverage narration – natural language description action perform camera wearer contain clue manipulated object ( e.g. , "" be pour vegetable chop board pan "" ) . narration provide form weak supervision be cheap to acquire and readily available state-of-the-art egocentric dataset . introduce narration-supervised in-hand object segmentation ( ns-ihos ) , novel task model have to learn to segment object learn natural-language narration . narration be then not employ inference time . showcase potential task propose weakly-supervise in-hand object segmentation human narrations ( wish ) , end-to-end model distil knowledge narration to learn plausible hand-object association and enable in-hand object segmentation use narration test time . benchmark wish different baseline base open-vocabulary object detector and vision-language model , show superiority design . experiment epic-kitchens and ego4d show wish surpass baseline , recover more 50%50\% performance fully supervise method , employ fine-grained pixel-wise annotation . code and datum can be find https://fpv-iplab.github.io/wish/.",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.25998,vrwkv-editor : reduce quadratic complexity transformer-based video editing,"Abdelilah Aitrouga, Youssef Hmamouche, Amal El Fallah Seghrouchni","light recent progress video editing , deep learning model focus spatial and temporal dependency have emerge primary method . however , model suffer quadratic computational complexity traditional attention mechanism , make difficult to adapt long-duration and high-resolution video . limitation restrict applicability practical context such real-time video processing . to tackle challenge , introduce method to reduce time and space complexity system propose vrwkv-editor , novel video editing model integrate linear spatio-temporal aggregation module video-based diffusion model . vrwkv-editor leverage bidirectional weight key-value recurrence mechanism rwkv transformer to capture global dependency preserve temporal coherence , achieve linear complexity sacrifice quality . extensive experiment demonstrate propose method achieve to 3 . 7× speedup and 60 % low memory usage compare state-of-the-art diffusion-based video editing method , maintain competitive performance frame consistency and text alignment . furthermore , comparative analysis conduct video different sequence length confirm gap edit speed approach and architecture self-attention become more significant long video .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.25989,reliable and holistic visual in-context learn prompt selection,"Wenxiao Wu, Jing-Hao Xue, Chengming Xu, Chen Liu, Xinwei Sun, Changxin Gao, Nong Sang, Yanwei Fu","visual in-context learning ( vicl ) have emerge prominent approach adapt visual foundation model novel task , effectively exploit contextual information embed in-context example , can be formulate global ranking problem potential candidate . current vicl method , such partial2global and vpr , be ground similarity-priority assumption image more visually similar query image serve well in-context example . foundational assumption , intuitive , lack sufficient justification efficacy select optimal in-context example . furthermore , partial2global construct global ranking series randomly sample pairwise preference prediction . reliance random sampling can lead incomplete coverage and redundant sampling comparison , thus far adversely impact final global ranking . to address issue , paper introduce enhance variant partial2global design reliable and holistic selection in-context example vicl . propose method , dub rh-partial2global , leverage jackknife conformal prediction-guide strategy to construct reliable alternative set and cover design-based sampling approach to ensure comprehensive and uniform coverage pairwise preference . extensive experiment demonstrate rh-partial2global achieve excellent performance and outperform partial2global diverse visual task . source code be available https://github.com/wu-wenxiao/rh-partial2global .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.25970,pinpoint3d : fine-grained 3d part segmentation few click,"Bojun Zhang, Hangjian Ye, Hao Zheng, Jianzheng Huang, Zhengyu Lin, Zhenhong Guo, Feng Zheng","fine-graine 3d part segmentation be crucial enable embody ai system to perform complex manipulation task , such interact specific functional component object . however , exist interactive segmentation method be largely confine coarse , instance-level target , non-interactive approach struggle sparse , real-world scan and suffer severe lack annotated datum . to address limitation , introduce pinpoint3d , novel interactive framework fine-grained , multi-granularity 3d segmentation , capable generate precise part-level mask only few user point click . key component work be new 3d datum synthesis pipeline develop to create large-scale , scene-level dataset dense part annotation , overcome critical bottleneck have hinder progress field . comprehensive experiment and user study , demonstrate method significantly outperform exist approach , achieve average iou 55 . 8 % object part first-click setting and surpass 71 . 3 % iou only few additional click . compare current state-of-the-art baseline , pinpoint3d yield 16 % improvement iou and precision , highlight effectiveness challenge , sparse point cloud high efficiency . work represent significant step more nuanced and precise machine perception and interaction complex 3d environment .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.25969,multi-purpose tracking framework salmon welfare monitoring challenging environments,"Espen Uri Høgstedt, Christian Schellewald, Annette Stahl, Rudolf Mester","computer vision ( cv)-base continuous , automated and precise salmon welfare monitoring be key step reduce salmon mortality and improve salmon welfare industrial aquaculture net pen . available cv method determine welfare indicator focus single indicator and rely object detector and tracker other application area to aid welfare indicator calculation algorithm . come high resource demand real-world application , indicator must be calculate separately . addition , method be vulnerable difficulty underwater salmon scene , such object occlusion , similar object appearance , and similar object motion . to address challenge , propose flexible tracking framework use pose estimation network to extract bounding box salmon and correspond body part , and exploit information body part , specialized module , to tackle challenge specific underwater salmon scene . subsequently , high-detail body part track be employ to calculate welfare indicator . construct two novel dataset assess two salmon tracking challenge : salmon id transfer crowded scene and salmon id switch turn . method outperform current state-of-the-art pedestrian tracker , boosttrack , salmon tracking challenge . additionally , create dataset calculate salmon tail beat wavelength , demonstrate body part tracking method be well-suited automate welfare monitoring base tail beat analysis . dataset and code be available https://github.com/espenbh/boostcomptrack .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.25963,self-supervise anatomical consistency learning vision-grounded medical report generation,"Longzhen Yang, Zhangkai Ni, Ying Wen, Yihang Liu, Lianghua He, Heng Tao Shen","vision-grounde medical report generation aim to produce clinically accurate description medical image , anchor explicit visual evidence to improve interpretability and facilitate integration clinical workflow . however , exist method often rely separately train detection module require extensive expert annotation , introduce high labeling cost and limit generalizability pathology distribution bias dataset . to address challenge , propose self-supervised anatomical consistency learning ( ss-acl)—a novel and annotation-free framework align generate report correspond anatomical region use simple textual prompt . ss-acl construct hierarchical anatomical graph inspire invariant top-down inclusion structure human anatomy , organize entity spatial location . recursively reconstruct fine-grained anatomical region to enforce intra-sample spatial alignment , inherently guide attention map visually relevant area prompt text . to far enhance inter-sample semantic alignment abnormality recognition , ss-acl introduce region-level contrastive learning base anatomical consistency . align embedding serve prior report generation , enable attention map to provide interpretable visual evidence . extensive experiment demonstrate ss-acl , rely expert annotation , ( i ) generate accurate and visually ground reports—outperforme state-of-the-art method 10 % lexical accuracy and 25 % clinical efficacy , and ( ii ) achieve competitive performance various downstream visual task , surpass current lead visual foundation model 8 % zero-shot visual grounding . code be available https://github.com/kaelsunkiller/ssacl .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.25940,co3 : contrasting concepts compose well,"Debottam Dutta, Jianchong Chen, Rajalaxmi Rajagopalan, Yu-Lin Wei, Romit Roy Choudhury","propose to improve multi‑concept prompt fidelity text‑to‑image diffusion model . begin common failure cases—prompt "" cat and dog "" sometimes yield image one concept be miss , faint , or collide awkwardly . hypothesize happen diffusion model drift mixed mode over‑emphasize single concept learn strongly training . instead re-traine , introduce corrective sampling strategy steer away region joint prompt behavior overlap too strongly single concept prompt . goal be to steer "" pure "" joint mode concept can coexist balanced visual presence .. far show exist multi‑concept guidance scheme can operate unstable weight regime amplify imbalance ; characterize favorable region and adapt sampling to remain . approach , co3 , be plug‑and‑play , require model tuning , and complement standard classifier‑free guidance . experiment diverse multi-concept prompt indicate improvement concept coverage , balance and robustness , few drop or distort concept compare standard baseline and prior compositional method . result suggest lightweight corrective guidance can substantially mitigate brittle semantic alignment behavior modern diffusion system .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.25934,unimmad : unify multi-modal and multi-class anomaly detection moe-driven feature decompression,"Yuan Zhao, Youwei Pang, Lihe Zhang, Hanqi Liu, Jiaming Zuo, Huchuan Lu, Xiaoqi Zhao","exist anomaly detection ( ad ) method often treat modality and class independent factor . paradigm have enrich development ad research branch and produce many specialized model , have also lead fragmented solution and excessive memory overhead . moreover , reconstruction-based multi-class approach typically rely share decode path , struggle to handle large variation domain , result distorted normality boundary , domain interference , and high false alarm rate . to address limitation , propose unimmad , unified framework multi-modal and multi-class anomaly detection . core unimmad be mixture-of-expert ( moe)-driven feature decompression mechanism , enable adaptive and disentangle reconstruction tailor specific domain . process be guide "" general → specific "" paradigm . encoding stage , multi-modal input vary combination be compress compact , general-purpose feature . encoder incorporate feature compression module to suppress latent anomaly , encourage cross-modal interaction , and avoid shortcut learning . decode stage , general feature be decompress modality-specific and class-specific form sparsely-gated cross moe , dynamically select expert pathway base input modality and class . to far improve efficiency , design group dynamic filtering mechanism and moe-in-moe structure , reduce parameter usage 75 % maintain sparse activation and fast inference . unimmad achieve state-of-the-art performance 9 anomaly detection dataset , span 3 field , 12 modality , and 66 class . source code will be available https://github.com/yuanzhao-cvlab/unimmad .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.25927,impact scaling training data adversarial robustness,"Marco Zimmerli, Andreas Plesner, Till Aczel, Roger Wattenhofer","deep neural network remain vulnerable adversarial example advance architecture and training paradigm . investigate training data characteristic affect adversarial robustness 36 state-of-the-art vision model span supervise , self-supervised , and contrastive learning approach , train dataset 1 . 2 m 22b image . model be evaluate six black-box attack category : random perturbation , two type geometric mask , coco object manipulation , imagenet-c corruption , and imagenet-r style shift . robustness follow logarithmic scale law both datum volume and model size : tenfold increase datum reduce attack success rate ( asr ) average 3 . 2 % , tenfold increase model size reduce asr average 13 . 4 % . notably , self-supervised model train curate dataset , such dinov2 , outperform other train much large but less curate dataset , challenge assumption scale alone drive robustness . adversarial fine-tuning resnet50s improve generalization structural variation but not color distribution . human evaluation reveal persistent gap human and machine vision . result show scaling improve robustness , datum quality , architecture , and training objective play more decisive role raw scale achieve broad-spectrum adversarial resilience .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.25916,vlm-fo1 : bridge gap high-level reasoning and fine-grained perception vlm,"Peng Liu, Haozhan Shen, Chunxin Fang, Zhicheng Sun, Jiajia Liao, Tiancheng Zhao","vision-language models ( vlms ) excel high-level scene understanding but falter fine-grained perception task require precise localization . failure stem fundamental mismatch , generate exact numerical coordinate be challenge task language-centric architecture . paper , introduce vlm-fo1 , novel framework overcome limitation reframe object-centric perception brittle coordinate generation problem robust feature retrieval task . method operate plug-and-play module integrate pre-trained vlm . leverage hybrid fine-graine region encoder ( hfre ) , feature dual-vision encoder , to generate powerful region token rich both semantic and spatial detail . token-based referencing system then enable llm to seamlessly reason and ground language specific visual region . experiment show vlm-fo1 achieve state-of-the-art performance diverse suite benchmark , demonstrate exceptional capability object grounding , region generative understanding , and visual region reasoning . crucially , two-stage training strategy ensure perception gain be achieve compromise base model ’s general visual understanding capability . vlm-fo1 establish effective and flexible paradigm build perception-aware vlm , bridge gap high-level reasoning and fine-grained visual grounding .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.25896,llavashield : safeguard multimodal multi-turn dialogue vision-language model,"Guolei Huang, Qingzhi Peng, Gan Xu, Yuxuan Lu, Yongjun Shen","vision-language model ( vlms ) move interactive , multi-turn use , new safety risk arise single-turn or single-modality moderation miss . multimodal multi-turn ( mmt ) dialogue , malicious intent can be spread turn and image , context-sensitive reply may still advance harmful content . to address challenge , present first systematic definition and study mmt dialogue safety . build formulation , introduce multimodal multi-turn dialogue safety ( mmds ) dataset . far develop automate multimodal multi-turn red-teame framework base monte carlo tree search ( mcts ) to generate unsafe multimodal multi-turn dialogue mmds . mmds contain 4 , 484 annotate multimodal dialogue sample fine-grained safety rating , policy dimension label , and evidence-based rationale user and assistant . leverage mmds , present llavashield , powerful tool jointly detect and assess risk user input and assistant response . comprehensive experiment , llavashield consistently outperform strong baseline mmt content moderation task and dynamic policy configuration , establish new state-of-the-art result . will publicly release dataset and model to support future research .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.25889,multimodal llm approach visual question answer multiparametric 3d brain mri,"Arvind Murari Vepa, Yannan Yu, Jingru Gan, Anthony Cuturrufo, Weikai Li, Wei Wang, Fabien Scalzo, Yizhou Sun","introduce mpllm , prompt-conditioned hierarchical mixture-of-expert ( moe ) architecture visual question answer multiparametric 3d brain mri ( mpmri ) . mpllm route modality-level and token-level projection expert to fuse multiple interrelated 3d modality , enable efficient training image–report pretraining . to address limit image-text pair supervision , mpllm integrate synthetic visual question answer ( vqa ) protocol generate medically relevant vqa segmentation annotation , and collaborate medical expert clinical validation . mpllm outperform strong medical vlm baseline 5 . 3 % average multiple mpmri dataset . study feature three main contribution : ( 1 ) first clinically validate vqa dataset 3d brain mpmri , ( 2 ) novel multimodal llm handle multiple interrelated 3d modality , and ( 3 ) strong empirical result demonstrate medical utility methodology . ablation highlight importance modality-level and token-level expert and prompt-conditioned routing .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.25866,deepsketcher : internalize visual manipulation multimodal reasoning,"Chi Zhang, Haibo Qiu, Qiming Zhang, Zhixiong Zeng, Lin Ma, Jing Zhang",""" thinking image "" paradigm represent pivotal shift reasoning vision language models ( vlms ) , move text-dominant chain-of-thought image-interactive reasoning . invoke visual tool or generate intermediate visual representation , vlm can iteratively attend fine-grained region , enable deep image understanding and more faithful multimodal reasoning . emerge paradigm , however , still leave substantial room exploration datum construction accuracy , structural design , and broad application scenario , offer rich opportunity advance multimodal reasoning . to far advance line work , present deepsketcher , comprehensive suite comprise image–text interleave dataset and self-contained model . dataset contain 31k chain-of-thought ( cot ) reasoning trajectory diverse tool call and result edit image , cover wide range datum type and manipulation instruction high annotation accuracy . build resource , design model perform interleave reasoning and natively generate "" visual thought "" operate directly visual embed space , rather invoke external tool and repeatedly re-encode generate image . design enable tool-free and more flexible "" think image "" . extensive experiment multimodal reasoning benchmark demonstrate strong performance , validate both utility dataset and effectiveness model design .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.25863,maple : multi-scale attribute-enhance prompt learning few-shot whole slide image classification,"Junjie Zhou, Wei Shao, Yagao Yue, Wei Mu, Peng Wan, Qi Zhu, Daoqiang Zhang","prompt learning have emerge promising paradigm adapt pre-trained vision-language model ( vlms ) to few-shot whole slide image ( wsi ) classification align visual feature textual representation , thereby reduce annotation cost and enhance model generalization . nevertheless , existing method typically rely slide-level prompt and fail to capture subtype-specific phenotypic variation histological entity ( e.g. , nucleus , gland ) be critical cancer diagnosis . to address gap , propose multi-scale attribute-enhance prompt learning ( maple ) , hierarchical framework few-shot wsi classification jointly integrate multi-scale visual semantic and perform prediction both entity and slide level . specifically , first leverage large language model ( llms ) to generate entity-level prompt can help identify multi-scale histological entity and phenotypic attribute , as well slide-level prompt to capture global visual description . then , entity-guided cross-attention module be propose to generate entity-level feature , follow align correspond subtype-specific attribute fine-grained entity-level prediction . to enrich entity representation , far develop cross-scale entity graph learn module can update representation capture semantic correlation and scale . refined representation be then aggregate slide-level representation and align corresponding prompt slide-level prediction . finally , combine entity-level and slide-level output to produce final prediction result . result three cancer cohort confirm effectiveness approach address few-shot pathology diagnosis task . code will be available https://github.com/jj-zhou-code/maple .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.25856,patchead : unify industrial visual prompting frameworks patch-exclusive anomaly detection,"Po-Han Huang, Jeng-Lin Li, Po-Hsuan Huang, Ming-Ching Chang, Wei-Chao Chen","industrial anomaly detection be increasingly rely foundation model , aim strong out-of-distribution generalization and rapid adaptation real-world deployment . notably , study have primarily focus textual prompt tuning , leave intrinsic visual counterpart fragment processing step specific foundation model . aim to address limitation propose unified patch-focused framework , patch-exclusive anomaly detection ( patchead ) , enable training-free anomaly detection be compatible diverse foundation model . framework construct visual prompt technique , include alignment module and foreground masking . experiment show superior few-shot and batch zero-shot performance compare prior work , absence textual feature . study far examine backbone structure and pretraine characteristic affect patch-similarity robustness , provide actionable guidance select and configure foundation model real-world visual inspection . result confirm well-unified patch-only framework can enable quick , calibration-light deployment need carefully engineer textual prompt .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.25851,muslr : multimodal symbolic logical reasoning,"Jundong Xu, Hao Fei, Yuhui Zhang, Liangming Pan, Qijun Huang, Qian Liu, Preslav Nakov, Min-Yen Kan, William Yang Wang, Mong-Li Lee, Wynne Hsu","multimodal symbolic logical reasoning , aim to deduce new fact multimodal input formal logic , be critical high-stakes application such autonomous driving and medical diagnosis , rigorous , deterministic reasoning help prevent serious consequence . to evaluate such capability current state-of-the-art vision language model ( vlms ) , introduce first benchmark muslr multimodal symbolic logical reasoning ground formal logical rule . muslr comprise 1 , 093 instance 7 domain , include 35 atomic symbolic logic and 976 logical combination , reasoning depth range 2 9 . evaluate 7 state-of-the-art vlm muslr and find struggle multimodal symbolic reasoning , good model , gpt-4 . 1 , achieve only 46 . 8 % . thus , propose logicam , modular framework apply formal logical rule to multimodal input , boost gpt-4 . 1 ’s chain-of-thought performance 14 . 13 % , and deliver even large gain complex logic such first-order logic . also conduct comprehensive error analysis , show 70 % failure stem logical misalignment modality , offer key insight to guide future improvement . datum and code be publicly available https://llm-symbol.github.io/muslr .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.25818,vela : llm-hybrid-as-a-judge approach evaluating long image caption,"Kazuki Matsuda, Yuiga Wada, Shinnosuke Hirano, Seitaro Otsuki, Komei Sugiura","study , focus automatic evaluation long and detailed image caption generate multimodal large language models ( mllms ) . most exist automatic evaluation metric image captioning be primarily design short caption and be not suitable evaluate long caption . moreover , recent llm-as-a-judge approach suffer slow inference reliance autoregressive inference and early fusion visual information . to address limitation , propose vela , automatic evaluation metric long caption develop novel llm-hybrid-as-a-judge framework . furthermore , propose longcap-arena , benchmark specifically design evaluate metric long caption . benchmark comprise 7 , 805 image , corresponding human-provided long reference caption and long candidate caption , and 32 , 246 human judgment three distinct perspective : descriptiveness , relevance , and fluency . demonstrate vela outperform exist metric and achieve superhuman performance longcap-arena . code and dataset be available https://vela.kinsta.page/.",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.25811,logo-vgr : visual grounded reasoning open-world logo recognition,"Zichen Liang, Jingjing Fei, Jie Wang, Zheming Yang, Changqing Li, Pei Wu, Minghui Qiu, Fei Yang, Xialei Liu","recent advance multimodal large language model ( mllm ) have be primarily evaluate general-purpose benchmark , application domain-specific scenario , such intelligent product moderation , remain underexplored . to address gap , introduce open-world logo recognition benchmark , core challenge product moderation . traditional logo recognition method rely memorize representation ten thousand brands—an impractical approach real-world propose method , logo-vgr , enable generalization large-scale brand recognition supervision only small subset brand . specifically , reformulate logo recognition comparison-based task , require model to match product image candidate logo rather directly generate brand label . far observe exist model tend to overfit memorize brand distribution instead learn robust multimodal reasoning , result poor performance unseen brand . to overcome limitation , logo-vgr introduce new paradigm domain-specific multimodal reasoning : logo perception grounding inject domain knowledge , and logo-guide visual ground reasoning enhance model ’s reasoning capability . experimental result show logo-vgr outperform strong baseline nearly 10 point ood setting , demonstrate superior generalization .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.25805,adapt sam dynamic similarity graphs few-shot parameter-efficient small dense object detection : case study chickpea pods field conditions,"Xintong Jiang, Yixue Liu, Mohamed Debbagh, Yu Tian, Valerio Hoyos-Villegas, Viacheslav Adamchuk, Shangpeng Sun","parameter-efficient fine-tuning ( peft ) foundation model agricultural computer vision task remain challenge limited training datum and complex field condition . study introduce dynamic similarity-based graph adaptation ( dsga ) module to adapt segment anything model ( sam ) extreme datum constraint precise foreground and instance segmentation small dense object complex agricultural environment . dynamic similarity graph construction learnable polynomial decay-initialized weight ranking mechanism and adaptive local feature aggregation , dsga establish robust spatial and dynamic similarity representation only 4 . 00 m trainable parameter , be 4 . 26 % original sam . integrate graph-based feature adaptation low-rank adaptation ( lora ) create complementary optimization framework effectively capture local and global dependency image embedding preserve model stability and parameter efficiency . experimental result challenging chickpea pod dataset demonstrate dsga lora achieve superior performance multiple metric evaluate 2 , 4 , 8 and 10 shot , progressive performance gain shot count increase . quantitative metric show 17 . 31 % improvement structure-measure and 62 . 36 % gain adaptive f-measure compare baseline sam fine-tuning . comprehensive ablation study and visualization analysis grad-cam and t-sne validate framework ’s effectiveness feature discrimination . propose adaptation demonstrate practical utility automate agricultural monitoring application , achieve accurate pod-counting adjusted r2\text{r}^{2 } 0 . 8987 image 10 to 120 pod challenge field condition .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.25794,point-it-out : benchmarke embody reasoning vision language models multi-stage visual grounding,"Haotian Xue, Yunhao Ge, Yu Zeng, Zhaoshuo Li, Ming-Yu Liu, Yongxin Chen, Jiaojiao Fan","vision-language models ( vlms ) have demonstrate impressive world knowledge wide range task , make promise candidate embodied reasoning application . however , exist benchmark primarily evaluate embody reasoning ability vlm multiple-choice question base image annotation – example , select trajectory well describe event image . work , introduce point-it-out ( pio ) benchmark , novel benchmark design to systematically assess embody reasoning ability vlms precise visual grounding . propose hierarchical evaluation protocol span three stage ( s1 : referred-object localization , s2 : task-driven pointing , and s3 : visual trace prediction ) , datum collect critical domain embodied intelligence , include indoor , kitchen , driving , and robotic manipulation scenario . extensive experiment ten state-of-the-art vlm reveal several interesting finding . example , strong general-purpose model such gpt-4o , excel many benchmark ( e.g. , language , perception , and reasoning ) , underperform compare open-source model precise visual grounding ; model such molmo perform well s1 and s2 but struggle s3 , requires ground combine visual trace planning .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.25791,: electrocardiogram cross-modal model echocardiogram tasks,"Yuan Gao, Sangwook Kim, Chris McIntosh","electrocardiogram ( ecg ) be widely use tool assess cardiac function low cost and accessibility . emergent research show ecg can help make prediction key outcome traditionally derive more complex modality such echocardiogram ( echo ) , enable use ecg more accessible method to predict broad measurement cardiac function . echo , particular , be great importance require considerable hospital resource play key role clinical cardiac assessment . to aid use case , introduce echoingecg , probabilistic student-teacher model leverage uncertainty-aware ecg embedding and echo supervision to improve ecg-base cardiac function prediction . approach integrate probabilistic cross-modal embedding ( pcme++ ) , probabilistic contrastive framework , echo-clip , vision-language pre-trained model train echo-text pair , to distill echo knowledge ecg representation . experiment and external validation , show echoingecg outperform state-of-the-art foundation ecg model zero-shot , few-shot , and fine-tune setting echo prediction base ecg . also highlight variance estimation ( enable method ) enhance understanding model performance identify underlying region uncertainty ecg . code be available : https://github.com/mcintoshml/echoingecg .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.25776,editable noise map inversion : encode target-image noise high-fidelity image manipulation,"Mingyu Kang, Yong Suk Choi","text-to-image diffusion model have achieve remarkable success generate high-quality and diverse image . build advancement , diffusion model have also demonstrate exceptional performance text-guided image editing . key strategy effective image editing involve invert source image editable noise map associate target image . however , previous inversion method face challenge adhere closely target text prompt . limitation arise invert noise map , enable faithful reconstruction source image , restrict flexibility need desire edit . to overcome issue , propose editable noise map inversion ( enm inversion ) , novel inversion technique search optimal noise map to ensure content preservation and editability . analyze property noise map enhanced editability . base analysis , method introduce editable noise refinement align desire edit minimize difference reconstructed and edit noise map . extensive experiment demonstrate enm inversion outperform exist approach wide range image editing task preservation and edit fidelity target prompt . approach can also be easily apply video editing , enable temporal consistency and content manipulation frame .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.25774,pcpo : proportionate credit policy optimization aligning image generation model,"Jeongjae Lee, Jong Chul Ye","reinforcement learning have advance alignment text-to-image ( t2i ) model , state-of-the-art policy gradient method be still hamper training instability and high variance , hinder convergence speed and compromise image quality . analysis identify key cause instability : disproportionate credit assignment , mathematical structure generative sampler produce volatile and non-proportional feedback timestep . to address , introduce proportionate credit policy optimization ( pcpo ) , framework enforce proportional credit assignment stable objective reformulation and principled reweighting timestep . correction stabilize training process , lead significantly accelerate convergence and superior image quality . improvement quality be direct result mitigate model collapse , common failure mode recursive training . pcpo substantially outperform exist policy gradient baseline front , include state-of-the-art dancegrpo .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.25773,v-hub : visual-centric humor understanding benchmark video llms,"Zhengpeng Shi, Hengli Li, Yanpeng Zhao, Jianqun Zhou, Yuxuan Wang, Qinrong Cui, Wei Bi, Songchun Zhu, Bo Zhao, Zilong Zheng","ai model capable comprehend humor hold real-world example , enhance engagement human-machine interaction . to gauge and diagnose capacity multimodal large language model ( mllm ) humor understanding , introduce v-hub , novel visual-centric video humor understand benchmark . v-hub comprise curate collection minimally verbal short video , source classic silent film and online resource , and reflect real-world scenario humor can be appreciate purely visual cue . video clip be pair rich annotation , include caption , description , and explanation , support evaluation task caption matching and humor explanation . to broaden applicability , far construct open-ended video qa task , make readily integrable exist video understanding benchmark . evaluate diverse set mllm , specialized video-llms versatile omnillms can process audio , cover open-source and proprietary domain . experimental result expose difficulty mllm face comprehend humor visual cue alone . example , model exhibit marked performance drop caption matching move text-based video-based evaluation ( audio ) . finding also demonstrate incorporate audio help video humor understanding , highlight informativeness sound and promise integrate rich modality complex video understanding task .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.25771,free lunch alignment text-to-image diffusion models preference image pairs,"Jia Jun Cheng Xian, Muchen Li, Haotian Yang, Xin Tao, Pengfei Wan, Leonid Sigal, Renjie Liao","recent advance diffusion-based text-to-image ( t2i ) model have lead remarkable success generate high-quality image textual prompt . however , ensure accurate alignment text and generate image remain significant challenge state-of-the-art diffusion model . to address , exist study often employ reinforcement learning human feedback ( rlhf ) to align t2i output human preference . method , however , either rely directly pair image preference datum or require learn reward function , depend heavily costly , high-quality human annotation and thus face scalability limitation . work , introduce text preference optimization ( tpo ) , novel framework enable "" free-lunc "" alignment t2i model , achieve alignment need pair image preference datum . tpo work train model to prefer match prompt mismatch prompt , be construct perturb original caption use large language model ( llm ) . framework be general and compatible exist preference-based algorithm . extend both dpo and kto setting , result tdpo and tkto . quantitative and qualitative evaluation multiple benchmark show method consistently outperform original counterpart , yield superior human preference score and well text-to-image alignment . open-source code be available https://github.com/dsl-lab/t2i-free-lunch-alignment .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.25749,art-viton : measurement-guided latent diffusion artifact-free virtual try-on,"Junseo Park, Hyeryung Jang","virtual try-on ( viton ) aim to generate realistic image person wear target garment , require precise garment alignment try-on region and faithful preservation identity and background non-try-on region . latent diffusion model ( ldm ) have advance alignment and detail synthesis , preserve non-try-on region remain challenge . common post-hoc strategy directly replace region original content , but abrupt transition often produce boundary artifact . to overcome , reformulate viton linear inverse problem and adopt trajectory-aligned solver progressively enforce measurement consistency , reduce abrupt change non-try-on region . however , exist solver still suffer semantic drift generation , lead artifact . propose art-viton , measurement-guided diffusion framework ensure measurement adherence maintain artifact-free synthesis . method integrate residual prior-based initialization to mitigate training-inference mismatch and artifact-free measurement-guided sampling combine datum consistency , frequency-level correction , and periodic standard denoising . experiment viton-hd , dresscode , and shhq-1 . 0 demonstrate art-viton effectively preserve identity and background , eliminate boundary artifact , and consistently improve visual fidelity and robustness state-of-the-art baseline .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.25748,dolphin v1 . 0 technical report,"Taohan Weng, Chi zhang, Chaoran Yan, Siya Liu, Xiaoyang Liu, Yalun Wu, Boyang Wang, Boyan Wang, Jiren Ren, Kaiwen Yan, Jinze Yu, Kaibing Hu, Henan Liu, Haoyun zheng, Anjie Le, Hongcheng Guo","ultrasound be vital modern medicine but face challenge operator dependence , image noise , and dynamic real-time scanning , hinder effective ai integration . large multimodal model excel other medical imaging area , struggle ultrasound ’s unique complexity . to bridge gap , introduce dolphin v1 . 0 ( v1 ) and reasoning-augmented version , dolphin r1—the first large-scale multimodal ultrasound foundation model design to unify diverse clinical task single vision-language framework . to tackle variability , noise , and operator dependence inherent ultrasound imaging , curate groundbreaking multimodal dataset 2-million-scale , integrate textbook knowledge , public ultrasound datum , synthetic knowledge-distilled sample , and general multimodal corpora . comprehensive dataset ensure model achieve robust perception , strong generalization , and broad clinical adaptability medical domain .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.25745,fincap : topic-aligne caption short-form financial youtube video,"Siddhant Sukhani, Yash Bhardwaj, Riya Bhadani, Veer Kejriwal, Michael Galarnyk, Sudheer Chava","evaluate multimodal large language model ( mllm ) topic-aligned captioning financial short-form video ( svs ) test joint reasoning transcript ( t ) , audio ( a ) , and video ( v ) . use 624 annotate youtube svs , assess seven modality combination ( t , a , v , ta , tv , av , tav ) five topic : main recommendation , sentiment analysis , video purpose , visual analysis , and financial entity recognition . video alone perform strongly four five topic , underscore value capture visual context and effective cue such emotion , gesture , and body language . selective pair such tv or av often surpass tav , imply too many modality may introduce noise . result establish first baseline financial short-form video captioning and illustrate potential and challenge ground complex visual cue domain . code and datum can be find github111https://github.com/gtfintechlab/fincap cc-by-nc-sa 4 . 0 license .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.25744,ipdrecon : image-plane geometric decoding view-invariant indoor scene reconstruction,"Mingyang Li, Yimeng Fan, Changsong Liu, Tianyu Zhou, Xin Wang, Yanyan Liu, Wei Zhang","volume-based indoor scene reconstruction method demonstrate significant research value superior generalization capability and real-time deployment potential . however , exist method rely multi-view pixel back-projection ray intersection weak geometric constraint to determine spatial position , cause reconstruction quality to depend heavily input view density poor performance overlap region and unobserved area . to address issue , key lie reduce dependency inter-view geometric constraint exploit rich spatial information individual view . propose ipdrecon , image-plane decode framework comprise three core component : pixel-level confidence encoder ( pce ) , affine compensation module ( acm ) , and image-plane spatial decoder ( ipsd ) . module collaboratively decode 3d structural information encode 2d image physical imaging process , effectively preserve spatial geometric feature include edge , hollow structure , and complex texture significantly enhance view-invariant reconstruction . experiment scannetv2 confirm ipdrecon achieve superior reconstruction stability , maintain nearly identical quality view count reduce 40 % . method achieve coefficient variation only 0 . 24 % , performance retention rate 99 . 7 % , and maximum performance drop merely 0 . 42 % . demonstrate exploit intra-view spatial information provide robust solution view-limited scenario practical application .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.25740,drag geometry : pixels geometry-guided image editing,"Xinyu Pu, Hongsong Wang, Jie Gui, Pan Zhou","interactive point-based image editing serve controllable editor , enable precise and flexible manipulation image content . however , most drag-based method operate primarily 2d pixel plane limited use 3d cue . result , often produce imprecise and inconsistent edit , particularly geometry-intensive scenario such rotation and perspective transformation . to address limitation , propose novel geometry-guided drag-based image editing method—geodrag , address three key challenge : 1 ) incorporate 3d geometric cue pixel-level editing , 2 ) mitigate discontinuity cause geometry-only guidance , and 3 ) resolve conflict arise multi-point dragging . build unified displacement field jointly encode 3d geometry and 2d spatial prior , geodrag enable coherent , high-fidelity , and structure-consistent editing single forward pass . addition , conflict-free partition strategy be introduce to isolate editing region , effectively prevent interference and ensure consistency . extensive experiment various editing scenario validate effectiveness method , show superior precision , structural consistency , and reliable multi-point editability . code will be available https://github.com/xinyu-pu/geodrag .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.25739,liehmr : autoregressive human mesh recovery $ so(3)$ diffusion,"Donghwan Kim, Tae-Kyun Kim","tackle problem human mesh recovery ( hmr ) single rgb image , formulate image-conditioned human pose and shape generation . recover 3d human pose 2d observation be inherently ambiguous , most exist approach have regress single deterministic output . probabilistic method attempt to address generate multiple plausible output to model ambiguity . however , method often exhibit trade-off accuracy and sample diversity , and single prediction be not competitive state-of-the-art deterministic model . to overcome limitation , propose novel approach model well-aligned distribution 2d observation . particular , introduce s​o​(3)so(3 ) diffusion model , generate distribution pose parameter represent 3d rotation unconditional and conditional to image observation condition dropout . model learn hierarchical structure human body joint use transformer . instead use transformer denoising model , time-independent transformer extract latent vector joint and small mlp-based denoising model learn per-joint distribution condition latent vector . experimentally demonstrate and analyze model predict accurate pose probability distribution effectively .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.25738,1st solution mosev1 challenge lsvos 2025 : cgfseg,"Tingmin Li, Yixuan Li, Yang Yang","video object segmentation ( vos ) aim to track and segment specific object entire video sequence , yet remain highly challenging complex real-world scenario . mosev1 and lvos dataset , adopt mosev1 challenge lsvos 2025 , be specifically design to enhance robustness vos model complex real-world scenario , include long-term object disappearance and reappearance , as well presence small and inconspicuous object . paper , present improved method , confidence-guide fusion segmentation ( cgfseg ) , vos task mosev1 challenge . training , feature extractor sam2 be frozen , remain component be fine-tuned to preserve strong feature extraction ability and improve segmentation accuracy . inference stage , introduce pixel-check strategy progressively refine prediction exploit complementary strength multiple model , thereby yield robust final mask . result , method achieve j&f score 86 . 37 % test set , rank 1st mosev1 challenge lsvos 2025 . result highlight effectiveness approach address challenge vos task complex scenario .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.25731,lato : landmark-tokenize diffusion transformer fine-grained human face editing,"Zhenghao Zhang, Ziying Zhang, Junchao Liao, Xiangyu Meng, Qiang Hu, Siyu Zhu, Xiaoyun Zhang, Long Qin, Weizhi Wang","recent multimodal model instruction-based face edit enable semantic manipulation but still struggle precise attribute control and identity preservation . structural facial representation such landmark be effective intermediate supervision , yet most exist method treat rigid geometric constraint , can degrade identity conditional landmark deviate significantly source ( e.g. , large expression or pose change , inaccurate landmark estimate ) . to address limitation , propose lato , landmark-tokenized diffusion transformer fine-grained , identity-preserving face edit . key innovation include : ( 1 ) landmark tokenizer directly quantize raw landmark coordinate discrete facial token , obviate need dense pixel-wise correspondence ; ( 2 ) location-mappe positional encoding integrate facial and image token unified processing , enable flexible yet decouple geometry-appearance interaction high efficiency and strong identity preservation ; and ( 3 ) landmark predictor leverage vision–language model to infer target landmark instruction and source image , structured chain-of-thought improve estimation accuracy and interactive control . to mitigate datum scarcity , curate hfl-150 k , knowledge large benchmark task , contain 150 k real face pair fine-grained instruction . extensive experiment show lato outperform state-of-the-art method 7 . 8 % identity preservation and 4 . 6 % semantic consistency . code and dataset will be make publicly available acceptance .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.25723,sage : spatial-visual adaptive graph exploration visual place recognition,"Shunpeng Chen, Changwei Wang, Rongtao Xu, Xingtian Pei, Yukun Song, Jinzhou Lin, Wenhao Xu, Jingyi Zhang, Li Guo, Shibiao Xu","visual place recognition ( vpr ) require robust retrieval geotagge image large appearance , viewpoint , and environmental variation . prior method focus descriptor fine-tuning or fix sampling strategy yet neglect dynamic interplay spatial context and visual similarity training . present sage ( spatial-visual adaptive graph exploration ) , unified training pipeline enhance granular spatial–visual discrimination jointly improve local feature aggregation , organize sample training , and hard sample mining . introduce lightweight soft probing module learn residual weight training datum patch descriptor bilinear aggregation , boost distinctive local cue . training reconstruct online geo–visual graph fuse geographic proximity and current visual similarity candidate neighborhood reflect evolving embed landscape . to concentrate learn most informative place neighborhood , seed cluster high-affinity anchor and iteratively expand greedy weighted clique expansion sampler . implement frozen dinov2 backbone and parameter-efficient fine-tuning , sage achieve sota eight benchmark . attain 98 . 9 % , 95 . 8 % , 94 . 5 % , and 96 . 0 % recall@1 sped , pitts30k-test , msls-val , and nordland , respectively . notably , method obtain 100 % recall@10 sped only use 4096d global descriptor . code and model will be available : https://github.com/chenshunpeng/sage .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.25717,importance sampling multi-negative multimodal direct preference optimization,"Xintong Li, Chuhan Wang, Junda Wu, Rohan Surana, Tong Yu, Julian McAuley, Jingbo Shang","direct preference optimization ( dpo ) have recently be extend text-only model vision-language model . however , exist method rely oversimplified pairwise comparison , generate single negative image basic perturbation or similarity-based retrieval , fail to capture complex nature multimodal preference , induce optimization bias and hallucination . to address issue , propose misp-dpo , first framework to incorporate multiple , semantically diverse negative image multimodal dpo plackett-luce model . method embed prompt and candidate image clip ( contrastive language–image pre-traine ) space and apply sparse autoencoder to uncover semantic deviation interpretable factor . negative sample be select base reconstruction difficulty , semantic deviation positive , and mutual diversity , yield broad and more informative supervision . to handle multi-negative comparison , adopt plackett–luce objective and introduce importance sampling strategy improve training efficiency . experiment five diverse benchmark demonstrate misp-dpo consistently improve multimodal alignment prior method , validate effectiveness semantic-aware , multi-negative sampling preference-based learning .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.25711,probmed : probabilistic framework medical multimodal binding,"Yuan Gao, Sangwook Kim, Jianzhong You, Chris McIntosh","medical decision-making require integrate diverse medical information , image clinical narrative . medical modality be often acquire many-to-many manner . however , current medical vision-language pretraining model ( med-vlpms ) fail to directly account many-to-many mapping model training and embedding . to address , present probabilistic modality-enhanced diagnosis ( probmed ) , multimodal med-vlpm employ probabilistic contrastive learning to model distribution embedding rather deterministic estimate . probmed align four distinct modalities—ch x-rays , electrocardiogram , echocardiogram , and clinical unified probabilistic embed space . use infonce loss hellinger distance to integrate inter-modality distribution . introduce probabilistic synthetic sampling loss capture modality-specific mean and variance to improve intra-modality binding . extensive experiment 13 medical dataset demonstrate model outperform current med-vlpms cross-modality retrieval , zero-shot , and few-shot classification . also demonstrate robust integration multiple modality prognostication , show improve intra- and inter-medical modality binding . code be available : https://github.com/mcintoshml/probmed .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.25705,diffusion models memorize,"Juyeop Kim, Songkuk Kim, Jong-Seok Lee","success image generation , diffusion model can memorize training datum , raise serious privacy and copyright concern . prior work have seek to characterize , detect , and mitigate memorization , fundamental question and occur remain unresolved . paper , revisit diffusion and denoising process and analyze latent space dynamic to address question : "" do diffusion model memorize ? "" show memorization be drive overestimation training sample early denoising , reduce diversity , collapse denoise trajectory , and accelerate convergence memorized image . specifically : ( i ) memorization can not be explain overfitte alone , training loss be large memorization classifier-free guidance amplifying prediction and induce overestimation ; ( ii ) memorized prompt inject training image noise prediction , force latent trajectory to converge and steer denoise paired sample ; and ( iii ) decomposition intermediate latent reveal initial randomness be quickly suppress and replace memorized content , deviation theoretical denoising schedule correlate almost perfectly memorization severity . together , result identify early overestimation central underlying mechanism memorization diffusion model .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.25699,aimcot : active information-driven multimodal chain-of-thought vision-language reasoning,"Xiping Li, Jianghong Ma","multimodal chain-of-thought ( cot ) have emerge powerful technique enhance vision-language reasoning interleaved information . however , exist method often rely simplistic heuristic construct interleaved cot , typically depend attention map , empirical analysis reveal can be unreliable . ’s more , shortcoming passive and purposeless selection strategy and arbitrary trigger mechanism capture model ’s cognitive need information be far amplify . paper , propose aimcot , active information-driven multi-modal chain-of-thought framework address fundamental limitation . aimcot introduce three synergistic component : ( 1 ) context-enhance attention-map generation ( cag ) , mitigate text-vision granularity imbalance , thereby produce more reliable attention map foundation . ( 2 ) active visual probing ( avp ) , replace passive selection proactive , goal-oriented strategy ground information theory to select image region help answer question maximally . ( 3 ) dynamic attention-shifting trigger ( dat ) , intelligently determine optimal moment to insert visual information monitor model ’s text-to-vision attention shift . extensive experiment three challenging benchmark demonstrate aimcot significantly outperform state-of-the-art method different setting . actively forage information and dynamically structure reasoning process , aimcot represent critical step more robust , effective , and human-like multimodal reasoning . code be available https://anonymous.4open.science/r/aimcot.",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.25682,omnidfa : unified framework open set synthesis image detection and few-shot attribution,"Shiyu Wu, Shuyan Li, Jing Li, Jing Liu, Yequan Wang","ai-generate image ( aigi ) detection and source model attribution remain central challenge combat deepfake abuse , primarily structural diversity generative model . current detection method be prone overfitte specific forgery trait , source attribution offer robust alternative fine-grained feature discrimination . however , synthetic image attribution remains constrain scarcity large-scale , well-categorized synthetic dataset , limit practicality and compatibility detection system . work , propose new paradigm image attribution call open-set , few-shot source identification . paradigm be design to reliably identify unseen generator use only limited sample , make highly suitable real-world application . end , introduce omnidfa ( omni detector and few-shot attributor ) , novel framework aigi not only assess authenticity image , but also determine synthesis origin few-shot manner . to facilitate work , construct omnifake , large class-aware synthetic image dataset curate 1 . 171 . 17 m image 4545 distinct generative model , substantially enrich foundational resource research aigi detection and attribution . experiment demonstrate omnidfa exhibit excellent capability open-set attribution and achieve state-of-the-art generalization performance aigi detection . dataset and code will be make available .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.25659,yolo-base defect detection metal sheets,"Po-Heng Chou, Chun-Chi Wang, Wei-Lung Mao","paper , propose yolo-based deep learning ( dl ) model automatic defect detection to solve time-consuming and labor-intensive task industrial manufacturing . experiment , image metal sheet be use dataset train yolo model to detect defect surface and hole metal sheet . however , lack metal sheet image significantly degrade performance detection accuracy . to address issue , consingan be use to generate considerable amount datum . four version yolo model ( i.e. , yolov3 , v4 , v7 , and v9 ) be combine consingan datum augmentation . propose yolov9 model consingan outperform other yolo model accuracy 91 . 3 % , and detection time 146 ms . propose yolov9 model be integrate manufacture hardware and supervisory control and datum acquisition ( scada ) system to establish practical automate optical inspection ( aoi ) system . additionally , propose automate defect detection be easily apply other component industrial manufacturing .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.25654,describeearth : describe remote sensing images,"Kaiyu Li, Zixuan Jiang, Xiangyong Cao, Jiayu Wang, Yuchen Xiao, Deyu Meng, Zhi Wang","automated textual description remote sense image be crucial unlock full potential diverse application , environmental monitoring urban planning and disaster management . however , exist study remote sense image captioning primarily focus image level , lack object-level fine-grained interpretation , prevent full utilization and transformation rich semantic and structural information contain remote sense image . to address limitation , propose geo-dlc , novel task object-level fine-grained image captioning remote sensing . to support task , construct de-dataset , large-scale dataset contain 25 category and 261 , 806 annotated instance detailed description object attribute , relationship , and contexts . furthermore , introduce de-benchmark , llm-assiste question-answere base evaluation suite design to systematically measure model capability geo-dlc task . also present describeearth , multi-modal large language model ( mllm ) architecture explicitly design geo-dlc , integrate scale-adaptive focal strategy and domain-guided fusion module leverage remote sense vision-language model feature encode high-resolution detail and remote sense category prior maintain global context . describeearth model consistently outperform state-of-the-art general mllm de-benchmark , demonstrate superior factual accuracy , descriptive richness , and grammatical soundness , particularly capture intrinsic object feature and surround environmental attribute simple , complex , and even out-of-distribution remote sense scenario . datum , code and weight be release https://github.com/earth-insights/describeearth .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.25644,use image video game to improve detection truck axles,"Leandro Arab Marcomini, Andre Luiz Cunha","convolutional neural networks ( cnns ) traditionally require large amount datum to train model good performance . however , datum collection be expensive process , time and resource . generate synthetic image be good alternative , video game produce realistic 3d model . paper aim to determine image extract video game can be effectively use to train cnn to detect real-life truck axle . three different database be create , real-life and synthetic truck , to provide training and testing example three different only look once ( yolo ) architecture . result be evaluate base four metric : recall , precision , f1-score , and mean average precision ( map ) . to evaluate statistical significance result , mann-whitney u test be also apply result map model . synthetic image truck extract video game prove to be reliable source training datum , contribute performance network . high map score reach 99 % . result indicate synthetic image can be use to train neural network , provide reliable , low-cost datum source extract knowledge .",Computer Vision and Pattern Recognition,30/09/2025
10.48550/arXiv.2509.26598,be robust llm fingerprints adversarially robust ?,"Anshul Nasery, Edoardo Contente, Alkin Kaz, Pramod Viswanath, Sewoong Oh","model fingerprinting have emerge promising paradigm claim model ownership . however , robustness evaluation scheme have mostly focus benign perturbation such incremental fine-tuning , model merging , and prompt . lack systematic investigation adversarial robustness malicious model host leave current system vulnerable . to bridge gap , first define concrete , practical threat model model fingerprinting . then take critical look exist model fingerprinting scheme to identify fundamental vulnerability . base , develop adaptive adversarial attack tailor vulnerability , and demonstrate can bypass model authentication completely ten recently propose fingerprinting scheme maintain high utility model end user . work encourage fingerprint designer to adopt adversarial robustness design . end recommendation future fingerprinting method .",Cryptography and Security,30/09/2025
10.48550/arXiv.2509.26562,deepprov : behavioral characterization and repair neural networks inference provenance graph analysis,"Firas Ben Hmida, Abderrahmen Amich, Ata Kaboudi, Birhanu Eshete","deep neural network ( dnn ) be increasingly be deploy high-stakes application , self-driving car biometric authentication . however , unpredictable and unreliable behavior real-world setting require new approach to characterize and ensure reliability . paper introduce deepprov , novel and customizable system design to capture and characterize runtime behavior dnn inference use underlie graph structure . inspire system audit provenance graph , deepprov model computational information flow dnn ’s inference process inference provenance graphs ( ipgs ) . graph provide detailed structural representation behavior dnn , allow both empirical and structural analysis . deepprov use insight to systematically repair dnn specific objective , such improve robustness , privacy , or fairness . instantiate deepprov adversarial robustness goal model repair and conduct extensive case study to evaluate effectiveness . result demonstrate effectiveness and scalability diverse classification task , attack scenario , and model complexity . deepprov automatically identify repair action node and edge-level ipg , significantly enhance robustness model . particular , apply deepprov repair strategy just single layer dnn yield average 55 % improvement adversarial accuracy . moreover , deepprov complement exist defense , achieve substantial gain adversarial robustness . robustness , demonstrate broad potential deepprov adaptable system to characterize dnn behavior other critical area , such privacy auditing and fairness analysis .",Cryptography and Security,30/09/2025
10.48550/arXiv.2509.26530,explainable and resilient ml-based physical-layer attack detector,"Aleksandra Knapińska, Marija Furdek","detection emerge attack network infrastructure be critical aspect security management . to meet grow scale and complexity modern threat , machine learning ( ml ) technique offer valuable tool automate detection malicious activity . however , technique become more complex , internal operation grow increasingly opaque . context , address need explainable physical-layer attack detection method . first , analyze inner working various classifier train to alert physical layer intrusion , examine influence different monitor parameter vary depend type attack be detect . analysis not only improve interpretability model but also suggest way to enhance design increase speed . second part , evaluate detector ' resilience malicious parameter noising . result highlight key trade-off model speed and resilience . work serve design guideline develop fast and robust detector train available network monitor datum .",Cryptography and Security,30/09/2025
10.48550/arXiv.2509.26509,logic solver guided directed fuzzing hardware designs,"Raghul Saravanan, Sai Manoj P D","ever-increasing complexity design specification processor and intellectual property ( ip ) present formidable challenge early bug detection modern ic design cycle . recent advancement hardware fuzzing have prove effective detect bug rtl design cutting-edge processor . modern ic design flow involve incremental update and modification hardware design necessitate rigorous verification and extend overall verification period . to accelerate process , direct fuzzing have emerge focus generate target stimulus specific region design , avoid need exhaustive , full-scale verification .",Cryptography and Security,30/09/2025
10.48550/arXiv.2509.26404,seedprint : fingerprint can even tell seed large language model be train,"Yao Tong, Haonan Wang, Siquan Li, Kenji Kawaguchi, Tianyang Hu","fingerprint large language models ( llms ) be essential provenance verification and model attribution . exist method typically extract post-hoc signature base training dynamic , datum exposure , or hyperparameters—propertie only emerge training begin . contrast , propose strong and more intrinsic notion llm fingerprinting : seedprints , method leverage random initialization bias persistent , seed-dependent identifier present even training . show untrained model exhibit reproducible token selection bias condition solely parameter initialization . bias be stable and measurable training , enable statistical detection method to recover model ’s lineage high confidence . prior technique , unreliable convergence and vulnerable distribution shift , seedprints remain effective training stage and robust domain shift or parameter modification . experiment llama-style and qwen-style model show seedprints achieve seed-level distinguishability and can provide birth-to-lifecycle identity verification akin biometric fingerprint . evaluation large-scale pretraine model and fingerprinting benchmark far confirm effectiveness practical deployment scenario . result suggest initialization imprint unique and persistent identity neural language model , form true "" galtonian "" fingerprint .",Cryptography and Security,30/09/2025
10.48550/arXiv.2509.26393,exact bias linear trng correctors - spectral approach,"Maciej Skorski, Francisco-Javier Soto, Onur Günlü","use fourier analysis , paper establish exact security bound linear extractor true random number generators ( trngs ) . provide first near-optimal total variation security characterisation interpolate optimal ℓ∞\ell_{\infty } and ℓ2\ell_{2 } norm result , express code weight enumerator and input bias parameter . bound improve security assessment order magnitude previous approximation . scan 20 , 000 code , reveal fundamental trade-off compression efficiency and cryptographic security . instance , show achieve 8080 bit security can require sacrifice more 50 % code rate correct 10 % input bias . bound enhance security evaluation trng post-processing scheme and quantify inherent cost randomness extraction hardware implementation .",Cryptography and Security,30/09/2025
10.48550/arXiv.2509.25926,better privilege separation agents restricting data types,"Dennis Jacob, Emad Alghamdi, Zhanhao Hu, Basel Alomair, David Wagner","large language model ( llms ) have become increasingly popular ability to interact unstructured content . such , llm be now key driver automation language processing system , such ai agent . unfortunately , advantage have come vulnerability to prompt injection , attack adversary subvert llm ’s intend functionality inject task . past approach have propose detector and finetune to provide robustness , but technique be vulnerable adaptive attack or can not be use state-of-the-art model . end propose type-directed privilege separation llms , method systematically prevent prompt injection . restrict ability llm to interact third-party datum convert untrusted content curate set datum type ; raw string , data type be limited scope and content , eliminate possibility prompt injection . evaluate method several case study and find design leverage principle can systematically prevent prompt injection attack maintain high utility .",Cryptography and Security,30/09/2025
10.48550/arXiv.2509.25624,stac : innocent tools form dangerous chains jailbreak llm agent,"Jing-Jing Li, Jianfeng He, Chao Shang, Devang Kulshreshtha, Xun Xian, Yi Zhang, Hang Su, Sandesh Swamy, Yanjun Qi","llm advance autonomous agent tool-use capability , introduce security challenge extend traditional content-based llm safety concern . paper introduce sequential tool attack chaining ( stac ) , novel multi-turn attack framework exploit agent tool use . stac chain together tool call appear harmless isolation but , combine , collectively enable harmful operation only become apparent final execution step . apply framework to automatically generate and systematically evaluate 483 stac case , feature 1 , 352 set user-agent-environment interaction and span diverse domain , task , agent type , and 10 failure mode . evaluation show state-of-the-art llm agent , include gpt-4 . 1 , be highly vulnerable stac , attack success rate ( asr ) exceed 90 % most case . core design stac ’s automate framework be closed-loop pipeline synthesize executable multi-step tool chain , validate in-environment execution , and reverse-engineer stealthy multi-turn prompt reliably induce agent to execute verified malicious sequence . far perform defense analysis stac and find exist prompt-based defense provide limited protection . to address gap , propose new reasoning-driven defense prompt achieve far strong protection , cut asr to 28 . 8 % . result highlight crucial gap : defend tool-enabled agent require reasoning entire action sequence and cumulative effect , rather evaluate isolated prompt or response .",Cryptography and Security,30/09/2025
10.48550/arXiv.2509.25566,zero trust-base decentralized identity management system autonomous vehicles,"Amal Yousseef, Shalaka Satam, Banafsheh Saber Latibari, Mai Abdel-Malek, Soheil Salehi, Pratik Satam","rise autonomous vehicle ( av ) promise to significantly enhance transportation safety and efficiency mitigate human error , be responsible 90 % road accident . however , increase connectivity av introduce new cybersecurity challenge , traditional perimeter-based security model be inadequate dynamic and untrusted environment . paper present novel zero trust-base decentralized identity management ( d-im ) protocol av . integrate core principle zero trust architecture , "" never trust , always verify "" , tamper resistant and decentralized nature blockchain network , framework eliminate reliance centralized authority and provide continuous verification entity . detail system ’s design , leverage hyperledger iroha to enable lightweight and secure authentication central trust entity . comprehensive experimental evaluation , conduct both urban and highway scenario , validate protocol ’s practicality . result demonstrate d-im framework introduce minimal overhead , less 7 . 5 % reduction packet reception rate ( prr ) urban setting and increase 11 % channel busy ratio ( cbr ) lte-v2x . finding prove protocol ’s efficiency and robustness , provide resilient foundation secure real-time v2x communication impersonation and replay attack .",Cryptography and Security,29/09/2025
10.48550/arXiv.2509.25525,defeat cerberus : concept-guide privacy-leakage mitigation multimodal language model,"Boyang Zhang, Istemi Ekin Akkus, Ruichuan Chen, Alice Dethise, Klaus Satzke, Ivica Rimac, Yang Zhang","multimodal large language model ( mllm ) have demonstrate remarkable capability processing and reasoning diverse modality , but advanced ability also raise significant privacy concern , particularly regard personally identifiable information ( pii ) leakage . relevant research have be conduct single-modal language model extent , vulnerability multimodal setting have yet to be fully investigate . work , investigate emerge risk focus vision language model ( vlms ) , representative subclass mllms cover two modality most relevant pii leakage , vision and text . introduce concept-guided mitigation approach identify and modify model ’s internal state associate pii-relate content . method guide vlm to refuse pii-sensitive task effectively and efficiently , require re-traine or fine-tuning . also address current lack multimodal pii dataset construct various one simulate real-world scenario . experimental result demonstrate method can achieve average refusal rate 93 . 3 % various pii-related task minimal impact unrelated model performance . far examine mitigation ’s performance various condition to show adaptability propose method .",Cryptography and Security,29/09/2025
10.48550/arXiv.2509.25476,environmental rate manipulation attacks power grid security,"Yonatan Gizachew Achamyeleh, Yang Xiang, Yun-Ping Hsiao, Yasamin Moghaddas, Mohammad Abdullah Al Faruque","grow complexity global supply chain have make hardware trojans significant threat sensor-based power electronic . traditional trojan design depend digital trigger or fix threshold condition can be detect standard testing . contrast , introduce environmental rate manipulation ( erm ) , novel trojan trigger mechanism activate monitor rate change environmental parameter rather absolute value . approach allow trojan to remain inactive normal condition and evade redundancy and sensor-fusion defense . implement compact 14 μ\mum2 circuit measure capacitor charge rate standard sensor front-end and disrupt inverter pulse-width modulation pwm signal rapid change be induce . experiment commercial texas instruments solar inverter demonstrate erm can trigger catastrophic driver chip failure . furthermore , etap simulation indicate single compromise 100 kw inverter may initiate cascade grid instability . attack ’s significance extend individual sensor entire class environmental sensing system common power electronic , demonstrate fundamental challenge hardware security .",Cryptography and Security,29/09/2025
10.48550/arXiv.2509.25469,balance compliance and privacy offline cbdc transactions use secure element-based system,"Panagiotis Michalopoulos, Anthony Mack, Cameron Clark, Linus Chen, Johannes Sedlmeir, Andreas Veneris","blockchain technology have spawn vast ecosystem digital currency central bank digital currencies ( cbdcs ) – digital form fiat currency – be one . important feature digital currency be facilitate transaction network connectivity , can enhance scalability cryptocurrencie and privacy cbdc user . however , case cbdcs , characteristic also introduce new regulatory challenge , particularly come apply establish anti-money laundering and counter financing terrorism ( aml/cft ) framework . paper introduce prototype offline digital currency payment , equally applicable cryptocurrencie and cbdcs , leverage secure elements and digital credential to address tension offline payment support regulatory compliance . performance evaluation result suggest prototype can be flexibly adapt different regulatory environment , transaction latency comparable real-life commercial payment system . furthermore , conceptualize integration zero-knowledge proofs design could accommodate various tier enhance privacy protection .",Cryptography and Security,29/09/2025
10.48550/arXiv.2509.25462,manage differentiated secure connectivity use intent,"Loay Abdelrazek, Filippo Rebecchi","mobile network 5 g and 6 g era require to rethink to manage security introduction new service , use case , own security requirement , simultaneously expand threat landscape . automation have emerge key enabler to address complexity network , exist approach lack expressiveness to define and enforce complex , goal-driven , and measurable security requirement . paper , propose concept differentiated security level and leverage intent management framework . discuss requirement and enabler to extend currently define intent-based management framework to pave path intent-based security management mobile network . approach formalize functional and non-functional security requirement and demonstrate can be express and model use extend tm forum ( tmf ) intent security ontology . far discuss require standardization step to achieve intent-based security management . work aim advance security automation , improve adaptability , and strengthen resilience and security posture next-generation mobile network",Cryptography and Security,29/09/2025
10.48550/arXiv.2509.25430,find phones fast : low-latency and scalable monitoring cellular communications sensitive areas,"Martin Kotuliak, Simon Erni, Jakub Polák, Marc Roeschlin, Richard Baker, Ivan Martinovic, Srdjan Čapkun","widespread availability cellular device introduce new threat vector allow user or attacker to bypass security policy and physical barrier and bring unauthorized device sensitive area . threat can arise user non-compliance or deliberate action aim datum exfiltration/infiltration hide device , drone , etc . identify critical gap context : absence low-latency system high-quality and instantaneous monitoring cellular transmission . such low-latency system be crucial to allow timely detection , decision ( e.g. , geofencing or localization ) , and disruption unauthorized communication sensitive area . operator-base monitoring system , build purpose such people count or tracking , lack real-time capability , require cooperation multiple operator , and thus be hard to deploy . operator-independent monitoring approach propose literature either lack low-latency capability or do not scale .",Cryptography and Security,29/09/2025
10.48550/arXiv.2509.25410,characterize event-themed malicious web campaign : case study war-themed website,"Maraz Mia, Mir Mehedi A. Pritom, Tariqul Islam, Shouhuai Xu","cybercrime such online scam and fraud have become prevalent . cybercriminal often abuse various global or regional event theme fraudulent activity to breach user trust and attain high attack success rate . attack attempt to manipulate and deceive innocent people interact meticulously craft website malicious payload , phishing , or fraudulent transaction . to deepen understanding problem , paper investigate to characterize event-themed malicious website-based campaign , case study war-themed website . find attacker tailor attack exploit unique aspect event , evidence activity such fundraising , provide aid , collect essential supply , or seek update news . use explainable unsupervised clustering method to draw further insight , could guide design effective early defense various event-themed malicious web campaign .",Cryptography and Security,29/09/2025
10.48550/arXiv.2509.25408,optimal threshold signatures bitcoin,"Korok Ray, Sindura Saraswathi","formulate design threshold signature scheme make possible cryptocurrency protocol bitcoin . fund be secure m-of-n threshold signature , at least mm signature be need to unlock fund . user design scheme know malicious attacker can also obtain signature probability . high threshold offer more security , but also risk lock user own fund . optimal threshold balance twin effect . intervention increase security or usability signature allow high threshold . model dynamic threshold signature scheme , probability user or attacker obtain signature decay time . dynamic threshold signature scheme be optimal , and increase security or usability allow high threshold and long time lock .",Cryptography and Security,29/09/2025
10.48550/arXiv.2509.26640,spata : systematic pattern analysis detailed and transparent data cards,"João Vitorino, Eva Maia, Isabel Praça, Carlos Soares","susceptibility artificial intelligence ( ai ) datum perturbation and adversarial example , be crucial to perform thorough robustness evaluation machine learning ( ml ) model be deploy . however , examine model ’s decision boundary and identify potential vulnerability typically require access training and testing dataset , may pose risk datum privacy and confidentiality . to improve transparency organization handle confidential datum or manage critical infrastructure , be essential to allow external verification and validation ai disclosure private dataset . paper present systematic pattern analysis ( spata ) , deterministic method convert tabular dataset domain-independent representation statistical pattern , to provide more detailed and transparent datum card . spata compute projection datum instance discrete space can be analyze and compare , risk datum leakage . project dataset can be reliably use evaluation different feature affect ml model robustness and generation interpretable explanation behavior , contribute more trustworthy ai .",Cryptography and Security,30/09/2025
10.48550/arXiv.2509.26310,strong random unitarie and fast scrambling,"Thomas Schuster, Fermi Ma, Alex Lombardi, Fernando Brandao, Hsin-Yuan Huang","understand fast physical system can resemble haar-random unitarie be fundamental question physics . many experiment interest quantum gravity and many-body physic , include butterfly effect quantum information scramble and hayden-preskill thought experiment , involve query random unitary uu inverse u†u^{\dagger } , conjugate u∗u^ { * } , and transpose utu^{t } . however , conventional notion approximate unitary design and pseudorandom unitarie ( prus ) fail to capture experiment . work , introduce and construct strong unitary design and strong pru remain robust such query . construction achieve optimal circuit depth 𝒪​(log⁡n)\mathcal{o}(\log n ) system qubit . far show strong unitary design can form circuit depth 𝒪​(log2⁡n)\mathcal{o}(\log^{2}n ) circuit compose independent two-qubit haar-random gate , and strong prus can form circuit depth poly⁡(log⁡n)\operatorname{poly}(\log n ) circuit ancilla qubit . result provide operational proof fast scrambling conjecture black hole physic : observable feature fast scrambling quantum system reproduce haar-random behavior logarithmic time .",Cryptography and Security,30/09/2025
10.48550/arXiv.2509.26032,stealthy yet effective : distribution-preserving backdoor attacks graph classification,"Xiaobao Wang, Ruoxiao Sun, Yujun Zhang, Bingdao Feng, Dongxiao He, Luzhi Wang, Di Jin","graph neural networks ( gnns ) have demonstrate strong performance task such node classification , link prediction , and graph classification , but remain vulnerable backdoor attack implant imperceptible trigger training to control prediction . node-level attack exploit local message passing , graph-level attack face hard challenge manipulate global representation maintain stealth . identify two main source anomaly exist graph classification backdoor method : structural deviation rare subgraph trigger and semantic deviation cause label flipping , make poison graph easily detectable anomaly detection model . to address , propose dpsba , clean-label backdoor framework learn in-distribution trigger adversarial training guide anomaly-aware discriminator . dpsba effectively suppress both structural and semantic anomaly , achieve high attack success significantly improve stealth . extensive experiment real-world dataset validate dpsba achieve superior balance effectiveness and detectability compare state-of-the-art baseline .",Cryptography and Security,30/09/2025
10.48550/arXiv.2509.25927,impact scaling training data adversarial robustness,"Marco Zimmerli, Andreas Plesner, Till Aczel, Roger Wattenhofer","deep neural network remain vulnerable adversarial example advance architecture and training paradigm . investigate training data characteristic affect adversarial robustness 36 state-of-the-art vision model span supervise , self-supervised , and contrastive learning approach , train dataset 1 . 2 m 22b image . model be evaluate six black-box attack category : random perturbation , two type geometric mask , coco object manipulation , imagenet-c corruption , and imagenet-r style shift . robustness follow logarithmic scale law both datum volume and model size : tenfold increase datum reduce attack success rate ( asr ) average 3 . 2 % , tenfold increase model size reduce asr average 13 . 4 % . notably , self-supervised model train curate dataset , such dinov2 , outperform other train much large but less curate dataset , challenge assumption scale alone drive robustness . adversarial fine-tuning resnet50s improve generalization structural variation but not color distribution . human evaluation reveal persistent gap human and machine vision . result show scaling improve robustness , datum quality , architecture , and training objective play more decisive role raw scale achieve broad-spectrum adversarial resilience .",Cryptography and Security,30/09/2025
10.48550/arXiv.2509.25514,agnomin - architecture agnostic multi-label function name prediction,"Yonatan Gizachew Achamyeleh, Tongtao Zhang, Joshua Hyunki Kim, Gabriel Garcia, Shih-Yuan Yu, Anton Kocheturov, Mohammad Abdullah Al Faruque","function name prediction be crucial understanding strip binary software reverse engineering , key step enable subsequent vulnerability analysis and patching . however , exist approach often struggle architecture-specific limitation , datum scarcity , and diverse naming convention . present agnomin , novel architecture-agnostic approach multi-label function name prediction strip binary . agnomin build feature-enriche hierarchical graphs ( fehgs ) , combine control flow graphs , function call graphs , and dynamically learn pcode feature . hierarchical graph neural network process enriched structure to generate consistent function representation architecture , vital scalable security assessment . function name prediction , agnomin employ renée-inspired decoder , enhance attention-based head layer and algorithmic improvement .",Cryptography and Security,29/09/2025
10.48550/arXiv.2509.25241,fine-tuning large language models domain-specific cybersecurity knowledge,Yuan Huang,"recent advancement training paradigm large language models ( llms ) have unlock remarkable capability natural language processing and cross-domain generalization . llms excel task programming and mathematical problem-solving , zero-shot performance specialized domain require expert knowledge , such cybersecurity , be often suboptimal . limitation arise foundational llm be design general-purpose application , constrain ability to encapsulate domain-specific expertise parameter space . to address , explore fine-tuning strategy to embed cybersecurity knowledge llms , enhance performance cybersecurity question-answere ( q&a ) task prioritize computational efficiency . specifically , investigate supervised fine-tuning ( sft ) , low-rank adaptation ( lora ) , and quantized low-rank adaptation ( qlora ) use cybersecurity q&a dataset . result demonstrate fine-tuning approach significantly outperform foundational model cybersecurity q&a task . moreover , lora and qlora achieve comparable performance sft substantially low computational cost , offer efficient pathway adapt llm specialized domain . work highlight potential low-rank fine-tuning strategy to bridge gap general-purpose llm and domain-specific application .",Cryptography and Security,25/09/2025
10.48550/arXiv.2509.25205,polynomial contrastive learning privacy-preserve representation learning graphs,Daksh Pandey,"self-supervise learn ( ssl ) have emerge powerful paradigm learn representation graph datum require manual label . however , lead ssl method grace be fundamentally incompatible privacy-preserving technology such homomorphic encryption ( he ) reliance non-polynomial operation . paper introduce poly-grace , novel framework he-compatible self-supervised learning graph . approach consist fully polynomial-friendly graph convolutional network ( gcn ) encoder and novel , polynomial-based contrastive loss function . experiment three benchmark datasets—cora , citeseer , and pubmed—we demonstrate poly-grace not only enable private pre-training but also achieve performance be highly competitive , and case citeseer , superior standard non-private baseline . work represent significant step practical and high-performance privacy-preserving graph representation learning .",Cryptography and Security,19/09/2025
10.48550/arXiv.2509.25113,two-dimensional xor-base secret sharing layered multipath communication,"Wai Ming Chan, Remi Chou, Taejoon Kim","paper introduce first two-dimensional xor-based secret sharing scheme layered multipath communication network . present construction guarantee successful message recovery and perfect privacy adversary observe and disrupt single path transmission layer . scheme achieve information-theoretic security use only bitwise xor operation linear o​(|s|)o(|s| ) complexity , |s||s| be message length . provide mathematical proof demonstrate scheme maintain unconditional security regardless computational resource available adversary . encryption-based approach vulnerable quantum computing advance , construction offer provable security suitable resource-constrained military environment computational assumption may fail .",Cryptography and Security,29/09/2025
10.48550/arXiv.2509.25072,optimize privacy-preserving primitives to support llm-scale application,"Yaman Jandali, Ruisi Zhang, Nojan Sheybani, Farinaz Koushanfar","privacy-preserve technology have introduce paradigm shift allow realizable secure computing real-world system . significant barrier practical adoption primitive be significant computational and communication overhead be incur apply scale . paper , present overview effort to bridge gap overhead and practicality privacy-preserving learning system use multi-party computation ( mpc ) , zero-knowledge proof ( zkps ) , and fully homomorphic encryption ( fhe ) . meticulous hardware/software/algorithm co-design , show progress enable llm-scale application privacy-preserving setting . show efficacy solution several contexts , include dnn ip ownership , ethical llm usage enforcement , and transformer inference .",Cryptography and Security,29/09/2025
10.48550/arXiv.2509.24955,secret leader election ethereum pos : empirical security analysis whisk and homomorphic sortition dos leader and censorship attacks,"Tereza Burianová, Martin Perešíni, Ivan Homoliak","proposer anonymity proof-of-stake ( pos ) blockchain be critical concern risk target attack such malicious denial-of-service ( dos ) and censorship attack . several secret single leader election ( ssle ) mechanism have be propose to address threat , practical impact and trade-off remain insufficiently explore . work , present unified experimental framework evaluate ssle mechanism adversarial condition , ground simplified yet representative model ethereum ’s pos consensus layer . framework include configurable adversary capable launch target dos and censorship attack , include coordinate strategy simultaneously compromise group validator . simulate and compare key protection mechanism – whisk , and homomorphic sortition . good knowledge , be first comparative study to examine adversarial dos scenario involve multiple attacker diverse protection mechanism . result show design offer strong protection target dos attack leader , defend effectively coordinated attack validator group . moreover , whisk simplify dos attack narrow target set validator small list known candidate . homomorphic sortition , theoretical strength , remain impractical complexity cryptographic operation large validator set .",Cryptography and Security,29/09/2025
10.48550/arXiv.2509.24823,of-semwat : high-payload text embed semantic watermarking ai-generate image arbitrary size,"Benedetta Tondi, Andrea Costanzo, Mauro Barni","propose high-payload image watermarking method textual embed , semantic description image - may also correspond input text prompt- , be embed image . order to be able to robustly embed high payload large-scale image - such produce modern ai generator - propose approach build traditional watermarking scheme exploit orthogonal and turbo code improved robustness , and integrate frequency-domain embed and perceptual masking technique to enhance watermark imperceptibility . experiment show propose method be extremely robust wide variety image processing , and embed text can be retrieve also traditional and ai inpainte , permit to unveil semantic modification image have undergo image-text mismatch analysis .",Cryptography and Security,29/09/2025
10.48550/arXiv.2509.24698,lisa technical report : agentic framework smart contract auditing,"Izaiah Sun, Daniel Tan, Andy Deng","present lisa , agentic smart contract vulnerability detection framework combine rule-based and logic-based method to address broad spectrum vulnerability smart contract . lisa leverage datum historical audit report to learn detection experience ( model fine-tuning ) , enable to generalize learn pattern unseen project and evolve threat profile . evaluation , lisa significantly outperform llm-base approach and traditional static analysis tool , achieve superior coverage vulnerability type and high detection accuracy . result suggest lisa offer compelling solution industry : deliver more reliable and comprehensive vulnerability detection reduce dependence manual effort .",Cryptography and Security,29/09/2025
10.48550/arXiv.2509.24624,privmark : private large language models watermarke mpc,"Thomas Fargues, Ye Dong, Tianwei Zhang, Jin-Song Dong","rapid growth large language models ( llms ) have highlight press need reliable mechanism to verify content ownership and ensure traceability . watermarking offer promising path forward , but remain limit privacy concern sensitive scenario , traditional approach often require direct access model ’s parameter or training datum . work , propose secure multi-party computation ( mpc)-base private llm watermarking framework , privmark , to address concern . concretely , investigate postmark ( emnlp ' 2024 ) , one state-of-the-art llms watermarking method , and formulate basic operation . then , construct efficient protocol operation use mpc primitive black-box manner . way , privmark enable multiple party to collaboratively watermark llm ’s output expose model ’s weight single compute party . implement privmark use secretflow-spu ( usenix atc ' 2023 ) and evaluate performance use aby3 ( ccs ' 2018 ) backend . experimental result show privmark achieve semantically identical result compare plaintext baseline mpc and be resistant paraphrase and remove attack reasonable efficiency .",Cryptography and Security,29/09/2025
10.48550/arXiv.2509.24623,mapping quantum threats : engineering inventory cryptographic dependencies,Carlos Benitez,"emergence large-scale quantum computer , power algorithm shor ’s and grover ’s , pose existential threat modern public-key cryptography . vulnerability stem ability machine to efficiently solve hard mathematical problems—such integer factorization and elliptic curve discrete logarithm problem—that underpin widely use cryptographic primitive . include rsa , diffie–hellman ( dh ) , elliptic curve diffie–hellman ( ecdh ) , and elliptic curve digital signature algorithm ( ecdsa ) , be foundational security digital ecosystem .",Cryptography and Security,29/09/2025
10.48550/arXiv.2509.24444,bugmagnifier : ton transaction simulator revealing smart contract vulnerabilitie,"Yury Yanovich, Victoria Kovalevskaya, Maksim Egorov, Elizaveta Smirnova, Matvey Mishuris, Yash Madhwal, Kirill Ziborov, Vladimir Gorgadze, Subodh Sharma","open network ( ton ) blockchain employ asynchronous execution model introduce unique security challenge smart contract , particularly race condition arise unpredictable message processing order . previous work establish vulnerability pattern static analysis audit report , dynamic detection temporal dependency systematic testing remain open problem . present bugmagnifier , transaction simulation framework systematically reveal vulnerability ton smart contract control message orchestration . build ton sandbox and integrate ton virtual machine ( tvm ) , tool combine precise message queue manipulation differential state analysis and probabilistic permutation testing to detect asynchronous execution flaw . experimental evaluation demonstrate bugmagnifier ’s effectiveness extensive parametric study purpose-built vulnerable contract , reveal message ratio-dependent detection complexity align theoretical prediction . quantitative model enable predictive vulnerability assessment shift discovery manual expert analysis automate evidence generation . provide reproducible test scenario temporal vulnerability , bugmagnifier address critical gap ton security tooling , offer practical support safe smart contract development asynchronous blockchain environment .",Cryptography and Security,29/09/2025
10.48550/arXiv.2509.24418,gspr : align llm safeguard generalizable safety policy reasoner,"Haoran Li, Yulin Chen, Jingru Zeng, Hao Peng, Huihao Jing, Wenbin Hu, Xi Yang, Ziqian Zeng, Sirui Han, Yangqiu Song","large language model ( llms ) be increasingly integrate numerous application various domain , llms ' safety become critical concern application developer and intended user . currently , great effort have be make to develop safety benchmark fine-grained taxonomy . however , benchmark ' taxonomy be disparate different safety policy . thus , exist safeguard train benchmark be either coarse-grained to only distinguish "" safe "" and "" unsafe , "" or constrain narrow risk taxonomy single benchmark . to leverage fine-grained safety taxonomy multiple safety benchmark , paper , propose gspr , generalizable safety policy reasoner to identify unsafe input prompt and llms ' output violate safety taxonomy group relative policy optimization ( grpo ) . prior safeguard only cover fix set risk factor , gspr incentivize reasoning capability varied safety taxonomy careful cold-start strategy and reward design . consequently , gspr can be train multiple safety benchmark distinct taxonomy and naturally exhibit powerful generalization ability . conduct extensive experiment to show gspr significantly improve exist safety guardrail ' reasoning capability safety and category prediction task . moreover , gspr not only demonstrate powerful safety generalization ability but also achieve least inference token cost explanation .",Cryptography and Security,29/09/2025
10.48550/arXiv.2509.24408,funcpoison : poisoning function library to hijack multi-agent autonomous driving systems,"Yuzhen Long, Songze Li","autonomous driving system increasingly rely multi-agent architecture power large language model ( llms ) , specialized agent collaborate to perceive , reason , and plan . key component system be share function library , collection software tool agent use to process sensor datum and navigate complex driving environment . critical role agent decision-making , function library remain under-explored vulnerability . paper , introduce funcpoison , novel poisoning-based attack target function library to manipulate behavior llm-driven multi-agent autonomous system . funcpoison exploit two key weakness agent access function library : ( 1 ) agent rely text-based instruction to select tool ; and ( 2 ) tool be activate use standardized command format attacker can replicate . inject malicious tool deceptive instruction , funcpoison manipulate one agent ’ decisions—such misinterpret road conditions—triggere cascade error mislead other agent system . experimentally evaluate funcpoison two representative multi-agent autonomous driving system , demonstrate ability to significantly degrade trajectory accuracy , flexibly target specific agent to induce coordinated misbehavior , and evade diverse defense mechanism . result reveal function library , often consider simple toolset , can serve critical attack surface llm-base autonomous driving system , raise elevated concern reliability .",Cryptography and Security,29/09/2025
10.48550/arXiv.2509.24272,"mcp server attack : taxonomy , feasibility , and mitigation","Weibo Zhao, Jiahao Liu, Bonan Ruan, Shaofei Li, Zhenkai Liang","model context protocol ( mcp ) server enable ai application to connect external system plug-and-play manner , but rapid proliferation also introduce severe security risk . mature software ecosystem rigorous vetting , mcp server still lack standardized review mechanism , give adversary opportunity to distribute malicious implementation . press risk , security implication mcp server remain underexplored . to address gap , present first systematic study treat mcp server active threat actor and decompose core component to examine adversarial developer can implant malicious intent . specifically , investigate three research question : ( i ) type attack malicious mcp server can launch , ( ii ) vulnerable mcp host and large language models ( llms ) be attack , and ( iii ) feasible be to carry mcp server attack practice . study propose component-based taxonomy comprise twelve attack category . category , develop proof-of-concept ( poc ) server and demonstrate effectiveness diverse real-world host–llm setting . far show attacker can generate large number malicious server virtually cost . then test state-of-the-art scanner generate server and find exist detection approach be insufficient . finding highlight malicious mcp server be easy to implement , difficult to detect current tool , and capable cause concrete damage ai agent system . address threat require coordinate effort protocol designer , host developer , llm provider , and end user to build more secure and resilient mcp ecosystem .",Cryptography and Security,29/09/2025
10.48550/arXiv.2509.24257,verillm : lightweight framework publicly verifiable decentralized inference,"Ke Wang, Felix Qu, Libin Xia, Zishuo Zhao, Chris Tong, Lynn Ai, Eric Yang","decentralized inference be appeal paradigm serve large language model ( llms ) , offer strong security , high efficiency , and low operating cost . yet permissionless set admit priori trust participate node , make output verifiability prerequisite secure deployment .",Cryptography and Security,29/09/2025
10.48550/arXiv.2509.24240,takedown : be do modern coding agent exploit,"Eunkyu Lee, Donghyeon Kim, Wonyoung Kim, Insu Yun","code agent , be llm-driven agent specialize software development , have become increasingly prevalent modern programming environment . traditional ai code assistant , offer simple code completion and suggestion , modern code agent tackle more complex task great autonomy , such generate entire program natural language instruction . to enable such capability , modern code agent incorporate extensive functionality , turn raise significant concern security and privacy . grow adoption , systematic and in-depth security analysis agent have largely be overlook .",Cryptography and Security,29/09/2025
10.48550/arXiv.2509.24174,lluad : low-latency user-anonymized dns,"Philip Sjösvärd, Hongyu Jin, Panos Papadimitratos","domain name system ( dns ) be involve practically web activity , translate easy-to-remember domain name internet protocol ( ip ) address . central role internet , dns expose user web activity detail . privacy challenge be honest-but-curious dns servers/resolver provide translation/lookup service . particular , majority dns query handle public dns resolver , organization run can track , collect , and analyze massive user activity datum . exist solution encrypt dns traffic client and resolver be insufficient , resolver be privacy threat . dns query relay separate duty multiple entity , to limit datum accessible entity , can not prevent collude entity share user traffic log . to achieve near-zero-trust dns privacy compatible exist dns infrastructure , propose lluad : locally store popularity list , most popular dns record , user device , form privacy-preserving manner base user interest . way , lluad can improve privacy and reduce access time web content . popularity list be proactively retrieve ( curious ) public server continually update and refresh record base user popularity vote , efficiently broadcast record updates/change to adhere aggressive load-balancing scheme ( i.e. , name server actively load-balance user connection change record ip address ) . user vote be anonymize use novel , efficient , and highly scalable client-driven voting mix network – packet length independent number hop , centrally enforce limit number vote cast user , and robustness poor client participation – to ensure geographically relevant and correctly/securely instantiate popularity list . find 25 00025\ , 000 entry long popularity list , lluad provide privacy-preserving and high performance dns : be due instant local ( and anonymous ) resolution 94 % 94\text{\ , }\mathrm{\char 37\relax } query base popularity list , few remain query use other privacy-preserving , but latency-costly , alternative , such query public resolver public anonymous network , e.g. , tor . strong dns privacy and low average lookup latency , lluad maintain network traffic overhead par widely deploy secure dns protocol , memory/storage overhead less 2 mb2\text{\ , }\mathrm{mb } .",Cryptography and Security,29/09/2025
10.48550/arXiv.2509.24173,fundamental limit discrete distribution estimation utility-optimized local differential privacy,"Sun-Moon Yoon, Hyun-Young Park, Seung-Hyun Nam, Si-Hyeon Lee","study problem discrete distribution estimation utility-optimized local differential privacy ( uldp ) , enforce local differential privacy ( ldp ) sensitive datum allow more accurate inference non-sensitive datum . setting , completely characterize fundamental privacy–utility trade-off . converse proof build several key idea , include generalized uniform asymptotic cramér–rao lower bind , reduction show suffice to consider newly define class extremal uldp mechanism , and novel distribution decomposition technique tailor uldp constraint . achievability , propose class utility-optimized block design ( ubd ) scheme , obtain nontrivial modification block design mechanism know to be optimal standard ldp constraint , incorporate distribution decomposition idea use converse proof and score-based linear estimator . result provide tight characterization estimation accuracy achievable uldp and reveal new insight structure optimal mechanism privacy-preserving statistical inference .",Cryptography and Security,29/09/2025
10.48550/arXiv.2509.24153,dns time curiosity : tale collaborative user privacy protection,"Philip Sjösvärd, Hongyu Jin, Panos Papadimitratos","domain name system ( dns ) be central internet user activity , resolve access domain name internet protocol ( ip ) address . result , curious dns resolver can learn internet user ’ interest . public dns resolver be rise popularity , offer low-latency resolution , high reliability , privacy-preserve policy , and support encrypt dns query . however , client-resolver traffic encryption , increasingly deploy to protect user eavesdropper , do not protect user curious resolver . similarly , privacy-preserving policy be base solely write commitment and do not provide technical safeguard . dns query relay scheme can separate duty to limit datum accessible entity , can not prevent collude entity share user traffic log . thus , key challenge remain : organization operate public dns resolver , account majority dns resolution , can potentially collect and analyze massive volume internet user activity datum . dns infrastructure can not be fully trust , can safeguard user privacy ? answer positively and advocate user-driven approach to reduce exposure dns service . will discuss key idea proposal , aim to achieve high level privacy sacrifice performance : maintain low latency , network bandwidth , memory/storage overhead , and computational overhead .",Cryptography and Security,29/09/2025
10.48550/arXiv.2509.24048,analyze and evaluate unbiased language model watermark,"Yihan Wu, Xuehao Cui, Ruibo Chen, Heng Huang","verify authenticity ai-generate text have become increasingly important rapid advancement large language model , and unbiased watermarking have emerge promising approach ability to preserve output distribution degrade quality . however , recent work reveal unbiased watermark can accumulate distributional bias multiple generation and exist robustness evaluation be inconsistent study . to address issue , introduce uwbench , first open-source benchmark dedicate principled evaluation unbiased watermarking method . framework combine theoretical and empirical contribution : propose statistical metric to quantify multi-batch distribution drift , prove impossibility result show unbiased watermark can perfectly preserve distribution infinite query , and develop formal analysis robustness token-level modification attack . complement theory , establish three-axis evaluation protocol—unbiasedness , detectability , and robustness—and show token modification attack provide more stable robustness assessment paraphrasing-based method . together , uwbench offer community standardized and reproducible platform advance design and evaluation unbiased watermarking algorithm .",Cryptography and Security,28/09/2025
10.48550/arXiv.2509.24043,ensemble framework unbiased language model watermarking,"Yihan Wu, Ruibo Chen, Georgios Milis, Heng Huang","large language model become increasingly capable and widely deploy , verify provenance machine-generated content be critical ensure trust , safety , and accountability . watermarking technique have emerge promising solution embed imperceptible statistical signal generation process . , unbiased watermarking be particularly attractive theoretical guarantee preserve language model ’s output distribution , thereby avoid degradation fluency or detectability distributional shift . however , exist unbiased watermarking scheme often suffer weak detection power and limited robustness , especially short text length or distributional perturbation . work , propose ens , novel ensemble framework enhance detectability and robustness logits-based unbiased watermark strictly preserve unbiasedness . ens sequentially compose multiple independent watermark instance , govern distinct key , to amplify watermark signal . theoretically prove ensemble construction remain unbiased expectation and demonstrate improve signal-to-noise ratio statistical detector . empirical evaluation multiple llm family show ens substantially reduce number token need reliable detection and increase resistance smooth and paraphrasing attack compromise generation quality .",Cryptography and Security,28/09/2025
10.48550/arXiv.2509.24037,automated vulnerability validation and verification : large language model approach,"Alireza Lotfi, Charalampos Katsis, Elisa Bertino","software vulnerability remain critical security challenge , provide entry point attacker to compromise enterprise network . advance security practice , lack high-quality dataset capture behavior diverse exploit hinder effective vulnerability assessment and mitigation . paper introduce end-to-end multi-step pipeline leverage generative ai , specifically large language model ( llms ) , to address challenge orchestrate and reproduce attack know software vulnerability control environment . approach extract information cve disclosure national vulnerability database , augment external public knowledge ( e.g. , threat advisory , code snippet ) use retrieval-augmented generation ( rag ) , and automate creation containerized environment and exploit code tailor vulnerability . pipeline iteratively refine generate artifact , validate success attack use test case , and support complex multi-container setup . methodology provide approach to overcome key obstacle , include noisy and incomplete vulnerability description , integrate llms and rag to fill information gap and enhance context . demonstrate effectiveness pipeline wide range vulnerability type , such memory overflow and denial service , memory corruption and remote code execution , span diverse programming language , library and year . do so , uncover significant inconsistency cve description , emphasize need more rigorous verification description cve disclosure process . approach be model-agnostic , work multiple llm , and open-source artifact to enable reproducibility and accelerate security research . good knowledge , be first system to systematically orchestrate and exploit know vulnerability containerized environment combine general-purpose llm reasoning cve datum and rag-base context enrichment .",Cryptography and Security,28/09/2025
10.48550/arXiv.2509.23970,binary diff summarization use large language model,"Meet Udeshi, Venkata Sai Charan Putrevu, Prashanth Krishnamurthy, Prashant Anantharaman, Sean Carrick, Ramesh Karri, Farshad Khorrami","security software supply chain be necessary to ensure software update do not contain maliciously inject code or introduce vulnerability may compromise integrity critical infrastructure . verify integrity software update involve binary differential analysis ( binary diffing ) to highlight change two binary version incorporate binary analysis and reverse engineering . large language model ( llms ) have be apply binary analysis to augment traditional tool produce natural language summary cybersecurity expert can grasp further analysis . combine llm-base binary code summarization binary diffing can improve llm ’s focus critical change and enable complex task such automate malware detection . to address , propose novel framework binary diff summarization use llms . introduce novel functional sensitivity score ( fss ) help automate triage sensitive binary function downstream detection task . create software supply chain security benchmark inject 3 different malware 6 open-source project generate 104 binary version , 392 binary diff , and 46 , 023 function . , framework achieve precision 0 . 98 and recall 0 . 64 malware detection , display high accuracy low false positive . malicious and benign function , achieve fss separation 3 . 0 point , confirm fss categorization can classify sensitive function . conduct case study real-world xz util supply chain attack ; framework correctly detect inject backdoor function high fss .",Cryptography and Security,28/09/2025
10.48550/arXiv.2509.23871,taught well learned ill : distillation-conditional backdoor attack,"Yukun Chen, Boheng Li, Yu Yuan, Leyi Qi, Yiming Li, Tianwei Zhang, Zhan Qin, Kui Ren","knowledge distillation ( kd ) be vital technique deploy deep neural network ( dnn ) resource-constrained device transfer knowledge large teacher model lightweight student model . teacher model third-party platform may undergo security verification ( e.g. e.g. , backdoor detection ) , uncover novel and critical threat : distillation-conditional backdoor attack ( dcba ) . dcba inject dormant and undetectable backdoor teacher model , become activate student model kd process , even clean distillation dataset . direct extension exist method be ineffective dcba , implement attack formulate bilevel optimization problem and propose simple yet effective method ( i.e. i.e. , scar ) . specifically , inner optimization simulate kd process optimize surrogate student model , outer optimization leverage output surrogate to optimize teacher model implant conditional backdoor . scar address complex optimization utilize implicit differentiation algorithm pre-optimized trigger injection function . extensive experiment diverse dataset , model architecture , and kd technique validate effectiveness scar and resistance exist backdoor detection , highlight significant yet previously overlook vulnerability kd process . code be available https://github.com/whitolfchen/scar .",Cryptography and Security,28/09/2025
10.48550/arXiv.2509.23834,gpm : gaussian pancake mechanism planting undetectable backdoors differential privacy,"Haochen Sun, Xi He","differential privacy ( dp ) have become gold standard preserve individual privacy data analysis . however , implicit yet fundamental assumption underlie rigorous privacy guarantee be correct implementation and execution dp mechanism . several incident unintended privacy loss have occur numerical issue and inappropriate configuration dp software , have be successfully exploit privacy attack . to well understand seriousness defective dp software , ask follow question : be possible to elevate passive defect active privacy attack maintain covertness ?",Cryptography and Security,28/09/2025
10.48550/arXiv.2509.23680,first look privacy risk android task-executable voice assistant applications,"Shidong Pan, Yikai Ge, Xiaoyu Sun","development foundation ai technology , task-executable voice assistant ( va ) have become more popular , enhance user convenience and expand device functionality . android task-executable va be application be capable understand complex task and perform corresponding operation . give prevalence and great autonomy , be exist work examine privacy risk voice assistant task-execution pattern holistic manner . to fill research gap , paper present user-centric comprehensive empirical study privacy risk android task-executable va application . collect ten mainstream va research target and analyze operational characteristic . then cross-check privacy declaration six source , include privacy label , policy , and manifest file , and finding reveal widespread inconsistency . moreover , uncover three significant privacy threat model : ( 1 ) privacy misdisclosure mega app , integrated mini app such alexa skill be inadequately represent ; ( 2 ) privilege escalation inter-application interaction , exploit android ’s communication mechanism bypass user consent ; and ( 3 ) abuse google system application , enable app to evade declaration dangerous permission . study contribute actionable recommendation practitioner and underscore broad relevance privacy risk emerge autonomous ai agent .",Cryptography and Security,28/09/2025
10.48550/arXiv.2509.23621,automl cybersecurity : empirical study,"Sherif Saad, Kevin Shi, Mohammed Mamun, Hythem Elmiligi","automate machine learning ( automl ) have emerge promising paradigm automate machine learning ( ml ) pipeline design , broaden ai adoption . yet reliability complex domain such cybersecurity remain underexplored . paper systematically evaluate eight open-source automl framework 11 publicly available cybersecurity dataset , span intrusion detection , malware classification , phishing , fraud detection , and spam filtering . result show substantial performance variability tool and dataset , single solution consistently superior . paradigm shift be observe : challenge have move select individual ml model identify most suitable automl framework , complicate difference runtime efficiency , automation capability , and support feature . automl tool frequently favor tree-based model , perform well but risk overfitting and limit interpretability . key challenge identify include adversarial vulnerability , model drift , and inadequate feature engineering . conclude good practice and research direction to strengthen robustness , interpretability , and trust automl high-stakes cybersecurity application .",Cryptography and Security,28/09/2025
10.48550/arXiv.2509.23594,stolenlora : explore lora extraction attacks synthetic data,"Yixu Wang, Yan Teng, Yingchun Wang, Xingjun Ma","parameter-efficient fine-tuning ( peft ) method lora have transform vision model adaptation , enable rapid deployment customize model . however , compactness lora adaptation introduce new safety concern , particularly vulnerability to model extraction attack . paper introduce new focus model extraction attack name lora extraction extract lora-adaptive model base public pre-trained model . then propose novel extraction method call stolenlora train substitute model to extract functionality lora-adapted model use synthetic datum . stolenlora leverage large language model to craft effective prompt datum generation , and incorporate disagreement-base semi-supervise learning ( dsl ) strategy to maximize information gain limited query . experiment demonstrate effectiveness stolenlora , achieve 96 . 60 % attack success rate only 10k query , even cross-backbone scenario attacker and victim model utilize different pre-trained backbone . finding reveal specific vulnerability lora-adapted model type extraction and underscore urgent need robust defense mechanism tailor peft method . also explore preliminary defense strategy base diversified lora deployment , highlight potential to mitigate such attack .",Cryptography and Security,28/09/2025
10.48550/arXiv.2509.23573,uncover vulnerability llm-assiste cyber threat intelligence,"Yuqiao Meng, Luoxi Tang, Feiyang Yu, Jinyuan Jia, Guanhua Yan, Ping Yang, Zhaohan Xi","large language models ( llms ) be intensively use to assist security analyst counteract rapid exploitation cyber threat , llms offer cyber threat intelligence ( cti ) to support vulnerability assessment and incident response . recent work have show llms can support wide range cti task such threat analysis , vulnerability detection , and intrusion defense , significant performance gap persist practical deployment . paper , investigate intrinsic vulnerability llms cti , focus challenge arise nature threat landscape rather model architecture . use large-scale evaluation multiple cti benchmark and real-world threat report , introduce novel categorization methodology integrate stratification , autoregressive refinement , and human-in-the-loop supervision to reliably analyze failure instance . extensive experiment and human inspection , reveal three fundamental vulnerability : spurious correlation , contradictory knowledge , and constrain generalization , limit llms effectively support cti . subsequently , provide actionable insight design more robust llm-powered cti system to facilitate future research .",Cryptography and Security,28/09/2025
10.48550/arXiv.2509.23571,benchmarke llm-assiste blue teaming standardized threat hunting,"Yuqiao Meng, Luoxi Tang, Feiyang Yu, Xi Li, Guanhua Yan, Ping Yang, Zhaohan Xi","cyber threat continue to grow scale and sophistication , blue team defender increasingly require advanced tool to proactively detect and mitigate risk . large language models ( llms ) offer promise capability enhance threat analysis . however , effectiveness real-world blue team threat-hunte scenario remains insufficiently explore . paper present cyberteam , benchmark design to guide llm blue teaming practice . cyberteam construct standardize workflow two stage . first , model realistic threat-hunting workflow capture dependency analytical task threat attribution incident response . next , task be address set operational module tailor specific analytical requirement . transform threat hunt structured sequence reasoning step , step ground discrete operation and order accord task-specific dependency . guide framework , llm be direct to perform threat-hunting task modularize step . overall , cyberteam integrate 30 task and 9 operational module to guide llm standardize threat analysis . evaluate lead llms and state-of-the-art cybersecurity agent , compare cyberteam open-ended reasoning strategy . result highlight improvement enable standardized design , also reveal limitation open-ended reasoning real-world threat hunting .",Cryptography and Security,28/09/2025
10.48550/arXiv.2509.23519,reliabilityrag : effective and provably robust defense rag-based web-search,"Zeyu Shen, Basileal Imana, Tong Wu, Chong Xiang, Prateek Mittal, Aleksandra Korolova","abstract . retrieval-augmented generation ( rag ) enhance large language models ground output external document . system , however , remain vulnerable attack retrieval corpus , such prompt injection . rag-base search system ( e.g. , google ’s search ai overview ) present interesting setting study and protect such threat , defense algorithm can benefit built-in reliability signals—like document ranking—and represent non-llm challenge adversary decade work to thwart seo .",Cryptography and Security,27/09/2025
10.48550/arXiv.2509.23459,masksql : safeguard privacy llm-base text-to-sql abstraction,"Sepideh Abedini, Shubhankar Mohapatra, D. B. Emerson, Masoumeh Shafieinejad, Jesse C. Cresswell, Xi He","large language model ( llms ) have show promising performance task require reasoning , such text-to-sql translation , code generation , and debugging . however , regulatory framework strict privacy requirement constrain integration sensitive system . state-of-the-art llms be also proprietary , costly , and resource-intensive , make local deployment impractical . consequently , utilize such llm often require share datum third-party provider , raise privacy concern and risk noncompliance regulation . fine-tuned small language model ( slms ) can outperform llms certain task and be deploy locally to mitigate privacy concern , underperform more complex task such text-to-sql translation . work , introduce masksql , text-to-sql framework utilize abstraction privacy protection mechanism to mask sensitive information llm prompt . redaction , remove content entirely , or generalization , broaden token , abstraction retain essential information discard unnecessary detail , strike effective privacy–utility balance text-to-sql task . moreover , provide mechanism to control privacy-utility tradeoff , masksql facilitate adoption broad range use case . experimental result show masksql outperform lead slm-base text-to-sql model and achieve performance approach state-of-the-art llm-based model , preserve privacy . code be available .",Cryptography and Security,27/09/2025
10.48550/arXiv.2509.23418,detect youtube scam videos multimodal signals and policy reasoning,"Ummay Kulsum, Aafaq Sabir, Abhinaya S.B., Anupam Das","youtube have emerge dominant platform information dissemination and entertainment . however , vast accessibility have also make target scammer , frequently upload deceptive or malicious content . prior research have document range scam type , and detection approach rely primarily textual or statistical metadata . effective extent , signal be easy to evade and potentially overlook other modality , such visual cue .",Cryptography and Security,27/09/2025
10.48550/arXiv.2509.23305,ics-simlab : containerized approach simulating industrial control systems cyber security research,"Jaxson Brown, Duc-Son Pham, Sie-Teng Soh, Foad Motalebi, Sivaraman Eswaran, Mahathir Almashor","industrial control systems ( icss ) be complex interconnect system use to manage process control industrial environment , such chemical processing plant and water treatment facility . modern industrial environment move internet-face service , ics face increase risk attack necessitate ics-specific intrusion detection systems ( ids ) . development such ids rely significantly simulate testbe be unrealistic and sometimes hazardous to utilize operational control system . testbed have be propose , often use limited selection virtual ics simulation to test and verify cyber security solution . be lack investigation do develop system can efficiently simulate multiple ics architecture . currently , trend research involve develop security solution just one ics simulation , can result bias specific architecture .",Cryptography and Security,27/09/2025
10.48550/arXiv.2509.23091,fedbit : accelerate privacy-preserve federated learning bit-interleaved packing and cross-layer co-design,"Xiangchen Meng, Yangdi Lyu","federated learning ( fl ) fully homomorphic encryption ( fhe ) effectively safeguard datum privacy model aggregation encrypt local model update transmission , mitigate threat untrusted server or eavesdropper transmission . however , computational burden and ciphertext expansion associate homomorphic encryption can significantly increase resource and communication overhead . to address challenge , propose fedbit , hardware/software co-designe framework optimize brakerski-fan-vercauteren ( bfv ) scheme . fedbit employ bit-interleaved datum pack embed multiple model parameter single ciphertext coefficient , thereby minimize ciphertext expansion and maximize computational parallelism . additionally , integrate dedicated fpga accelerator to handle cryptographic operation and optimize dataflow to reduce memory overhead . experimental result demonstrate fedbit achieve speedup two order magnitude encryption and lower average communication overhead 60 . 7 % , maintain high accuracy .",Cryptography and Security,27/09/2025
10.48550/arXiv.2509.23041,"virus infection attack llms : poisoning can spread "" via "" synthetic data","Zi Liang, Qingqing Ye, Xuan Liu, Yanyun Wang, Jianliang Xu, Haibo Hu","synthetic datum refer artificial sample generate model . have be validate to significantly enhance performance large language model ( llms ) training and have be widely adopt llm development , potential security risk may introduce remain uninvestigated . paper systematically evaluate resilience synthetic-data-integrated training paradigm llms mainstream poisoning and backdoor attack . reveal paradigm exhibit strong resistance exist attack , primarily thank different distribution pattern poison datum and query use to generate synthetic sample . to enhance effectiveness attack and far investigate security risk introduce synthetic datum , introduce novel and universal attack framework , namely , virus infection attack ( via ) , enable propagation current attack synthetic datum even purely clean query . inspire principle virus design cybersecurity , via conceal poisoning payload protective "" shell "" and strategically search optimal hijacking point benign sample to maximize likelihood generate malicious content . extensive experiment datum poisoning and backdoor attack show via significantly increase presence poison content synthetic datum and correspondingly raise attack success rate ( asr ) downstream model level comparable observe poison upstream model .",Cryptography and Security,27/09/2025
10.48550/arXiv.2509.23019,llm watermark evasion bias inversion,"Jeongyeon Hwang, Sangdon Park, Jungseul Ok","watermarke large language model ( llms ) embed statistical signal generation to enable detection model-produced text . watermarking have prove effective benign setting , robustness adversarial evasion remains contest . to advance rigorous understanding and evaluation such vulnerability , propose bias-inversion rewrite attack ( bira ) , be theoretically motivated and model-agnostic . bira weaken watermark signal suppress logit likely watermarke token llm-base rewriting , knowledge underlie watermarking scheme . recent watermarking method , bira achieve 99 % evasion preserve semantic content original text . demonstrate attack , result reveal systematic vulnerability , emphasize need stress testing and robust defense .",Cryptography and Security,27/09/2025
10.48550/arXiv.2509.22900,context-aware mobile privacy notice : implementation deployable contextual privacy policies generator,"Haochen Gong, Zhen Tao, Shidong Pan, Zhenchang Xing, Xiaoyu Sun","lengthy and legally phrased privacy policy impede user ' understanding mobile application collect and process personal datum . prior work propose contextual privacy policies ( cpps ) mobile app to display short policy snippet only correspond user interface contexts , but pipeline could not be deployable real-world mobile environment . paper , present privscan , first deployable cpp software development kit ( sdk ) android . capture live app screenshot to identify gui element associate type personal datum and display cpp concise , user-facing format . provide lightweight float button offer low-friction , on-demand control . architecture leverage remote deployment to decouple multimodal backend pipeline mobile client comprise five modular component , thereby reduce on-device resource demand and ease cross-platform portability . feasibility-oriented evaluation show average execution time 9 . 15 s , demonstrate practicality approach . source code privscan be available https://github.com/buyanghc/privscan and demo video can be find https://www.youtube.com/watch?v=ck-25otfyhc .",Cryptography and Security,26/09/2025
10.48550/arXiv.2509.22873,antiflipper : secure and efficient defense label-flippe attack federated learning,"Aashnan Rahman, Abid Hasan, Sherajul Arifin, Faisal Haque Bappy, Tahrim Hossain, Tariqul Islam, Abu Raihan Mostofa Kamal, Md. Azam Hossain","federated learning ( fl ) enable privacy-preserving model training keep datum decentralize . however , remain vulnerable label-flipping attack , malicious client manipulate label to poison global model . simplicity , attack can severely degrade model performance , and defend remain challenge . introduce antiflipper , novel and computationally efficient defense multi-class label-flipping attack fl . exist method ensure security cost high computational overhead , antiflipper employ novel client-side detection strategy , significantly reduce central server ’s burden aggregation . comprehensive empirical evaluation multiple dataset different distribution demonstrate antiflipper achieve accuracy comparable state-of-the-art defense require substantially few computational resource server side . balance security and efficiency , antiflipper address critical gap exist defense , make particularly suitable resource-constrained fl deployment model integrity and operational efficiency be essential .",Cryptography and Security,26/09/2025
10.48550/arXiv.2509.22857,paper : privacy-preserve resnet models use low-degree polynomial approximations and structural optimizations leveled fhe,"Eduardo Chielle, Manaar Alam, Jinting Liu, Jovan Kascelan, Michail Maniatakos","recent work have make non-interactive privacy-preserving inference more practical run deep convolution neural network ( cnn ) fully homomorphic encryption ( fhe ) . however , method remain limited reliance bootstrappe , costly fhe operation apply multiple layer , severely slow inference . also depend high-degree polynomial approximation non-linear activation , increase multiplicative depth and reduce accuracy 2–5 % compare plaintext relu model . work , focus resnets , widely adopt benchmark architecture privacy-preserving inference , and close accuracy gap fhe-based non-interactive model and plaintext counterpart , also achieve fast inference exist method . use quadratic polynomial approximation relu , achieve theoretical minimum multiplicative depth non-linear activation , penalty-based training strategy . far introduce structural optimization such node fusing , weight redistribution , and tower reuse . optimization reduce require fhe level cnn nearly factor five compare prior work , allow to run resnet model leveled fhe bootstrappe . to far accelerate inference and recover accuracy typically lose polynomial approximation , introduce parameter cluster joint strategy datum encode layout and ensemble technique . experiment resnet-18 , resnet-20 , and resnet-32 cifar-10 and cifar-100 show approach achieve 4×4\times fast private inference prior work comparable accuracy plaintext relu model .",Cryptography and Security,26/09/2025
10.48550/arXiv.2509.22814,"model context protocol vision systems : audit , security , and protocol extensions","Aditi Tiwari, Akshit Bhalla, Darshan Prasad","model context protocol ( mcp ) define schema-bound execution model agent–tool interaction , enable modular computer vision workflow retrain . knowledge , be first protocol-level , deployment-scale audit mcp vision system , identify systemic weakness schema semantic , interoperability , and runtime coordination . analyze 91 publicly register vision-centric mcp server , annotate nine dimension compositional fidelity , and develop executable benchmark validator to detect and categorize protocol violation . audit reveal high prevalence schema format divergence , miss runtime schema validation , undeclared coordinate convention , and reliance untracked bridging script . validator-base testing quantifie failure , schema-format check flag misalignment 78 . 0 % system , coordinate-convention check detect spatial reference error 24 . 6 % , and memory-scope check issue average 33 . 8 warning 100 execution . security probe show dynamic and multi-agent workflow exhibit elevated risk privilege escalation and untyped tool connection . propose benchmark and validator suite , implement control testbed and to be release github , establish reproducible framework measure and improve reliability and security compositional vision workflow .",Cryptography and Security,26/09/2025
10.48550/arXiv.2509.22796,do fix ? llm-aide categorization security patches critical memory bug,"Xingyu Li, Juefei Pu, Yifan Wu, Xiaochen Zou, Shitong Zhu, Xiaochen Zou, Shitong Zhu, Qiushi Wu, Zheng Zhang, Joshua Hsu, Yue Dong, Zhiyun Qian, Kangjie Lu, Trent Jaeger, Michael De Lucia, Srikanth V. Krishnamurthy","open-source software project be foundational modern software ecosystem , linux kernel stand critical exemplar ubiquity and complexity . security patch be continuously integrate linux mainline kernel , downstream maintainer often delay adoption , create window vulnerability . key reason lag be difficulty identify security-critical patch , particularly address exploitable vulnerability such out-of-bound ( oob ) access and use-after-free ( uaf ) bug . challenge be exacerbate intentionally silent bug fix , incomplete or miss cve assignment , delay cve issuance , and recent change cve assignment criterion linux kernel .",Cryptography and Security,26/09/2025
10.48550/arXiv.2509.22762,trustcheckpoint : time betrays malware unconditional software root trust,"Friedrich Doku, Peter Dinda","modern iot and embed platform must start execution know trust state to thwart malware , ensure secure firmware update , and protect critical infrastructure . current approach to establish root trust depend secret key and/or specialize secure hardware , drive cost , may involve third party , add operational complexity , and rely assumption attacker ’s computational power . contrast , trustcheckpoints be first system to establish unconditional software root trust base formal model—without rely secret or trusted hardware . developer capture full-system checkpoint and later roll back and prove external verifier . verifier issue timing-constrained , randomize kk-independent polynomial challenge ( horner ’s rule ) repeatedly scan fast on-chip memory randomize pass . malicious code attempt to persist , must swap slow , unchecked off-chip storage , cause detectable timing delay .",Cryptography and Security,26/09/2025
10.48550/arXiv.2509.22745,defend moe llm harmful fine-tuning safety routing alignment,"Jaehan Kim, Minkyoo Song, Seungwon Shin, Sooel Son","recent large language model ( llms ) have increasingly adopt mixture-of-expert ( moe ) architecture efficiency . moe-base llms heavily depend superficial safety mechanism harmful input be route safety-critical expert . however , analysis reveal route decision harmful input drift significantly fine-tune , expose critical vulnerability harmful fine-tuning ( hft ) attack . exist defense , primarily design monolithic llm , be less effective moe llm fail to prevent drift harmful input routing . to address limitation , propose safemoe , safe fine-tuning method tailor moe llms . safemoe directly mitigate route drift penalize gap routing weight fine-tuned model and initial safety-aligned model , thereby preserve safety-aligned routing harmful input safety-critical expert . experiment open-source moe llm range 7b 141b parameter demonstrate safemoe effectively mitigate hft attack , reduce harmfulness score olmoe 62 . 0 5 . 0 , example , maintain task utility 1 % degradation and incur only 2 % overhead . significantly outperform state-of-the-art defense method safeguard llm fine-tuning and remain effective recent large-scale moe llm such gpt-oss and llama 4 . implementation be available https://anonymous.4open.science/r/safemoe.",Cryptography and Security,26/09/2025
10.48550/arXiv.2509.22732,bidirectional intention inference enhances llms ' defense multi-turn jailbreak attacks,"Haibo Tong, Dongcheng Zhao, Guobin Shen, Xiang He, Dachuan Lin, Feifei Zhao, Yi Zeng","remarkable capability large language models ( llms ) have raise significant safety concern , particularly regard "" jailbreak "" attack exploit adversarial prompt to bypass safety alignment mechanism . exist defense research primarily focus single-turn attack , multi-turn jailbreak attack progressively break safeguard conceal malicious intent and tactical manipulation , ultimately render conventional single-turn defense ineffective . to address critical challenge , propose bidirectional intention inference defense ( biid ) . method integrate forward request-based intention inference backward response-based intention retrospection , establish bidirectional synergy mechanism to detect risk conceal seemingly benign input , thereby construct more robust guardrail effectively prevent harmful content generation . propose method undergo systematic evaluation compare no-defense baseline and seven representative defense method three llm and two safety benchmark 10 different attack method . experimental result demonstrate propose method significantly reduce attack success rate ( asr ) single-turn and multi-turn jailbreak attempt , outperform exist baseline method effectively maintain practical utility . notably , comparative experiment three multi-turn safety dataset far validate propose model ’s significant advantage other defense approach .",Cryptography and Security,25/09/2025
10.48550/arXiv.2509.22723,"responsible diffusion : comprehensive survey safety , ethics , and trust diffusion model","Kang Wei, Xin Yuan, Fushuo Huo, Chuan Ma, Long Yuan, Songze Li, Ming Ding, Dacheng Tao","diffusion model ( dms ) have be investigate various domain due ability to generate high-quality datum , thereby attract significant attention . however , similar traditional deep learning system , also exist potential threat dms . to provide advanced and comprehensive insight safety , ethic , and trust dms , survey comprehensively elucidate framework , threat , and countermeasure . threat and countermeasure be systematically examine and categorize to facilitate thorough analysis . furthermore , introduce specific example dms be use , danger might bring , and way to protect danger . finally , discuss key lesson learn , highlight open challenge relate dm security , and outline prospective research direction critical field . work aim to accelerate progress not only technical capability generative artificial intelligence but also maturity and wisdom application .",Cryptography and Security,25/09/2025
10.48550/arXiv.2509.22663,security friction quotient zero trust identity policy empirical validation,Michel Youssef,"define practical method to quantify trade-off security and operational friction identity control zero trust program . introduce security friction quotient ( sfq ) and evaluate widely use conditional access policy use simulated authentication trace capture enterprise-like characteristic cohort n=1 , 200n=1{ , }200 user 12-week horizon . result report effect size 95 % confidence interval n=2 , 000n=2{ , }000 monte carlo run policy . prove clarity property ( boundedness , monotonic response , weight identifiability ) and corroborate approach field observation passkey deployment . sfq provide interpretable , reproducible metric to support policy design , review , and continuous improvement .",Cryptography and Security,02/09/2025
10.48550/arXiv.2509.25145,quantitative quantum soundness multipartite compile nonlocal game,"Matilde Baroni, Igor Klep, Dominik Leichtle, Marc-Olivier Renou, Ivan Šupić, Lucas Tendick, Xiangling Xu","compile nonlocal game transfer power bell-type multi-prover test single-device setting replace spatial separation cryptography . concretely , klvy compiler ( stoc ' 23 ) map multi-prover game interactive single-prover protocol , use quantum homomorphic encryption . crucial security property such compiler be quantum soundness , ensure dishonest quantum prover can not exceed original game ’s quantum value . practical cryptographic implementation , soundness must be quantitative , provide concrete bound , rather merely asymptotic . quantitative quantum soundness have be establish klvy compiler bipartite case , have only be show asymptotically multipartite game . be significant gap , multipartite nonlocality exhibit phenomena bipartite analogue , and difficulty enforce space-like separation make single-device compilation especially compelling . work close gap show quantitative quantum soundness klvy compiler multipartite nonlocal game . way , introduce npa-like hierarchy quantum instrument and prove completeness , thereby characterize correlation operationally-non-signale sequential strategy . far develop novel geometric argument decomposition sequential strategy signal and non-signaling part , might be independent interest .",Cryptography and Security,29/09/2025
10.48550/arXiv.2509.24515,agentic specification generator move programs,"Yu-Fu Fu, Meng Xu, Taesoo Kim","llm-base specification generation be gain traction , exist tool primarily focus mainstream programming language c , java , and even solidity , leave emerge and yet verification-oriented language move underexplored . paper , introduce msg , automate specification generation tool design move smart contract . msg aim to highlight key insight uniquely present apply llm-base specification generation new ecosystem . specifically , msg demonstrate llms exhibit robust code comprehension and generation capability even non-mainstream language . msg successfully generate verifiable specification 84 % test move function and even identify clause previously overlook expert . additionally , msg show explicitly leverage specification language feature agentic , modular design improve specification quality substantially ( generate 57 % more verifiable clause conventional design ) . incorporate feedback verification toolchain far enhance effectiveness msg , lead 30 % increase generate verifiable specification .",Cryptography and Security,29/09/2025
10.48550/arXiv.2509.24488,sanitize response : mitigating privacy leakage large language model,"Wenjie Fu, Huandong Wang, Junyao Gao, Guoan Wan, Tao Jiang","large language models ( llms ) achieve remarkable success wide range application , such chatbot and code copilot , concern surround generation harmful content have come increasingly focus . significant advance align llms safety and ethical standard , adversarial prompt can still be craft elicit undesirable response . exist mitigation strategy be predominantly base post-hoc filtering , introduce substantial latency or computational overhead , and be incompatible token-level streaming generation . work , introduce self-sanitize , novel llm-driven mitigation framework inspire cognitive psychology , emulate human self-monitor and self-repair behavior conversation . self-sanitize comprise lightweight self-monitor module continuously inspect high-level intention llm token level representation engineering , and self-repair module perform in-place correction harmful content initiate separate review dialogue . design allow real-time streaming monitoring and seamless repair , negligible impact latency and resource utilization . give privacy-invasive content have often be insufficiently focus previous study , perform extensive experiment four llm three privacy leakage scenario . result demonstrate self-sanitize achieve superior mitigation performance minimal overhead and degrade utility llms , offer practical and robust solution safe llm deployment . code be available follow link111https://github.com/wjfu99/llm˙self˙sanitize",Cryptography and Security,29/09/2025
10.48550/arXiv.2509.24484,limitations pseudorandom unitaries,"Prabhanjan Ananth, Aditya Gulati, Yao-Ting Lin","pseudorandom unitarie ( prus ) , one key quantum pseudorandom notion , be efficiently computable unitarie be computationally indistinguishable haar random unitarie . be evidence to believe pru be weak one-way function , so far relationship other quantum cryptographic primitive ( be plausibly weak one-way function ) have not be fully establish .",Cryptography and Security,29/09/2025
10.48550/arXiv.2509.24432,pseudorandom unitaries haar random oracle model,"Prabhanjan Ananth, John Bostanci, Aditya Gulati, Yao-Ting Lin","quantum haar random oracle model be idealized model party have access single haar random unitary and inverse . construct strong pseudorandom unitarie quantum haar random oracle model . strictly improve prior work either only prove existence pseudorandom unitarie inverseless quantum haar random oracle model [ ananth , bostanci , gulati , lin , eurocrypt 2025 ] or prove existence weak notion ( imply strong pseudorandom unitarie ) quantum haar random oracle model [ hhan , yamada , 2024 ] . result also present viable approach build quantum pseudorandomness random quantum circuit and analyze pseudorandom object nature .",Cryptography and Security,29/09/2025
10.48550/arXiv.2509.24368,watermarking diffusion language model,"Thibaud Gloaguen, Robin Staab, Nikola Jovanović, Martin Vechev","introduce first watermark tailor diffusion language model ( dlm ) , emergent llm paradigm able to generate token arbitrary order , contrast standard autoregressive language model ( arlms ) generate token sequentially . have be much work arlm watermarking , key challenge attempt to apply scheme directly dlm setting be rely previously generate token , be not always available dlm generation . work address challenge : ( i ) apply watermark expectation context even context token be yet to be determine , and ( ii ) promote token increase watermark strength use context other token . be accomplish keep watermark detector unchanged . experimental evaluation demonstrate dlm watermark lead > 99 % true positive rate minimal quality impact and achieve similar robustness exist arlm watermark , enable first time reliable dlm watermarking . code be available here .",Cryptography and Security,29/09/2025
10.48550/arXiv.2509.24032,sandcell : sandboxing rust unsafe code,"Jialun Zhang, Merve Gülmez, Thomas Nyman, Gang Tan","rust be modern system programming language ensure memory safety enforce ownership and borrowing rule compile time . unsafe keyword allow programmer to bypass restriction , introduce significant risk . various approach isolate unsafe code to protect safe rust vulnerability have be propose , yet method provide only fix isolation boundary and do not accommodate expressive policy require sandboxe both safe and unsafe code . paper present sandcell flexible and lightweight isolation rust leverage exist syntactic boundary . sandcell allow programmer to specify component to sandbox minimal annotation effort , enable fine-grained control isolation . system also introduce novel technique to minimize overhead transfer datum sandbox . evaluation demonstrate sandcell ’s effectiveness prevent vulnerability various rust application maintain reasonable performance overhead .",Cryptography and Security,28/09/2025
10.48550/arXiv.2509.23893,dynamic orthogonal continual fine-tuning mitigate catastrophic forgettings,"Zhixin Zhang, Zeming Wei, Meng Sun","catastrophic forgetting remain critical challenge continual learning large language model ( llms ) , model struggle to retain performance historical task fine-tune new sequential datum access past dataset . paper , first reveal drift functional direction fine-tuning process be key reason exist regularization-based method fail long-term llm continual learning . to address , propose dynamic orthogonal continual ( doc ) fine-tuning , novel approach track drift functional direction and dynamically update fine-tuning process . furthermore , adjust gradient new task parameter to be orthogonal track historical function direction , method mitigate interference new and old task . extensive experiment various llm continual learning benchmark demonstrate approach outperform prior method , effectively reduce catastrophic forgetting and provide robust tool continuous llm fine-tuning . code be available https://github.com/meloxxxxxx/doc .",Cryptography and Security,28/09/2025
10.48550/arXiv.2509.23882,"quant fever , reasoning blackholes , schrodinger 's compliance , and more : probe gpt-oss-20b","Shuyi Lin, Tian Lu, Zikai Wang, Bo Wen, Yibo Zhao, Cheng Tan","openai ’s gpt‑oss family provide open‑weight language model explicit chain‑of‑thought ( cot ) reasoning and harmony prompt format . summarize extensive security evaluation gpt‑oss‑20b probe model ’s behavior different adversarial condition . use jailbreak oracle ( jo ) [ 1 ] , systematic llm evaluation tool , study uncover several failure mode include quant fever , reasoning blackhole , schrodinger ’s compliance , reason procedure mirage , and chain‑oriented prompting . experiment demonstrate behavior can be exploit gpt-oss-20b model , lead severe consequence .",Cryptography and Security,28/09/2025
10.48550/arXiv.2509.23789,visual cot make vlms smarter but more fragile,"Chunxue Xu, Yiwei Wang, Yujun Cai, Bryan Hooi, Songze Li","chain-of-thought ( cot ) technique have significantly enhance reasoning vision-language model ( vlms ) . extend paradigm , visual cot integrate explicit visual edit , such cropping or annotate region interest , reasoning process , achieve superior multimodal performance . however , robustness visual cot-base vlm image-level noise remain unexplored . paper , present first systematic evaluation visual cot robustness visual perturbation . benchmark span 12 image corruption type 4 visual question answering ( vqa ) dataset , enable comprehensive comparison vlms use visual cot , and vlm do not . result reveal integrate visual cot consistently improve absolute accuracy regardless input image be clean or corrupt noise ; however , also increase sensitivity to input perturbation , result sharp performance degradation compare standard vlm . extensive analysis , identify intermediate reasoning component visual cot , i.e. , edit image patch , primary source fragility . build analysis , propose plug-and-play robustness enhancement method integrate ground dino model visual cot pipeline , provide high-confidence local visual cue to stabilize reasoning . work reveal clear fragility pattern visual cot and offer effective , architecture-agnostic solution enhance visual robustness .",Cryptography and Security,28/09/2025
10.48550/arXiv.2509.23694,safesearch : automated red-teaming safety llm-base search agent,"Jianshuo Dong, Sheng Guo, Hao Wang, Zhuotao Liu, Tianwei Zhang, Ke Xu, Minlie Huang, Han Qiu","search agent connect llms internet , enable access broad and more up-to-date information . however , unreliable search result may also pose safety threat to end user , establish new threat surface . work , conduct two in-the-wild experiment to demonstrate both prevalence low-quality search result and potential to misguide agent behavior . to counter threat , introduce automate red-teame framework be systematic , scalable , and cost-efficient , enable lightweight and harmless safety assessment search agent . build framework , construct safesearch benchmark , include 300 test case cover five category risk ( e.g. , misinformation and indirect prompt injection ) . use benchmark , evaluate three representative search agent scaffold , cover search workflow , tool-calling , and deep research , 7 proprietary and 8 open-source backend llms . result reveal substantial vulnerability llm-base search agent : expose unreliable website , high asr reach 90 . 5 % gpt-4 . 1-mini search workflow setting . moreover , analysis highlight limited effectiveness common defense practice , such reminder prompt . emphasize value framework promote transparency safe agent development . codebase and test case be publicly available : https://github.com/jianshuod/safesearch .",Cryptography and Security,28/09/2025
10.48550/arXiv.2509.23558,formalization drive llm prompt jailbreaking reinforcement learning,"Zhaoqi Wang, Daqing He, Zijian Zhang, Xin Li, Liehuang Zhu, Meng Li, Jiamou Liu","large language model ( llms ) have demonstrate remarkable capability , yet also introduce novel security challenge . instance , prompt jailbreake attack involve adversary craft sophisticated prompt elicit response llms deviate human value . to uncover vulnerability llm alignment method , propose pass framework ( prompt jailbreaking semantic and structural formalization ) . specifically , pass employ reinforcement learning to transform initial jailbreak prompt formalize description , enhance stealthiness and enable bypass exist alignment defense . jailbreak output be then structure graphrag system , leverage extract relevant term and formalize symbol contextual input original query , strengthen subsequent attack and facilitate more effective jailbreak . conduct extensive experiment common open-source model , demonstrate effectiveness attack .",Cryptography and Security,28/09/2025
10.48550/arXiv.2509.23449,embedding : interpretable feature extraction binary code similarity,"Charles E. Gagnon, Steven H. H. Ding, Philippe Charland, Benjamin C. M. Fung","binary code similarity detection be core task reverse engineering . support malware analysis and vulnerability discovery identify semantically similar code different contexts . modern method have progress manually engineer feature vector representation . hand-crafted statistic ( e.g. , operation ratio ) be interpretable , but shallow and fail to generalize . embedding-based method overcome learn robust cross-setting representation , but representation be opaque vector prevent rapid verification . also face scalability–accuracy trade-off , high-dimensional nearest-neighbor search require approximation reduce precision . current approach thus force compromise interpretability , generalizability , and scalability .",Cryptography and Security,27/09/2025
10.48550/arXiv.2509.23179,near-cache architectural framework cryptographic computing,"Jingyao Zhang, Elaheh Sadredini","recent advancement post-quantum cryptographic algorithm have lead standardization national institute standards and technology ( nist ) to safeguard information security post-quantum era . algorithm , however , employ public key and signature be 3 9×\time long use pre-quantum cryptography , result significant performance and energy efficiency overhead . critical bottleneck identify analysis be cache bandwidth . limitation motivate adoption on-chip in-/near-cache computing , computing paradigm offer high-performance , exceptional energy efficiency , and flexibility to accelerate post-quantum cryptographic algorithm . analysis exist work reveal challenge integrate in-/near-cache computing modern computer system and performance limitation external bandwidth limitation , highlight need innovative solution can seamlessly integrate exist system performance and energy efficiency issue . paper , introduce near-cache-slice computing paradigm support customization and virtual address , name crypto-near-cache ( cnc ) , design to accelerate post-quantum cryptographic algorithm and other application . place sram array bitline computing capability cache slice , high internal bandwidth and short datum movement be achieve native support virtual addressing . isa extension to facilitate cnc be also propose , detailed discussion implementation aspect core/cache datapath .",Cryptography and Security,27/09/2025
10.48550/arXiv.2509.23101,quantum-ready blockchain fraud detection ensemble graph neural networks,"M.Z. Haider, Tayyaba Noreen, M. Salman","blockchain business application and cryptocurrencie such enable secure , decentralize value transfer , yet pseudonymous nature create opportunity illicit activity , challenge regulator and exchange anti-money laundering ( aml ) enforcement . detect fraudulent transaction blockchain network require model can capture structural and temporal dependency remain resilient noise , imbalance , and adversarial behavior . work , propose ensemble framework integrate graph convolutional networks ( gcn ) , graph attention networks ( gat ) , and graph isomorphism networks ( gin ) to enhance blockchain fraud detection . use real-world elliptic dataset , tune soft voting ensemble achieve high recall illicit transaction maintain false positive rate 1 % , beat individual gnn model and baseline method . modular architecture incorporate quantum-ready design hook , allow seamless future integration quantum feature mapping and hybrid quantum–classical graph neural network . ensure scalability , robustness , and long-term adaptability quantum computing technology mature . finding highlight ensemble gnn practical and forward-looking solution real-time cryptocurrency monitoring , provide both immediate aml utility and pathway quantum-enhanced financial security analytic .",Cryptography and Security,27/09/2025
10.48550/arXiv.2509.22684,zkprophet : understand performance zero-knowledge proofs gpu,"Tarunesh Verma, Yichao Yuan, Nishil Talati, Todd Austin","zero-knowledge proofs ( zkp ) be protocol construct cryptographic proof to demonstrate knowledge secret input computation reveal information secret . zkp enable novel application private and verifiable computing such anonymize cryptocurrencie and blockchain scaling and have see adoption several real-world system . prior work have accelerate zkp gpu leverage inherent parallelism core computation kernel multi-scalar multiplication ( msm ) . however , find systematic characterization execution bottleneck zkp , as well scalability modern gpu architecture , be miss literature .",Cryptography and Security,17/09/2025
10.48550/arXiv.2509.22428,privacy mechanism design base empirical distribution,"Leonhard Grosse, Sara Saeidian, Mikael Skoglund, Tobias J. Oechtering","pointwise maximal leakage ( pml ) be per-outcome privacy measure base threat model quantitative information flow . privacy guarantee pml rely knowledge distribution generate private datum . work , propose framework pml privacy assessment and mechanism design empirical estimate data-generating distribution . extend pml framework to consider set data-generating distribution , arrive bound worst-case leakage give set . use bound large-deviation bound literature to provide method obtain distribution-independent ( ε , δ)(\varepsilon , \delta)-pml guarantee data-generating distribution be estimate available datum sample . provide optimal binary mechanism , and show mechanism design type uncertainty data-generating distribution reduce linearly constrained convex program . far , show optimal mechanism design distribution estimate can be use . finally , apply tool leakage assessment laplace mechanism and gaussian mechanism binary private datum , and numerically show present approach mechanism design can yield significant utility increase compare local differential privacy , retain similar privacy guarantee .",Cryptography and Security,26/09/2025
10.48550/arXiv.2509.22280,"global analysis cyber threats energy sector : "" current conflict "" geopolitical perspective","Gustavo Sánchez, Ghada Elbez, Veit Hagenmeyer","escalate frequency and sophistication cyber threat increase need comprehensive understanding . paper explore intersection geopolitical dynamic , cyber threat intelligence analysis , and advanced detection technology , focus energy domain . leverage generative artificial intelligence to extract and structure information raw cyber threat description , enable enhance analysis . conduct geopolitical comparison threat actor origin and target region multiple database , provide insight trend general threat landscape . additionally , evaluate effectiveness cybersecurity tool — particular emphasis learning-based technique — detect indicator compromise energy-targeted attack . analysis yield new insight , provide actionable information researcher , policy maker , and cybersecurity professional .",Cryptography and Security,26/09/2025
10.48550/arXiv.2509.22256,secure and efficient access control computer-use agents context space,"Haochen Gong, Chenxiao Li, Rui Chang, Wenbo Shen","large language model ( llm)-base computer-use agent represent convergence ai and os capability , enable natural language to control system- and application-level function . however , llms ' inherent uncertainty issue , grant agent control computer pose significant security risk . agent action deviate user intention , can cause irreversible consequence . exist mitigation approach , such user confirmation and llm-base dynamic action validation , still suffer limitation usability , security , and performance . to address challenge , propose csagent , system-level , static policy-based access control framework computer-use agent . to bridge gap static policy and dynamic context and user intent , csagent introduce intent- and context-aware policy , and provide automated toolchain to assist developer construct and refine . csagent enforce policy optimize os service , ensure agent action can only be execute specific user intent and contexts . csagent support protect agent control computer diverse interface , include api , cli , and gui . implement and evaluate csagent , successfully defend more 99 . 36 % attack introduce only 6 . 83 % performance overhead .",Cryptography and Security,26/09/2025
10.48550/arXiv.2509.22215,"learn , check , test -- security testing use automata learning and model checking","Stefan Marksteiner, Mikael Sjödin, Marjan Sirjani","cyber-physical system be part industrial system and critical infrastructure . therefore , should be examine comprehensive manner to verify correctness and security . same time , complexity such system demand such examination to be systematic and , possible , automate efficiency and accuracy . method can be useful context be model checking . however , require model faithfully represent behavior examine system . obtain model be not trivial , many system can be examine only black box setting due , e.g. , long supply chain or secrecy . therefore utilize active black box learn technique to infer behavioral model form mealy machine such system and translate form can be evaluate use model checker . end , will investigate cyber-physical system black box use external communication interface . first annotate model proposition map context information respective protocol model use context-based proposition maps ( cpms ) . gain annotate mealy machine resemble kripke structure . then formally define template , use to transfer structure format to be process model checker . far define generic security property base basic security requirement ( authentication , confidentiality , privilege level , and key validity ) . use cpm , can instantiate property meaningful context to check specific protocol , make approach flexible and scalable . furthermore , gain model can be easily alter to introduce non-deterministic behavior ( timeout ) or fault and examine property still hold different condition . lastly , demonstrate versatility approach provide case study very different system ( passport and automotive control unit ) , speak different communication protocol ( nfc and uds ) , check same tool chain and same security property .",Cryptography and Security,26/09/2025
10.48550/arXiv.2509.22213,accuracy-first rényi differential privacy and post-processing immunity,"Ossi Räisä, Antti Koskela, Antti Honkela","accuracy-first perspective differential privacy address important shortcoming allow data analyst to adaptively adjust quantitative privacy bind instead stick predetermine bind . exist work accuracy-first perspective have neglect important property differential privacy know post-processe immunity , ensure adversary be not able to weaken privacy guarantee post-processing . address gap determine exist definition accuracy-first perspective have post-processing immunity , and do not . only definition post-processing immunity , pure ex-post privacy , lack useful tool practical problem , such ex-post analogue gaussian mechanism , and algorithm to check accuracy separate private validation set be high enough . to address , propose new definition base rényi differential privacy have post-processe immunity , and develop basic theory and tool need practical application . demonstrate practicality theory application synthetic datum generation , algorithm successfully adjust privacy bind accuracy threshold be meet private validation dataset .",Cryptography and Security,26/09/2025
10.48550/arXiv.2509.22154,collusion-driven impersonation attack channel-resistant rf fingerprinting,"Zhou Xu, Guyue Li, Zhe Peng, Aiqun Hu","radio frequency fingerprint ( rff ) be promising device identification technology , recent research shift robustness security grow concern vulnerability . date , security rff basic spoofing such mac address tamper have be validate , resilience advanced mimicry remain unknown . to address gap , propose collusion-driven impersonation attack achieve rf-level mimicry , successfully break rff identification system diverse environment . specifically , attacker synchronize collude receiver to match centralized logarithmic power spectrum ( clps ) legitimate transmitter ; colluder deem clps identical , victim receiver will also accept forge fingerprint , complete rf-level spoof . give distribution clps feature be relatively concentrated and have clear underlying structure , design spoof signal generation network integrate variational autoencoder ( vae ) multi-objective loss function to enhance similarity and deceptive capability generate sample . carry extensive simulation , validate cross-channel attack environment incorporate standard channel variation include additive white gaussian noise ( awgn ) , multipath fading , and doppler shift . result indicate propose attack scheme essentially maintain success rate 95 % different channel condition , reveal effectiveness attack .",Cryptography and Security,26/09/2025
10.48550/arXiv.2509.22143,express lane spam and centralization : empirical analysis arbitrum 's timeboost,"Johnnatan Messias, Christof Ferreira Torres","defi application be vulnerable mev , specialized actor profit reorder or inserting transaction . to mitigate latency race and internalize mev revenue , arbitrum introduce timeboost , auction-based transaction sequence mechanism grant short-term priority access express lane . paper present first large-scale empirical study timeboost , analyze 11 . 5 million express lane transaction and 151 thousand auction april and july 2025 . result reveal five main finding . first , express lane control be highly centralize , two entity win more 90 % auction . second , express lane access provide early inclusion , profitable mev opportunity cluster end block , limit value priority access . third , approximately 22 % time-boosted transaction be revert , indicate timeboost do not effectively mitigate spam . fourth , secondary market resell express lane right have collapse poor execution reliability and unsustainable economic . finally , auction competition decline time , lead steadily reduce revenue arbitrum dao . take together , finding show timeboost fail to deliver state goal fairness , decentralization , and spam reduction . instead , reinforce centralization and narrow adoption , highlight limitation auction-based ordering mechanism fair transaction sequence rollup .",Cryptography and Security,26/09/2025
10.48550/arXiv.2509.22126,guidance watermarking diffusion model,"Enoal Gesny, Eva Giboulot, Teddy Furon, Vivien Chappelier","paper introduce novel watermarking method diffusion model . be base guide diffusion process use gradient compute off-the-shelf watermark decoder . gradient computation encompass different image augmentation , increase robustness attack decoder be not originally robust , retrain or fine-tuning . method effectively convert post-hoc watermarking scheme in-generation embed diffusion process . show approach be complementary to watermarke technique modify variational autoencoder end diffusion process . validate method different diffusion model and detector . watermarking guidance do not significantly alter generate image give seed and prompt , preserve both diversity and quality generation .",Cryptography and Security,26/09/2025
10.48550/arXiv.2509.22040,""" ai , shell "" : demystify prompt injection attacks agentic ai code editor","Yue Liu, Yanjie Zhao, Yunbo Lyu, Ting Zhang, Haoyu Wang, David Lo","agentic ai code editor drive large language model have recently become more popular ability to improve developer productivity software development . modern editor such cursor be design not just code completion , but also more system privilege complex code task ( e.g. , run command terminal , access development environment , and interact external system ) . bring close "" fully automate programming "" dream , also raise new security concern . study , present first empirical analysis prompt injection attack target high-privilege agentic ai code editor . show attacker can remotely exploit system poison external development resource malicious instruction , effectively hijack ai agent to run malicious command , turn "" ai "" "" attacker ’s shell "" . to perform analysis , implement aishelljack , automate testing framework assess prompt injection vulnerability agentic ai code editor . aishelljack contain 314 unique attack payload cover 70 technique mitre att&ck framework . use aishelljack , conduct large-scale evaluation github copilot and cursor , and evaluation result show attack success rate can reach as high 84 % execute malicious command . moreover , attack be prove effective wide range objective , range initial access and system discovery credential theft and datum exfiltration .",Cryptography and Security,26/09/2025
10.48550/arXiv.2509.22027,nanotag : systems support efficient byte-granular overflow detection arm mte,"Mingkai Li, Hang Ye, Joseph Devietti, Suman Jana, Tanvir Ahmed Khan","memory safety bug , such buffer overflow and use-after-free , be lead cause software safety issue production . software-base approach , e.g. , address sanitizer ( asan ) , can detect such bug high precision , but prohibitively high overhead . arm ’s memory tagging extension ( mte ) offer promising alternative to detect bug hardware much low overhead . however , paper , perform thorough investigation google pixel 8 , first production implementation arm mte , and show mte can only achieve coarse precision bug detection compare software-based approach such asan , mainly 16-byte tag granularity .",Cryptography and Security,26/09/2025
10.48550/arXiv.2509.22022,eliminate exponential key growth prg-base distribute point function,"Marc Damie, Florian Hahn, Andreas Peter, Jan Ramon","distribute point functions ( dpfs ) enable share secret point function multiple party , support privacy-preserving technology such private information retrieval , and anonymous communication . 2-party prg-base scheme logarithmic key size have be know decade , extend solution multi-party setting have prove challenge . particular , prg-base multi-party dpf have historically struggle practicality due key size grow exponentially number party and field size .",Cryptography and Security,26/09/2025
10.48550/arXiv.2509.21884,can not steal : mitigate prompt leakages llm system vectors,"Bochuan Cao, Changjiang Li, Yuanpu Cao, Yameng Ge, Ting Wang, Jinghui Chen","large language model ( llms ) have be widely adopt various application , leverage customized system prompt diverse task . face potential system prompt leakage risk , model developer have implement strategy to prevent leakage , primarily disable llm repeat context encounter know attack pattern . however , remain vulnerable new and unforeseen prompt-leaking technique . paper , first introduce simple yet effective prompt leak attack to reveal such risk . attack be capable extract system prompt various llm-base application , even sota llm model such gpt-4o or claude 3 . 5 sonnet . finding far inspire to search fundamental solution problem have system prompt context . end , propose sysvec , novel method encode system prompt internal representation vector rather raw text . do so , sysvec minimize risk unauthorized disclosure preserve llm ’s core language capability . remarkably , approach not only enhance security but also improve model ’s general instruction-following ability . experimental result demonstrate sysvec effectively mitigate prompt leakage attack , preserve llm ’s functional integrity , and help alleviate forgetting issue long-context scenario .",Cryptography and Security,26/09/2025
10.48550/arXiv.2509.21843,sbfa : single sneaky bit flip attack to break large language model,"Jingkai Guo, Chaitali Chakrabarti, Deliang Fan","model integrity large language model ( llms ) have become press security concern massive online deployment . prior bit-flip attacks ( bfas)—a class popular ai weight memory fault-injection techniques—can severely compromise deep neural networks ( dnn ): as few ten bit flip can degrade accuracy random guessing . recent study extend bfa llms and reveal , intuition well robustness modularity and redundancy , only handful adversarial bit flip can also cause llms ' catastrophic accuracy degradation . however , exist bfa method typically focus either integer or floating-point model separately , limit attack flexibility . moreover , floating-point model , random bit flip often cause perturb parameter extreme value ( e.g. , flip exponent bit ) , make not stealthy and lead numerical runtime error ( e.g. , invalid tensor value ( nan/inf ) ) . work , first time , propose sbfa ( sneaky bit-flip attack ) , collapse llm performance only one single bit flip keep perturb value benign layer-wise weight distribution . be achieve iterative searching and rank define parameter sensitivity metric , impactscore , combine gradient sensitivity and perturbation range constrain benign layer-wise weight distribution . novel lightweight skip search algorithm be also propose to greatly reduce search complexity , lead successful sbfa search take only ten minute sota llms . qwen , llama , and gemma model , only one single bit flip , sbfa successfully degrade accuracy random level mmlu and sst-2 both bf16 and int8 datum format . remarkably , flip single bit billion parameter reveal severe security concern sota llm model .",Cryptography and Security,26/09/2025
10.48550/arXiv.2509.21821,sok : potential and challenges large language models reverse engineering,"Xinyu Hu, Zhiwei Fu, Shaocong Xie, Steven H. H. Ding, Philippe Charland","reverse engineering ( re ) be central to software security , enable task such vulnerability discovery and malware analysis , but remain labor-intensive and require substantial expertise . early advance deep learning start automate part re , particularly malware detection and vulnerability classification . more recently , rapidly grow body work have apply large language models ( llms ) similar purpose . role compare prior machine learning remain unclear , effort simply adapt exist pipeline minimal change other seek to exploit broad reasoning and generative ability . difference , combine varied problem definition , method , and evaluation practice , limit comparability , reproducibility , and cumulative progress . paper systematize field review 44 research paper , include peer-reviewed publication and preprint , and 18 additional open-source project apply llm re . propose taxonomy organize exist work objective , target , method , evaluation strategy , and datum scale . analysis identify strength and limitation , highlight reproducibility and evaluation gap , and examine emerge risk . conclude open challenge and future research direction aim to guide more coherent and security-relevant application llms re .",Cryptography and Security,26/09/2025
10.48550/arXiv.2509.21786,lattice-based dynamic $ k$-times anonymous authentication,"Junjie Song, Jinguang Han, Man Ho Au, Rupeng Yang, Chao Sun","development internet , privacy have become close concern user . anonymous authentication play important role privacy-preserving system . kk-time anonymous authentication ( kk-taa ) scheme allow member group to be authenticate anonymously application provider kk time . consider quantum computing attack , lattice-based kk-taa be introduce . however , exist scheme do not support dynamically grant and revoke user . paper , construct first lattice-based dynamic kk-taa , offer limited time anonymous authentication , dynamic member management , and post-quantum security . present concrete construction , and reduce security standard complexity assumption . notably , compare exist lattice-based kk-taa , scheme be efficient term communication cost .",Cryptography and Security,26/09/2025
10.48550/arXiv.2509.21772,phishlumos : adaptive multi-agent system proactive phishing campaign mitigation,"Daiki Chiba, Hiroki Nakano, Takashi Koide","phishing attack be significant societal threat , disproportionately harm vulnerable population and erode trust essential digital service . current defense be often reactive , fail modern evasive tactic cloak conceal malicious content . to address , introduce phishlumos , adaptive multi-agent system proactively mitigate entire attack campaign . confront core cybersecurity imbalance : attacker can easily scale operation , defense remain intensive expert task . instead be block evasion , phishlumos treat critical signal to investigate underlie infrastructure . large language model ( llm)-powered agent uncover share hosting , certificate , and domain registration pattern . real-world datum , system identify 100 % campaign median case , week confirmation cybersecurity expert . phishlumos demonstrate practical shift reactive url blocking proactive campaign mitigation , protect user be harm and make digital world safe .",Cryptography and Security,26/09/2025
10.48550/arXiv.2509.21768,psrt : accelerate lrm-base guard models prefilled safe reasoning trace,"Jiawei Zhao, Yuang Qi, Weiming Zhang, Nenghai Yu, Kejiang Chen","large reasoning models ( lrms ) have demonstrate remarkable performance task such mathematic and code generation . motivate strength , recent work have empirically demonstrate effectiveness lrms guard model improve harmful query detection . however , lrms typically generate long reasoning trace inference , cause substantial computational overhead . paper , introduce psrt , method replace model ’s reasoning process prefille safe reasoning trace , thereby significantly reduce inference cost lrms . concretely , psrt prefill "" safe reasoning virtual token "" construct dataset and learn continuous embedding . aid indicator token , psrt enable harmful-query detection single forward pass preserve classification effectiveness lrms . evaluate psrt 7 model , 13 dataset , and 8 jailbreak method . term efficiency , psrt completely remove overhead generate reasoning token inference . term classification performance , psrt achieve nearly identical accuracy , only minor average f1 drop 0 . 015 7 model and 5 datasets111our code be available https://github.com/weiyezhimeng/psrt ..",Cryptography and Security,26/09/2025
