DOI,Title,Authors,Abstract,Section,Date
10.48550/arXiv.2510.05090,"finish first , perfect later : test-time token-level cross-validation diffusion large language model","Runchu Tian, Junxia Cui, Xueqiang Xu, Feng Yao, Jingbo Shang","diffusion large language model ( dllms ) have recently emerge promising alternative autoregressive ( ar ) model , offer advantage such accelerate parallel decoding and bidirectional context modeling . however , vanilla decode strategy discrete dllms suffer critical limitation : once token be accept , can no long be revise subsequent step . result , early mistake persist iteration , harm both intermediate prediction and final output quality . to address issue , propose tolerator ( token-level cross-validation refinement ) , training-free decode strategy leverage cross-validation predict token . exist method follow single progressive unmask procedure , tolerator introduce two-stage process : ( i ) sequence fill-up and ( ii ) iterative refinement remaske and decode subset token treat remain context . design enable previously accept token to be reconsider and correct necessary , lead more reliable diffusion decode output . evaluate tolerator five standard benchmark cover language understanding , code generation , and mathematic . experiment show method achieve consistent improvement baseline same computational budget . finding suggest decode algorithm be crucial realize full potential diffusion large language model . code and datum be publicly available .",Computation and Language,06/10/2025
10.48550/arXiv.2510.05087,teachlm : post-traine llm education use authentic learning data,"Janos Perczel, Jin Chow, Dorottya Demszky","promise generative ai to revolutionize education be constrain pedagogical limit large language model ( llms ) . major issue be lack access high-quality training datum reflect learning actual student . prompt engineering have emerge stopgap , but ability prompt to encode complex pedagogical strategy rule-based natural language be inherently limit . to address gap introduce teachlm – llm optimize teach parameter-efficient fine-tuning state-of-the-art model . teachlm be train dataset comprise 100 , 000 hour one-on-one , longitudinal student-tutor interaction maintain polygence , undergo rigorous anonymization process to protect privacy . use parameter-efficient fine-tuning to develop authentic student model enable generation high-fidelity synthetic student–tutor dialogue . build capability , propose novel multi-turn evaluation protocol leverage synthetic dialogue generation to provide fast , scalable , and reproducible assessment dialogical capability llms . evaluation demonstrate fine-tune authentic learning datum significantly improve conversational and pedagogical performance – double student talk time , improve question style , increase dialogue turn 50 % , and great personalization instruction .",Computation and Language,06/10/2025
10.48550/arXiv.2510.05077,slm-mux : orchestrate small language model reasoning,"Chenyu Wang, Zishen Wan, Hao Kang, Emma Chen, Zhiqiang Xie, Tushar Krishna, Vijay Janapa Reddi, Yilun Du","rapid development language model , number small language model ( slms ) have grow significantly . do not achieve state-of-the-art accuracy , be more efficient and often excel specific task . raise natural question : can multiple slm be orchestrate system contribute effectively , achieve high accuracy individual model ? exist orchestration method have primarily target frontier model ( e.g. , gpt-4 ) and perform suboptimally apply slm . to address gap , propose three-stage approach orchestrate slm . first , introduce slm-mux , multi-model architecture effectively coordinate multiple slm . build , develop two optimization strategy : ( i ) model selection search identify most complementary slm give pool , and ( ii ) test-time scaling tailor slm-mux . approach deliver strong result : compare exist orchestration method , approach achieve to 13 . 4 % improvement math , 8 . 8 % gpqa , and 7 . 0 % gsm8k . just two slm , slm-mux outperform qwen 2 . 5 72b gpqa and gsm8 k , and match performance math . far provide theoretical analysis to substantiate advantage method . summary , demonstrate slms can be effectively orchestrate more accurate and efficient system propose approach . project page and code : https://slm-mux.github.io .",Computation and Language,06/10/2025
10.48550/arXiv.2510.05038,guided query refinement : multimodal hybrid retrieval test-time optimization,"Omri Uzan, Asaf Yehudai, Roi pony, Eyal Shnarch, Ariel Gera","multimodal encoder have push boundary visual document retrieval , match textual query token directly image patch and achieve state-of-the-art performance public benchmark . recent model rely paradigm have massively scale size query and document representation , present obstacle deployment and scalability real-world pipeline . furthermore , purely vision-centric approach may be constrain inherent modality gap still exhibit modern vision-language model . work , connect challenge paradigm hybrid retrieval , investigate lightweight dense text retriever can enhance strong vision-centric model . exist hybrid method , rely coarse-grained fusion rank or score , fail to exploit rich interaction model ’s representation space . to address , introduce guided query refinement ( gqr ) , novel test-time optimization method refine primary retriever ’s query embed use guidance complementary retriever ’s score . extensive experiment visual document retrieval benchmark , demonstrate gqr allow vision-centric model to match performance model significantly large representation , be up 14x fast and require 54x less memory . finding show gqr effectively push pareto frontier performance and efficiency multimodal retrieval . release code github repository .",Computation and Language,06/10/2025
10.48550/arXiv.2510.05025,imperceptible jailbreaking large language model,"Kuofeng Gao, Yiming Li, Chao Du, Xin Wang, Xingjun Ma, Shu-Tao Xia, Tianyu Pang","jailbreake attack vision modality typically rely imperceptible adversarial perturbation , attack textual modality be generally assume to require visible modification ( e.g. , non-semantic suffix ) . paper , introduce imperceptible jailbreak exploit class unicode character call variation selector . append invisible variation selector malicious question , jailbreak prompt appear visually identical original malicious question screen , tokenization be "" secretly "" alter . propose chain-of-search pipeline to generate such adversarial suffix to induce harmful response . experiment show imperceptible jailbreak achieve high attack success rate four align llm and generalize prompt injection attack , all produce visible modification write prompt . code be available https://github.com/sail-sg/imperceptible-jailbreak .",Computation and Language,06/10/2025
10.48550/arXiv.2510.05003,resource-efficient fine-tuning llama-3 . 2-3b medical chain-of-thought reasoning,Imran Mansha,"large language models ( llms ) be increasingly be apply healthcare , but challenge reasoning transparency , factual consistency , and domain-specific adaptability limit safe deployment clinical setting . paper present proof-of-concept study fine-tuning meta ’s llama-3 . 2 ( 3b instruct ) medical chain thought ( cot ) reasoning use unsloth framework and parameter-efficient fine-tuning ( peft ) qlora . train model freedomintelligence/medical-o1-reasoning-sft dataset , provide step-by-step reasoning trace various medical domain . fact rouge-l score remain stable 0 . 3052 and fine-tune , qualitative inspection reveal preservation reasoning style and improve interpretability performance degradation . demonstrate feasibility adapt compact llm specialized reasoning task constrain computational resource , such kaggle gpus . fine-tuned model and training pipeline be publicly release hugging face hub , offer reproducible baseline to support future research interpretable and resource-efficient medical ai .",Computation and Language,06/10/2025
10.48550/arXiv.2510.04983,"aware , sentence boundaries : contextual transformer framework identify cultural capital stem narratives","Khalid Mehtab Khan, Anagha Kulkarni","identify cultural capital ( cc ) theme student reflection can offer valuable insight help foster equitable learn environment classroom . however , theme such aspirational goal or family support be often weave narrative , rather appear direct keyword . make difficult to detect standard nlp model process sentence isolation . core challenge stem lack awareness , standard model be pre-traine general corpora , leave blind domain-specific language and narrative context inherent datum . to address , introduce aware , framework systematically attempt to improve transformer model ’s awareness nuanced task . aware have three core component : 1 ) domain awareness , adapt model ’s vocabulary linguistic style student reflection ; 2 ) context awareness , generate sentence embedding be aware full essay context ; and 3 ) class overlap awareness , employ multi-label strategy to recognize coexistence theme single sentence . result show make model explicitly aware property input , aware outperform strong baseline 2 . 1 percentage point macro-f1 and show considerable improvement theme . work provide robust and generalizable methodology text classification task meaning depend context narrative .",Computation and Language,06/10/2025
10.48550/arXiv.2510.04945,first context-free grammar apply nawatl corpora augmentation,"Juan-José Guzmán-Landa, Juan-Manuel Torres-Moreno, Miguel Figueroa-Saavedra, Ligia Quintana-Torres, Martha-Lorena Avendaño-Garrido, Graham Ranger","article introduce context-free grammar ( cfg ) nawatl language . nawatl be amerindian language π\pi-language type , i.e. language few digital resource , corpora available machine learning be virtually non-existent . objective here be to generate significant number grammatically correct artificial sentence , order to increase corpora available language model training . want to show grammar enable significantly to expand corpus nawatl call π\pi-yalli . corpus , thus enrich , enable to train algorithm such fasttext and to evaluate sentence-level semantic task . preliminary result show use grammar , comparative improvement be achieve llm . however , be observe to achieve more significant improvement , grammar model nawatl language even more effectively be require .",Computation and Language,06/10/2025
10.48550/arXiv.2510.04933,geometry truth : layer-wise semantic dynamics hallucination detection large language model,Amir Hameed Mir,"large language models ( llms ) often produce fluent yet factually incorrect statements—a phenomenon know hallucination—pose serious risk high-stakes domain . present layer-wise semantic dynamics ( lsd ) , geometric framework hallucination detection analyze evolution hidden-state semantic transformer layer . prior method rely multiple sampling pass or external verification source , lsd operate intrinsically model ’s representational space . use margin-based contrastive learning , lsd align hide activation ground-truth embedding derive factual encoder , reveal distinct separation semantic trajectory : factual response preserve stable alignment , hallucination exhibit pronounce semantic drift depth . evaluate truthfulqa and synthetic factual-hallucination dataset , lsd achieve f1-score 0 . 92 , auroc 0 . 96 , and cluster accuracy 0 . 89 , outperform selfcheckgpt and semantic entropy baseline require only single forward pass . efficiency yield 5–20×\times speedup sampling-based method sacrifice precision or interpretability . lsd offer scalable , model-agnostic mechanism real-time hallucination monitoring and provide new insight geometry factual consistency large language model .",Computation and Language,06/10/2025
10.48550/arXiv.2510.04919,do llms align task ? evaluate text-to-sql dataset alignment,"Davood Rafiei, Morgan Lindsay Heisler, Weiwei Zhang, Mohammadreza Pourreza, Yong Zhang","supervised fine-tuning ( sft ) be effective method adapt large language models ( llms ) down-stream task . however , variability training datum can hinder model ’s ability to generalize domain . paper study problem dataset alignment natural language sql ( nl2sql or text-to-sql ) , examine well sft training datum match structural characteristic target query and alignment impact model performance . hypothesize alignment can be accurately estimate compare distribution structural sql feature training set , target datum , and model ’s prediction prior sft . comprehensive experiment three large cross-domain nl2sql benchmark and multiple model family , show structural alignment be strong predictor fine-tune success . alignment be high , sft yield substantial gain accuracy and sql generation quality ; alignment be low , improvement be marginal or absent . finding highlight importance alignment-aware datum selection effective fine-tuning and generalization nl2sql task .",Computation and Language,06/10/2025
10.48550/arXiv.2510.04891,socialharmbench : reveal llm vulnerability socially harmful requests,"Punya Syon Pandey, Hai Son Le, Devansh Bhardwaj, Rada Mihalcea, Zhijing Jin","large language model ( llms ) be increasingly deploy contexts failure can have direct sociopolitical consequence . yet , exist safety benchmark rarely test vulnerability domain such political manipulation , propaganda and disinformation generation , or surveillance and information control . introduce socialharmbench , dataset 585 prompt span 7 sociopolitical category and 34 country , design to surface llms most acutely fail politically charge contexts . evaluation reveal several shortcoming : open-weight model exhibit high vulnerability harmful compliance , mistral-7b reach attack success rate as high 97%–98 % domain such historical revisionism , propaganda , and political manipulation . moreover , temporal and geographic analysis show llms be most fragile confront 21st-century or pre-20th-century contexts , and respond prompt tie region such latin america , usa , and uk . finding demonstrate current safeguard fail to generalize high-stakes sociopolitical setting , expose systematic bias and raise concern reliability llms preserve human right and democratic value . 111our socialharmbench dataset : huggingface.co/datasets/psyonp/socialharmbench , and . codebase : github.com/psyonp/socialharmbench .",Computation and Language,06/10/2025
10.48550/arXiv.2510.04850,detecting distillation data reasoning model,"Hengxiang Zhang, Hyeong Kyu Choi, Yixuan Li, Hongxin Wei","reasoning distillation have emerge efficient and powerful paradigm enhance reasoning capability large language model . however , reasoning distillation may inadvertently cause benchmark contamination , evaluation datum include distillation dataset can inflate performance metric distil model . work , formally define task distillation datum detection , be uniquely challenging partial availability distillation datum . then , propose novel and effective method token probability deviation ( tbd ) , leverage probability pattern generate output token . method be motivate analysis distilled model tend to generate near-deterministic token see question , produce more low-probability token unseen question . key idea tbd be to quantify far generate token ' probability deviate high reference probability . effect , method achieve competitive detection performance produce low score see question unseen question . extensive experiment demonstrate effectiveness method , achieve auc 0 . 918 and tpr@1 % fpr 0 . 470 s1 dataset .",Computation and Language,06/10/2025
10.48550/arXiv.2510.04849,"models lie , learn : multilingual span-level hallucination detection psiloqa","Elisei Rykov, Kseniia Petrushina, Maksim Savkin, Valerii Olisov, Artem Vazhentsev, Kseniia Titova, Alexander Panchenko, Vasily Konovalov, Julia Belikova","hallucination detection remain fundamental challenge safe and reliable deployment large language model ( llms ) , especially application require factual accuracy . exist hallucination benchmark often operate sequence level and be limit english , lack fine-grained , multilingual supervision need comprehensive evaluation . work , introduce psiloqa , large-scale , multilingual dataset annotate span-level hallucination 14 language . psiloqa be construct automate three-stage pipeline : generate question–answer pair wikipedia use gpt-4o , elicit potentially hallucinate answer diverse llm no-context setting , and automatically annotate hallucinate span use gpt-4o compare golden answer and retrieve context . evaluate wide range hallucination detection method – include uncertainty quantification , llm-base tagging , and fine-tuned encoder model – and show encoder-based model achieve strong performance language . furthermore , psiloqa demonstrate effective cross-lingual generalization and support robust knowledge transfer other benchmark , be significantly more cost-efficient human-annotated dataset . dataset and result advance development scalable , fine-grained hallucination detection multilingual settings.111https://github.com/s-nlp/psiloqa",Computation and Language,06/10/2025
10.48550/arXiv.2510.04848,instability downstream task performance llm pretraining,"Yuto Nishida, Masaru Isonuma, Yusuke Oda","train large language model ( llms ) , be common practice to track downstream task performance training process and select checkpoint high validation score . however , downstream metric often exhibit substantial fluctuation , make difficult to identify checkpoint truly represent best-performing model . study , empirically analyze stability downstream task performance llm train diverse web-scale corpora . find task score frequently fluctuate training , aggregate and example level . to address instability , investigate two post-hoc checkpoint integration method : checkpoint averaging and ensemble , motivate hypothesis aggregate neighboring checkpoint can reduce performance volatility . demonstrate empirically and theoretically method improve downstream performance stability require change training procedure .",Computation and Language,06/10/2025
10.48550/arXiv.2510.04832,build asr endangered languages spoken dictionary,"Christopher Bartley, Anton Ragni","nearly half world ’s language be endanger . speech technology such automatic speech recognition ( asr ) be central revival effort , yet most language remain unsupported standard pipeline expect utterance-level supervise datum . speech datum often exist endanger language but rarely match format . manx gaelic ( ∼\sim2 , 200 speaker ) , example , have have transcribe speech 1948 , yet remain unsupported modern system . paper , explore little datum , and form , be need to build asr critically endanger language . show short-form pronunciation resource be viable alternative , and 40 minute such datum produce usable asr manx ( < < 50 % wer ) . replicate approach , apply cornish ( ∼\sim600 speaker ) , critically endanger language . result show barrier entry , quantity and form , be far low previously think , give hope to endangered language community can not afford to meet requirement arbitrarily impose .",Computation and Language,06/10/2025
10.48550/arXiv.2510.04800,hybrid architectures language model : systematic analysis and design insights,"Sangmin Bae, Bilge Acun, Haroun Habeeb, Seungyeon Kim, Chien-Yu Lin, Liang Luo, Junjie Wang, Carole-Jean Wu","recent progress large language model demonstrate hybrid architectures–combining self-attention mechanism structured state space model mamba–can achieve compelling balance modeling quality and computational efficiency , particularly long-context task . hybrid model show promising performance , systematic comparison hybridization strategy and analysis key factor effectiveness have not be clearly share community . work , present holistic evaluation hybrid architecture base inter-layer ( sequential ) or intra-layer ( parallel ) fusion . evaluate design variety perspective : language modeling performance , long-context capability , scale analysis , and training and inference efficiency . investigate core characteristic computational primitive , identify most critical element hybridization strategy and far propose optimal design recipe both hybrid model . comprehensive analysis provide practical guidance and valuable insight develop hybrid language model , facilitate optimization architectural configuration .",Computation and Language,06/10/2025
10.48550/arXiv.2510.04764,be babylms deaf gricean maxims ? pragmatic evaluation sample-efficient language model,"Raha Askari, Sina Zarrieß, Özge Alacam, Judith Sieker","implicit meaning be integral human communication , make essential language model to be capable identify and interpret . grice ( 1975 ) propose set conversational maxim guide cooperative dialogue , note speaker may deliberately violate principle to express meaning literal word , and listener , turn , recognize such violation to draw pragmatic inference . build surian et al . ( 1996 ) ’s study child ’s sensitivity violation gricean maxim , introduce novel benchmark to test language model pretraine < 10 m and < 100 m token can distinguish maxim-adhering maxim-violating utterance . compare babylms five maxim and situate performance relative child and large language model ( llm ) pretraine 3 t token . find overall , model train < 100 m token outperform train < 10 m , yet fall short child-level and llm competence . result suggest modest datum increase improve aspect pragmatic behavior , lead finer-grained differentiation pragmatic dimension .",Computation and Language,06/10/2025
10.48550/arXiv.2510.04757,modernbert + colbert : enhance biomedical rag advanced re-ranking retriever,"Eduardo Martínez Rivera, Filippo Menolascina","retrieval-augmented generation ( rag ) be powerful technique enrich large language models ( llms ) external knowledge , allow factually ground response , critical requirement high-stakes domain such healthcare . however , efficacy rag system be fundamentally restrict performance retrieval module , irrelevant or semantically misalign document directly compromise accuracy final generate response . general-purpose dense retriever can struggle nuanced language specialise domain , high accuracy in-domain model be often achieve prohibitive computational cost . work , aim to address trade-off develop and evaluate two-stage retrieval architecture combine lightweight modernbert bidirectional encoder efficient initial candidate retrieval colbertv2 late-interaction model fine-grained re-ranking . conduct comprehensive evaluation retriever module performance and rag system performance biomedical context , fine-tune ir module use 10k question-passage pair pubmedqa . analysis retriever module confirm positive impact colbert re-ranker , improve recall@3 to 4 . 2 percentage point compare retrieve-only counterpart . integrate biomedical rag , ir module lead state-of-the-art average accuracy 0 . 4448 five task mirage question-answere benchmark , outperform strong baseline such medcpt ( 0 . 4436 ) . ablation study reveal performance be critically dependent joint fine-tuning process align retriever and re-ranker ; otherwise , re-ranker might degrade performance . furthermore , parameter-efficient system achieve result indexing speed 7 . 5 time fast lead baseline , provide practical pathway develop trustworthy biomedical rag system . implementation be available : https://anonymous.4open.science/r/biorag-mc-9f3d/",Computation and Language,06/10/2025
10.48550/arXiv.2510.04717,json whisperer : efficient json edit llm,"Sarel Duanis, Asnat Greenstein-Messica, Eliya Habba","large language model ( llms ) can modify json document natural language command , but current approach regenerate entire structure edit , result computational inefficiency . present json whisperer , framework enable llm to generate rfc 6902 diff patches-expresse only necessary modifications-rather complete document . identify two key challenge patch-based editing : ( 1 ) llm often miss related update generate isolate patch , and ( 2 ) array manipulation require track index shift operation , llm handle poorly . to address issue , introduce ease ( explicitly address sequence encoding ) , transform array dictionary stable key , eliminate index arithmetic complexity . evaluation show patch generation ease reduce token usage 31 % maintain edit quality 5 % full regeneration particular gain complex instruction and list manipulation . dataset be available : https://github.com/emnlp2025/json-whisperer/",Computation and Language,06/10/2025
10.48550/arXiv.2510.04694,multilingual routing mixture-of-expert,"Lucas Bandarkar, Chenyuan Yang, Mohsen Fayyaz, Junlin Hu, Nanyun Peng","mixture-of-expert ( moe ) architecture have become key scale modern llm , yet little be understand sparse route dynamic respond multilingual datum . work , analyze expert route pattern use parallel multilingual dataset and present highly interpretable layer-wise phenomenon . find moe model route token language-specific way early and late decoder layer but exhibit significant cross-lingual routing alignment middle layer , mirror parameter-sharing trend observe dense llm . particular , reveal clear , strong correlation model ’s performance give language and similarly token be route english layer . extend correlation , explore inference-time intervention induce high cross-lingual routing alignment . introduce method steer router promote middle-layer task expert frequently activate english , and successfully increase multilingual performance . 1-2 % gain be remarkably consistent two evaluation task , three model , and 15 + language , especially give simple intervention override router extensively train , state-of-the-art llms . comparison , intervention outside middle layer or target multilingual-specialized expert only yield performance degradation . altogether , present numerous finding explain moes process non-english text and demonstrate generalization be limit model ’s ability to leverage language-universal expert language .",Computation and Language,06/10/2025
10.48550/arXiv.2510.04682,titok : transfer token-level knowledge contrastive excess transplant lora,"Chanjoo Jung, Jaehyung Kim","large language models ( llms ) be widely apply real world scenario , but fine-tune come significant computational and storage cost . parameter-efficient fine-tuning ( peft ) method such lora mitigate cost , but adapt parameter be dependent base model and can not be transfer different backbone . one way to address issue be knowledge distillation , but effectiveness inherently depend training datum . recent work such translora avoid generate synthetic datum , but add complexity require train additional discriminator model . paper , propose titok111code will be release acceptance : https://github.com/naughtymaltiz16/titok , new framework enable effective lora transplantation token-level knowledge transfer . specifically , titok capture task-relevant information contrastive excess source model and lora . excess highlight informative token and enable selective filtering synthetic datum , all additional model or overhead . experiment three benchmark multiple transfer setting , experiment show propose method be consistently effective , achieve average performance gain + 4–8 % compare baseline overall .",Computation and Language,06/10/2025
10.48550/arXiv.2510.04678,multi-agent tool-integrated policy optimization,"Zhanfeng Mo, Xingxuan Li, Yuntao Chen, Lidong Bing","large language model ( llms ) increasingly rely multi-turn tool-integrated planning knowledge-intensive and complex reasoning task . exist implementation typically rely single agent , but suffer limited context length and noisy tool response . natural solution be to adopt multi-agent framework planner- and worker-agent to manage context . however , exist method support effective reinforcement learning post-training tool-integrated multi-agent framework . to address gap , propose multi-agent tool-integrate policy optimization ( matpo ) , enable distinct role ( planner and worker ) to be train single llm instance use role-specific prompt reinforcement learning . matpo be derive principle credit assignment mechanism planner and worker rollout . design eliminate need to deploy multiple llm , would be memory-intensive , preserve benefit specialization . experiment gaia-text , webwalkerqa , and frames show matpo consistently outperform single-agent baseline average 18 . 38%18 . 38\% relative improvement performance and exhibit great robustness noisy tool output . finding highlight effectiveness unify multiple agent role single llm and provide practical insight stable and efficient multi-agent rl training . 111our code be available https://github.com/mzf666/matpo .",Computation and Language,06/10/2025
10.48550/arXiv.2510.04671,focusmed : large language model-based framework enhancing medical question summarization focus identification,"Chao Liu, Ling Luo, Tengxiao Lv, Huan Zhuang, Lejing Yu, Jian Wang, Hongfei Lin","rapid development online medical platform , consumer health question ( chq ) be inefficient diagnosis redundant information and frequent non-professional term . medical question summary ( mqs ) task aim to transform chq streamlined doctor ' frequently ask question ( faqs ) , but exist method still face challenge such poor identification question focus and model hallucination . paper explore potential large language model ( llms ) mqs task and find direct fine-tuning be prone to focus identification bias and generate unfaithful content . end , propose optimization framework base core focus guidance . first , prompt template be design to drive llms to extract core focus chq be faithful original text . then , fine-tuning dataset be construct combination original chq-faq pair to improve ability to identify focus question . finally , multi-dimensional quality evaluation and selection mechanism be propose to comprehensively improve quality summary multiple dimension . conduct comprehensive experiment two widely-adopted mqs dataset use three establish evaluation metric . propose framework achieve state-of-the-art performance measure , demonstrate significant boost model ’s ability to identify critical focus question and notable mitigation hallucination . source code be freely available https://github.com/dut-liuchao/focusmed .",Computation and Language,06/10/2025
10.48550/arXiv.2510.04655,ft-mdt : extract decision trees medical texts novel low-rank adaptation method,"Yuheng Li, Jiechao Gao, Wei Han, Wenwen Ouyang, Wei Zhu, Hui Yi Leong","knowledge medical decision process , can be model medical decision tree ( mdts ) , be critical build clinical decision support system . however , current mdt construction method rely heavily time-consuming and laborious manual annotation . to address challenge , propose pi-lora ( path-integrated lora ) , novel low-rank adaptation method automatically extract mdt clinical guideline and textbook . integrate gradient path information to capture synergistic effect different module , enable more effective and reliable rank allocation . framework ensure most critical module receive appropriate rank allocation less important one be prune , result more efficient and accurate model extract medical decision tree clinical text . extensive experiment medical guideline dataset demonstrate pi-lora method significantly outperform exist parameter-efficient fine-tuning approach text2mdt task , achieve well accuracy substantially reduce model complexity . propose method achieve state-of-the-art result maintain lightweight architecture , make particularly suitable clinical decision support system computational resource may be limit .",Computation and Language,06/10/2025
10.48550/arXiv.2510.04641,evaluate llms demographic-targeted social bias detection : comprehensive benchmark study,"Ayan Majumdar, Feihao Chen, Jinghui Li, Xiaozhen Wang","large-scale web-scraped text corpora use to train general-purpose ai model often contain harmful demographic-targeted social bias , create regulatory need datum auditing and develop scalable bias-detection method . prior work have investigate bias text dataset and related detection method , study remain narrow scope . typically focus single content type ( e.g. , hate speech ) , cover limited demographic axis , overlook bias affect multiple demographic simultaneously , and analyze limited technique . consequently , practitioner lack holistic understanding strength and limitation recent large language model ( llms ) automate bias detection . study , present comprehensive evaluation framework aim english text to assess ability llms detect demographic-targeted social bias . to align regulatory requirement , frame bias detection multi-label task use demographic-focused taxonomy . then conduct systematic evaluation model scale and technique , include prompt , in-context learning , and fine-tuning . use twelve dataset span diverse content type and demographic , study demonstrate promise fine-tuned small model scalable detection . however , analysis also expose persistent gap demographic axis and multi-demographic targeted bias , underscore need more effective and scalable auditing framework . keyword : social bias , bias detection , prompting , fine-tuning",Computation and Language,06/10/2025
10.48550/arXiv.2510.04631,contrastive learning use graph embeddings domain adaptation language models process industry,"Anastasia Zhukova, Jonas Lührs, Christian E. Matt, Bela Gipp","recent trend nlp utilize knowledge graph ( kgs ) to enhance pretraine language model incorporate additional knowledge graph structure to learn domain-specific terminology or relationship document might otherwise be overlook . paper explore scincl , graph-aware neighborhood contrastive learning methodology originally design scientific publication , can be apply process industry domain , text log contain crucial information daily operation and be often structure sparse kg . experiment demonstrate language model fine-tuned triplet derive ge outperform state-of-the-art me5-large text encoder 9 . 8-14 . 3 % ( 5 . 4-8 . 0p ) proprietary process industry text embed benchmark ( piteb ) be 3-5 time small size .",Computation and Language,06/10/2025
10.48550/arXiv.2510.04601,fedsrd : sparsify-reconstruct-decompose communication-efficient federated large language model fine-tune,"Guochen Yan, Luyuan Xie, Qingni Shen, Yuejian Fang, Zhonghai Wu","current paradigm train large language model ( llms ) publicly available web data be become unsustainable , high-quality datum source specialized domain near exhaustion . federated learning ( fl ) emerge practical solution next generation ai decentralized web , enable privacy-preserving collaborative fine-tuning leverage private datum distribute global client base . low-rank adaptation ( lora ) be standard efficient fine-tuning , application federate setting present critical challenge : communication overhead remain significant bottleneck web ’s heterogeneous network condition . structural redundancy lora parameter not only incur heavy communication burden but also introduce conflict aggregate client update . to address , propose fedsrd , sparsify-reconstruct-decompose framework design communication-efficient fl . first introduce importance-aware sparsification method preserve structural integrity lora update to reduce uploaded parameter count . server then reconstruct and aggregate update full-rank space to mitigate conflict . finally , decompose global update sparse low-rank format broadcast , ensure symmetrically efficient cycle . also propose efficient variant , fedsrd-e , to reduce computational overhead . experimental result 10 benchmark demonstrate framework significantly reduce communication cost to 90 % even improve model performance heterogeneous client datum .",Computation and Language,06/10/2025
10.48550/arXiv.2510.04584,robustness assessment large audio language model multiple-choice evaluation,"Fernando López, Santosh Kesiraju, Jordi Luque","recent advance large audio language model ( lalm ) have primarily be assess use multiple-choice question answer ( mcqa ) framework . however , subtle change , such shift order choice , result substantially different result . exist mcqa framework do not account variability and report single accuracy number benchmark or category . dive mcqa evaluation framework and conduct systematic study span three benchmark ( mmau , mmar and mmsu ) and four model : audio flamingo 2 , audio flamingo 3 , qwen2 . 5-omni-7b-instruct , and kimi-audio-7b-instruct . finding indicate model be sensitive not only ordering choice , but also paraphrasing question and choice . finally , propose simple evaluation protocol and metric account subtle variation and provide more detailed evaluation report lalm mcqa framework .",Computation and Language,06/10/2025
10.48550/arXiv.2510.04581,can llm detect ambiguous plural reference ? analysis split-antecedent and mereological reference,"Dang Anh, Rick Nouwen, Massimo Poesio","goal be to study llms represent and interpret plural reference ambiguous and unambiguous contexts . ask follow research question : ( 1 ) do llms exhibit human-like preference represent plural reference ? ( 2 ) be llm able to detect ambiguity plural anaphoric expression and identify possible referent ? to address question , design set experiment , examine pronoun production use next-token prediction task , pronoun interpretation , and ambiguity detection use different prompt strategy . then assess comparable llm be human formulate and interpret plural reference . find llms be sometimes aware possible referent ambiguous pronoun . however , do not always follow human reference choose interpretation , especially possible interpretation be not explicitly mention . addition , struggle to identify ambiguity direct instruction . finding also reveal inconsistency result different type experiment .",Computation and Language,06/10/2025
10.48550/arXiv.2510.04551,fine-graine auxiliary learning real-world product recommendation,"Mario Almagro, Diego Ortego, David Jimenez",nan,Computation and Language,06/10/2025
10.48550/arXiv.2510.04506,grace : generative representation learning contrastive policy optimization,"Jiashuo Sun, Shixuan Liu, Zhaochen Su, Xianrui Zhong, Pengcheng Jiang, Bowen Jin, Peiran Li, Weijia Shi, Jiawei Han","prevail method train large language models ( llms ) text encoder rely contrastive loss treat model black-box function , discard generative and reasoning capability favor static embedding . introduce grace ( generative representation learning contrastive policy optimization ) , novel framework reimagine contrastive signal not loss to be minimize , but reward guide generative policy . grace , llm act policy πθ\pi_{\theta } produce explicit , human-interpretable rationales—structure natural language explanation semantic understanding . rationale be then encode high-quality embedding mean pooling . use policy gradient optimization , train model multi-component reward function maximize similarity query–positive pair and similarity negative . transform llm opaque encoder interpretable agent reasoning process be transparent and inspectable . mteb benchmark , grace yield broad cross-category gain : average four backbone , supervise setting improve overall score 11 . 5 % base model , and unsupervised variant add 6 . 9 % , preserve general capability . work treat contrastive objective reward rationale , unify representation learning generation to produce strong embedding and transparent rationale . model , datum and code be available https://github.com/gasolsun36/grace .",Computation and Language,06/10/2025
10.48550/arXiv.2510.04498,genquest : llm-based text adventure game language learners,"Qiao Wang, Adnan Labib, Robert Swier, Michael Hofmeyr, Zheng Yuan","genquest be generative text adventure game leverage large language models ( llms ) to facilitate second language learn immersive , interactive storytelling . system engage english foreign language ( efl ) learner collaborative "" choose-your-own-adventure "" style narrative , dynamically generate response learner choice . game mechanic such branch decision point and story milestone be incorporate to maintain narrative coherence allow learner-driven plot development . key pedagogical feature include content generation tailor learner ’s proficiency level , and vocabulary assistant provide in-context explanation learner-queried text string , range word and phrase sentence . finding pilot study university efl student china indicate promise vocabulary gain and positive user perception . also discuss be suggestion participant regard narrative length and quality , and request multi-modal content such illustration .",Computation and Language,06/10/2025
10.48550/arXiv.2510.04476,compressed convolutional attention : efficient attention compressed latent space,"Tomas Figliolia, Nicholas Alonso, Rishi Iyer, Quentin Anthony, Beren Millidge","multi-headed attention ’s ( mha ) quadratic compute and linearly grow kv-cache make long-context transformer expensive to train and serve . prior work such grouped query attention ( gqa ) and multi-latent attention ( mla ) shrink cache , speed decode , but leave compute , determine prefill and training speed , largely unchanged . introduce compressed convolutional attention ( cca ) , novel attention method down-project query , key , and value and perform entire attention operation share latent space . simple design dramatically cut parameter , kv-cache , and flop once desire compression factor . cca be orthogonal head-sharing , combine two to form compress convolutional grouped query attention ( ccgqa ) , far tighten compute–bandwidth pareto frontier user can tune compression either flop or memory limit sacrifice quality . experiment show ccgqa consistently outperform gqa and mla equal kv-cache compression dense and moe model . additionally , show ccgqa outperform other attention method moe model kv-cache gqa and mla , achieve 8x kv-cache compression drop performance compare standard mha . cca and ccgqa also dramatically reduce flop cost attention lead substantially fast training and prefill exist method . h100 gpu , fused cca/ccgqa kernel reduce prefill latency 1 . 7×1 . 7\times sequence length 16k relative mha , and accelerate backward 1 . 3×1 . 3\times .",Computation and Language,06/10/2025
10.48550/arXiv.2510.04454,mitigate forgetting supervised and reinforcement learning yield strong reasoner,"Xiangchi Yuan, Xiang Chen, Tong Yu, Dachuan Shi, Can Jin, Wenke Lee, Saayan Mitra","large language models ( llms ) show strong reasoning ability , often amplify chain-of-thought ( cot ) prompt and reinforcement learning ( rl ) . rl algorithm can substantially improve reasoning , struggle to expand reasoning boundary learn own reasoning trajectory rather acquire external knowledge . supervise fine-tuning ( sft ) offer complementary benefit but typically require large-scale datum and risk overfitte . recent attempt to combine sft and rl face three main challenge : datum inefficiency , algorithm-specific design , and catastrophic forgetting . propose plug-and-play framework dynamically integrate sft rl select challenging example sft . approach reduce sft datum requirement and remain agnostic choice rl or sft algorithm . to mitigate catastrophic forgetting rl-acquire skill sft , select high-entropy token loss calculation and freeze parameter identify critical rl . method achieve state-of-the-art ( sota ) reasoning performance use only 1 . 5 % sft datum and 20 . 4 % rl datum use prior sota , provide efficient and plug-and-play solution combine sft and rl reasoning post-training .",Computation and Language,06/10/2025
10.48550/arXiv.2510.04439,role unobserved sequences sample-based uncertainty quantification llm,"Lucie Kunitomo-Jacquin, Edison Marrese-Taylor, Ken Fukuda","quantifying uncertainty large language model ( llms ) be important safety-critical application help spot incorrect answer , know hallucination . one major trend uncertainty quantification method be base estimate entropy distribution llm ’s potential output sequence . estimation be base set output sequence and associate probability obtain query llm several time . paper , advocate and experimentally show probability unobserved sequence play crucial role , and recommend future research to integrate to enhance such llm uncertainty quantification method .",Computation and Language,06/10/2025
10.48550/arXiv.2510.04434,"good intentions acl : do nlp social good , and ?","Grace LeFevre, Qingcheng Zeng, Adam Leif, Jason Jewell, Denis Peskoff, Rob Voigt","social impact natural language processing ( nlp ) be increasingly important , rise community focus initiative relate nlp social good ( nlp4sg ) . indeed , recent year , almost 20 % paper acl anthology address topic relate social good define un sustainable development goals adauto et al . ( 2023 ) . study , take author- and venue-level perspective to map landscape nlp4sg , quantify proportion work address social good concern both and acl community , core acl contributor and non-acl author . approach discover two surprising fact landscape nlp4sg . first , acl author be dramatically more likely to do work address social good concern publish venue acl . second , vast majority publication use nlp technique to address concern social good be do non-acl author venue acl . discuss implication finding agenda-setting consideration acl community relate nlp4sg .",Computation and Language,06/10/2025
10.48550/arXiv.2510.04400,large language models preserve semantic isotopies story continuations,Marc Cavazza,"work , explore relevance textual semantic large language models ( llm ) , extend previous insight connection distributional semantic and structural semantic . investigate llm-generated text preserve semantic isotopie . design story continuation experiment use 10 , 000 rocstorie prompt complete five llm . first validate gpt-4o ’s ability to extract isotopie linguistic benchmark , then apply generate story . then analyze structural ( coverage , density , spread ) and semantic property isotopie to assess be affect completion . result show llm completion give token horizon preserve semantic isotopie multiple property .",Computation and Language,06/10/2025
10.48550/arXiv.2510.04394,time be effort : estimate human post-editing time grammar error correction tool evaluation,"Ankit Vadehra, Bill Johnson, Gene Saunders, Pascal Poupart","text editing can involve several iteration revision . incorporate efficient grammar error correction ( gec ) tool initial correction round can significantly impact further human editing effort and final text quality . raise interesting question to quantify gec tool usability : much effort can gec tool save user ? present first large-scale dataset post-edite ( pe ) time annotation and correction two english gec test dataset ( bea19 and conll14 ) . introduce post-editing effort time ( peet ) gec tools human-focused evaluation scorer to rank gec tool estimate pe time-to-correct . use dataset , quantify amount time save gec tools text editing . analyze edit type indicate determine sentence need correction and edit paraphrasing and punctuation change have great impact pe time . finally , comparison human ranking show peet correlate well technical effort judgment , provide new human-centric direction evaluate gec tool usability . 111we release dataset and code - https://github.com/ankitvad/peet_scorer",Computation and Language,05/10/2025
10.48550/arXiv.2510.04392,improve consistency retrieval-augmented systems group similarity reward,"Faisal Hamman, Chenyang Zhu, Anoop Kumar, Xujun Peng, Sanghamitra Dutta, Daben Liu, Alfy Samuel","rag system be increasingly deploy high-stakes domain user expect output to be consistent semantically equivalent query . however , exist system often exhibit significant inconsistency variability both retriever and generator ( llm ) , undermine trust and reliability . work , focus information requirement output convey same core content and information semantically equivalent input . introduce principle evaluation framework decompose rag consistency retriever-level , generator-level , and end-to-end component , help identify inconsistency source . to improve consistency , propose paraphrased set group relative policy optimization ( ps-grpo ) , rl approach leverage multiple rollout paraphrase set to assign group similarity reward . leverage ps-grpo to achieve information consistent rag ( con-rag ) , train generator to produce consistent output paraphrase query and remain robust retrieval-induced variability . exact reward computation paraphrase set be computationally expensive , also introduce scalable approximation method retain effectiveness enable efficient , large-scale training . empirical evaluation short-form , multi-hop , and long-form qa benchmark demonstrate con-rag significantly improve consistency and accuracy strong baseline , even absence explicit ground-truth supervision . work provide practical solution evaluate and build reliable rag system safety-critical deployment .",Computation and Language,05/10/2025
10.48550/arXiv.2510.04347,unmask backdoor : explainable defense gradient-attention anomaly scoring pre-trained language model,"Anindya Sundar Das, Kangjie Chen, Monowar Bhuyan","pre-trained language model have achieve remarkable success wide range natural language processing ( nlp ) task , particularly fine-tuned large , domain-relevant dataset . however , remain vulnerable backdoor attack , adversary embe malicious behavior use trigger pattern training datum . trigger remain dormant normal usage , but , activate , can cause targeted misclassification . work , investigate internal behavior backdoore pre-trained encoder-based language model , focus consistent shift attention and gradient attribution processing poison input ; trigger token dominate both attention and gradient signal , override surround context . propose inference-time defense construct anomaly score combine token-level attention and gradient information . extensive experiment text classification task diverse backdoor attack scenario demonstrate method significantly reduce attack success rate compare exist baseline . furthermore , provide interpretability-driven analysis scoring mechanism , shed light trigger localization and robustness propose defense .",Computation and Language,05/10/2025
10.48550/arXiv.2510.04340,inoculation prompting : elicit trait llms training can suppress test-time,"Daniel Tan, Anders Woodruff, Niels Warncke, Arun Jose, Maxime Riché, David Demitri Africa, Mia Taylor","language model finetune often result learn undesirable trait combination desire one . to address , propose inoculation prompting : modify finetune datum prepende short system-prompt instruction deliberately elicit undesirable trait . test time , evaluate instruction ; inoculate model have much low expression trait model train unmodified training datum . inoculation be selective : toy setting assistant response be always spanish and all-caps , appropriate inoculation ( e.g. , "" always speak spanish . "" ) teach model to capitalize response still respond english . find inoculation be also effective several additional setting : reduce emergent misalignment ( em ) task-specific finetuning , defend backdoor injection , and mitigate transmission trait subliminal learning . follow-up analysis suggest mechanism : make trait less surprising inoculation reduce optimization pressure to globally update model , thereby reduce degree generalization . analysis relate prior work em : inoculation explain prior finding educational contexts mitigate em insecure code . demonstrate simple and effective technique selective learning , result contribute well conceptual understanding and language model generalize .",Computation and Language,05/10/2025
10.48550/arXiv.2510.04338,evaluation clinical trials reporting quality use large language model,"Mathieu Laï-king, Patrick Paroubek","report quality be important topic clinical trial research article , can impact clinical decision . article , test ability large language model to assess reporting quality type article use consolidated standards reporting trials ( consort ) . create consort-qa , evaluation corpus two study abstract reporting quality consort-abstract standards111we publicly release corpus here : https://huggingface.co/datasets/laiking/consort-qa . then evaluate ability different large generative language model ( general domain or adapt biomedical domain ) to correctly assess consort criterion different know prompt method , include chain-of-thought . good combination model and prompt method achieve 85 % accuracy . use chain-of-thought add valuable information model ’s reasoning complete task222the code experiment be available : https://github.com/mathieulaiking/consort-qa .",Computation and Language,05/10/2025
10.48550/arXiv.2510.04320,"read scene , not script : outcome-aware safety llm","Rui Wu, Yihao Quan, Zeru Shi, Zhenting Wang, Yanshu Li, Ruixiang Tang","safety-aligne large language models ( llms ) still show two dominant failure mode : be easily jailbroken , or over-refuse harmless input contain sensitive surface signal . trace common cause : current model reason weakly link action and outcome and over-rely surface-form signal , lexical or stylistic cue do not encode consequence . define failure mode consequence-blindness . to study consequence-blindness , build benchmark name cb-bench ( consequence-blindness benchmark ) cover four risk scenario vary semantic risk align outcome risk , enable evaluation both match and mismatch condition be often ignore exist safety benchmark . mainstream model consistently fail to separate risk and exhibit consequence-blindness , indicate consequence-blindness be widespread and systematic . to mitigate consequence-blindness , introduce cs-chain-4k ( consequence chain ) , consequence-reasoning dataset safety alignment . model fine-tune cs-chain-4k show clear gain semantic-camouflage jailbreak and reduce over-refusal harmless input , maintain utility and generalization other benchmark . result clarify limit current alignment , establish consequence-aware reasoning core alignment goal and provide more practical and reproducible evaluation path . code and datum be available outcome-aware-safety-for-llms .",Computation and Language,05/10/2025
10.48550/arXiv.2510.04302,measure language model hallucinations distributional correctness,Thomas F Burns,"common evaluation paradigm language model focus score single response accuracy metric or proper scoring rule , fail to capture full richness model ’s belief state . recent work illustrate language model hallucinate in-part be optimise to be good test-taker binary scoring scheme reward answer abstention . insight naturally lead penalty-based approach , ignore crucial distinction model distribute uncertainty , example hedging incorrect answer hedge "" do n’t know "" response . novel evaluation metric , distributional correctness score ( dcs ) , be introduce to solve problem , i.e. , not consider model ’s entire probability distribution answer choice . dcs naturally distinguish harmful overconfidence wrong answer and uncertainty express abstention , provide score interpretable default range . theoretical analysis and illustrative example , dcs be demonstrate to offer more nuanced and align evaluation paradigm incentivise model to express genuine uncertainty rather guess . adapt 12 exist evaluation benchmark dcs ’s variant and measure performance six language model reveal half test benchmark score be negative test model , indicate significant tendency hallucination .",Computation and Language,05/10/2025
10.48550/arXiv.2510.04293,equipping retrieval-augmente large language models document structure awareness,"Lingnan Xu, Chong Feng, Kaiyuan Zhang, Liu Zhengyong, Wenqiang Xu, Fanqing Meng","large language model ( llms ) demonstrate impressive capability , reliance parametric knowledge often lead factual inaccuracy . retrieval-augmente generation ( rag ) mitigate leverage external document , yet exist approach treat retrieve passage isolate chunk , ignore valuable structure be crucial document organization . motivate gap , propose retrieve-documentroute-read ( rdr2 ) , novel framework explicitly incorporate structural information rag process . rdr2 employ llm-based router to dynamically navigate document structure tree , jointly evaluate content relevance and hierarchical relationship to assemble optimal evidence . key innovation lie formulate document routing trainable task , automatic action curation and structure-aware passage selection inspire human reading strategy . comprehensive evaluation five challenging dataset , rdr2 achieve state-of-the-art performance , demonstrate explicit structural awareness significantly enhance rag system ' ability to acquire and utilize knowledge , particularly complex scenario require multi-document synthesis . 111code & data : https://github.com/xulingnan/rdr2",Computation and Language,05/10/2025
10.48550/arXiv.2510.04291,pabsa : hybrid framework persian aspect-based sentiment analysis,"Mehrzad Tareh, Aydin Mohandesi, Ebrahim Ansari","sentiment analysis be key task natural language processing ( nlp ) , enable extraction meaningful insight user opinion various domain . however , perform sentiment analysis persian remain challenge scarcity label dataset , limited preprocessing tool , and lack high-quality embedding and feature extraction method . to address limitation , propose hybrid approach integrate machine learning ( ml ) and deep learning ( dl ) technique persian aspect-based sentiment analysis ( absa ) . particular , utilize polarity score multilingual bert additional feature and incorporate decision tree classifier , achieve accuracy 93 . 34%—surpasse exist benchmark pars-absa dataset . additionally , introduce persian synonym and entity dictionary , novel linguistic resource support text augmentation synonym and name entity replacement . result demonstrate effectiveness hybrid modeling and feature augmentation advance sentiment analysis low-resource language such persian .",Computation and Language,05/10/2025
10.48550/arXiv.2510.04285,probe geometry next token prediction use cumulant expansion softmax entropy,"Karthik Viswanathan, Sang Eon Park","introduce cumulant-expansion framework quantify large language model ( llms ) internalize higher-order statistical structure next-token prediction . treat softmax entropy layer ’s logit distribution perturbation "" center "" distribution , derive closed-form cumulant observable isolate successively higher-order correlation . empirically , track cumulant gpt-2 and pythia model pile-10 k prompt . ( i ) structured prompt exhibit characteristic rise–and–plateau profile layer , token-shuffled prompt remain flat , reveal dependence cumulant profile meaningful context . ( ii ) training , cumulant increase monotonically saturating , directly visualize model ’s progression capture variance learn skew , kurtosis , and higher-order statistical structure . ( iii ) mathematical prompt show distinct cumulant signature compare general text , quantify model employ fundamentally different processing mechanism mathematical linguistic content . together , result establish cumulant analysis lightweight , mathematically ground probe feature-learning dynamic high-dimensional neural network .",Computation and Language,05/10/2025
10.48550/arXiv.2510.04268,longtail-swap : benchmarke language model ' ability rare word,"Robin Algayres, Charles-Éric Saint-James, Mahi Luthra, Jiayi Shen, Dongyan Lin, Youssef Benchekroun, Rashel Moritz, Juan Pino, Emmanuel Dupoux","child learn to speak low amount datum and can be teach new word few-shot basis , make particularly data-efficient learner . babylm challenge aim explore language model ( lm ) training low-data regime but use metric concentrate head word distribution . here , introduce longtail-swap ( lt-swap ) , benchmark focus tail distribution , i.e. , measure ability lms to learn new word very little exposure , infant do . lt-swap be pretraine corpus-specific test set acceptable unacceptable sentence pair isolate semantic and syntactic usage rare word . model be evaluate zero-shot fashion compute average log probability two member pair . build two such test set associate 10 m word and 100 m word babylm training set , respectively , and evaluate 16 model babylm leaderboard . result not only highlight poor performance language model rare word but also reveal performance difference lm architecture be much more pronounced long tail head . offer new insight architecture be well handle rare word generalization . ’ve also make code publicly available github , enable generation lt-swap benchmark base english text .",Computation and Language,05/10/2025
10.48550/arXiv.2510.04226,epistemic diversity and knowledge collapse large language model,"Dustin Wright, Sarah Masud, Jared Moore, Srishti Yadav, Maria Antoniak, Chan Young Park, Isabelle Augenstein","large language model ( llms ) tend to generate lexically , semantically , and stylistically homogenous text . pose risk knowledge collapse , homogenous llms mediate shrinking range accessible information time . exist work homogenization be limit focus closed-ended multiple-choice setup or fuzzy semantic feature , and do not look trend time and cultural contexts . to overcome , present new methodology to measure epistemic diversity , i.e. , variation real-world claim llm output , use to perform broad empirical study llm knowledge collapse . test 27 llms , 155 topic cover 12 country , and 200 prompt variation source real user chat . topic study , show new model tend to generate more diverse claim , nearly model be less epistemically diverse basic web search . find model size have negative impact epistemic diversity , retrieval-augmented generation ( rag ) have positive impact , improvement rag vary cultural context . finally , compare traditional knowledge source ( wikipedia ) , find country-specific claim reflect english language more local one , highlight gap epistemic representation . 111code and datum : https://github.com/dwright37/llm-knowledge",Computation and Language,05/10/2025
10.48550/arXiv.2510.04214,teach llm to be persuasive : reward-enhance policy optimization alignment frm heterogeneous rewards,"Zhuoran Zhuang, Ye Chen, Xia Zeng, Chao Luo, Luhui Liu, Yihan Chen","study deploy large language model ( llms ) business development ( bd ) agent persuasive price negotiation online travel agency ( otas ) , align traveler affordability and hotel profitability directly affect booking , partner relationship , and access travel . agent must follow standard operating procedure ( sop ) conduct multi-turn persuasion , interpret colloquial input , and adhere guardrail ( over-promising , hallucination ) . conventional post-training—supervise fine-tuning ( sft ) or single-source reward optimization—overfit script , miss nuance persuasive style , and fail to enforce verifiable business constraint .",Computation and Language,05/10/2025
10.48550/arXiv.2510.04204,calm storm : unlocking native reasoning optimization modeling,"Zhengyang Tang, Zihan Ye, Chenyu Huang, Xuhan Huang, Chengpeng Li, Sihang Li, Guanhua Chen, Ming Yan, Zizhuo Wang, Hongyuan Zha, Dayiheng Liu, Benyou Wang","large reasoning models ( lrms ) have demonstrate strong capability complex multi-step reasoning , open new opportunity automate optimization modeling . however , exist domain adaptation method , originally design early instruction-tune model , often fail to exploit advanced reasoning pattern modern lrm — particular , show direct fine-tuning traditional non-reflective dataset lead limited gain . to fully leverage lrm ' inherent reasoning ability , propose calm ( corrective adaptation lightweight modification ) , framework progressively refine lrms native reasoning mode optimization modeling task . calm , expert intervener identify reasoning flaw and provide concise corrective hint , lrm incorporate to produce improve reasoning trajectory . intervention modify few 2 . 6 % generated token , but generate high-quality datum soft adaptation supervised fine-tuning . adapt model be then far improve reinforcement learning . build calm , develop storm ( smart thinking optimization reasoning model ) , 4b-parameter lrm achieve new state-of-the-art average accuracy 68 . 9 % five popular optimization modeling benchmark , match performance 671b lrm . result demonstrate dynamic , hint-based datum synthesis preserve and amplify native reasoning pattern modern lrm , offer more effective and scalable path expert-level performance challenge optimization modeling task .",Computation and Language,05/10/2025
10.48550/arXiv.2510.04147,self speculative decode diffusion large language model,"Yifeng Gao, Ziang Ji, Yuxuan Wang, Biqing Qi, Hanlin Xu, Linfeng Zhang","diffusion-base large language models ( dllms ) have emerge competitive alternative autoregressive model , offer unique advantage bidirectional attention and parallel generation paradigm . however , generation result current parallel decode method deviate stepwise decode , introduce potential performance degradation , limit practical deployment . to address problem , propose self speculative decoding ( ssd ) , lossless inference acceleration method leverage dllm both speculative decode drafter and verifi auxiliary module . ssd introduce self-drafting mechanism model generate prediction multiple position , then verify hierarchical verification tree single forward pass . traditional speculative decoding require separate draft model , ssd eliminate model redundancy and memory overhead exploit dllm inherent parallel prediction capability multiple position . self-speculative approach allow model to progressively verify and accept multiple token single forward pass . experiment demonstrate ssd achieve to 3 . 46×\times speedup keep output identical to stepwise decode open source model such llada and dream . code will be make publicly available github .",Computation and Language,05/10/2025
10.48550/arXiv.2510.04139,fine tuning methods low-resource language,"Tim Bakkenes, Daniel Wang, Anton Johansson","rise large language models have not be inclusive culture . model be mostly train english text and culture make underperform other language and cultural contexts . develop generalizable method prepare culturally relevant dataset and post-traine gemma 2 model , project aim to increase performance gemma 2 underrepresented language and showcase other can do same to unlock power generative ai country and preserve cultural heritage .",Computation and Language,05/10/2025
10.48550/arXiv.2510.04124,"sri lanka document dataset : large-scale , multilingual resource law , news , and policy ( v20251005 )",Nuwan I. Senaratna,"present collection open , machine-readable document dataset cover parliamentary proceeding , legal judgment , government publication , news , and tourism statistic sri lanka . v20251005 , collection currently comprise 215 , 670 document ( 60 . 3 gb ) 13 dataset sinhala , tamil , and english . dataset be update daily and mirror github and hugging face . resource aim to support research computational linguistic , legal analytic , socio-political study , and multilingual natural language processing . describe data source , collection pipeline , format , and potential use case , discuss licensing and ethical consideration .",Computation and Language,05/10/2025
10.48550/arXiv.2510.04120,"unveiling llms ' metaphorical understanding : explore conceptual irrelevance , context leveraging and syntactic influence","Fengying Ye, Shanshan Wang, Lidia S. Chao, Derek F. Wong","metaphor analysis be complex linguistic phenomenon shape context and external factor . large language models ( llms ) demonstrate advanced capability knowledge integration , contextual reasoning , and creative generation , mechanism metaphor comprehension remain insufficiently explore . study examine llms ' metaphor-processing ability three perspective : ( 1 ) concept mapping : use embed space projection to evaluate llms map concept target domain ( e.g. , misinterpreting "" fall love "" "" drop love "" ) ; ( 2 ) metaphor-literal repository : analyze metaphorical word and literal counterpart to identify inherent metaphorical knowledge ; and ( 3 ) syntactic sensitivity : assess metaphorical syntactic structure influence llm ' performance . finding reveal llms generate 15%-25 % conceptually irrelevant interpretation , depend metaphorical indicator train datum rather contextual cue , and be more sensitive syntactic irregularity structural comprehension . insight underline limitation llms metaphor analysis and call more robust computational approach .",Computation and Language,05/10/2025
10.48550/arXiv.2510.04081,scale code-assisted chain-of-thought and instruction model reasoning,"Honglin Lin, Qizhi Pei, Xin Gao, Zhuoshi Pan, Yu Li, Juntao Li, Conghui He, Lijun Wu","reasoning capability be pivotal large language models ( llms ) to solve complex task , yet achieve reliable and scalable reasoning remain challenge . chain-of-thought ( cot ) prompting have become mainstream approach , exist method often suffer uncontrolled generation , insufficient quality , and limited diversity reasoning path . recent effort leverage code to enhance cot ground reasoning executable step , but such method be typically constrain to predefine mathematical problem , hinder scalability and generalizability . work , propose caco ( code-assisted chain-of-thought ) , novel framework automate synthesis high-quality , verifiable , and diverse instruction-cot reasoning datum code-driven augmentation . prior work , caco first fine-tune code-based cot generator exist math and programming solution unified code format , then scale data generation large amount diverse reasoning trace . crucially , introduce automated validation code execution and rule-based filtering to ensure logical correctness and structural diversity , follow reverse-engineering filter output natural language instruction and language cots to enrich task adaptability . closed-loop process enable fully automate , scalable synthesis reasoning datum guarantee executability . experiment create caco-1 . 3 m dataset demonstrate caco-traine model achieve strong competitive performance mathematical reasoning benchmark , outperform exist strong baseline . further analysis reveal caco ’s code-anchored verification and instruction diversity contribute superior generalization unseen task . work establish paradigm building self-sustaining , trustworthy reasoning system human intervention .",Computation and Language,05/10/2025
10.48550/arXiv.2510.04080,poli-rl : point-to-list reinforcement learning framework conditional semantic textual similarity,"Zixin Song, Bowen Zhang, Qian-Wen Zhang, Di Yin, Xing Sun, Chunping Li","conditional semantic textual similarity ( c-sts ) measure semantic proximity text segment specific condition , thereby overcome ambiguity inherent traditional sts . however , existing method be largely confine discriminative model , fail to fully integrate recent breakthrough nlp community concern large language models ( llms ) and reinforcement learning ( rl ) . rl be particularly well-suited paradigm task , can directly optimize non-differentiable spearman rank metric and guide reasoning process require c-sts . however , find naively apply listwise rl fail to produce meaningful improvement , model be overwhelm complex , coarse-grained reward signal . to address challenge , introduce poli-rl , novel point-to-list reinforcement learning framework . poli-rl employ two-stage curriculum : first train model simple pointwise reward to establish fundamental scoring capability , then transition hybrid reward combine pointwise , pairwise , and listwise objective to refine model ’s ability to discern subtle semantic distinction . crucially , propose innovative parallel slice ranking reward ( psrr ) mechanism compute rank reward parallel slice , slice comprise same-indexed completion different sample . provide precise , differentiate learning signal individual completion , enable granular credit assignment and effective optimization . official c-sts benchmark , poli-rl achieve spearman correlation coefficient 48 . 18 , establish new sota cross-encoder architecture . first work to successfully apply rl c-sts , study introduce powerful and precise paradigm train llm complex , ranking-base conditional judgment task .",Computation and Language,05/10/2025
10.48550/arXiv.2510.04071,make diffusion language models super data learners ?,"Zitian Gao, Haoming Luo, Lynx Chen, Jason Klein Liu, Ran Tao, Joey Zhou, Bryan Dai","recent study have show diffusion language model achieve remarkable datum efficiency limited-data constraint , yet underlie mechanism remain unclear . work , perform extensive ablation experiment to disentangle source efficiency . result show random masking input token play dominant role . far show similar gain can be obtain dropout attention and mlp layer , as well weight decay , indicate stochastic regularization broadly enhance datum efficiency multi-epoch training . code be available https://github.com/zitian-gao/data-efficiency .",Computation and Language,05/10/2025
10.48550/arXiv.2510.04045,explore chain-of-thought reasoning steerable pluralistic alignment,"Yunfan Zhang, Kathleen McKeown, Smaranda Muresan","large language models ( llms ) be typically train to reflect relatively uniform set value , limit applicability task require understanding nuanced human perspective . recent research have underscore importance enable llm to support steerable pluralism — capacity to adopt specific perspective and align generate output . work , investigate chain-of-thought ( cot ) reasoning technique can be apply build steerable pluralistic model . explore several method , include cot prompt , fine-tune human-authored cot , fine-tune synthetic explanation , and reinforcement learning verifiable rewards ( rlvr ) . evaluate approach use value kaleidoscope and opinionqa dataset . method study , rlvr consistently outperform other and demonstrate strong training sample efficiency . far analyze generate cot trace respect faithfulness and safety .",Computation and Language,05/10/2025
10.48550/arXiv.2510.04032,small language models emergency departments decision support : benchmark study,"Zirui Wang, Jiajun Wu, Braden Teitge, Jessalyn Holodinsky, Steve Drew","large language model ( llms ) have become increasingly popular medical domain to assist physician variety clinical and operational task . give fast-paced and high-stakes environment emergency department ( ed ) , small language model ( slms ) , characterize reduction parameter count compare llms , offer significant potential inherent reasoning capability and efficient performance . enable slm to support physician provide timely and accurate information synthesis , thereby improve clinical decision-making and workflow efficiency . paper , present comprehensive benchmark design to identify slm suit ed decision support , take account both specialized medical expertise and broad general problem-solving capability . evaluation , focus slms have be train mixture general-domain and medical corpora . key motivation emphasize slms be practical hardware limitation , operational cost constraint , and privacy concern typical real-world deployment . benchmark dataset include medmcqa , medqa-4option , and pubmedqa , medical abstract dataset emulating task align real ed physician ’ daily task . experimental result reveal general-domain slm surprisingly outperform medically fine-tuned counterpart diverse benchmark ed . indicate ed , specialized medical fine-tuning model may not be require .",Computation and Language,05/10/2025
10.48550/arXiv.2510.04031,do use counterfactual help llm explain textual importance classification ?,"Nelvin Tan, James Asikin Cheung, Yu-Ching Shih, Dong Yang, Amol Salunkhe","large language model ( llms ) be become useful many domain due impressive ability arise large training dataset and large model size . more recently , have be show to be very effective textual classification task , motivate need to explain llms ' decision . motivate practical constrain llm be black-boxed and llm call be expensive , study incorporate counterfactual llm reasoning can affect llm ’s ability to identify top word have contribute classification decision . end , introduce framework call decision change rate help quantify importance top word classification . experimental result show use counterfactual can be helpful .",Computation and Language,05/10/2025
10.48550/arXiv.2510.04013,llm microscope : model internals reveal about answer correctness and context utilization,"Jiarui Liu, Jivitesh Jain, Mona Diab, Nishant Subramani","large language model ( llms ) have tremendous utility , trustworthiness be still chief concern : model often generate incorrect information high confidence . contextual information can help guide generation , identify query would benefit retrieve context and assess effectiveness context remain challenge . work , operationalize interpretability method to ascertain can predict correctness model output model ’s activation alone . also explore model internal contain signal efficacy external context . consider correct , incorrect , and irrelevant context and introduce metric to distinguish . experiment six different model reveal simple classifier train intermediate layer activation first output token can predict output correctness about 75 % accuracy , enable early auditing . model-internals-based metric significantly outperform prompt baseline distinguish correct and incorrect context , guard inaccuracy introduce polluted context . finding offer lens to well understand underlie decision-making process llms . 111our code be publicly available https://github.com/jiarui-liu/llm-microscope .",Computation and Language,05/10/2025
10.48550/arXiv.2510.04002,agrigpt-vl : agricultural vision-language understanding suite,"Bo Yang, Yunkui Chen, Lanfei Feng, Yu Zhang, Xiao Xu, Jianyu Zhang, Nueraili Aierken, Runhe Huang, Hongjian Lin, Yibin Ying, Shijian Li","rapid advance multimodal large language model , agricultural application remain constrain scarcity domain-tailored model , curate vision–language corpora , and rigorous evaluation . to address challenge , present agrigpt-vl suite , unify multimodal framework agriculture . contribution be threefold . first , introduce agri-3m-vl , large vision–language corpus agriculture knowledge , curate scalable multi-agent datum generator ; comprise 1 m image–caption pair , 2 m image-grounde vqa pair , 50 k expert-level vqa instance , and 15k grpo reinforcement learning dataset . second , develop agrigpt-vl , agriculture-specialized vision–language model train progressive curriculum textual grounding , multimodal shallow/deep alignment , and grpo refinement . method achieve strong multimodal reasoning preserve text-only capability . third , establish agribench-vl-4 k , compact yet challenging evaluation suite open-ended and image-grounded question , pair multi-metric evaluation and llm-as-a-judge framework . experiment show agrigpt-vl outperform lead general-purpose vlm agribench-vl-4 k , achieve high pairwise win rate llm-as-a-judge evaluation . meanwhile , remain competitive text-only agribench-13 k noticeable degradation language ability . ablation study far confirm consistent gain alignment and grpo refinement stage . will open-sourced resource to support reproducible research and deployment low-resource agricultural setting .",Computation and Language,05/10/2025
10.48550/arXiv.2510.04001,name entity recognition covid-19 tweet entity knowledge augmentation,"Xuankang Zhang, Jiangming Liu","covid-19 pandemic cause severe social and economic disruption world , raise various subject be discuss social medium . identify pandemic-related name entity express social medium be fundamental and important to understand discussion pandemic . however , be limited work name entity recognition topic follow challenge : 1 ) covid-19 text social medium be informal and annotation be rare and insufficient to train robust recognition model , and 2 ) name entity recognition covid-19 require extensive domain-specific knowledge . to address issue , propose novel entity knowledge augmentation approach covid-19 , can also be apply general biomedical name entity recognition informal text format and formal text format . experiment carry covid-19 tweet dataset and pubmed dataset show propose entity knowledge augmentation improve ner performance fully-supervised and few-shot setting . source code be publicly available : https://github.com/kkkenshi/llm-eka/tree/master .",Computation and Language,05/10/2025
10.48550/arXiv.2510.03999,simulate and understanding deceptive behaviors long-horizon interactions,"Yang Xu, Xuanming Zhang, Min-Hsuan Yeh, Jwala Dhamala, Ousmane Dia, Rahul Gupta, Yixuan Li","deception be pervasive feature human communication and emerge concern large language model ( llms ) . recent study document instance llm deception pressure , most evaluation remain confined single-turn prompt and fail to capture long-horizon interaction deceptive strategy typically unfold . introduce first simulation framework probe and evaluate deception llms extend sequence interdependent task and dynamic contextual pressure . framework instantiate multi-agent system : performer agent task complete task and supervisor agent evaluate progress , provide feedback , and maintain evolve state trust . independent deception auditor then review full trajectory to identify and deception occur . conduct extensive experiment 11 frontier model , span both closed- and open-source system , and find deception be model-dependent , increase event pressure , and consistently erode supervisor trust . qualitative analyses far reveal distinct strategy concealment , equivocation , and falsification . finding establish deception emergent risk long-horizon interaction and provide foundation evaluate future llm real-world , trust-sensitive contexts .",Computation and Language,05/10/2025
10.48550/arXiv.2510.03997,mapping patient-perceive physician traits nationwide online reviews llm,"Junjie Luo, Rui Han, Arshana Welivita, Zeleikun Di, Jingfu Wu, Xuzhe Zhi, Ritu Agarwal, Gordon Gao","understand patient perceive physician be essential improve trust , communication , and satisfaction . present large language model ( llm)-base pipeline infer big five personality trait and five patient-oriented subjective judgment . analysis encompass 4 . 1 million patient review 226 , 999 u . s . physician initial pool one million . validate method multi-model comparison and human expert benchmarking , achieve strong agreement human and llm assessment ( correlation coefficient 0 . 72-0 . 89 ) and external validity correlation patient satisfaction ( r = 0 . 41-0 . 81 , p<0 . 001p<0 . 001 ) . national-scale analysis reveal systematic pattern : male physician receive high rating trait , large disparity clinical competence perception ; empathy-related trait predominate pediatric and psychiatry ; and trait positively predict overall satisfaction . cluster analysis identify four distinct physician archetype , "" well-rounded excellent "" ( 33 . 8 % , uniformly high trait ) "" underperforming "" ( 22 . 6 % , consistently low ) . finding demonstrate automate trait extraction patient narrative can provide interpretable , validate metric understand physician-patient relationship scale , implication quality measurement , bias detection , and workforce development healthcare .",Computation and Language,05/10/2025
10.48550/arXiv.2510.03898,read line : benchmark uncovering political bias bangla news articles,"Nusrat Jahan Lia, Shubhashis Roy Dipta, Abdullah Khan Zehady, Naymul Islam, Madhusodan Chakraborty, Abdullah Al Wasif","detect medium bias be crucial , specifically south asian region . , annotated dataset and computational study bangla political bias research remain scarce . crucially , political stance detection bangla news require understanding linguistic cue , cultural context , subtle bias , rhetorical strategy , code-switching , implicit sentiment , and socio-political background . to address , introduce banglabias , first benchmark dataset 200 politically significant and highly debate bangla news article , label government-leaning , government-critique , and neutral stance , diagnostic analysis evaluate large language model ( llms ) . comprehensive evaluation 28 proprietary and open-source llms show strong performance detect government-critique content ( f1 0 . 83 ) but substantial difficulty neutral article ( f1 as low 0 . 00 ) . model also tend to over-predict government-leaning stance , often misinterpret ambiguous narrative . banglabias and associated diagnostic provide foundation advance stance detection bangla medium research and offer insight improve llm performance low-resource languages.111https://anonymous.4open.science/r/banglabias",Computation and Language,04/10/2025
10.48550/arXiv.2510.03805,token length : step pruner efficient and accurate reasoning large language model,"Canhui Wu, Qiong Cao, Chang Li, Zhenfang Wang, Chao Xue, Yuwei Fan, Wei Xi, Xiaodong He","large reasoning models ( lrms ) demonstrate strong performance complex task but often suffer excessive verbosity , know "" overthinke . "" exist solution reinforcement learning ( rl ) typically penalize generated token to promote conciseness . however , method encounter two challenge : response few token do not always correspond few reasoning step , and model may develop hack behavior later stage training discard reasoning step to minimize token usage . work , introduce step pruner ( sp ) , rl framework steer lrm more efficient reasoning favor compact reasoning step . step-aware reward function prioritize correctness impose penalty redundant step , and withhold reward incorrect response to prevent reinforcement erroneous reasoning . moreover , propose dynamic stopping mechanism : length output step exceed upper limit , halt update to prevent hack behavior cause merge step . extensive experiment four reasoning benchmark demonstrate sp achieve state-of-the-art accuracy significantly reduce response length . instance , aime24 , sp reduce token usage 69 . 7 % .",Computation and Language,04/10/2025
10.48550/arXiv.2510.03799,mechanistic interpretability socio-political frame language model,"Hadi Asghari, Sami Nenno","paper explore ability large language model to generate and recognize deep cognitive frame , particularly socio-political contexts . demonstrate llms be highly fluent generate text evoke specific frame and can recognize frame zero-shot setting . inspire mechanistic interpretability research , investigate location ' strict father ' and ' nurture parent ' frame model ’s hide representation , identify singular dimension correlate strongly presence . finding contribute understand llm capture and express meaningful human concept .",Computation and Language,04/10/2025
10.48550/arXiv.2510.03781,rezwan : leverage large language models comprehensive hadith text processing : 1 . 2 m corpus development,"Majid Asgari-Bidhendi, Muhammad Amin Ghaseminia, Alireza Shahbazi, Sayyed Ali Hossayni, Najmeh Torabian, Behrouz Minaei-Bidgoli","paper present development rezwan , large-scale ai-assiste hadith corpus comprise 1 . 2 m narration , extract and structure fully automate pipeline . build digital repository such maktabat ahl al-bayt , pipeline employ large language models ( llms ) segmentation , chain–text separation , validation , and multi-layer enrichment . narration be enhance machine translation twelve language , intelligent diacritization , abstractive summarization , thematic tagging , and cross-text semantic analysis . multi-step process transform raw text richly annotate research-ready infrastructure digital humanity and islamic study . rigorous evaluation be conduct 1 , 213 randomly sample narration , assess six domain expert . result show near-human accuracy structured task such chain–text separation ( 9 . 33/10 ) and summarization ( 9 . 33/10 ) , highlight ongoing challenge diacritization and semantic similarity detection . comparative analysis manually curate noor corpus demonstrate superiority najm scale and quality , mean overall score 8 . 46/10 3 . 66/10 . furthermore , cost analysis confirm economic feasibility ai approach : task require 229 , 000 hour expert labor be complete month fraction cost . work introduce new paradigm religious text processing show ai can augment human expertise , enable large-scale , multilingual , and semantically enrich access islamic heritage . keyword : hadith corpus , large language model , digital humanities , islamic nlp , semantic enrichment",Computation and Language,04/10/2025
10.48550/arXiv.2510.03762,prompt balance matter : understand imbalanced few-shot learning affect multilingual sense disambiguation llm,"Deshan Sumanathilaka, Nicholas Micallef, Julian Hough","recent advance large language models ( llms ) have significantly reshape landscape natural language processing ( nlp ) . various prompt technique , few-shot prompting have gain considerable attention practicality and effectiveness . study investigate few-shot prompt strategy impact word sense disambiguation ( wsd ) task , particularly focus bias introduce imbalance sample distribution . use glossgpt prompt method , advanced approach english wsd , to test effectiveness five language : english , german , spanish , french , and italian . result show imbalance few-shot example can cause incorrect sense prediction multilingual language , but issue do not appear english . to assess model behavior , evaluate both gpt-4o and llama-3 . 1-70b model and result highlight sensitivity multilingual wsd to sample distribution few-shot setting , emphasize need balanced and representative prompt strategy .",Computation and Language,04/10/2025
10.48550/arXiv.2510.03758,cross-lingual multi-granularity framework interpretable parkinson 's disease diagnosis speech,"Ilias Tougui, Mehdi Zakroum, Mounir Ghogho","parkinson ’s disease ( pd ) affect 10 million people worldwide , speech impairment to 89 % patient . current speech-based detection system analyze entire utterance , potentially overlook diagnostic value specific phonetic element . develop granularity-aware approach multilingual pd detection use automate pipeline extract time-aligned phoneme , syllable , and word recording . use italian , spanish , and english dataset , implement bidirectional lstm multi-head attention to compare diagnostic performance different granularity level . phoneme-level analysis achieve superior performance auroc 93 . 78 % ± 2 . 34 % and accuracy 92 . 17 % ± 2 . 43 % . demonstrate enhance diagnostic capability cross-linguistic pd detection . importantly , attention analysis reveal most informative speech feature align use establish clinical protocol : sustain vowel ( /a/ , /e/ , /o/ , /i/ ) phoneme level , diadochokinetic syllable ( /ta/ , /pa/ , /la/ , /ka/ ) syllable level , and /pataka/ sequence word level . source code will be available https://github.com/jetliqs/clearpd111source code and model weight to be publish proceeding .",Computation and Language,04/10/2025
10.48550/arXiv.2510.03748,treeprompt : leverage hierarchical few-shot example selection improved english-persian and english-german translation,"Ramtin Kakavand, Ebrahim Ansari","large language models ( llms ) have consistently demonstrate strong performance machine translation , especially guide high-quality prompt . few-shot prompting be effective technique to improve translation quality ; however , most exist example selection method focus solely query-to-example similarity and do not account quality example . work , propose treeprompt , novel example selection approach learn llm preference to identify high-quality , contextually relevant example tree-structured framework . to far explore balance similarity and quality , combine treeprompt k-nearest neighbors ( k-nn ) and adaptive few-shot prompt ( afsp ) . evaluation two language pairs—english–persian ( mizan ) and english–german ( wmt19)—show integrate treeprompt afsp or random selection lead improved translation performance .",Computation and Language,04/10/2025
10.48550/arXiv.2510.03687,medreflect : teach medical llms to self-improve reflective correction,"Yue Huang, Yanyuan Chen, Dexuan Xu, Weihua Yue, Huamin Zhang, Meikang Qiu, Yu Huang","medical problem solve demand expert knowledge and intricate reasoning . recent study large language model ( llms ) attempt to ease complexity introduce external knowledge verification retrieval-augmented generation or training reasoning dataset . however , approach suffer drawback such retrieval overhead and high annotation cost , and heavily rely substitute external assistant to reach limited performance medical field . paper , introduce medreflect , generalizable framework design to inspire llms physician‑like reflective thinking mode . medreflect generate single‑pass reflection chain include initial hypothesis generation , self‑questioning , self‑answering and decision refinement . self-verified and self-reflective nature release large language model ’s latent capability medical problem-solving external retrieval or heavy annotation . demonstrate medreflect enable cost-efficient medical dataset construction : merely 2 , 000 randomly sample training example and light fine-tuning , approach achieve notable absolute accuracy improvement series medical benchmark cut annotation requirement . result provide evidence llms can learn to solve specialized medical problem self-reflection and self-improve , reduce reliance external supervision and extensive task-specific fine-tuning datum .",Computation and Language,04/10/2025
10.48550/arXiv.2510.03663,unidoc-bench : unified benchmark document-centric multimodal rag,"Xiangyu Peng, Cab Qin, Zeyuan Chen, Ran Xu, Caiming Xiong, Chien-Sheng Wu","multimodal retrieval-augmented generation ( mm-rag ) be key approach apply large language model ( llms ) and agent real-world knowledge basis , yet current evaluation be fragmented—focuse text or image isolation , or simplify multimodal setup , fail to capture document-centric multimodal use case . paper , introduce unidoc-bench111the code and datum will be available : https://github.com/salesforceairesearch/unidoc-bench , first large-scale , realistic benchmark mm-rag build 7070k real-world pdf page 88 domain . pipeline extract and link evidence text , table , and figure , then generate 1 , 6001 , 600 multimodal qa pair span factual retrieval , comparison , summarization , and logical reasoning query . to ensure reliability , 20%20\% qa pair be validate multiple annotator and expert adjudication . unidoc-bench support apples-to-apple comparison four paradigm — 1 ) text-only , 2 ) image-only , 3 ) multimodal text–image fusion and 4 ) multimodal joint retrieval — unified protocol standardized candidate pool , prompt , and evaluation metric . experiment show multimodal text–image fusion rag system consistently outperform unimodal and jointly multimodal embedding–based retrieval , indicate text nor image alone be sufficient and current multimodal embedding remain inadequate . benchmarking , analysis reveal and visual context complement textual evidence , uncover systematic failure mode , and offer actionable guidance develop more robust mm-rag pipeline .",Computation and Language,04/10/2025
10.48550/arXiv.2510.03639,unsupervised speech recognition syllable-level,"Liming Wang, Junrui Ni, Kai-Wei Chang, Saurabhchand Bhati, David Harwath, Mark Hasegawa-Johnson, James R. Glass","train speech recognizer unpaired speech and text – know unsupervised speech recognition ( uasr ) – be crucial step extend asr low-resource language long-tail distribution and enable multimodal learning non-parallel datum . however , exist approach base phone often rely costly resource such grapheme-to-phoneme converter ( g2ps ) and struggle to generalize language ambiguous phoneme boundary training instability . paper , address challenge introduce syllable-level uasr framework base mask language modeling , avoid need g2p and instability gan-base method . approach achieve 40 % relative reduction character error rate ( cer ) librispeech and generalize effectively mandarin , language have remain particularly difficult prior method . code will be release acceptance .",Computation and Language,04/10/2025
10.48550/arXiv.2510.03611,can llm induce graph ? investigate memory drift and context length,"Raquib Bin Yousuf, Aadyant Khatri, Shengzhe Xu, Mandar Sharma, Naren Ramakrishnan","recently propose evaluation benchmark aim to characterize effective context length and forget tendency large language model ( llms ) . however , benchmark often rely simplistic "" needle haystack "" retrieval or continuation task may not accurately reflect performance model information-dense scenario . thus , rather simple next token prediction , argue evaluate model more complex reasoning task require to induce structured relational knowledge text - such graph potentially noisy natural language content . input text can be view generate term graph , structure be not make explicit and connection must be induce distribute textual cue , separate long contexts and intersperse irrelevant information . finding reveal llms begin to exhibit memory drift and contextual forgetting much short effective length task form relational reasoning , compare existing benchmark suggest . finding , offer recommendation optimal use popular llm complex reasoning task . far show even model specialize reasoning , such openai o1 , remain vulnerable early memory drift setting . result point significant limitation model ' ability to abstract structured knowledge unstructured input and highlight need architectural adaptation to improve long-range reasoning . codebase to support reproducibility be publicly available.111https://github.com/discoveryanalyticscenter/memorydrift .",Computation and Language,04/10/2025
10.48550/arXiv.2510.03595,decouple task-solving and output formatting llm generation,"Haikang Deng, Po-Nien Kung, Nanyun Peng","large language model ( llms ) be increasingly adept follow instruction contain task description to solve complex problem , such mathematical reasoning and automatic evaluation ( llm-as-a-judge ) . however , prompt grow more complex , model often struggle to adhere instruction . difficulty be especially common instructive prompt intertwine reasoning directives—specifye model should solve—with rigid formatting requirement dictate solution must be present . entanglement create compete goal model , suggest more explicit separation two aspect could lead improved performance . front , introduce deco-g , decode framework explicitly decouple format adherence task solving . deco-g handle format compliance separate tractable probabilistic model ( tpm ) , prompt llms only task instruction . decode step , deco-g combine next token probability llm tpm calculate format compliance likelihood to form output probability . to make approach both practical and scalable modern instruction-tune llms , introduce three key innovation : instruction-aware distillation , flexible trie-building algorithm , and hmm state pruning computational efficiency . demonstrate effectiveness deco-g wide range task diverse format requirement , include mathematical reasoning , llm-as-a-judge , and event argument extraction . overall , approach yield 1 . 0 % 6 . 0 % relative gain regular prompt practice guarantee format compliance .",Computation and Language,04/10/2025
10.48550/arXiv.2510.03577,"llm , report ! medical information extraction prompting , fine-tuning and post-correction","Ikram Belmadani, Parisa Nazari Hashemi, Thomas Sebbag, Benoit Favre, Guillaume Fortier, Solen Quiniou, Emmanuel Morin, Richard Dufour","llm , report ! medical information extraction prompting , fine-tuning and post-correction",Computation and Language,03/10/2025
10.48550/arXiv.2510.03561,reactive transformer ( rxt ) -- stateful real-time process event-driven reactive language model,Adam Filipek,"transformer architecture have become de facto standard large language models ( llms ) , demonstrate remarkable capability language understanding and generation . however , application conversational ai be fundamentally constrain stateless nature and quadratic computational complexity ( o​(l2)o(l^{2 } ) ) respect sequence length ll . current model emulate memory reprocess ever-expanding conversation history turn , lead prohibitive cost and latency long dialogue . paper introduce reactive transformer ( rxt ) , novel architecture design to overcome limitation shift data-driven event-driven paradigm . rxt process conversational turn discrete event real-time , maintain context integrate , fixed-size short-term memory ( stm ) system . architecture feature distinct operational cycle generator-decoder produce response base current query and previous memory state , memory-encoder and dedicated memory attention network asynchronously update stm representation complete interaction . design fundamentally alter scale dynamic , reduce total user-facing cost conversation quadratic ( o​(n2⋅t)o(n^{2}\cdot t ) ) to linear ( o​(n⋅t)o(n\cdot t ) ) respect number interaction nn . decouple response generation memory update , rxt achieve low latency , enable truly real-time , stateful , and economically viable long-form conversation . validate architecture series proof-of-concept experiment synthetic datum , demonstrate superior performance and constant-time inference latency compare baseline stateless model comparable size .",Computation and Language,03/10/2025
10.48550/arXiv.2510.03553,ccd-bench : probe cultural conflict large language model decision-making,"Hasibur Rahman, Hanan Salam","large language model ( llms ) be increasingly implicate interpersonal and societal decision-making , ability to navigate explicit conflict legitimately different cultural value system remain largely unexamined . exist benchmark predominantly target cultural knowledge ( culturalbench ) , value prediction ( worldvaluesbench ) , or single-axis bias diagnostic ( cdeval ) ; none , however , evaluate llms adjudicate multiple culturally ground value directly clash . address gap ccd-bench , benchmark assess llm decision-make overt cross-cultural value conflict . ccd-bench comprise 2 , 182 open-ende dilemma span seven domain , pair exactly ten anonymize response option correspond ten globe cultural cluster , represent organizational behavior 62 society . dilemma be present use stratified latin square to mitigate ordering effect . evaluate 17 lead non-reasoning llms . llms disproportionately prefer nordic europe ( mean 20 . 2 % ) and germanic europe ( 12 . 4 % ) , option eastern europe and middle east & north africa be underrepresented ( 5 . 6–5 . 8 % ) . 87 . 9 % rationale reference two or more globe dimension , apparent pluralism be largely superficial : llms repeatedly recombine narrow subset future orientation and performance orientation , and rarely ground choice assertiveness or gender egalitarianism ( both < 3%<3\% ) . ordering effect be negligible ( cramér ’s v<0 . 10v<0 . 10 ) , and symmetrize kl divergence indicate llms cluster developer lineage rather geography . take together , pattern suggest contemporary alignment pipeline encourage consensus-oriented , progress-centric worldview underserve scenario demand explicit power negotiation , rights-based reasoning , or gender-aware analysis . ccd-bench thus shift evaluation isolated bias detection pluralistic decision making , reveal current llm maintain western-centric , consensus-oriented preference even confront ten equally valid , culturally diverse alternative , and underscore need alignment strategy substantively engage diverse worldview .",Computation and Language,03/10/2025
10.48550/arXiv.2510.03541,be protest anyway ? codebook conceptualization be still first-order concern llm-era classification,"Andrew Halterman, Katherine A. Keith","generative large language model ( llms ) be now use extensively text classification computational social science ( css ) . work , focus step before and llm prompting—conceptualization concept to be classify and use llm prediction downstream statistical argue have be overlook much llm-era css . claim llms can tempt analyst to skip conceptualization step , create conceptualization error bias downstream estimate . use simulation , show conceptualization-induced bias can not be correct solely increase llm accuracy or post-hoc bias correction method . conclude remind css analyst conceptualization be still first-order concern llm-era and provide concrete advice to pursue low-cost , unbiased , low-variance downstream estimate .",Computation and Language,03/10/2025
10.48550/arXiv.2510.03536,trimediq : triplet-structured approach interactive medical question answering,"Zhaohan Meng, Zaiqiao Meng, Siwei Liu, Iadh Ounis","large language models ( llms ) perform strongly static and single-turn medical question answer ( qa ) benchmark , yet such setting diverge iterative information gathering process require practical clinical consultation . mediq framework address mismatch recast diagnosis interactive dialogue patient and expert system , but reliability llms drop dramatically force to reason dialogue log , clinical fact appear sentence clear link . to bridge gap , introduce trimediq , triplet-structured approach summarise patient response triplet and integrate knowledge graph ( kg ) , enable multi-hop reasoning . introduce frozen triplet generator extract clinically relevant triplet , use prompt design to ensure factual consistency . parallel , trainable projection module , comprise graph encoder and projector , capture relational information kg to enhance expert reasoning . trimediq operate two step : ( i ) projection module fine-tune llm weight frozen ; and ( ii ) use fine-tuned module to guide multi-hop reasoning inference . evaluate trimediq two interactive qa benchmark , show achieve to 10 . 4 % improvement accuracy five baseline imedqa dataset . result demonstrate convert patient response structured triplet-based graph enable more accurate clinical reasoning multi-turn setting , provide solution deployment llm-base medical assistant 111the complete code and public dataset be available : anonymised github ..",Computation and Language,03/10/2025
10.48550/arXiv.2510.03528,fine-tune noisy instruction : effect generalization and performance,"Ahmed Alajrami, Xingwei Tan, Nikolaos Aletras","instruction-tune play vital role enhance task-solving ability large language model ( llms ) , improve usability generate helpful response various task . however , previous work have demonstrate be sensitive minor variation instruction phrasing . paper , explore introduce perturbation instruction-tuning datum can enhance llms ' resistance noisy instruction . focus instruction-tuning perturbation , such remove stop word or shuffle word , affect llm ' performance original and perturb version widely-use benchmark ( mmlu , bbh , gsm8 k ) . far assess learn dynamic and potential shift model behavior . surprisingly , result suggest instruction-tuning perturb instruction can , case , improve downstream performance . finding highlight importance include perturb instruction instruction-tuning , can make llm more resilient noisy user input . 111code be available here : https://github.com/aajrami/finetuning-on-noisy-instructions/",Computation and Language,03/10/2025
10.48550/arXiv.2510.03527,"sample , align , synthesize : graph-base response synthesis congrs","Sayan Ghosh, Shahzaib Saqib Warraich, Dhruv Tarsadiya, Gregory Yauney, Swabha Swayamdipta","language model can be sample multiple time to access distribution underlie response , but exist method can not efficiently synthesize rich epistemic signal different long-form response . introduce consensus graphs ( congrs ) , flexible dag-base datum structure represent share information , as well semantic variation set sample lm response same prompt . construct congrs use light-weight lexical sequence alignment algorithm bioinformatic , supplement target usage secondary lm judge . far , design task-dependent decode method to synthesize single , final response congrs data structure . experiment show synthesize response congrs improve factual precision two biography generation task to 31 % average response and reduce reliance lm judge more 80 % compare other method . also use congrs three refusal-based task require abstention unanswerable query and find abstention rate be increase to 56 % . apply approach math and aime reasoning task and find improvement self-verification and majority vote baseline to 6 point accuracy . show congrs provide flexible method capture variation lm response and use epistemic signal provide response variation to synthesize more effective response . code and datum be : github.com/dill-lab/sample-fusion-with-congrs .",Computation and Language,03/10/2025
10.48550/arXiv.2510.03521,identify financial risk information use rag contrastive insight,Ali Elahi,"specialized domain , human often compare new problem similar example , highlight nuance , and draw conclusion instead analyze information isolation . apply reasoning specialized context llms top rag , pipeline can capture contextually relevant information , but be not design to retrieve comparable case or related problem .",Computation and Language,03/10/2025
10.48550/arXiv.2510.03519,ts-reasoner : aligning time series foundation models llm reasoning,"Fangxu Yu, Hongyu Zhao, Tianyi Zhou","time series reasoning be crucial decision-make diverse domain , include finance , energy usage , traffic , weather , and scientific discovery . existing time series foundation model ( tsfm ) can capture low-level dynamic pattern and provide accurate forecasting , further analysis usually require additional background knowledge and sophisticated reasoning , be lack most tsfm but can be achieve large language model ( llms ) . other hand , expensive post-training , llm often struggle numerical understanding time series datum . be intuitive to integrate two type model , develop effective training recipe align two modality reasoning task be still open challenge . end , propose ts-reasoner align latent representation tsfm textual input llms downstream understanding/reasoning task . specifically , propose simple yet effective method to curate diverse , synthetic pair time series and textual caption alignment training . then develop two-stage training recipe apply instruction finetuning alignment pretraine . exist work train llm to take time series input , leverage pretraine tsfm and freeze training . extensive experiment several benchmark demonstrate ts-reasoner not only outperform wide range prevail llm , vision language models ( vlms ) , and time series llms , but also achieve remarkable datum efficiency , e.g. , use less training datum .",Computation and Language,03/10/2025
10.48550/arXiv.2510.03490,seer : span-based emotion evidence retrieval benchmark,"Aneesha Sampath, Oya Aran, Emily Mower Provost","introduce seer ( span-based emotion evidence retrieval ) benchmark to test large language model ' ( llms ) ability to identify specific span text express emotion . traditional emotion recognition task assign single label entire sentence , seer target underexplored task emotion evidence detection : pinpoint exact phrase convey emotion . span-level approach be crucial application empathetic dialogue and clinical support , need to know emotion be express , not just emotion be . seer include two task : identify emotion evidence single sentence , and identify evidence short passage five consecutive sentence . contain new annotation emotion and emotion evidence 1200 real-world sentence . evaluate 14 open-source llm and find , model approach average human performance single-sentence input , accuracy degrade long passage . error analysis reveal key failure mode , include overreliance emotion keyword and false positive neutral text .",Computation and Language,03/10/2025
10.48550/arXiv.2510.03467,search most human-like emergent language,"Brendon Boldt, David Mortensen","paper , design signal game-based emergent communication environment to generate state-of-the-art emergent language term similarity human language . be do hyperparameter optimization , use xferbench objective function . xferbench quantify statistical similarity emergent language human language measure suitability deep transfer learn human language . additionally , demonstrate predictive power entropy transfer learn performance emergent language as well corroborate previous result entropy-minimization property emergent communication system . finally , report generalization regard hyperparameter produce more realistic emergent language , that is , one transfer well human language .",Computation and Language,03/10/2025
10.48550/arXiv.2510.03458,"omni-embed-nemotron : unified multimodal retrieval model text , image , audio , and video","Mengyao Xu, Wenfei Zhou, Yauhen Babakhin, Gabriel Moreira, Ronay Ak, Radek Osmulski, Bo Liu, Even Oldridge, Benedikt Schifferer","present , unify multimodal retrieval embed model develop to handle increase complexity real-world information need . retrieval-augmented generation ( rag ) have significantly advanced language model incorporate external knowledge , exist text-based retriever rely clean , structured input and struggle visually and semantically rich content find real-world document such pdfs , slide , or video . recent work such colpali have show preserve document layout use image-based representation can improve retrieval quality . build , and inspire capability recent multimodal model such qwen2 . 5-omni , extend retrieval text and image to also support audio and video modality . enable cross-modal ( e.g. , text → video ) and joint-modal ( e.g. , text → video+audio ) retrieval use single model . describe architecture , train setup , and evaluation result omni-embed-nemotron , and demonstrate effectiveness text , image , and video retrieval .",Computation and Language,03/10/2025
10.48550/arXiv.2510.03439,morpheme induction emergent language,"Brendon Boldt, David Mortensen","introduce csar , algorithm induce morpheme emergent language corpora parallel utterance and meaning . be greedy algorithm ( 1 ) weight morpheme base mutual information form and meaning , ( 2 ) select highest-weighted pair , ( 3 ) remove corpus , and ( 4 ) repeat process to induce further morpheme ( i.e. , count , select , ablate , repeat ) . effectiveness csar be first validate procedurally generate dataset and compare baseline related task . second , validate csar ’s performance human language datum to show algorithm make reasonable prediction adjacent domain . finally , analyze handful emergent language , quantify linguistic characteristic degree synonymy and polysemy .",Computation and Language,03/10/2025
10.48550/arXiv.2510.03384,implicit values embed humans and llm complete subjective everyday task,"Arjun Arunasalam, Madison Pickering, Z. Berkay Celik, Blase Ur","large language model ( llms ) can underpin ai assistant help user everyday task , such make recommendation or perform basic computation . ai assistant ' promise , little be know implicit value assistant display complete subjective everyday task . human may consider value environmentalism , charity , and diversity . extent do llms exhibit value complete everyday task ? do compare human ? answer question audit six popular llms complete 30 everyday task , compare llms other and 100 human crowdworker us . find llm often do not align human , nor other llms , implicit value exhibit .",Computation and Language,03/10/2025
10.48550/arXiv.2510.03323,graph-s3 : enhance agentic textual graph retrieval synthetic stepwise supervision,"Ge Chang, Jinbo Su, Jiacheng Liu, Pengfei Yang, Yuhao Shang, Huiwen Zheng, Hongli Ma, Yan Liang, Yuanchun Li, Yunxin Liu","significant portion real-world datum be inherently represent textual graph , and integrate graph large language model ( llms ) be promise to enable complex graph-based question answer . however , key challenge llm-base textual graph qa system lie graph retrieval , i.e. , to retrieve relevant content large graph be sufficiently informative remain compact llm context . exist retriever suffer poor performance either rely shallow embed similarity or employ interactive retrieving policy demand excessive datum labeling and training cost . to address issue , present graph-s3 , agentic textual graph reasoning framework employ llm-base retriever train synthetic stepwise supervision . instead reward agent base final answer , may lead sparse and unstable training signal , propose to closely evaluate step retriever base offline-extracted golden subgraph . main technique include datum synthesis pipeline to extract golden subgraph reward generation and two-stage training scheme to learn interactive graph exploration policy base synthesized reward . base extensive experiment three common dataset comparison seven strong baseline , approach achieve average improvement 8 . 1 % accuracy and 9 . 7 % f1 score . advantage be even high more complicated multi-hop reasoning task . code will be open-sourced .",Computation and Language,01/10/2025
10.48550/arXiv.2510.03315,decompose attention to find context-sensitive neuron,Alex Gibson,"study transformer language model , analyze attention head attention pattern be spread out , and attention score depend weakly content . argue softmax denominator head be stable underlying token distribution be fix . sample softmax denominator "" calibration text "" , can combine together output multiple such stable head first layer gpt2-small , approximate combine output linear summary surround text . approximation enable procedure weight alone - and single calibration text - can uncover hundred first layer neuron respond high-level contextual property surround text , include neuron do not activate calibration text .",Computation and Language,01/10/2025
10.48550/arXiv.2510.05096,paper2video : automatic video generation scientific papers,"Zeyu Zhu, Kevin Qinghong Lin, Mike Zheng Shou","academic presentation video have become essential medium research communication , yet produce remain highly labor-intensive , often require hour slide design , recording , and edit short 2 to 10 minute video . natural video , presentation video generation involve distinctive challenge : long-context input research paper , dense multi-modal information ( text , figure , table ) , and need to coordinate multiple align channel such slide , subtitle , speech , and human talker . to address challenge , introduce paper2video , first benchmark 101 research paper pair author-created presentation video , slide , and speaker metadata . far design four tailor evaluation metrics—meta similarity , presentarena , presentquiz , and ip memory—to measure video convey paper ’s information audience . build foundation , propose papertalker , first multi-agent framework academic presentation video generation . integrate slide generation effective layout refinement novel effective tree search visual choice , cursor grounding , subtitle , speech synthesis , and talking-head rendering , parallelize slide-wise generation efficiency . experiment paper2video demonstrate presentation video produce approach be more faithful and informative exist baseline , establish practical step automated and ready-to-use academic video generation . dataset , agent , and code be available https://github.com/showlab/paper2video",Computation and Language,06/10/2025
10.48550/arXiv.2510.05095,noisy traces stable gradient : bias-variance optimized preference optimization align large reasoning model,"Mingkang Zhu, Xi Chen, Bei Yu, Hengshuang Zhao, Jiaya Jia","large reasoning model ( lrms ) generate intermediate reasoning trace produce final answer , yield strong gain multi-step and mathematical task . yet align lrms human preference , crucial prerequisite model deployment , remain underexplored . statistically correct objective preference alignment require marginalize reasoning trace , but computation be intractable practice . common workaround optimize single sample trajectory , introduce substantial gradient variance stochastic trace sampling . to address challenge , frame preference optimization lrm lens bias–variance and propose bias–variance optimized preference optimization ( bvpo ) , simple , drop-in method mix two gradient estimator : high-variance trace-based estimator and low-variance empty-trace estimator obtain disable reasoning trace generation . theory show bvpo strictly reduce trace-induced variance nontrivial mixture , provide closed-form choice mix weight minimize mean-squared error relative true marginal gradient , and standard smoothness and step-size condition , tighten classical convergence bound stochastic gradient descent . empirically , bvpo improve alignment good baseline to 7 . 8 point alpacaeval 2 and 6 . 8 point arena-hard . be train only general conversational datum , bvpo also boost reasoning performance base model to 4 . 0 point average six math reasoning benchmark . result identify variance trace sampling key bottleneck and demonstrate directly optimize bias–variance trade-off yield more stable training and strong overall performance .",Computation and Language,06/10/2025
10.48550/arXiv.2510.05092,learn to interpret weight differences language model,"Avichal Goel, Yoon Kim, Nir Shavit, Tony T. Wang","finetune ( pretraine ) language model be standard approach update internal parametric knowledge and specialize new task and domain . however , corresponding model weight change ( "" weight diff "" ) be not generally interpretable . inspect finetune dataset can give sense model might have change , dataset be often not publicly available or be too large to work directly . goal comprehensively understand weight diff natural language , introduce diff interpretation tuning ( dit ) , method train model to describe own finetuning-induced modification . approach use synthetic , label weight diff to train dit adapter , can be apply compatible finetuned model to make describe have change . demonstrate two proof-of-concept setting ( report hide behavior and summarize finetune knowledge ) method enable model to describe finetuning-induced modification use accurate natural language description .",Computation and Language,06/10/2025
10.48550/arXiv.2510.05052,proactive defense llm jailbreak,"Weiliang Zhao, Jinjun Peng, Daniel Ben-Levi, Zhou Yu, Junfeng Yang","proliferation powerful large language model ( llms ) have necessitate robust safety alignment , yet model remain vulnerable evolve adversarial attack , include multi-turn jailbreak iteratively search successful query . current defense , primarily reactive and static , often fail to counter search-based attack . paper , introduce proact , novel proactive defense framework design to disrupt and mislead autonomous jailbreaking process . core idea be to intentionally provide adversary "" spurious response "" appear to be result successful jailbreak attack but contain actual harmful content . misleading response provide false signal attacker ’s internal optimization loop , cause adversarial search to terminate prematurely and effectively jailbreake jailbreak . conduct extensive experiment state-of-the-art llms , jailbreake framework , and safety benchmark , method consistently and significantly reduce attack success rate to 92 % . combine other defense framework , far reduce success rate late attack strategy 0 % . proact represent orthogonal defense strategy can serve additional guardrail to enhance llm safety most effective jailbreaking attack .",Computation and Language,06/10/2025
10.48550/arXiv.2510.05016,large language models achieve gold medal performance international astronomy & astrophysics olympiad,"Lucas Carrit Delgado Pinheiro, Ziru Chen, Bruno Caixeta Piazza, Ness Shroff, Yingbin Liang, Yuan-Sen Ting, Huan Sun",nan,Computation and Language,06/10/2025
10.48550/arXiv.2510.04996,reinforce-ada : adaptive sampling framework reinforce-style llm training,"Wei Xiong, Chenlu Ye, Baohao Liao, Hanze Dong, Xinxing Xu, Christof Monz, Jiang Bian, Nan Jiang, Tong Zhang","reinforcement learning apply large language model ( llms ) reasoning task be often bottleneck unstable gradient estimate fixed and uniform sampling response prompt . prior work such gvm-raft address dynamically allocate inference budget prompt to minimize stochastic gradient variance budget constraint . inspire insight , propose reinforce-ada , adaptive sampling framework online rl post-training llms continuously reallocate sampling effort prompt great uncertainty or learn potential . conventional two-stage allocation method , reinforce-ada interleave estimation and sampling online successive elimination process , and automatically stop sample prompt once sufficient signal be collect . to stabilize update , form fixed-size group enforce reward diversity and compute advantage baseline use global statistic aggregate adaptive sampling phase . empirical result multiple model architecture and reasoning benchmark show reinforce-ada accelerate convergence and improve final performance compare grpo , especially use balanced sampling variant . work highlight central role variance-aware , adaptive datum curation enable efficient and reliable reinforcement learning reasoning-capable llms . code be available .",Computation and Language,06/10/2025
10.48550/arXiv.2510.05096,paper2video : automatic video generation scientific papers,"Zeyu Zhu, Kevin Qinghong Lin, Mike Zheng Shou","academic presentation video have become essential medium research communication , yet produce remain highly labor-intensive , often require hour slide design , recording , and edit short 2 to 10 minute video . natural video , presentation video generation involve distinctive challenge : long-context input research paper , dense multi-modal information ( text , figure , table ) , and need to coordinate multiple align channel such slide , subtitle , speech , and human talker . to address challenge , introduce paper2video , first benchmark 101 research paper pair author-created presentation video , slide , and speaker metadata . far design four tailor evaluation metrics—meta similarity , presentarena , presentquiz , and ip memory—to measure video convey paper ’s information audience . build foundation , propose papertalker , first multi-agent framework academic presentation video generation . integrate slide generation effective layout refinement novel effective tree search visual choice , cursor grounding , subtitle , speech synthesis , and talking-head rendering , parallelize slide-wise generation efficiency . experiment paper2video demonstrate presentation video produce approach be more faithful and informative exist baseline , establish practical step automated and ready-to-use academic video generation . dataset , agent , and code be available https://github.com/showlab/paper2video",Computer Vision and Pattern Recognition,06/10/2025
10.48550/arXiv.2510.05094,vchain : chain-of-visual-thought reasoning video generation,"Ziqi Huang, Ning Yu, Gordon Chen, Haonan Qiu, Paul Debevec, Ziwei Liu","recent video generation model can produce smooth and visually appealing clip , but often struggle to synthesize complex dynamic coherent chain consequence . accurately model visual outcome and state transition time remain core challenge . contrast , large language and multimodal model ( e.g. , gpt-4o ) exhibit strong visual state reasoning and future prediction capability . to bridge strength , introduce vchain , novel inference-time chain-of-visual-thought framework inject visual reasoning signal multimodal model video generation . specifically , vchain contain dedicated pipeline leverage large multimodal model to generate sparse set critical keyframe snapshot , be then use to guide sparse inference-time tuning pre-trained video generator only key moment . approach be tuning-efficient , introduce minimal overhead and avoid dense supervision . extensive experiment complex , multi-step scenario show vchain significantly enhance quality generate video .",Computer Vision and Pattern Recognition,06/10/2025
10.48550/arXiv.2510.05093,character mixing video generation,"Tingting Liao, Chongjian Ge, Guangyi Liu, Hao Li, Yi Zhou","imagine mr. bean step tom and jerry—can generate video character interact naturally different world ? study inter-character interaction text-to-video generation , key challenge be to preserve character ’s identity and behavior enable coherent cross-context interaction . be difficult character may never have coexist and mix style often cause style delusion , realistic character appear cartoonish or vice versa . introduce framework tackle issue cross-character embed ( cce ) , learn identity and behavioral logic multimodal source , and cross-character augmentation ( cca ) , enrich training synthetic co-existence and mixed-style datum . together , technique allow natural interaction previously uncoexistent character lose stylistic fidelity . experiment curate benchmark cartoon and live-action series 10 character show clear improvement identity preservation , interaction quality , and robustness style delusion , enable new form generative storytelling . additional result and video be available project page : https://tingtingliao.github.io/mimix .",Computer Vision and Pattern Recognition,06/10/2025
10.48550/arXiv.2510.05091,factuality matter : image generation and editing meet structured visuals,"Le Zhuo, Songhao Han, Yuandong Pu, Boxiang Qiu, Sayak Paul, Yue Liao, Yihao Liu, Jie Shao, Xi Chen, Si Liu, Hongsheng Li","modern visual generation model excel create aesthetically pleasing natural image , struggle produce or edit structured visual chart , diagram , and mathematical figure , demand composition planning , text rendering , and multimodal reasoning factual fidelity . to address , present first comprehensive , systematic investigation domain , encompass datum construction , model training , and evaluation benchmark . first , construct large-scale dataset 1 . 3 million high-quality structured image pair derive executable drawing program and augment chain-of-thought reasoning annotation . build , train unified model integrate vlm flux . 1 kontext lightweight connector enhanced multimodal understanding . three-stage training curriculum enable progressive feature alignment , knowledge infusion , and reasoning-augmented generation , far boost external reasoner inference time . finally , introduce structbench , novel benchmark generation and edit 1 , 700 challenging instance , and accompany evaluation metric , structscore , employ multi-round q&a protocol to assess fine-grained factual accuracy . evaluation 15 model reveal even lead closed-source system remain far satisfactory . model attain strong editing performance , and inference-time reasoning yield consistent gain diverse architecture . release dataset , model , and benchmark , aim to advance unified multimodal foundation structured visual .",Computer Vision and Pattern Recognition,06/10/2025
10.48550/arXiv.2510.05071,neuroplastic modular framework : cross-domain image classification garbage and industrial surfaces,"Debojyoti Ghosh, Soumya K Ghosh, Adrijit Goswami","efficient and accurate classification waste and industrial surface defect be essential ensure sustainable waste management and maintain high standard quality control . paper introduce neuroplastic modular classifier , novel hybrid architecture design robust and adaptive image classification dynamic environment . model combine resnet-50 backbone localize feature extraction vision transformer ( vit ) to capture global semantic context . additionally , faiss-based similarity retrieval be incorporate to provide memory reference to previously encounter datum , enrich model ’s feature space . key innovation architecture be neuroplastic modular design compose expandable , learnable block dynamically grow training performance plateaus . inspire biological learning system , mechanism allow model to adapt datum complexity time , improve generalization . garbage classification , validate model kolektor surface defect dataset 2 ( kolektorsdd2 ) , involve industrial defect detection metal surface . experimental result domain show propose architecture outperform traditional static model accuracy and adaptability . neuroplastic modular classifier offer scalable , high-performance solution real-world image classification , strong applicability both environmental and industrial domain .",Computer Vision and Pattern Recognition,06/10/2025
10.48550/arXiv.2510.05053,no-reference quality assessment contrast-distorted images use contrast-enhanced pseudo reference,"Mohammad-Ali Mahmoudpour, Saeed Mahmoudpour","contrast change be important factor affect quality image . image capturing , unfavorable lighting condition can cause contrast change and visual quality loss . various method have be propose to assess quality image different distortion such blur and noise , contrast distortion have be largely overlook visual impact and property be different other conventional type distortion . paper , propose no-reference image quality assessment ( nr-iqa ) metric contrast-distorted image . use set contrast enhancement algorithm , aim to generate pseudo-reference image be visually close actual reference image , such nr problem be transform full-reference ( fr ) assessment high accuracy . end , large dataset contrast-enhanced image be produce to train classification network can select most suitable contrast enhancement algorithm – base image content and distortion – pseudo-reference image generation . finally , evaluation be perform fr manner to assess quality difference contrast-enhanced ( pseudo-reference ) and degrade image . performance evaluation propose method three database contain contrast distortion ( ccid2014 , tid2013 , and csiq ) , indicate promising performance propose method .",Computer Vision and Pattern Recognition,06/10/2025
10.48550/arXiv.2510.05051,segmast3r : geometry grounded segment matching,"Rohit Jayanti, Swayam Agrawal, Vansh Garg, Siddharth Tourani, Muhammad Haris Khan, Sourav Garg, Madhava Krishna","segment matching be important intermediate task computer vision establish correspondence semantically or geometrically coherent region image . keypoint matching , focus localize feature , segment matching capture structured region , offer great robustness occlusion , lighting variation , and viewpoint change . paper , leverage spatial understanding 3d foundation model to tackle wide-baseline segment matching , challenging setting involve extreme viewpoint shift . propose architecture use inductive bias 3d foundation model to match segment image pair 180∘180^{\circ } rotation . extensive experiment show approach outperform state-of-the-art method , include sam2 video propagator and local feature matching method , to 30 % auprc metric , scannet++ and replica dataset . far demonstrate benefit propose model relevant downstream task , include 3d instance mapping and object-relative navigation .",Computer Vision and Pattern Recognition,06/10/2025
10.48550/arXiv.2510.05015,explore efficacy modified transfer learning identify parkinson 's disease drawn image pattern,"Nabil Daiyan, Md Rakibul Haque","parkinson ’s disease ( pd ) be progressive neurodegenerative condition characterize death dopaminergic neuron , lead various movement disorder symptom . early diagnosis pd be crucial to prevent adverse effect , yet traditional diagnostic method be often cumbersome and costly . study , machine learning-based approach be propose use hand-drawn spiral and wave image potential biomarker pd detection . methodology leverage convolutional neural network ( cnns ) , transfer learning , and attention mechanism to improve model performance and resilience overfitte . to enhance diversity and richness spiral and wave category , training dataset undergoe augmentation to increase number image . propose architecture comprise three phase : utilize pre-trained cnn , incorporate custom convolutional layer , and ensemble voting . employ hard voting far enhance performance aggregate prediction multiple model . experimental result show promise accuracy rate . spiral image , weight average precision , recall , and f1-score be 90 % , and wave image , be 96 . 67 % . combine prediction ensemble hard voting , overall accuracy be 93 . 3 % . finding underscore potential machine learning early pd diagnosis , offer non-invasive and cost-effective solution to improve patient outcome .",Computer Vision and Pattern Recognition,06/10/2025
10.48550/arXiv.2510.04966,activemark : watermarking visual foundation model massive activation,"Anna Chistyakova, Mikhail Pautov","be train large and vast dataset , visual foundation model ( vfm ) can be fine-tuned diverse downstream task , achieve remarkable performance and efficiency various computer vision application . high computation cost datum collection and training motivate owner vfm to distribute license to protect intellectual property right . however , dishonest user protect model ’s copy may illegally redistribute , example , to make profit . consequence , development reliable ownership verification tool be great importance today , such method can be use to differentiate redistribute copy protect model and independent model . paper , propose approach ownership verification visual foundation model fine-tune small set expressive layer vfm small encoder-decoder network to embed digital watermark internal representation hold-out set input image . importantly , watermark embed remain detectable functional copy protect model , obtain , example , fine-tune vfm particular downstream task . theoretically and experimentally , demonstrate propose method yield low probability false detection non-watermarked model and low probability false misdetection watermarked model .",Computer Vision and Pattern Recognition,06/10/2025
10.48550/arXiv.2510.04961,ssdd : single-step diffusion decoder efficient image tokenization,"Théophane Vallaeys, Jakob Verbeek, Matthieu Cord","tokenizer be key component state-of-the-art generative image model , extract most important feature signal reduce datum dimension and redundancy . most current tokenizer be base kl-regularized variational autoencoder ( kl-vae ) , train reconstruction , perceptual and adversarial loss . diffusion decoder have be propose more principled alternative to model distribution image condition latent . however , match performance kl-vae still require adversarial loss , as well high decode time iterative sampling . to address limitation , introduce new pixel diffusion decoder architecture improved scaling and training stability , benefit transformer component and gan-free training . use distillation to replicate performance diffusion decoder efficient single-step decoder . make ssdd first diffusion decoder optimize single-step reconstruction train adversarial loss , reach high reconstruction quality and fast sampling kl-vae . particular , ssdd improve reconstruction fid 0 . 870 . 87 0 . 500 . 50 1 . 4×1 . 4\times high throughput and preserve generation quality dits 3 . 8×3 . 8\times fast sampling . such , ssdd can be use drop-in replacement kl-vae , and build higher-quality and fast generative model .",Computer Vision and Pattern Recognition,06/10/2025
10.48550/arXiv.2510.04947,bidirectional mammogram view translation column-aware and implicit 3d conditional diffusion,"Xin Li, Kaixiang Yang, Qiang Li, Zhiwei Wang","dual-view mammography , include craniocaudal ( cc ) and mediolateral oblique ( mlo ) projection , offer complementary anatomical view crucial breast cancer diagnosis . however , real-world clinical workflow , one view may be miss , corrupted , or degrade acquisition error or compression artifact , limit effectiveness downstream analysis . view-to-view translation can help recover missing view and improve lesion alignment . natural image , task mammography be highly challenging large non-rigid deformation and severe tissue overlap x-ray projection , obscure pixel-level correspondence . paper , propose column-aware and implicit 3d diffusion ( ca3d-diff ) , novel bidirectional mammogram view translation framework base conditional diffusion model . to address cross-view structural misalignment , first design column-aware cross-attention mechanism leverage geometric property anatomically corresponding region tend to lie similar column position view . gaussian-decayed bias be apply to emphasize local column-wise correlation suppress distant mismatch . furthermore , introduce implicit 3d structure reconstruction module back-project noisy 2d latent coarse 3d feature volume base breast-view projection geometry . reconstructed 3d structure be refine and inject denoise unet to guide cross-view generation enhanced anatomical awareness . extensive experiment demonstrate ca3d-diff achieve superior performance bidirectional task , outperform state-of-the-art method visual fidelity and structural consistency . furthermore , synthesize view effectively improve single-view malignancy classification screening setting , demonstrate practical value method real-world diagnostic . advancement position ca3d-diff promising tool clinical application , particularly miss view recovery and improve cross-view representation learning . code be available https://github.com/lixinhust/ca3d-diff .",Computer Vision and Pattern Recognition,06/10/2025
10.48550/arXiv.2510.04939,unsupervised active learning natural feature progressive framework,"Yuxi Liu, Catherine Lalman, Yimin Yang","effectiveness modern deep learning model be predicate availability large-scale , human-annotated dataset , process be notoriously expensive and time-consuming . active learning ( al ) offer strategic solution label only most informative and representative datum , iterative nature still necessitate significant human involvement . unsupervised active learning ( ual ) present alternative shift annotation burden single , post-selection step . unfortunately , prevail ual method struggle to achieve state-of-the-art performance . approach typically rely local , gradient-based scoring sample importance estimation , not only make vulnerable ambiguous and noisy datum but also hinder capacity to select sample adequately represent full data distribution . moreover , use shallow , one-shot linear selection fall short true ual paradigm . paper , propose natural feature progressive framework ( nfpf ) , ual method revolutionize sample importance be measure . core , nfpf employ specific feature learning machine ( sflm ) to effectively quantify sample ’s contribution to model performance . far utilize sflm to define powerful reconstruction difference metric initial sample selection . comprehensive experiment show nfpf significantly outperform establish ual method and achieve performance par supervised al method vision dataset . detailed ablation study and qualitative visualization provide compelling evidence nfpf ’s superior performance , enhance robustness , and improve datum distribution coverage .",Computer Vision and Pattern Recognition,06/10/2025
10.48550/arXiv.2510.04923,ren : anatomically-informe mixture-of-expert interstitial lung disease diagnosis,"Alec K. Peltekian, Halil Ertugrul Aktas, Gorkem Durak, Kevin Grudzinski, Bradford C. Bemiss, Carrie Richardson, Jane E. Dematte, G. R. Scott Budinger, Anthony J. Esposito, Alexander Misharin, Alok Choudhary, Ankit Agrawal, Ulas Bagci","mixture-of-expert ( moe ) architecture have significantly contribute scalable machine learning enable specialized subnetwork to tackle complex task efficiently . however , traditional moe system lack domain-specific constraint essential medical imaging , anatomical structure and regional disease heterogeneity strongly influence pathological pattern . here , introduce regional expert networks ( ren ) , first anatomically-informed moe framework tailor specifically medical image classification . ren leverage anatomical prior to train seven specialized expert , dedicate distinct lung lobe and bilateral lung combination , enable precise modeling region-specific pathological variation . multi-modal gating mechanism dynamically integrate radiomic biomarker and deep learning ( dl ) feature ( cnn , vit , mamba ) weight expert contribution optimally . apply interstitial lung disease ( ild ) classification , ren achieve consistently superior performance : radiomics-guided ensemble reach average auc 0 . 8646 ±\pm 0 . 0467 , +12 . 5 % improvement swinunetr baseline ( auc 0 . 7685 , p=0 . 031p=0 . 031 ) . region-specific expert far reveal lower-lobe model achieve auc 0 . 88-0 . 90 , surpass dl counterpart ( cnn : 0 . 76-0 . 79 ) and align know disease progression pattern . rigorous patient-level cross-validation , ren demonstrate strong generalizability and clinical interpretability , present scalable , anatomically-guided approach readily extensible other structured medical imaging application .",Computer Vision and Pattern Recognition,06/10/2025
10.48550/arXiv.2510.04916,semantics-aware hierarchical self-supervised approach classification remote sensing images,"Giulio Weikmann, Gianmarco Perantoni, Lorenzo Bruzzone","deep learning have become increasingly important remote sense image classification ability to extract semantic information complex datum . classification task often include predefine label hierarchy represent semantic relationship class . however , hierarchy be frequently overlook , and most approach focus only fine-grained classification scheme . paper , present novel semantics-aware hierarchical consensus ( sahc ) method learn hierarchical feature and relationship integrate hierarchy-specific classification head deep network architecture , specialize different degree class granularity . propose approach employ trainable hierarchy matrix , guide network learning hierarchical structure self-supervised manner . furthermore , introduce hierarchical consensus mechanism to ensure consistent probability distribution different hierarchical level . mechanism act weighted ensemble be able to effectively leverage inherent structure hierarchical classification task . propose sahc method be evaluate three benchmark dataset different degree hierarchical complexity different task , use distinct backbone architecture to effectively emphasize adaptability . experimental result show both effectiveness propose approach guide network learning and robustness hierarchical consensus remote sense image classification task .",Computer Vision and Pattern Recognition,06/10/2025
10.48550/arXiv.2510.04912,"comparative analysis yolov5 , fast r-cnn , ssd , and retinanet motorbike detection kigali autonomous drive context","Ngeyen Yinkfu, Sunday Nwovu, Jonathan Kayizzi, Angelique Uwamahoro","kigali , rwanda , motorcycle taxi be primary mode transportation , often navigate unpredictably and disregard traffic rule , pose significant challenge autonomous driving system . study compare four object detection models—yolov5 , faster r-cnn , ssd , and retinanet—for motorbike detection use custom dataset 198 image collect kigali . implement pytorch transfer learning , model be evaluate accuracy , localization , and inference speed to assess suitability real-time navigation resource-constrained setting . identify implementation challenge , include dataset limitation and model complexity , and recommend simplified architecture future work to enhance accessibility autonomous system develop country rwanda .",Computer Vision and Pattern Recognition,06/10/2025
10.48550/arXiv.2510.04876,benthicat : opti-acoustic dataset advance benthic classification and habitat mapping,"Hayat Rajani, Valerio Franchi, Borja Martinez-Clavel Valles, Raimon Ramos, Rafael Garcia, Nuno Gracias","benthic habitat mapping be fundamental understand marine ecosystem , guide conservation effort , and support sustainable resource management . yet , scarcity large , annotated dataset limit development and benchmarking machine learning model domain . paper introduce thorough multi-modal dataset , comprise million side-scan sonar ( sss ) tile collect coast catalonia ( spain ) , complement bathymetric map and set co-registere optical image target survey use autonomous underwater vehicle ( auv ) . approximately 36 00036\ , 000 sss tile have be manually annotate segmentation mask to enable supervised fine-tuning classification model . raw sensor datum , together mosaic , be also release to support further exploration and algorithm development . to address challenge multi-sensor datum fusion auv , spatially associate optical image correspond sss tile , facilitate self-supervised , cross-modal representation learning . accompany open-source preprocessing and annotation tool be provide to enhance accessibility and encourage research . resource aim to establish standardized benchmark underwater habitat mapping , promote advancement autonomous seafloor classification and multi-sensor integration .",Computer Vision and Pattern Recognition,06/10/2025
10.48550/arXiv.2510.04864,in-field mapping grape yield and quality illumination-invariant deep learning,"Ciem Cornelissen, Sander De Coninck, Axel Willekens, Sam Leroux, Pieter Simoens","paper present end-to-end , iot-enable robotic system non-destructive , real-time , and spatially-resolved mapping grape yield and quality ( brix , acidity ) vineyard . system feature comprehensive analytical pipeline integrate two key module : high-performance model grape bunch detection and weight estimation , and novel deep learning framework quality assessment hyperspectral ( hsi ) datum . critical barrier to in-field hsi be "" domain shift "" cause variable illumination . to overcome , quality assessment be power light-invariant spectral autoencoder ( lisa ) , domain-adversarial framework learn illumination-invariant feature uncalibrated datum . validate system ’s robustness purpose-built hsi dataset span three distinct illumination domain : control artificial lighting ( lab ) , and variable natural sunlight capture morning and afternoon . result show complete pipeline achieve recall ( 0 . 82 ) bunch detection and r2r^{2 } ( 0 . 76 ) weight prediction , lisa module improve quality prediction generalization 20 % compare baseline . combine robust module , system successfully generate high-resolution , georeference datum grape yield and quality , provide actionable , data-driven insight precision viticulture .",Computer Vision and Pattern Recognition,06/10/2025
10.48550/arXiv.2510.04856,erde : entropy-regularized distillation early-exit,"Martial Guidez, Stefan Duffner, Yannick Alpou, Oscar Röth, Christophe Garcia","deep neural network and particular convolutional neural networks have demonstrate state-of-the-art performance image classification relatively high efficiency , still exhibit high computational cost , often render impractical real-time and edge application . therefore , multitude compression technique have be develop to reduce cost maintain accuracy . addition , dynamic architecture have be introduce to modulate level compression execution time , be desirable property many resource-limited application scenario . propose method effectively integrate two well-established optimization technique : early exit and knowledge distillation , reduce student early-exit model be train more complex teacher early-exit model . primary contribution research lie approach train student early-exit model . comparison conventional knowledge distillation loss , approach incorporate new entropy-based loss image teacher ’s classification be incorrect . propose method optimize trade-off accuracy and efficiency , thereby achieve significant reduction computational complexity compromise classification performance . validity approach be substantiate experimental result image classification dataset cifar10 , cifar100 and svhn , far open new research perspective knowledge distillation other contexts .",Computer Vision and Pattern Recognition,06/10/2025
10.48550/arXiv.2510.04854,read room : infer social context dyadic interaction recognition cyber-physical-social infrastructure systems,"Cheyu Lin, John Martins, Katherine A. Flanigan, Ph.D","cyber-physical system ( cps ) integrate sensing , computing , and control to improve infrastructure performance , focus economic goal performance and safety . however , often neglect potential human-centered ( or "" social "" ) benefit . cyber-physical-social infrastructure system ( cpsis ) aim to address align cps social objective . involve define social benefit , understand human interaction other and infrastructure , develop privacy-preserving measurement method , model interaction prediction , link social benefit , and actuate physical environment to foster positive social outcome . paper delve recognize dyadic human interaction use real-world datum , be backbone measure social behavior . lay foundation to address need to enhance understanding deep meaning and mutual response inherent human interaction . rgb camera be informative interaction recognition , privacy concern arise . depth sensor offer privacy-conscious alternative analyze skeletal movement . study compare five skeleton-based interaction recognition algorithm dataset 12 dyadic interaction . single-person dataset , interaction , categorize communication type emblem and affect display , offer insight cultural and emotional aspect human interaction .",Computer Vision and Pattern Recognition,06/10/2025
10.48550/arXiv.2510.04844,actions kinesics : extract human psychological states bodily movement,"Cheyu Lin, Katherine A. Flanigan",nan,Computer Vision and Pattern Recognition,06/10/2025
10.48550/arXiv.2510.04838,random : automatic inner-loop optimization dataset distillation,"Muquan Li, Hang Gou, Dongyang Zhang, Shuang Liang, Xiurui Xie, Deqiang Ouyang, Ke Qin","grow demand efficient deep learning have position dataset distillation pivotal technique compress training dataset preserve model performance . however , exist inner-loop optimization method dataset distillation typically rely random truncation strategy , lack flexibility and often yield suboptimal result . work , observe neural network exhibit distinct learning dynamic different training stages—early , middle , and late—make random truncation ineffective . to address limitation , propose automatic truncated backpropagation time ( at-bptt ) , novel framework dynamically adapt truncation position and window size accord intrinsic gradient behavior . at-bptt introduce three key component : ( 1 ) probabilistic mechanism stage-aware timestep selection , ( 2 ) adaptive window size strategy base gradient variation , and ( 3 ) low-rank hessian approximation to reduce computational overhead . extensive experiment cifar-10 , cifar-100 , tiny-imagenet , and imagenet-1 k show at-bptt achieve state-of-the-art performance , improve accuracy average 6 . 16 % baseline method . moreover , approach accelerate inner-loop optimization 3 . 9 × save 63 % memory cost .",Computer Vision and Pattern Recognition,06/10/2025
10.48550/arXiv.2510.04823,flow matching conditional mri-ct and cbct-ct image synthesis,"Arnela Hadzic, Simon Johannes Joham, Martin Urschler","generate synthetic ct ( sct ) mri or cbct play crucial role enable mri-only and cbct-based adaptive radiotherapy , improve treatment precision reduce patient radiation exposure . to address task , adopt fully 3d flow matching ( fm ) framework , motivate recent work demonstrate fm ’s efficiency produce high-quality image . approach , gaussian noise volume be transform sct image integrate learn fm velocity field , condition feature extract input mri or cbct use lightweight 3d encoder . evaluate method synthrad2025 challenge benchmark , train separate model mri →\rightarrow sct and cbct →\rightarrow sct three anatomical region : abdomen , head and neck , and thorax . validation and testing be perform challenge submission system . result indicate method accurately reconstruct global anatomical structure ; however , preservation fine detail be limited , primarily relatively low training resolution impose memory and runtime constraint . future work will explore patch-based training and latent-space flow model to improve resolution and local structural fidelity .",Computer Vision and Pattern Recognition,06/10/2025
10.48550/arXiv.2510.04822,avatarvton : 4d virtual try-on animatable avatars,"Zicheng Jiang, Jixin Gao, Shengfeng He, Xinzhe Li, Yulong Zheng, Zhaotong Yang, Junyu Dong, Yong Du","propose avatarvton , first 4d virtual try-on framework generate realistic try-on result single in-shop garment image , enable free pose control , novel-view rendering , and diverse garment choice . exist method , avatarvton support dynamic garment interaction single-view supervision , rely multi-view garment capture or physics prior . framework consist two key module : ( 1 ) reciprocal flow rectifier , prior-free optical-flow correction strategy stabilize avatar fitting and ensure temporal coherence ; and ( 2 ) non-linear deformer , decompose gaussian map view-pose-invariant and view-pose-specific component , enable adaptive , non-linear garment deformation . to establish benchmark 4d virtual try-on , extend exist baseline unified module fair qualitative and quantitative comparison . extensive experiment show avatarvton achieve high fidelity , diversity , and dynamic garment realism , make well-suited ar/vr , gaming , and digital-human application .",Computer Vision and Pattern Recognition,06/10/2025
10.48550/arXiv.2510.04819,visual representations language model,"Benlin Liu, Amita Kamath, Madeleine Grunde-McLaughlin, Winson Han, Ranjay Krishna","interpretability work analyze vit encoder and transformer activation , do not yet understand multimodal language models ( mlms ) struggle perception-heavy task . offer under-studied perspective examine popular mlm ( llava-onevision , qwen2 . 5-vl , and llama-3-llava-next ) process visual key-value token . first study flow visual information language model , find image value tokens encode sufficient information to perform several perception-heavy task zero-shot : segmentation , semantic correspondence , temporal correspondence , and refer expression detection . find language model do augment visual information receive projection input visual encodings—which reveal correlate overall mlm perception capability—it contain less visual information several task equivalent visual encoder ( siglip ) have not undergo mlm finetuning . far , find visual information correspond input-agnostic image key token later layer language model contain artifact reduce perception capability overall mlm . next , discuss control visual information language model , show add text prefix image input improve perception capability visual representation . finally , reveal language model be able to well control visual information , perception would significantly improve ; e.g. , 33 . 3 % art style question blink benchmark , perception information present language model be not surface output ! finding reveal insight role key-value token multimodal system , pave way deep mechanistic interpretability mlm and suggest new direction train visual encoder and language model component .",Computer Vision and Pattern Recognition,06/10/2025
10.48550/arXiv.2510.04802,do just see ? arbitrary view synthesis egocentric replay operating room workflow ambient sensor,"Han Zhang, Lalithkumar Seenivasan, Jose L. Porras, Roger D. Soberanis-Mukul, Hao Ding, Hongchao Shu, Benjamin D. Killeen, Ankita Ghosh, Lonny Yarmus, Masaru Ishii, Angela Christine Argento, Mathias Unberath","observe surgical practice have historically rely fix vantage point or recollection , leave egocentric visual perspective guide clinical decision undocumente . fixed-camera video can capture surgical workflow room-scale , but can not reconstruct team member actually see . thus , video only provide limited insight decision affect surgical safety , training , and workflow optimization be make . here introduce egosurg , first framework to reconstruct dynamic , egocentric replay operating room ( or ) staff directly wall-mounted fixed-camera video , and thus , intervention clinical workflow . egosurg couple neural render diffusion-based view enhancement , enable high-visual fidelity synthesis arbitrary and egocentric viewpoint moment . evaluation multi-site surgical case and control study , egosurg reconstruct person-specific visual field and arbitrary viewpoint high visual quality and fidelity . transform exist or camera infrastructure navigable dynamic 3d record , egosurg establish new foundation immersive surgical data science , enable surgical practice to be visualize , experienced , and analyze angle .",Computer Vision and Pattern Recognition,06/10/2025
10.48550/arXiv.2510.04797,dit-vton : diffusion transformer framework unified multi-category virtual try-on and virtual try-all integrated image editing,"Qi Li, Shuwen Qiu, Julien Han, Xingzi Xu, Mehmet Saygin Seyfioglu, Kee Kiat Koo, Karim Bouyarmane","rapid growth e-commerce have intensify demand virtual try-on ( vto ) technology , enable customer to realistically visualize product overlay own image . recent advance , exist vto model face challenge fine-grained detail preservation , robustness real-world imagery , efficient sampling , image editing capability , and generalization diverse product category . paper , present dit-vton , novel vto framework leverage architecture base diffusion transformer ( dit ) , renowne performance text-conditioned image generation ( text-to-image ) , adapt here image-conditioned vto task . systematically explore multiple dit configuration , include in-context token concatenation , channel concatenation , and controlnet integration , to determine good setup vto image conditioning . to enhance robustness , train model expand dataset encompass varied background , unstructured reference , and non-garment category , demonstrate benefit datum scale vto adaptability . dit-vton also redefine vto task garment try-on , offer versatile virtual try-all ( vta ) solution capable handle wide range product category and support advanced image editing functionality , such pose preservation , precise localize region editing and refinement , texture transfer and object-level customization . experimental result show model surpass state-of-the-art method public benchmark test viton-hd , achieve superior detail preservation and robustness reliance additional image condition encoder . also surpass state-of-the-art model have vta and image editing capability varied dataset compose thousand product category . result , dit-vton significantly advance vto applicability diverse real-world scenario , enhance realism and personalization online shopping experience .",Computer Vision and Pattern Recognition,03/10/2025
10.48550/arXiv.2510.04794,comparative study vision transformers and cnn few-shot rigid transformation and fundamental matrix estimation,"Alon Kaya, Igal Bilik, Inna Stainvas","vision-transformer ( vits ) and large-scale convolution-neural-network ( cnn ) have reshape computer vision pretraine feature representation enable strong transfer learn diverse task . however , efficiency backbone architecture geometric estimation task involve image deformation low-data regime remain open question . work consider two such task : 1 ) estimate 2d rigid transformation pair image and 2 ) predict fundamental matrix stereo image pair , important problem various application , such autonomous mobility , robotic , and 3d scene reconstruction . address intriguing question , work systematically compare large-scale cnn ( resnet , efficientnet , clip-resnet ) vit-based foundation model ( clip-vit variant and dino ) various datum size setting , include few-shot scenario . pretraine model be optimize classification or contrastive learning , encourage to focus mostly high-level semantic . consider task require balance local and global feature differently , challenge straightforward adoption model backbone . empirical comparative analysis show , similar training scratch , vits outperform cnn refinement large downstream-data scenario . however , small datum scenario , inductive bias and small capacity cnn improve performance , allow to match vit . moreover , vits exhibit strong generalization cross-domain evaluation data distribution change . result emphasize importance carefully select model architecture refinement , motivate future research hybrid architecture balance local and global representation .",Computer Vision and Pattern Recognition,06/10/2025
10.48550/arXiv.2510.04781,hands-free heritage : automate 3d scanning cultural heritage digitization,"Javed Ahmad, Federico Dassiè, Selene Frascella, Gabriele Marchello, Ferdinando Cannella, Arianna Traviglia","high-fidelity 3d scanning be essential preserve cultural heritage artefact , support documentation , analysis , and long-term conservation . however , conventional method typically require specialized expertise and manual intervention to maintain optimal scanning condition and coverage . present automate two-robot scanning system eliminate need handheld or semi-automatic workflow combine coordinated robotic manipulation high-resolution 3d scanning . system parameterize scan space distinct region , enable coordinate motion planning scanner-equipped robot and tray-handling robot . optimized trajectory planning and waypoint distribution ensure comprehensive surface coverage , minimize occlusion , and balance reconstruction accuracy system efficiency . experimental result show approach achieve significantly low chamfer distance and high f-score compare baseline method , offer superior geometric accuracy , improved digitization efficiency , and reduce reliance expert operator .",Computer Vision and Pattern Recognition,06/10/2025
10.48550/arXiv.2510.04772,federated learning surgical vision appendicitis classification : result fedsurg endovis 2024 challenge,"Max Kirchner, Hanna Hoffmann, Alexander C. Jenke, Oliver L. Saldanha, Kevin Pfeiffer, Weam Kanjo, Julia Alekseenko, Claas de Boer, Santhi Raj Kolamuri, Lorenzo Mazza, Nicolas Padoy, Sophia Bano, Annika Reinke, Lena Maier-Hein, Danail Stoyanov, Jakob N. Kather, Fiona R. Kolbinger, Sebastian Bodenstedt, Stefanie Speidel",purpose : fedsurg challenge be design to benchmark state art federate learning surgical video classification . goal be to assess well current method generalize unseen clinical center and adapt local fine-tuning enable collaborative model development share patient datum .,Computer Vision and Pattern Recognition,06/10/2025
10.48550/arXiv.2510.04770,seen : bounded distribution estimation open-vocabulary learning,"Xiaomeng Fan, Yuchuan Mao, Zhi Gao, Yuwei Wu, Jin Chen, Yunde Jia","open-vocabulary learning require model data distribution open environment , consist seen-class and unseen-class datum . exist method estimate distribution open environment use seen-class datum , absence unseen class make estimation error inherently unidentifiable . intuitively , learn see class be crucial distribution estimation to bind estimation error . theoretically demonstrate distribution can be effectively estimate generate unseen-class datum , estimation error be upper-bounded . build theoretical insight , propose novel open-vocabulary learning method , generate unseen-class datum estimate distribution open environment . method consist class-domain-wise data generation pipeline and distribution alignment algorithm . data generation pipeline generate unseen-class datum guidance hierarchical semantic tree and domain information infer seen-class datum , facilitate accurate distribution estimation . generate datum , distribution alignment algorithm estimate and maximize posterior probability to enhance generalization open-vocabulary learning . extensive experiment 1111 dataset demonstrate method outperform baseline approach 14%14\% , highlight effectiveness and superiority .",Computer Vision and Pattern Recognition,06/10/2025
10.48550/arXiv.2510.04759,progressive gaussian transformer anisotropy-aware sampling open vocabulary occupancy prediction,"Chi Yan, Dan Xu","3d occupancy prediction task have witness remarkable progress recent year , play crucial role vision-based autonomous driving system . traditional method be limit fix semantic category , recent approach have move predict text-aligned feature to enable open-vocabulary text query real-world scene . however , exist trade-off text-aligned scene modeling : sparse gaussian representation struggle to capture small object scene , dense representation incur significant computational overhead . to address limitation , present pg-occ , innovative progressive gaussian transformer framework enable open-vocabulary 3d occupancy prediction . framework employ progressive online densification , feed-forward strategy gradually enhance 3d gaussian representation to capture fine-grained scene detail . iteratively enhance representation , framework achieve increasingly precise and detailed scene understanding . key contribution be introduction anisotropy-aware sampling strategy spatio-temporal fusion , adaptively assign receptive field gaussians different scale and stage , enable more effective feature aggregation and rich scene information capture . extensive evaluation , demonstrate pg-occ achieve state-of-the-art performance relative 14 . 3 % miou improvement previous good performing method . code and pretraine model will be release publication project page : https://yanchi-3dv.github.io/pg-occ .",Computer Vision and Pattern Recognition,06/10/2025
10.48550/arXiv.2510.04753,appearance : transformer-base person identification conversational dynamics,"Masoumeh Chapariniya, Teodora Vukovic, Sarah Ebling, Volker Dellwo","paper investigate performance transformer-based architecture person identification natural , face‑to‑face conversation scenario . implement and evaluate two-stream framework separately model spatial configuration and temporal motion pattern 133 coco wholebody keypoint , extract subset candor conversational corpus . experiment compare pre-trained and from-scratch training , investigate use velocity feature , and introduce multi-scale temporal transformer hierarchical motion modeling . result demonstrate domain-specific training significantly outperform transfer learning , and spatial configuration carry more discriminative information temporal dynamic . spatial transformer achieve 95 . 74 % accuracy , multi-scale temporal transformer achieve 93 . 90 % . feature‑level fusion push performance 98 . 03 % , confirm postural and dynamic information be complementary . finding highlight potential transformer architecture person identification natural interaction and provide insight future multimodal and cross-cultural study .",Computer Vision and Pattern Recognition,06/10/2025
10.48550/arXiv.2510.04741,anomaly-aware yolo : frugal yet robust approach infrared small target detection,"Alina Ciocarlan, Sylvie Le Hégarat-Mascle, Sidonie Lefebvre","infrared small target detection ( irstd ) be challenging task defense application , complex background and tiny target size often result numerous false alarm use conventional object detector . to overcome limitation , propose anomaly-aware yolo ( aa-yolo ) , integrate statistical anomaly detection test detection head . treat small target unexpected pattern background , aa-yolo effectively control false alarm rate . approach not only achieve competitive performance several irstd benchmark , but also demonstrate remarkable robustness scenario limited training datum , noise , and domain shift . furthermore , only detection head be modify , design be highly generic and have be successfully apply various yolo backbone , include lightweight model . also provide promising result integrate instance segmentation yolo . versatility make attractive solution real-world deployment resource be constrain . code will be publicly release .",Computer Vision and Pattern Recognition,06/10/2025
10.48550/arXiv.2510.04739,exposureengine : orient logo detection and sponsor visibility analytics sports broadcast,"Mehdi Houshmand Sarkhoosh, Frøy Øye, Henrik Nestor Sørlie, Nam Hoang Vu, Dag Johansen, Cise Midoglu, Tomas Kupka, Pål Halvorsen","quantify sponsor visibility sport broadcast be critical marketing task traditionally hinder manual , subjective , and unscalable analysis method . automated system offer alternative , reliance axis-aligned horizontal bounding box ( hbb ) lead inaccurate exposure metric logo appear rotate or skew dynamic camera angle and perspective distortion . paper introduce exposureengine , end-to-end system design accurate , rotation-aware sponsor visibility analytic sport broadcast , demonstrate soccer case study . approach predict oriented bounding box ( obb ) to provide geometrically precise fit logo regardless orientation on-screen . to train and evaluate detector , develop new dataset comprise 1 , 103 frame swedish elite soccer , feature 670 unique sponsor logo annotate obb s. model achieve mean average precision ( map@0 . 5 ) 0 . 859 , precision 0 . 96 and recall 0 . 87 , demonstrate robust performance localize logo diverse broadcast condition . system integrate detection analytical pipeline calculate precise visibility metric , such exposure duration and on-screen coverage . furthermore , incorporate language-driven agentic layer , enable user to generate report , summary , and medium content natural language query . complete system , include dataset and analytic dashboard , provide comprehensive solution auditable and interpretable sponsor measurement sport medium . overview exposureengine be available online.111https://youtu.be/trw6obisuw4",Computer Vision and Pattern Recognition,06/10/2025
10.48550/arXiv.2510.04723,benchmark monocular metric depth estimation wildlife setting,"Niccolò Niccoli, Lorenzo Seidenari, Ilaria Greco, Francesco Rovero","camera trap be widely use wildlife monitoring , but extract accurate distance measurement monocular image remain challenge lack depth information . monocular depth estimation ( mde ) method have advance significantly , performance natural wildlife environment have not be systematically evaluate . work introduce first benchmark monocular metric depth estimation wildlife monitoring condition . evaluate four state-of-the-art mde method ( depth v2 , ml depth pro , zoedepth , and metric3d ) geometric baseline 93 camera trap image ground truth distance obtain use calibrate charuco pattern . result demonstrate depth v2 achieve good overall performance mean absolute error 0 . 454 m and correlation 0 . 962 , method zoedepth show significant degradation outdoor natural environment ( mae : 3 . 087 m ) . find median-based depth extraction consistently outperform mean-based approach deep learning method . additionally , analyze computational efficiency , zoedepth be fast ( 0 . 17 image ) but least accurate , depth v2 provide optimal balance accuracy and speed ( 0 . 22 image ) . benchmark establishe performance baseline wildlife application and provide practical guidance implement depth estimation conservation monitoring system .",Computer Vision and Pattern Recognition,06/10/2025
10.48550/arXiv.2510.04714,object-centric representation learning enhanced 3d scene graph prediction,"KunHo Heo, GiHyun Kim, SuYeon Kim, MyeongAh Cho","3d semantic scene graph prediction aim to detect object and semantic relationship 3d scene , and have emerge crucial technology robotic and ar/vr application . previous research have address dataset limitation and explore various approach include open-vocabulary setting , frequently fail to optimize representational capacity object and relationship feature , show excessive reliance graph neural networks insufficient discriminative capability . work , demonstrate extensive analysis quality object feature play critical role determine overall scene graph accuracy . to address challenge , design highly discriminative object feature encoder and employ contrastive pretraining strategy decouple object representation learn scene graph prediction . design not only enhance object classification accuracy but also yield direct improvement relationship prediction . notably , plug pretraine encoder exist framework , observe substantial performance improvement evaluation metric . additionally , existing approach have not fully exploit integration relationship information , effectively combine both geometric and semantic feature to achieve superior relationship prediction . comprehensive experiment 3dssg dataset demonstrate approach significantly outperform previous state-of-the-art method . code be publicly available https://github.com/visualsciencelab-khu/ocrl-3dssg-code .",Computer Vision and Pattern Recognition,06/10/2025
10.48550/arXiv.2510.04712,reactdiff : fundamental multiple appropriate facial reaction diffusion model,"Luo Cheng, Song Siyang, Yan Siyuan, Yu Zhen, Ge Zongyuan","automatic generation diverse and human-like facial reaction dyadic dialogue remain critical challenge human-computer interaction system . exist method fail to model stochasticity and dynamic inherent real human reaction . to address , propose reactdiff , novel temporal diffusion framework generate diverse facial reaction be appropriate respond give dialogue context . key insight be plausible human reaction demonstrate smoothness , and coherence time , and conform constraint impose human facial anatomy . to achieve , reactdiff incorporate two vital prior ( spatio-temporal facial kinematic ) diffusion process : i ) temporal facial behavioral kinematic and ii ) facial action unit dependencie . two constraint guide model realistic human reaction manifold , avoid visually unrealistic jitter , unstable transition , unnatural expression , and other artifact . extensive experiment react2024 dataset demonstrate approach not only achieve state-of-the-art reaction quality but also excel diversity and reaction appropriateness . code be publicly available https://github.com/lingjivoo/reactdiff .",Computer Vision and Pattern Recognition,06/10/2025
10.48550/arXiv.2510.04706,"id-consistent , precise expression generation blendshape-guided diffusion","Foivos Paraperas Papantoniou, Stefanos Zafeiriou","human-centric generative model design ai-driven storytelling must bring together two core capability : identity consistency and precise control human performance . recent diffusion-based approach have make significant progress maintain facial identity , achieve fine-grained expression control compromise identity remain challenge . work , present diffusion-based framework faithfully reimagine subject particular facial expression . build id-consistent face foundation model , adopt compositional design feature expression cross-attention module guide flame blendshape parameter explicit control . train diverse mixture image and video datum rich expressive variation , adapter generalize basic emotion subtle micro-expression and expressive transition , overlook prior work . addition , pluggable reference adapter enable expression edit real image transfer appearance reference frame synthesis . extensive quantitative and qualitative evaluation show model outperform exist method tailor and identity-consistent expression generation . code and model can be find https://github.com/foivospar/arc2face .",Computer Vision and Pattern Recognition,06/10/2025
10.48550/arXiv.2510.04705,label-efficient cross-modality generalization liver segmentation multi-phase mri,"Quang-Khai Bui-Tran, Minh-Toan Dinh, Thanh-Huy Nguyen, Ba-Thinh Lam, Mai-Anh Vu, Ulas Bagci","accurate liver segmentation multi-phase mri be vital liver fibrosis assessment , yet label datum be often scarce and unevenly distribute imaging modality and vendor system . propose label-efficient segmentation approach promote cross-modality generalization real-world condition , ged4 hepatobiliary-phase annotation be limited , non-contrast sequence ( t1wi , t2wi , dwi ) be unlabeled , and spatial misalignment and miss phase be common . method integrate foundation-scale 3d segmentation backbone adapt fine-tuning , co-traine cross pseudo supervision leverage unlabeled volume , and standardized preprocessing pipeline . require spatial registration , model learn to generalize mri phase and vendor , demonstrate robust segmentation performance label and unlabeled domain . result exhibit effectiveness propose label-efficient baseline liver segmentation multi-phase , multi-vendor mri and highlight potential combine foundation model adaptation co-training real-world clinical imaging task .",Computer Vision and Pattern Recognition,06/10/2025
10.48550/arXiv.2510.04654,mome : estimate psychological traits gait multi-stage mixture movement experts,"Andy Cǎtrunǎ, Adrian Cosma, Emilian Rǎdoi","gait encode rich biometric and behavioural information , yet leverage manner walk to infer psychological trait remain challenging and underexplored problem . introduce hierarchical multi-stage mixture movement experts ( mome ) architecture multi-task prediction psychological attribute gait sequence represent 2d pose . mome process walk cycle four stage movement complexity , employ lightweight expert model to extract spatio-temporal feature and task-specific gating module adaptively weight expert trait and stage . evaluate psymo benchmark cover 17 psychological trait , method outperform state-of-the-art gait analysis model , achieve 37 . 47 % weight f1 score run level and 44 . 6 % subject level . experiment show integrate auxiliary task such identity recognition , gender prediction , and bmi estimation far improve psychological trait estimation . finding demonstrate viability multi-task gait-based learning psychological trait estimation and provide foundation future research movement-informed psychological inference .",Computer Vision and Pattern Recognition,06/10/2025
10.48550/arXiv.2510.04648,edupersona : benchmarke subjective ability boundaries virtual student agent,"Buyuan Zhu, Shiyu Hu, Yiping Ma, Yuanming Zhang, Kang Hao Cheong","large language model ( llms ) be increasingly integrate education , virtual student agent be become vital classroom simulation and teacher training . yet classroom-oriented subjective ability remain largely unassessed , limit understanding model boundary and hinder trustworthy deployment . present edupersona , large-scale benchmark span two language , three subject , and ten persona type base big five theory . dataset contain 1 , 308 authentic classroom dialogue round , correspond 12 , 814 teacher–student q&a turn , and be far expand persona stylization roughly 10×\times large scale ( 128k turn ) , provide solid foundation evaluation . build resource , decompose hard-to-quantify subjective performance three progressive task : task1 basic coherence ( behavior , emotion , expression , and voice align classroom context ) , task2 student realism , and task3 long-term persona consistency , thereby establish evaluation framework ground educational theory and research value . conduct systematic experiment three representative llms , compare original version ten persona-fine-tuned variant train edupersona . result show consistent and significant average improvement task : task1 33 . 6 % ↑\uparrow , task2 30 . 6 % ↑\uparrow , and task3 14 . 9 % ↑\uparrow . improvement highlight dataset ’s effectiveness and research value , also reveal heterogeneous difficulty persona modeling . summary , edupersona deliver first classroom benchmark center subjective ability , establish decoupled and verifiable research paradigm , and will open-source both dataset and framework to support broad research community advance trustworthy and human-like ai education .",Computer Vision and Pattern Recognition,06/10/2025
10.48550/arXiv.2510.04645,do superpixel segmentation methods influence deforestation image classification ?,"Hugo Resende, Fabio A. Faria, Eduardo B. Neto, Isabela Borlido, Victor Sundermann, Silvio Jamil F. Guimarães, Álvaro L. Fazenda","image segmentation be crucial step various visual application , include environmental monitoring remote sensing . context foresteyes project , combine citizen science and machine learn to detect deforestation tropical forest , image segment be use labeling volunteer and subsequent model training . traditionally , simple linear iterative clustering ( slic ) algorithm be adopt segmentation method . however , recent study have indicate other superpixel-based method outperform slic remote sense image segmentation , and might suggest be more suitable task detect deforest area . sense , study investigate impact four good segmentation method , together slic , training classifier target application . initially , result show little variation performance segmentation method , even select top five classifier use pycaret automl library . however , apply classifier fusion approach ( ensemble classifier ) , noticeable improvement balanced accuracy be observe , highlight importance both choice segmentation method and combination machine learning-base model deforestation detection task .",Computer Vision and Pattern Recognition,06/10/2025
10.48550/arXiv.2510.04630,sfanet : spatial-frequency attention network deepfake detection,"Vrushank Ahire, Aniruddh Muley, Shivam Zample, Siddharth Verma, Pranav Menon, Surbhi Madan, Abhinav Dhall","detect manipulated medium have now become pressing issue recent rise deepfake . most exist approach fail to generalize diverse dataset and generation technique . thus propose novel ensemble framework , combine strength transformer-based architecture , such swin transformers and vits , and texture-based method , to achieve well detection accuracy and robustness . method introduce innovative data-splitting , sequential training , frequency splitting , patch-based attention , and face segmentation technique to handle dataset imbalance , enhance high-impact region ( e.g. , eye and mouth ) , and improve generalization . model achieve state-of-the-art performance test dfwild-cup dataset , diverse subset eight deepfake dataset . ensemble benefit complementarity approach , transformer excel global feature extraction and texture-based method provide interpretability . work demonstrate hybrid model can effectively address evolve challenge deepfake detection , offer robust solution real-world application .",Computer Vision and Pattern Recognition,06/10/2025
10.48550/arXiv.2510.04628,spatial-spectral-frequency interactive network multimodal remote sensing classification,"Hao Liu, Yunhao Gao, Wei Li, Mingyang Zhang, Maoguo Gong, Lorenzo Bruzzone","deep learning-based method have achieve significant success remote sense earth observation datum analysis . numerous feature fusion technique address multimodal remote sense image classification integrate global and local feature . however , technique often struggle to extract structural and detail feature heterogeneous and redundant multimodal image . goal introduce frequency domain learning to model key and sparse detail feature , paper introduce spatial-spectral-frequency interaction network ( s2fin ) , integrate pairwise fusion module spatial , spectral , and frequency domain . specifically , propose high-frequency sparse enhancement transformer employ sparse spatial-spectral attention to optimize parameter high-frequency filter . subsequently , two-level spatial-frequency fusion strategy be introduce , comprise adaptive frequency channel module fuse low-frequency structure enhance high-frequency detail , and high-frequency resonance mask emphasize sharp edge phase similarity . addition , spatial-spectral attention fusion module far enhance feature extraction intermediate layer network . experiment four benchmark multimodal dataset limited label datum demonstrate s2fin perform superior classification , outperform state-of-the-art method . code be available https://github.com/haoliu-xdu/ssfin .",Computer Vision and Pattern Recognition,06/10/2025
10.48550/arXiv.2510.04587,pathology-cot : learn visual chain-of-thought agent expert whole slide image diagnosis behavior,"Sheng Wang, Ruiming Wu, Charles Herndon, Yihang Liu, Shunsuke Koga, Jeanne Shen, Zhi Huang","diagnose whole-slide image diagnosis be interactive , multi-stage process change magnification and move field . recent pathology foundation model be strong , practical agentic system decide field to examine next , adjust magnification , and deliver explainable diagnosis be still lack . blocker be datum : scalable , clinically align supervision expert view behavior be tacit and experience‑base , not write textbook or online , and therefore absent llm training . introduce ai session recorder , work standard wsi viewer unobtrusively record routine navigation and convert viewer log standardized behavioral command ( inspect/peek discrete magnification ) and bound box . lightweight human-in-the-loop review turn ai-drafte rationale pathology-cot dataset , form pair "" to look "" and "" matter "" supervision produce roughly six-fold low labeling time . use behavioral datum , build pathologist-o3 , two-stage agent first propose roi and then perform behavior-guided reasoning . gastrointestinal lymph-node metastasis detection achieve 84 . 5 % precision , 100 . 0 % recall , and 75 . 4 % accuracy , exceed state-of-the-art openai o3 model and generalizing backbone . knowledge , constitute one first behavior-grounded agentic system pathology . turn everyday viewer log scalable , expert‑validated supervision , framework make agentic pathology practical and establish path human‑aligned , upgradeable clinical ai .",Computer Vision and Pattern Recognition,06/10/2025
10.48550/arXiv.2510.04564,conditional representation learning customized tasks,"Honglin Liu, Chao Sun, Peng Hu, Yunfan Li, Xi Peng","conventional representation learning method learn universal representation primarily capture dominant semantic , may not always align customize downstream task . instance , animal habitat analysis , researcher prioritize scene-related feature , universal embedding emphasize categorical semantic , lead suboptimal result . solution , exist approach resort supervised fine-tuning , however incur high computational and annotation cost . paper , propose conditional representation learning ( crl ) , aim to extract representation tailor arbitrary user-specified criterion . specifically , reveal semantic space be determine basis , thereby enable set descriptive word to approximate basis customize feature space . build insight , give user-specified criterion , crl first employ large language model ( llm ) to generate descriptive text to construct semantic basis , then project image representation conditional feature space leverage vision-language model ( vlm ) . conditional representation well capture semantic specific criterion , could be utilize multiple customize task . extensive experiment classification and retrieval task demonstrate superiority and generality propose crl . code be available xlearning-scu/2025-neurips-crl .",Computer Vision and Pattern Recognition,06/10/2025
10.48550/arXiv.2510.04533,tag : tangential amplifying guidance hallucination-resistant diffusion sampling,"Hyunmin Cho, Donghoon Ahn, Susung Hong, Jee Eun Kim, Seungryong Kim, Kyong Hwan Jin","recent diffusion model achieve state-of-the-art performance image generation , but often suffer semantic inconsistency or hallucination . various inference-time guidance method can enhance generation , often operate indirectly rely external signal or architectural modification , introduce additional computational overhead . paper , propose tangential amplifying guidance ( tag ) , more efficient and direct guidance method operate solely trajectory signal modify underlie diffusion model . tag leverage intermediate sample projection basis and amplify tangential component estimate score respect basis to correct sampling trajectory . formalize guidance process leverage first-order taylor expansion , demonstrate amplify tangential component steer state higher-probability region , thereby reduce inconsistency and enhance sample quality . tag be plug-and-play , architecture-agnostic module improve diffusion sample fidelity minimal computational addition , offer new perspective diffusion guidance . 111project page be available : https://hyeon-cho.github.io/tag/",Computer Vision and Pattern Recognition,06/10/2025
10.48550/arXiv.2510.04504,asynchronous denoising diffusion models aligning text-to-image generation,"Zijing Hu, Yunze Tong, Fengda Zhang, Junkun Yuan, Jun Xiao, Kun Kuang","diffusion model have achieve impressive result generate high-quality image . yet , often struggle to faithfully align generate image input prompt . limitation arise synchronous denoising , pixel simultaneously evolve random noise clear image . result , generation , prompt-related region can only reference unrelated region same noise level , fail to obtain clear context and ultimately impairing text-to-image alignment . to address issue , propose asynchronous diffusion models—a novel framework allocate distinct timestep different pixel and reformulate pixel-wise denoising process . dynamically modulate timestep schedule individual pixel , prompt-related region be denoise more gradually unrelated region , thereby allow to leverage clear inter-pixel context . consequently , prompt-related region achieve well alignment final image . extensive experiment demonstrate asynchronous diffusion model can significantly improve text-to-image alignment diverse prompt . code repository work be available .",Computer Vision and Pattern Recognition,06/10/2025
10.48550/arXiv.2510.04483,tbstar-edit : image editing pattern shifting consistency enhancement,"Hao Fang, Zechao Zhan, Weixin Feng, Ziwei Huang, XuBin Li, Tiezheng Ge","recent advance image generation and editing technology have enable state-of-the-art model to achieve impressive result general domain . however , apply e-commerce scenario , general model often encounter consistency limitation . to address challenge , introduce tbstar-edit , new image editing model tailor e-commerce domain . rigorous datum engineering , model architecture design and training strategy , tbstar-edit achieve precise and high-fidelity image editing maintain integrity product appearance and layout . specifically , datum engineering , establish comprehensive datum construction pipeline , encompass data collection , construction , filtering , and augmentation , to acquire high-quality , instruction-following , and strongly consistent editing datum to support model training . model architecture design , design hierarchical model framework consist base model , pattern shift module , and consistency enhancement module . model training , adopt two-stage training strategy to enhance consistency preservation : first stage editing pattern shifting , and second stage consistency enhancement . stage involve train different module separate dataset . finally , conduct extensive evaluation tbstar-edit self-proposed e-commerce benchmark , and result demonstrate tbstar-edit outperform exist general-domain editing model objective metric ( vie score ) and subjective user preference .",Computer Vision and Pattern Recognition,06/10/2025
10.48550/arXiv.2510.04479,vasevqa-3d : benchmarke 3d vlm ancient greek pottery,"Nonghai Zhang, Zeyu Zhang, Jiazi Wang, Yang Zhao, Hao Tang","vision-language models ( vlms ) have achieve significant progress multimodal understanding task , demonstrate strong capability particularly general task such image captioning and visual reasoning . however , deal specialized cultural heritage domain 3d vase artifact , exist model face severe data scarcity issue and insufficient domain knowledge limitation . lack target training datum , current vlm struggle to effectively handle such culturally significant specialized task . to address challenge , propose vasevqa-3d dataset , serve first 3d visual question answer dataset ancient greek pottery analysis , collect 664 ancient greek vase 3d model correspond question-answer datum and establish complete datum construction pipeline . far develop vasevlm model , enhance model performance vase artifact analysis domain-adaptive training . experimental result validate effectiveness approach , improve 12 . 8 % r@1 metric and 6 . 6 % lexical similarity compare previous state-of-the-art vasevqa-3d dataset , significantly improve recognition and understanding 3d vase artifact , provide new technical pathway digital heritage preservation research . code : https://github.com/aigeeksgroup/vasevqa-3d. website : https://aigeeksgroup.github.io/vasevqa-3d.",Computer Vision and Pattern Recognition,06/10/2025
10.48550/arXiv.2510.04477,medclm : learn localize and reason cot-curriculum medical vision-language model,"Soo Yong Kim, Suin Cho, Vincent-Daniel Yun, Gyeongyeon Hwang","bridge clinical diagnostic reasoning ai remain central challenge medical imaging . introduce medclm , automated pipeline convert detection dataset large-scale medical visual question answer ( vqa ) datum chain-of-thought ( cot ) reasoning link lesion box to organ segmentation and structured rationale . contextual signal enable medical vision-language model to generate question–answer pair step-by-step reasoning . to utilize datum effectively , propose integrated cot–curriculum strategy compose easy stage explicit lesion box visual grounding , medium stage encourage implicit localization , and hard stage weakly supervised reasoning . experimental result demonstrate medclm attain state-of-the-art performance several medical vqa benchmark , provide scalable framework develop clinically align medical vision–language model . github repository will be release paper acceptance : https://github.com/anonymous/medclm",Computer Vision and Pattern Recognition,06/10/2025
10.48550/arXiv.2510.04472,spegnet : synergistic perception-guided network camouflaged object detection,"Baber Jan, Saeed Anwar, Aiman H. El-Maleh, Abdul Jabbar Siddiqui, Abdul Bais","camouflage object detection segment object intrinsic similarity and edge disruption . current detection method rely accumulate complex component . approach add component such boundary module , attention mechanism , and multi-scale processor independently . accumulation create computational burden proportional gain . to manage complexity , process reduce resolution , eliminate fine detail essential camouflage . present spegnet , address fragmentation unified design . architecture integrate multi-scale feature channel calibration and spatial enhancement . boundary emerge directly context-rich representation , maintain semantic-spatial alignment . progressive refinement implement scale-adaptive edge modulation peak influence intermediate resolution . design strike balance boundary precision and regional consistency . spegnet achieve 0 . 887 sαs_{\alpha } camo , 0 . 890 cod10 k , and 0 . 895 nc4 k , real-time inference speed . approach excel scale , tiny , intricate object large , pattern-similar one , handle occlusion and ambiguous boundary . code , model weight , and result be available https://github.com/baber-jan/spegnet .",Computer Vision and Pattern Recognition,06/10/2025
10.48550/arXiv.2510.04450,rear : rethink visual autoregressive models generator-tokenizer consistency regularization,"Qiyuan He, Yicong Li, Haotian Ye, Jinghao Wang, Xinyao Liao, Pheng-Ann Heng, Stefano Ermon, James Zou, Angela Yao","visual autoregressive ( ar ) generation offer promising path unify vision and language model , yet performance remain suboptimal diffusion model . prior work often attribute gap tokenizer limitation and rasterization ordering . work , identify core bottleneck perspective generator-tokenizer inconsistency , i.e. , ar-generate token may not be well-decode tokenizer . to address , propose rear , simple training strategy introduce token-wise regularization objective : predict next token , causal transformer be also train to recover visual embed current token and predict embedding target token noisy context . require change tokenizer , generation order , inference pipeline , or external model . simplicity , substantially improve performance . imagenet , reduce gfid 3 . 02 to 1 . 86 and improve be 316 . 9 use standard rasterization-based tokenizer . apply advanced tokenizer , achieve gfid 1 . 42 only 177 m parameter , match performance large state-of-the-art diffusion model ( 675 m ) .",Computer Vision and Pattern Recognition,06/10/2025
10.48550/arXiv.2510.04428,"a . . r . : enabling adaptive , iterative , and reasoning-base frame selection video question answering","Yuanhao Zou, Shengji Jin, Andong Deng, Youpeng Zhao, Jun Wang, Chen Chen","effectively apply vision-language model ( vlms ) video question answering ( videoqa ) hinge select concise yet comprehensive set frame , process entire video be computationally infeasible . however , current frame selection method face critical trade-off : approach rely lightweight similarity model , such clip , often fail to capture nuance complex query , result inaccurate similarity score can not reflect authentic query-frame relevance , far undermine frame selection . meanwhile , method leverage vlm deep analysis achieve high accuracy but incur prohibitive computational cost . to address limitation , propose a . . r . , training-free approach adaptive , iterative , and reasoning-based frame selection . leverage powerful vlm to perform deep , semantic analysis complex query , and analysis be deploy cost-effective iterative loop process only small batch most high-potential frame time . extensive experiment various videoqa benchmark demonstrate approach outperform exist frame selection method , significantly boost performance foundation vlm , and achieve substantial gain computational efficiency other vlm-base technique .",Computer Vision and Pattern Recognition,06/10/2025
10.48550/arXiv.2510.04410,codeformer++ : blind face restoration use deformable registration and deep metric learning,"Venkata Bharath Reddy Reddem, Akshay P Sarashetti, Ranjith Merugu, Amit Satish Unde","blind face restoration ( bfr ) have attract increase attention rise generative method . most exist approach integrate generative prior restoration process , aim to jointly address facial detail generation and identity preservation . however , method often suffer trade-off visual quality and identity fidelity , lead either identity distortion or suboptimal degradation removal . paper , present codeformer++ , novel framework maximize utility generative prior high-quality face restoration preserve identity . decompose bfr three sub-task : ( i ) identity-preserving face restoration , ( ii ) high-quality face generation , and ( iii ) dynamic fusion identity feature realistic texture detail . method make three key contribution : ( 1 ) learning-base deformable face registration module semantically align generate and restore face ; ( 2 ) texture guide restoration network to dynamically extract and transfer texture generate face to boost quality identity-preserving restore face ; and ( 3 ) integration deep metric learning bfr generation informative positive and hard negative sample to well fuse identity-preserving and generative feature . extensive experiment real-world and synthetic dataset demonstrate , propose codeformer++ achieve superior performance term visual fidelity and identity consistency .",Computer Vision and Pattern Recognition,06/10/2025
10.48550/arXiv.2510.04401,vision-language model can not even count 20 : expose failures vlms compositional counting,"Xuyang Guo, Zekai Huang, Zhenmei Shi, Zhao Song, Jiahao Zhang","vision-language models ( vlms ) have become central focus today ’s ai community , owe impressive ability gain training large-scale vision-language datum web . model have demonstrate strong performance diverse task , include image understanding , video understanding , complex visual reasoning , and embody ai . noteworthy success , fundamental question remain : can vlm count object correctly ? paper , introduce simple yet effective benchmark , vlmcountbench , design minimalist set only basic geometric shape ( e.g. , triangle , circle ) and composition , focus exclusively count task interference other factor . adopt strict independent variable control and systematically study effect simple property such color , size , and prompt refinement control ablation . empirical result reveal vlms can count reliably only one shape type be present , exhibit substantial failure multiple shape type be combine ( i.e. , compositional counting ) . highlight fundamental empirical limitation current vlm and motivate important direction future research .",Computer Vision and Pattern Recognition,06/10/2025
10.48550/arXiv.2510.04390,"morphosim : interactive , controllable , and editable language-guided 4d world simulator","Xuehai He, Shijie Zhou, Thivyanth Venkateswaran, Kaizhi Zheng, Ziyu Wan, Achuta Kadambi, Xin Eric Wang","world model support controllable and editable spatiotemporal environment be valuable robotic , enable scalable training datum , reproducible evaluation , and flexible task design . recent text-to-video model generate realistic dynamic , be constrain 2d view and offer limited interaction . introduce morphosim , language-guided framework generate 4d scene multi-view consistency and object-level control . natural language instruction , morphosim produce dynamic environment object can be direct , recolore , or remove , and scene can be observe arbitrary viewpoint . framework integrate trajectory-guided generation feature field distillation , allow edit to be apply interactively full re-generation . experiment show morphosim maintain high scene fidelity enable controllability and editability . code be available https://github.com/eric-ai-lab/morph4d.",Computer Vision and Pattern Recognition,05/10/2025
10.48550/arXiv.2510.04365,diffusion^2 : dual diffusion model uncertainty-aware adaptive noise momentary trajectory prediction,"Yuhao Luo, Yuang Zhang, Kehua Chen, Xinyu Zheng, Shucheng Zhang, Sikai Chen, Yinhai Wang","accurate pedestrian trajectory prediction be crucial ensure safety and efficiency autonomous driving and human-robot interaction scenario . early study primarily utilize sufficient observational datum to predict future trajectory . however , real-world scenario , such pedestrian suddenly emerge blind spot , sufficient observational datum be often unavailable ( i.e. momentary trajectory ) , make accurate prediction challenge and increase risk traffic accident . therefore , advance research pedestrian trajectory prediction extreme scenario be critical enhance traffic safety . work , propose novel framework term diffusion2 , tailor momentary trajectory prediction . diffusion2 consist two sequentially connect diffusion model : one backward prediction , generate unobserved historical trajectory , and other forward prediction , forecast future trajectory . give generate unobserved historical trajectory may introduce additional noise , propose dual-head parameterization mechanism to estimate aleatoric uncertainty and design temporally adaptive noise module dynamically modulate noise scale forward diffusion process . empirically , diffusion2 set new state-of-the-art momentary trajectory prediction eth/ucy and stanford drone dataset .",Computer Vision and Pattern Recognition,05/10/2025
10.48550/arXiv.2510.04333,rap : 3d rasterization augmented end-to-end planning,"Lan Feng, Yang Gao, Eloi Zablocki, Quanyi Li, Wuyang Li, Sichao Liu, Matthieu Cord, Alexandre Alahi","imitation learning end-to-end drive train policy only expert demonstration . once deploy closed loop , such policy lack recovery datum : small mistake can not be correct and quickly compound failure . promising direction be to generate alternative viewpoint and trajectory logged path . prior work explore photorealistic digital twin neural rendering or game engine , but method be prohibitively slow and costly , and thus mainly use evaluation . work , argue photorealism be unnecessary train end-to-end planner . matter be semantic fidelity and scalability : driving depend geometry and dynamic , not texture or lighting . motivate , propose 3d rasterization , replace costly rendering lightweight rasterization annotated primitive , enable augmentation such counterfactual recovery maneuver and cross-agent view synthesis . to transfer synthetic view effectively real-world deployment , introduce raster-to-real feature-space alignment bridge sim-to-real gap feature space . together , component form rasterization augmented planning ( rap ) , scalable datum augmentation pipeline planning . rap achieve state-of-the-art closed-loop robustness and long-tail generalization , rank 1st four major benchmark : navsim v1/v2 , waymo open dataset vision-base e2e driving , and bench2drive . result show lightweight rasterization feature alignment suffice to scale e2e training , offer practical alternative photorealistic rendering . project page : https://alan-lanfeng.github.io/rap/.",Computer Vision and Pattern Recognition,05/10/2025
10.48550/arXiv.2510.04315,genar : next-scale autoregressive generation spatial gene expression prediction,"Jiarui Ouyang, Yihui Wang, Yihang Gao, Yingxue Xu, Shu Yang, Hao Chen","spatial transcriptomics ( st ) offer spatially resolve gene expression but remain costly . predict expression directly widely available hematoxylin and eosin ( h&e ) stain image present cost-effective alternative . however , most computational approach ( i ) predict gene independently , overlook co-expression structure , and ( ii ) cast task continuous regression expression be discrete count . mismatch can yield biologically implausible output and complicate downstream analysis . introduce genar , multi-scale autoregressive framework refine prediction coarse fine . genar ( a ) cluster gene hierarchical group to expose cross-gene dependency , ( b ) model expression codebook-free discrete token generation to directly predict raw count , and ( c ) condition decode fused histological and spatial embedding . information-theoretic view , discrete formulation avoid log-induced bias and coarse-to-fine factorization align principled conditional decomposition . extensive experimental result four st dataset different tissue type demonstrate genar achieve state-of-the-art performance , offer potential implication precision medicine and cost-effective molecular profiling . code be publicly available https://github.com/oyjr/genar .",Computer Vision and Pattern Recognition,05/10/2025
10.48550/arXiv.2510.04312,care-pd : multi-site anonymize clinical dataset parkinson 's disease gait assessment,"Vida Adeli, Ivan Klabucar, Javad Rajabi, Benjamin Filtjens, Soroush Mehraban, Diwei Wang, Hyewon Seo, Trung-Hieu Hoang, Minh N. Do, Candice Muller, Claudia Oliveira, Daniel Boari Coelho, Pieter Ginis, Moran Gilat, Alice Nieuwboer, Joke Spildooren, Lucas Mckay, Hyeokhyen Kwon, Gari Clifford, Christine Esper, Stewart Factor, Imari Genias, Amirhossein Dadashzadeh, Leia Shum, Alan Whone, Majid Mirmehdi, Andrea Iaboni, Babak Taati","objective gait assessment parkinson ’s disease ( pd ) be limit absence large , diverse , and clinically annotate motion dataset . introduce care-pd , large publicly available archive 3d mesh gait datum pd , and first multi-site collection span 9 cohort 8 clinical center . recording ( rgb video or motion capture ) be convert anonymize smpl mesh harmonized preprocessing pipeline . care-pd support two key benchmark : supervise clinical score prediction ( estimate unified parkinson ’s disease rating scale , updrs , gait score ) and unsupervised motion pretext task ( 2d-to-3d keypoint lifting and full-body 3d reconstruction ) . clinical prediction be evaluate four generalization protocol : within-dataset , cross-dataset , leave-one-dataset-out , and multi-dataset in-domain adaptation . to assess clinical relevance , compare state-of-the-art motion encoder traditional gait-feature baseline , find encoder consistently outperform handcraft feature . pretraine care-pd reduce mpjpe ( 60 . 8 mm 7 . 5 mm ) and boost pd severity macro-f1 17 percentage point , underscore value clinically curate , diverse training datum . care-pd and benchmark code be release non-commercial research https://neurips2025.care-pd.ca .",Computer Vision and Pattern Recognition,05/10/2025
10.48550/arXiv.2510.04290,chronoedit : temporal reasoning image editing and world simulation,"Jay Zhangjie Wu, Xuanchi Ren, Tianchang Shen, Tianshi Cao, Kai He, Yifan Lu, Ruiyuan Gao, Enze Xie, Shiyi Lan, Jose M. Alvarez, Jun Gao, Sanja Fidler, Zian Wang, Huan Ling","recent advance large generative model have significantly advanced image editing and in-context image generation , yet critical gap remain ensure physical consistency , edit object must remain coherent . capability be especially vital world simulation relate task . paper , present chronoedit , framework reframe image editing video generation problem . first , chronoedit treat input and edit image first and last frame video , allow to leverage large pretraine video generative model capture not only object appearance but also implicit physics motion and interaction learn temporal consistency . second , chronoedit introduce temporal reasoning stage explicitly perform edit inference time . setting , target frame be jointly denoise reasoning token to imagine plausible editing trajectory constrain solution space physically viable transformation . reasoning token be then drop few step to avoid high computational cost render full video . to validate chronoedit , introduce pbench-edit , new benchmark image–prompt pair context require physical consistency , and demonstrate chronoedit surpass state-of-the-art baseline visual fidelity and physical plausibility . code and model both 14b and 2b variant chronoedit will be release project page : https://research.nvidia.com/labs/toronto-ai/chronoedit",Computer Vision and Pattern Recognition,05/10/2025
10.48550/arXiv.2510.04282,flexible and efficient spatio-temporal transformer sequential visual place recognition,"Yu Kiu, Chao Chen, Ge Jin, Chen Feng","sequential visual place recognition ( seq-vpr ) leverage transformer to capture spatio-temporal feature effectively ; however , exist approach prioritize performance expense flexibility and efficiency . practice , transformer-based seq-vpr model should be flexible number frame sequence ( seq-length ) , deliver fast inference , and have low memory usage to meet real-time constraint . knowledge , exist transformer-based seq-vpr method achieve flexibility and efficiency . to address gap , propose adapt-stformer , seq-vpr method build novel recurrent deformable transformer encoder ( recurrent-dte ) , use iterative recurrent mechanism to fuse information multiple sequential frame . design naturally support variable seq-length , fast inference , and low memory usage . experiment nordland , oxford , and nuscenes dataset show adapt-stformer boost recall to 17 % reduce sequence extraction time 36 % and lower memory usage 35 % compare second-best baseline .",Computer Vision and Pattern Recognition,05/10/2025
10.48550/arXiv.2510.04245,concept-based masking : patch-agnostic defense adversarial patch attack,"Ayushi Mehrotra, Derek Peng, Dipkamal Bhusal, Nidhi Rastogi","adversarial patch attack pose practical threat deep learning model force target misclassification localize perturbation , often realize physical world . exist defense typically assume prior knowledge patch size or location , limit applicability . work , propose patch-agnostic defense leverage concept-based explanation to identify and suppress most influential concept activation vector , thereby neutralize patch effect explicit detection . evaluate imagenette resnet-50 , method achieve high robust and clean accuracy state-of-the-art patchcleanser , maintain strong performance vary patch size and location . result highlight promise combine interpretability robustness and suggest concept-driven defense scalable strategy secure machine learn model adversarial patch attack . code be available https://github.com/ayushimehrotra/concept-masked-defense .",Computer Vision and Pattern Recognition,05/10/2025
10.48550/arXiv.2510.04243,good performance care 2025 -- liver task ( liseg-contrast ): contrast-aware semi-supervise segmentation domain generalization and test-time adaptation,"Jincan Lou, Jingkun Chen, Haoquan Li, Hang Li, Wenjian Huang, Weihua Chen, Fan Wang, Jianguo Zhang","accurate liver segmentation contrast-enhanced mri be essential diagnosis , treatment planning , and disease monitoring . however , remain challenge limited annotated datum , heterogeneous enhancement protocol , and significant domain shift scanner and institution . traditional image-to-image translation framework have make great progress domain generalization , but application be not straightforward . example , pix2pix require image registration , and cycle-gan can not be integrate seamlessly segmentation pipeline . meanwhile , method be originally use to deal cross-modality scenario , and often introduce structural distortion and suffer unstable training , may pose drawback single-modality scenario . to address challenge , propose cosseg-tta , compact segmentation framework ged4 ( gd-eob-dtpa enhance hepatobiliary phase mri ) modality build nnu-netv2 and enhance semi-supervised mean teacher scheme to exploit large amount unlabeled volume . domain adaptation module , incorporate randomized histogram-based style appearance transfer function and trainable contrast-aware network , enrich domain diversity and mitigate cross-center variability . furthermore , continual test-time adaptation strategy be employ to improve robustness inference . extensive experiment demonstrate framework consistently outperform nnu-netv2 baseline , achieve superior dice score and hausdorff distance exhibit strong generalization unseen domain low-annotation condition .",Computer Vision and Pattern Recognition,05/10/2025
10.48550/arXiv.2510.04231,recursive pyramidal algorithm solve image registration problem,Stefan Dirnstorfer,"problem image registration be find transformation align two image , such correspond point be same location . paper introduce simple , end-to-end trainable algorithm be implementable few line python code . approach be show to work very little training datum and training time , achieve accurate result setting . example application stereo vision be train 74 image 19x15 input window . just dozen line python code algorithm excel brevity and may serve good start relate scenario limitation training datum , training time or code complexity .",Computer Vision and Pattern Recognition,05/10/2025
10.48550/arXiv.2510.04225,zoom-in to sort ai-generate image out,"Yikun Ji, Yan Hong, Bowen Deng, jun lan, Huijia Zhu, Weiqiang Wang, Liqing Zhang, Jianfu Zhang","rapid growth ai-generate imagery have blur boundary real and synthetic content , raise critical concern digital integrity . vision-language model ( vlms ) offer interpretability explanation but often fail to detect subtle artifact high-quality synthetic image . propose zoomin , two-stage forensic framework improve accuracy and interpretability . mimic human visual inspection , zoomin first scan image to locate suspicious region and then perform focus analysis zoomed-in area to deliver ground verdict . to support training , introduce magnifake , dataset 20 , 000 real and high-quality synthetic image annotate bounding box and forensic explanation , generate automate vlm-base pipeline . approach achieve 96 . 39 % accuracy strong generalization external dataset , and provide human-understandable explanation ground visual evidence .",Computer Vision and Pattern Recognition,05/10/2025
10.48550/arXiv.2510.04220,masc : boost autoregressive image generation manifold-aligned semantic clustering,"Lixuan He, Shikang Zheng, Linfeng Zhang","autoregressive ( ar ) model have show great promise image generation , yet face fundamental inefficiency stem core component : vast , unstructured vocabulary visual token . conventional approach treat token flat vocabulary , disregard intrinsic structure token embed space proximity often correlate semantic similarity . oversight result highly complex prediction task , hinder training efficiency and limit final generation quality . to resolve , propose manifold-aligned semantic clustering ( masc ) , principle framework construct hierarchical semantic tree directly codebook ’s intrinsic structure . masc employ novel geometry-aware distance metric and density-driven agglomerative construction to model underlie manifold token embedding . transform flat , high-dimensional prediction task structured , hierarchical one , masc introduce beneficial inductive bias significantly simplify learn problem ar model . masc be design plug-and-play module , and extensive experiment validate effectiveness : accelerate training to 57 % and significantly improve generation quality , reduce fid llamagen-xl 2 . 87 to 2 . 58 . masc elevate exist ar framework to be highly competitive state-of-the-art method , establish structure prediction space be as crucial architectural innovation scalable generative modeling .",Computer Vision and Pattern Recognition,05/10/2025
10.48550/arXiv.2510.04201,world-to-image : ground text-to-image generation agent-driven world knowledge,"Moo Hyun Son, Jintaek Oh, Sun Bin Mun, Jaechul Roh, Sehyun Choi","text-to-image ( t2i ) model can synthesize high-quality image , performance degrade significantly prompt novel or out-of-distribution ( ood ) entity inherent knowledge cutoff . introduce world-to-image , novel framework bridge gap empower t2i generation agent-driven world knowledge . design agent dynamically search web to retrieve image concept unknown base model . information be then use to perform multimodal prompt optimization , steer powerful generative backbone accurate synthesis . critically , evaluation go traditional metric , utilize modern assessment llmgrader and imagereward to measure true semantic fidelity . experiment show world-to-image substantially outperform state-of-the-art method both semantic alignment and visual aesthetic , achieve +8 . 1 % improvement accuracy-to-prompt curate nice benchmark . framework achieve result high efficiency less three iteration , pave way t2i system can well reflect ever-changing real world . demo code be available here111https://github.com/mhson-kyle/world-to-image .",Computer Vision and Pattern Recognition,05/10/2025
10.48550/arXiv.2510.04188,let feature decide own solvers : hybrid feature caching diffusion transformers,"Shikang Zheng, Guantao Chen, Qinming Zhou, Yuqi Lin, Lixuan He, Chang Zou, Peiliang Cai, Jiacheng Liu, Linfeng Zhang","diffusion transformers offer state-of-the-art fidelity image and video synthesis , but iterative sampling process remain major bottleneck high cost transformer forward pass timestep . to mitigate , feature cache have emerge training-free acceleration technique reuse or forecast hide representation . however , exist method often apply uniform cache strategy feature dimension , ignore heterogeneous dynamic behavior . therefore , adopt new perspective model hide feature evolution mixture ode dimension , and introduce hyca , hybrid ode solver inspire cache framework apply dimension-wise caching strategy . hyca achieve near-lossless acceleration diverse domain and model , include 5 . 55×\times speedup flux , 5 . 56×\times speedup hunyuanvideo , 6 . 24×\times speedup qwen-image and qwen-image-edit retrain .",Computer Vision and Pattern Recognition,05/10/2025
10.48550/arXiv.2510.04180,segments concepts : interpretable image classification concept-guided segmentation,"Ran Eisenberg, Amit Rozner, Ethan Fetaya, Ofir Lindenbaum","deep neural network have achieve remarkable success computer vision ; however , black-box nature decision-making limit interpretability and trust , particularly safety-critical application . interpretability be crucial domain error have severe consequence . exist model not only lack transparency but also risk exploit unreliable or misleading feature , undermine both robustness and validity explanation . concept bottleneck models ( cbms ) aim to improve transparency reasoning human-interpretable concept . still , require costly concept annotation and lack spatial grounding , often fail to identify region support concept . propose seg-mil-cbm , novel framework integrate concept-guided image segmentation attention-based multiple instance learning ( mil ) framework , segment region be treat instance and model learn to aggregate evidence . reason semantically meaningful region align high-level concept , model highlight task-relevant evidence , down-weight irrelevant cue , and produce spatially ground , concept-level explanation require annotation concept or group . seg-mil-cbm achieve robust performance setting involve spurious correlation ( unintended dependency background and label ) , input corruption ( perturbation degrade visual quality ) , and large-scale benchmark , provide transparent , concept-level explanation .",Computer Vision and Pattern Recognition,05/10/2025
10.48550/arXiv.2510.04174,blade : bias-linke adaptive debiase,"Piyush Arora, Navlika Singh, Vasubhya Diwan, Pratik Mazumder","neural network have revolutionize numerous field , yet remain vulnerable critical flaw : tendency to learn implicit bias , spurious correlation certain attribute and target label training datum . bias be often more prevalent and easy to learn , cause model to rely superficial pattern rather task-relevant feature necessary generalization . exist method typically rely strong assumption , such prior knowledge bias or access bias-conflicting sample , i.e. , sample contradict spurious correlation and counterbalance bias-aligned sample , sample conform spurious correlation . however , such assumption be often impractical real-world setting . propose blade ( bias-linke adaptive debiasing ) , generative debiase framework require prior knowledge bias or bias-conflicting sample . blade first train generative model to translate image bias domain preserve task-relevant feature . then , adaptively refine image synthetic counterpart base image ’s susceptibility to bias . to encourage robust representation , blade align image bias-translated synthetic counterpart share task-relevant feature but differ bias , misalign sample share same bias . evaluate blade multiple benchmark dataset and show significantly outperform state-of-the-art method . notably , exceed close baseline absolute margin 18 % corrupted cifar-10 dataset bad group setting , establish new benchmark bias mitigation and demonstrate potential develop more robust deep learning model explicit supervision .",Computer Vision and Pattern Recognition,05/10/2025
10.48550/arXiv.2510.04142,learn : concept alignment autonomous distillation multiple drift mllm,"Xiaoyu Yang, Jie Lu, En Yu","paper identify critical yet underexplored challenge distil multi-modal large language model ( mllm ): reasoning trajectory generate multiple drift teacher exhibit concept drift , reasoning distribution evolve unpredictably and transmit bias student model , ultimately compromise performance . to tackle issue , pioneer theoretical connection concept drift and knowledge distillation , cast non-stationary reasoning dynamic multiple mllm teacher next-token prediction multi-stream reasoning trajectory . guide concept drift , introduce "" learn–compare–critique "" paradigm , culminate autonomous preference optimization ( apo ) . active guidance teacher , student model first learn and self-distil prefer thinking compare multiple teacher . then engage critical reflection drift inference teacher , perform concept alignment apo , ultimately yield robust , consistent , and generalizable model . extensive experiment demonstrate superior performance consistency , robustness and generalization knowledge distillation . besides , also contribute large-scale dataset cxr-max ( multi-teachers alignment x-rays ) , comprise 170 , 982 distil reasoning trajectory derive publicly accessible mllm base mimic-cxr . code and datum be public : https://anonymous.4open.science/r/autonomous-distillation/.",Computer Vision and Pattern Recognition,05/10/2025
10.48550/arXiv.2510.04125,joint learning pose regression and denoising diffusion score scaling sampling category-level 6d pose estimation,"Seunghyun Lee, Tae-Kyun Kim","late diffusion model have show promising result category-level 6d object pose estimation model conditional pose distribution depth image input . exist method , however , suffer slow convergence training , learn encoder diffusion denoising network end-to-end fashion , and require additional network evaluate sample pose hypothesis to filter low-quality pose candidate . paper , propose novel pipeline tackle limitation two key component . first , propose method pretrain encoder direct pose regression head , and jointly learn network regression head and denoise diffusion head , significantly accelerate training convergence achieve high accuracy . second , sample guidance time-dependent score scaling be propose s. t. exploration-exploitation trade-off be effectively take , eliminate need additional evaluation network . sample guidance maintain multi-modal characteristic symmetric object early denoise step ensure high-quality pose generation final step . extensive experiment multiple benchmark include real275 , housecat6d , and rope , demonstrate propose method , simple yet effective , achieve state-of-the-art accuracy even single-pose inference , be more efficient both training and inference .",Computer Vision and Pattern Recognition,05/10/2025
10.48550/arXiv.2510.04111,learn efficient meshflow and optical flow event camera,"Xinglong Luo, Ao Luo, Kunming Luo, Zhengning Wang, Ping Tan, Bing Zeng, Shuaicheng Liu","paper , explore problem event-based meshflow estimation , novel task involve predict spatially smooth sparse motion field event camera . to start , review state-of-the-art event-based flow estimation , highlight two key area further research : i ) lack meshflow-specific event dataset and method , and ii ) underexplored challenge event datum density . first , generate large-scale high-resolution event meshflow ( hrem ) dataset , showcase superiority encompass merit high resolution 1280×\times720 , handle dynamic object and complex motion pattern , and offer optical flow and meshflow label . aspect have not be fully explore previous work . besides , propose efficient event-base meshflow ( eemflow ) network , lightweight model feature specially craft encoder-decoder architecture to facilitate swift and accurate meshflow estimation . furthermore , upgrade eemflow network to support dense event optical flow , confidence-induced detail completion ( cdc ) module be propose to preserve sharp motion boundary . conduct comprehensive experiment to show exceptional performance and runtime efficiency ( 30×\time fast ) eemflow model compare recent state-of-the-art flow method . extension , expand hrem hrem+ , multi-density event dataset contribute thorough study robustness exist method datum vary density , and propose adaptive density module ( adm ) to adjust density input event datum more optimal range , enhance model ’s generalization ability . empirically demonstrate adm help to significantly improve performance eemflow and eemflow+ 8 % and 10 % , respectively . code and dataset be release https://github.com/boomluo02/eemflowplus .",Computer Vision and Pattern Recognition,05/10/2025
10.48550/arXiv.2510.04100,topo-bench : open-source topological mapping evaluation framework quantifiable perceptual aliasing,"Jiaming Wang, Diwen Liu, Jizhuo Chen, Harold Soh","topological mapping offer compact and robust representation navigation , but progress field be hinder lack standardized evaluation metric , dataset , and protocol . exist system be assess use different environment and criterion , prevent fair and reproducible comparison . moreover , key challenge—perceptual aliasing—remain under-quantified , strong influence system performance . address gap ( i ) formalize topological consistency fundamental property topological map and show localization accuracy provide efficient and interpretable surrogate metric , and ( ii ) propose first quantitative measure dataset ambiguity to enable fair comparison environment . to support protocol , curate diverse benchmark dataset calibrate ambiguity level , implement and release deep-learned baseline system , and evaluate classical method . experiment and analysis yield new insight limitation current approach perceptual aliasing . dataset , baseline , and evaluation tool be fully open-sourced to foster consistent and reproducible research topological mapping .",Computer Vision and Pattern Recognition,05/10/2025
10.48550/arXiv.2510.04069,diffusion low rank hybrid reconstruction sparse view medical imaging,"Zongyin Deng, Qing Zhou, Yuhao Fang, Zijian Wang, Yao Lu, Ye Zhang, Chun Li","work present tv-lora , novel method low-dose sparse-view ct reconstruction combine diffusion generative prior ( ncsn++ sde modeling ) and multi-regularization constraint , include anisotropic tv and nuclear norm ( lora ) , admm framework . to address ill-posedness and texture loss extremely sparse view , tv-lora integrate generative and physical constraint , and utilize 2d slice-based strategy fft acceleration and tensor-parallel optimization efficient inference . experiment aapm-2016 , cthd , and lidc dataset nview=8 , 4 , 2n_{\mathrm{view}}=8 , 4 , 2 show consistently surpass benchmark ssim , texture recovery , edge clarity , and artifact suppression , demonstrate strong robustness and generalizability . ablation study confirm complementary effect lora regularization and diffusion prior , fft-pcg module provide 4 . 5× speedup . overall , diffusion + tv-lora achieve high-fidelity , efficient 3d ct reconstruction and broad clinical applicability low-dose , sparse-sampling scenario .",Computer Vision and Pattern Recognition,05/10/2025
10.48550/arXiv.2510.04066,quantdemoire : quantization outlier aware image demoiréing,"Zheng Chen, Kewei Zhang, Xiaoyang Liu, Weihang Zhang, Mengfan Wang, Yifan Fu, Yulun Zhang","demoirée aim to remove moiré artifact often occur image . recent deep learning-based method have achieve promising result , typically require substantial computational resource , limit deployment edge device . model quantization offer compelling solution . however , directly apply exist quantization method demoiréing model introduce severe performance degradation . main reason be distribution outlier and weaken representation smooth region . to address issue , propose quantdemoire , post-training quantization framework tailor demoirée . contain two key component . first , introduce outlier-aware quantizer to reduce error outlier . use sampling-based range estimation to reduce activation outlier , and keep few extreme weight fp16 negligible cost . second , design frequency-aware calibration strategy . emphasize low- and mid-frequency component fine-tuning , mitigate banding artifact cause low-bit quantization . extensive experiment validate quantdemoire achieve large reduction parameter and computation maintain quality . meanwhile , outperform exist quantization method 4 db w4a4 . code be release : https://github.com/zhengchen1999/quantdemoire .",Computer Vision and Pattern Recognition,05/10/2025
10.48550/arXiv.2510.04063,ordinal encoding regularizer binary loss solar flare prediction,"Chetraj Pandey, Jinsu Hong, Anli Ji, Rafal A. Angryk, Berkay Aydin","prediction solar flare be typically formulate binary classification task , distinguish event either flare ( fl ) or no-flare ( nf ) accord specify threshold ( e.g. , ≥\geqc-class , ≥\geqm-class , or ≥\geqx-class ) . however , binary framework neglect inherent ordinal relationship sub-classe contain category ( fl and nf ) . several study solar flare prediction have empirically show most frequent misclassification occur prediction threshold . suggest model struggle to differentiate event be similar intensity but fall opposite side binary threshold . to mitigate limitation , propose modify loss function integrate ordinal information sub-classe binarize flare label conventional binary cross-entropy ( bce ) loss . approach serve ordinality-aware , data-driven regularization method penalize incorrect prediction flare event close proximity prediction threshold more heavily away boundary model optimization . incorporate ordinal weighting loss function , aim to enhance model ’s learning process leverage ordinal characteristic datum , thereby improve overall performance .",Computer Vision and Pattern Recognition,05/10/2025
10.48550/arXiv.2510.04057,metafind : scene-aware 3d asset retrieval coherent metaverse scene generation,"Zhenyu Pan, Yucheng Lu, Han Liu","present metafind , scene-aware tri-modal compositional retrieval framework design to enhance scene generation metaverse retrieve 3d asset large-scale repository . metafind address two core challenge : ( i ) inconsistent asset retrieval spatial , semantic , and stylistic constraint , and ( ii ) absence standardized retrieval paradigm specifically tailor 3d asset retrieval , exist approach mainly rely general-purpose 3d shape representation model . key innovation be flexible retrieval mechanism support arbitrary combination text , image , and 3d modality query , enhance spatial reasoning and style consistency jointly model object-level feature ( include appearance ) and scene-level layout structure . methodologically , metafind introduce plug-and-play equivariant layout encoder essgnn capture spatial relationship and object appearance feature , ensure retrieve 3d asset be contextually and stylistically coherent exist scene , regardless coordinate frame transformation . framework support iterative scene construction continuously adapt retrieval result current scene update . empirical evaluation demonstrate improved spatial and stylistic consistency metafind various retrieval task compare baseline method .",Computer Vision and Pattern Recognition,05/10/2025
10.48550/arXiv.2510.04044,quantization range estimation convolutional neural networks,"Bingtao Yang, Yujia Wang, Mengzhi Jiao, Hongwei Huo","post-traine quantization reduce storage deep neural network model have be demonstrate to be effective way various task . however , low-bit quantization maintain model accuracy be challenging problem . paper , present range estimation method to improve quantization performance post-traine quantization . model range estimation optimization problem minimize quantization error layer-wise local loss . prove problem be locally convex and present efficient search algorithm to find optimal solution . propose application above search algorithm transform weight space to do further improvement practice . experiment demonstrate method outperform state-of-the-art performance generally top-1 accuracy image classification task resnet series model and inception-v3 model . experimental result show propose method have almost loss top-1 accuracy 8-bit and 6-bit setting image classification , and accuracy 4-bit quantization be also significantly improve . code be available https://github.com/codeiscommitting/requant .",Computer Vision and Pattern Recognition,05/10/2025
10.48550/arXiv.2510.04039,\textsc{gui-spotlight } : adaptive iterative focus refinement enhanced gui visual grounding,"Bin Lei, Nuo Xu, Ali Payani, Mingyi Hong, Chunhua Liao, Yu Cao, Caiwen Ding","multimodal large language model ( mllm ) have markedly expand competence graphical user‑interface ( gui ) system , propel control simulation complex , real‑world environment diverse platform . however , practical usefulness be still bound reliability visual grounding , i.e. , map textual reference to exact on-screen element . limitation prevent system accurately perform pointer‑level action such clicking or dragging . to address , introduce gui‑spotlight—a model train image-grounded reasoning dynamically invoke multiple specialized tool to iteratively narrow focus relevant region screen , thereby substantially improve visual grounding accuracy . screenspot-pro benchmark , gui-spotlight train only 18 . 5​k\mathbf{18 . 5}k training sample achieve 52 . 8%\mathbf{52 . 8}\% accuracy , surpass v2p-7b ( 50 . 6%50 . 6\% 9 . 6​m9 . 6 m training sample ) and gta-1-7b ( 50 . 1%50 . 1\% 1 . 56​m1 . 56 m training sample ) . code be avaliable .",Computer Vision and Pattern Recognition,05/10/2025
10.48550/arXiv.2510.04024,enhance fake news video detection llm-driven creative process simulation,"Yuyan Bu, Qiang Sheng, Juan Cao, Shaofei Wang, Peng Qi, Yuhui Shi, Beizhe Hu","emergence fake news short video platform have become new significant societal concern , necessitate automatic video-news-specific detection . current detector primarily rely pattern-based feature to separate fake news video real one . however , limited and less diversified training datum lead biased pattern and hinder performance . weakness stem complex many-to-many relationship video material segment and fabricate news event real-world scenario : single video clip can be utilize multiple way to create different fake narrative , single fabricate event often combine multiple distinct video segment . however , exist dataset do not adequately reflect such relationship difficulty collect and annotate large-scale real-world datum , result sparse coverage and non-comprehensive learning characteristic potential fake news video creation . to address issue , propose data augmentation framework agentaug generate diverse fake news video simulate typical creative process . agentaug implement multiple llm-driven pipeline four fabrication category news video creation , combine active learning strategy base uncertainty sample to select potentially useful augmented sample training . experimental result two benchmark dataset demonstrate agentaug consistently improve performance short video fake news detector .",Computer Vision and Pattern Recognition,05/10/2025
10.48550/arXiv.2510.04022,video-in-the-loop : span-grounde long video qa interleaved reasoning,"Chendong Wang, Donglin Bai, Yifan Yang, Xiao Jin, Anlan Zhang, Rui Wang, Shiqi Jiang, Yuqing Yang, Hao Wu, Qi Dai, Chong Luo, Ting Cao, Lili Qiu, Suman Banerjee","present video-in-the-loop ( vitl ) , two-stage long-video qa framework preserve fix token budget first localize question-relevant interval(s ) low-fps skim and then answer span-aware reallocation visual token high effective frame rate , emit interleaved output span and final option direct attribution . also introduce vgrounding-qa , convert description base event graph span-grounded multiple-choice qa pair question ground-truth time span(s ) and relate reasoning . vitl be train end-to-end interleaved group-relative objective couple temporal iou localization answer correctness , allow credit to flow answer back span increase compute . fix token budget , vitl attain to 8 . 6 % 50 % less frame input long-video qa and temporal grounding ( e.g. , charades-sta , activitynet-captions ) and ablation show span-aware token reallocation consistently surpass uniform sampling . together , vgrounding-qa and vitl provide interpretable , compute-efficient recipe scalable long-video qa .",Computer Vision and Pattern Recognition,05/10/2025
10.48550/arXiv.2510.04021,"fit pixels , get labels : meta-learned implicit networks image segmentation","Kushal Vyas, Ashok Veeraraghavan, Guha Balakrishnan","implicit neural representation ( inr ) have achieve remarkable success learn expressive yet compact signal representation . however , be not naturally amenable to predictive task such segmentation , must learn semantic structure distribution signal . study , introduce metaseg , meta-learning framework to train inr medical image segmentation . metaseg use underlying inr simultaneously predict pixel intensity value and class label . then use meta-learning procedure to find optimal initial parameter inr training dataset image and segmentation map , such inr can simply be fine-tuned to fit pixel unseen test image , and automatically decode class label . evaluate metaseg 2d and 3d brain mri segmentation task and report dice score comparable to commonly use u-net model , but 90%90\% few parameter . metaseg offer fresh , scalable alternative traditional resource-heavy architecture such u-net and vision transformer medical image segmentation . project be available here .",Computer Vision and Pattern Recognition,05/10/2025
10.48550/arXiv.2510.04003,enhance ocr sino-vietnamese language processing fine-tuned paddleocrv5,"Minh Hoang Nguyen, Su Nguyen Thiet","recognize and process classical chinese ( han–nom ) text play vital role digitize vietnamese historical document and enable cross-lingual semantic research . however , exist ocr system struggle degraded scan , non-standard glyph , and handwriting variation common ancient source such khâm định việt sử thông giám cương mục . work , propose fine-tuning approach paddleocrv5 to improve character recognition han–nom text . retrain text recognition module use curate subset ancient vietnamese chinese manuscript , support full training pipeline cover preprocessing , lmdb conversion , evaluation , and visualization . experimental result show significant improvement base model — exact accuracy rise 37 . 5 % 50 . 0 % , particularly noisy image condition . furthermore , develop interactive demo visually compare pre- and post-fine-tune recognition result , facilitate downstream application such han–vietnamese semantic alignment , machine translation , and historical linguistic research . demo be available : https://huggingface.co/spaces/minhds/fine-tuned-paddleocrv5",Computer Vision and Pattern Recognition,05/10/2025
10.48550/arXiv.2510.03993,keep leash : controllable pseudo-label generation realistic long-tailed semi-supervised learning,"Yaxin Hou, Bo Han, Yuheng Jia, Hui Liu, Junhui Hou","current long-tailed semi-supervised learning method assume label datum exhibit long-tailed distribution , and unlabeled datum adhere typical predefine distribution ( i.e. , long-tailed , uniform , or inverse long-tailed ) . however , distribution unlabeled data be generally unknown and may follow arbitrary distribution . to tackle challenge , propose controllable pseudo-label generation ( cpg ) framework , expand label dataset progressively identify reliable pseudo-label unlabeled dataset and train model update label dataset know distribution , make unaffected unlabeled datum distribution . specifically , cpg operate controllable self-reinforce optimization cycle : ( i ) training step , dynamic controllable filtering mechanism selectively incorporate reliable pseudo-label unlabeled dataset label dataset , ensure update label dataset follow know distribution ; ( ii ) then construct bayes-optimal classifier use logit adjustment base update label datum distribution ; ( iii ) improve classifier subsequently help identify more reliable pseudo-label next training step . far theoretically prove optimization cycle can significantly reduce generalization error condition . additionally , propose class-aware adaptive augmentation module to far improve representation minority class , and auxiliary branch to maximize datum utilization leverage label and unlabeled sample . comprehensive evaluation various commonly use benchmark dataset show cpg achieve consistent improvement , surpass state-of-the-art method to 15 . 97 % accuracy . code be available https://github.com/yaxinhou/cpg .",Computer Vision and Pattern Recognition,05/10/2025
10.48550/arXiv.2510.03978,tokens waste : leverage long context biomedical vision-language model,"Min Woo Sun, Alejandro Lozano, Javier Gamazo Tejero, Vishwesh Nath, Xiao Xiao Sun, James Burgess, Yuhui Zhang, Kun Yuan, Robert Tibshirani, Sean Huver, Serena Yeung-Levy","embed vision–language model ( vlms ) be typically pretraine short text window ( < < 77 token ) , force truncation long-format caption . yet , distribution biomedical caption large-scale open source literature reveal huge portion caption far exceed 77 token . end , investigate impact pretraine long-format biomedical caption extend context length text encoder vlm . find long context ( thus , enable additional supervision provide long-format caption ) correlate well retrieval and classification performance . give finding , introduce biomedica-longcap , dataset 1 m image–caption pair enrich context-aware description full-text article , provide long and additional textual supervision . use biomedica-longcap , train bmc-longclip , long-context biomedical vlm text encoder support window to 512 token . model extend context capacity 6 . 6× , reduce token waste 55 % just 2 . 2 % . long-caption retrieval benchmark , achieve +30 % absolute gain recall@1 and +2 % average improvement classification , also converge fast short-context . result demonstrate long-context modeling be promising direction advance biomedical vlm .",Computer Vision and Pattern Recognition,04/10/2025
10.48550/arXiv.2510.03955,harness synthetic preference data enhance temporal understanding video-llms,"Sameep Vani, Shreyas Jena, Maitreya Patel, Chitta Baral, Somak Aditya, Yezhou Yang","video large language models ( video-llms ) have demonstrate remarkable performance general video understanding benchmarks-particularly video captioning and descriptive tasks-they consistently underperform task require fine-grained temporal understanding . limitation arise lack visual complexity and temporal nuance current fine-tuning dataset , lead model to rely heavily language-based reasoning rather truly understand video dynamic . work , propose timewarp , systematic method to create target synthetic temporal dataset to fine-tune model ’s response to encourage to focus give input video . introduce large-scale preference dataset , create use timewarp , capture intricate temporal dynamic often overlook , ground model ’s response visual and temporal information . demonstrate method be apply exist model , significantly improve performance temporal understanding benchmark , highlight effectiveness propose dataset advance temporal understanding video-llms , result absolute improvement performance seven benchmark . code be available https://github.com/sameepv21/timewarp .",Computer Vision and Pattern Recognition,04/10/2025
10.48550/arXiv.2510.03915,openflame : federated visual positioning system to enable large-scale augmented reality application,"Sagar Bharadwaj, Harrison Williams, Luke Wang, Michael Liang, Tao Jin, Srinivasan Seshan, Anthony Rowe","world-scale augmented reality ( ar ) application need ubiquitous 6dof localization backend to anchor content real world consistently device . large organization such google and niantic be 3d scan outdoor public space order to build own visual positioning systems ( vps ) . centralized vps solution fail to meet need many future ar applications—they do not cover private indoor space privacy concern , regulation , and labor bottleneck update and maintain 3d scan . paper , present openflame , federate vps backend allow independent organization 3d scan and maintain separate vps service own space . enable access control indoor 3d scan , distribute maintenance vps backend , and encourage large coverage . sharding vps service introduce several unique challenges—coherency localization result space , quality control vps service , selection right vps service location , and many other . introduce concept federated image-based localization and provide reference solution manage and merge datum map share private datum .",Computer Vision and Pattern Recognition,04/10/2025
10.48550/arXiv.2510.03909,generate human motion videos use cascade text-to-video framework,"Hyelin Nam, Hyojun Go, Byeongjun Park, Byung-Hoon Kim, Hyungjin Chung","human video generation be become increasingly important task broad application graphic , entertainment , and embody ai . rapid progress video diffusion model ( vdm ) , use general-purpose human video generation remain underexplored , most work constrain image-to-video setup or narrow domain dance video . work , propose cameo , cascaded framework general human motion video generation . seamlessly bridge text-to-motion ( t2 m ) model and conditional vdm , mitigate suboptimal factor may arise process both training and inference carefully design component . specifically , analyze and prepare textual prompt and visual condition to effectively train vdm , ensure robust alignment motion description , conditioning signal , and generate video . furthermore , introduce camera-aware conditioning module connect two stage , automatically select viewpoint align input text to enhance coherence and reduce manual intervention . demonstrate effectiveness approach both moviegen benchmark and newly introduce benchmark tailor t2m–vdm combination , highlight versatility diverse use case .",Computer Vision and Pattern Recognition,04/10/2025
10.48550/arXiv.2510.03906,filter vlms : benchmarke defogging methods object detection and segmentation performance,"Ardalan Aryashad, Parsa Razmara, Amin Mahjoub, Seyedarmin Azizi, Mahdi Salmani, Arad Firouzkouhi","autonomous drive perception system be particularly vulnerable foggy condition , light scattering reduce contrast and obscure fine detail critical safe operation . numerous defogging method exist-from handcraft filter to learn restoration models-improvement image fidelity do not consistently translate well downstream detection and segmentation . moreover , prior evaluation often rely synthetic datum , leave question real-world transferability . present structured empirical study benchmark comprehensive set pipeline , include ( i ) classical filter , ( ii ) modern defogging network , ( iii ) chain variant ( filter→\rightarrowmodel , model→\rightarrowfilter ) , and ( iv ) prompt-driven visual–language image editing model ( vlm ) apply directly foggy image . use foggy cityscapes , assess image quality and downstream performance object detection ( map ) and segmentation ( pq , rq , sq ) . analysis reveal defogging help , chain yield synergy or degradation , and vlm-base editor compare dedicated approach . addition , evaluate qualitative rubric-based score vlm judge and quantify alignment task metric , show strong correlation map . together , result establish transparent , task-oriented benchmark defogge method and highlight condition preprocesse genuinely improve autonomous perception adverse weather .",Computer Vision and Pattern Recognition,04/10/2025
10.48550/arXiv.2510.03903,zero-shot fine-grained image classification use large vision-language model,"Md. Atabuzzaman, Andrew Zhang, Chris Thomas","large vision-language model ( lvlm ) have demonstrate impressive performance vision-language reasoning task . however , potential zero-shot fine-grained image classification , challenging task require precise differentiation visually similar category , remain underexplored . present novel method transform zero-shot fine-grained image classification visual question-answering framework , leverage lvlm ' comprehensive understanding capability rather rely direct class name generation . enhance model performance novel attention intervention technique . also address key limitation exist dataset develop more comprehensive and precise class description benchmark . validate effectiveness method extensive experimentation multiple fine-grained image classification benchmark . propose method consistently outperform current state-of-the-art ( sota ) approach , demonstrate both effectiveness method and broad potential lvlm zero-shot fine-grained classification task . code and datasets : https://github.com/atabuzzaman/fine-grained-classification",Computer Vision and Pattern Recognition,04/10/2025
10.48550/arXiv.2510.03896,bridge thinking and acting : unleash physical potential vlm generalizable action expert,"Mingyu Liu, Zheng Huang, Xiaoyi Lin, Muzhi Zhu, Canyu Zhao, Zongze Du, Yating Wang, Haoyi Zhu, Hao Chen, Chunhua Shen","vision-language model ( vlm ) have demonstrate impressive planning and reasoning capability , translate ability physical world introduce significant challenge . conventional vision-language-action ( vla ) model , integrate reasoning and action monolithic architecture , generalize poorly be constrain scarce , narrow-domain datum . recent dual-system approach attempt to decouple "" thinking "" "" act , "" be often constrain semantic ambiguity action module . ambiguity make large-scale , cross-task training infeasible . consequently , system typically necessitate fine-tuning newly collect datum deploy novel environment , and cooperation mechanism two system remain ill-defined . to address limitation , introduce , first time , framework center generalizable action expert . approach utilize sparse 3d trajectory intermediate representation , effectively bridge high-level planning capability vlm low-level physical action module . planning phase , vlm be only require to generate coarse 3d waypoint . waypoint be then process generalizable action expert , refine dense , executable action sequence sample real-time point cloud observation environment . to promote training efficiency and robust generalization , introduce novel "" action pre-training , pointcloud fine-tuning "" paradigm . method combine broad generalization capability vlms visual understanding and plan fine-grained , action-level generalization action expert . extensive experiment , demonstrate method exhibit high-quality result and strong generalization diverse visual domain , camera viewpoint , and natural language instruction , enable zero-shot deployment further fine-tuning .",Computer Vision and Pattern Recognition,04/10/2025
10.48550/arXiv.2510.03880,explore instruction data quality explainable image quality assessment,"Yunhao Li, Sijing Wu, Huiyu Duan, Yucheng Zhu, Qi Jia, Guangtao Zhai","recent year , rapid development powerful multimodal large language model ( mllm ) , explainable image quality assessment ( iqa ) have gradually become popular , aim provide quality-related description and answer image . to achieve goal , recent method seek to construct large-scale instruction tuning dataset to empower mllm quality perception ability follow well-known scaling law . however , large amount instruction tuning datum may cause substantial computational cost and redundant datum , turn will cause harm performance model . to cope problem , paper , challenge scale law and systematically investigate role datum quality instruction tuning dataset explainable iqa . use powerful pre-trained mllm , first investigate change model performance fine-tune different size instruction tuning datum . find select subset datum set randomly use appropriate ratio can even lead well result train entire instruction tuning dataset , demonstrate redundancy current explainable iqa instruction tuning datum . randomly sample subset , propose clustering-based data selection framework three stage : cluster feature extraction , cluster quota allocation , and cluster sampling strategy . then systematically analyze choice stage and propose simple but efficient datum selection method iqa-select explainable iqa . experimental result demonstrate iqa-select can achieve 102 . 1%\% and 103 . 7%\% performance full fine-tuning use only 10%\% select datum q-bench and aesbench respectively , significantly reduce computational cost achieve well performance . hope paper can provide new perspective future research explore quality instruction tuning datum explainable iqa .",Computer Vision and Pattern Recognition,04/10/2025
10.48550/arXiv.2510.03878,multi-modal oral cancer detection use weighted ensemble convolutional neural networks,"Ajo Babu George, Sreehari J R Ajo Babu George, Sreehari J R Ajo Babu George, Sreehari J R","late diagnosis oral squamous cell carcinoma ( oscc ) contribute significantly high global mortality rate , 50 % case detect advanced stage and 5-year survival rate 50 % accord statistic . study aim to improve early detection oscc develop multimodal deep learning framework integrate clinical , radiological , and histopathological image use weighted ensemble densenet-121 convolutional neural network ( cnns ) .",Computer Vision and Pattern Recognition,04/10/2025
10.48550/arXiv.2510.03876,skin lesion classification base resnet-50 enhance adaptive spatial feature fusion,"Runhao Liu, Ziming Chen, Peng Zhang","skin cancer classification remain challenging problem high inter-class similarity , intra-class variability , and image noise dermoscopic image . to address issue , propose improved resnet-50 model enhance adaptive spatial feature fusion ( asff ) , adaptively integrate multi-scale semantic and surface feature to improve feature representation and reduce overfitting . resnet-50 model be enhance adaptive feature fusion mechanism to achieve more effective multi-scale feature extraction and improve overall performance . specifically , dual-branch design fuse high-level semantic and mid-level detail feature , be process global average pooling and fully connected layer to generate adaptive weight weighted fusion , thereby strengthen feature learn and reduce impact noise classification . method be evaluate subset isic 2020 dataset contain 3297 benign and malignant skin lesion image . experimental result show propose asff-base resnet-50 achieve good overall performance compare 5 classic convolutional neural network ( cnn ) model . propose model reach accuracy 93 . 18%\% high precision , recall , specificity , and f1 score . improved model achieve auc value 0 . 9670 and 0 . 9717 p-r and roc curve , respectively . then , evaluation base grad-cam far prove improved model adaptively focus lesion-relevant region suppress irrelevant background information , thereby validate enhance feature learning capability deep representation perspective . finding demonstrate propose approach provide more effective and efficient solution computer-aided skin cancer diagnosis .",Computer Vision and Pattern Recognition,04/10/2025
10.48550/arXiv.2510.03874,dhqa-4d : perceptual quality assessment dynamic 4d digital human,"Yunhao Li, Sijing Wu, Yucheng Zhu, Huiyu Duan, Zicheng Zhang, Guangtao Zhai","rapid development 3d scanning and reconstruction technology , dynamic digital human avatar base 4d mesh have become increasingly popular . high-precision dynamic digital human avatar can be apply various field such game production , animation generation , and remote immersive communication . however , 4d human avatar mesh be prone be degrade various type noise process collection , compression , and transmission , thereby affect view experience user . light fact , quality assessment dynamic 4d digital human become increasingly important . paper , first propose large-scale dynamic digital human quality assessment dataset , dhqa-4d , contain 32 high-quality real-scanned 4d human mesh sequence , 1920 distort texture 4d human mesh degrade 11 texture distortion , as well correspond texture and non-textured mean opinion score ( moss ) . equip dhqa-4d dataset , analyze influence different type distortion human perception texture dynamic 4d mesh and non-textured dynamic 4d mesh . additionally , propose , novel large multimodal model ( lmm ) base approach be able to assess texture 4d mesh and non-textured 4d mesh . concretely , dynamesh-rater elaborately extract multi-dimensional feature , include visual feature project 2d video , motion feature cropped video clip , and geometry feature 4d human mesh to provide comprehensive quality-related information . then utilize lmm model to integrate multi-dimensional feature and conduct lora-based instruction tuning technique to teach lmm model to predict quality score . extensive experimental result dhqa-4d dataset demonstrate superiority dynamesh-rat method previous quality assessment method .",Computer Vision and Pattern Recognition,04/10/2025
10.48550/arXiv.2510.03870,sdakd : student discriminator assisted knowledge distillation super-resolution generative adversarial networks,"Nikolaos Kaparinos, Vasileios Mezaris","generative adversarial networks ( gan ) achieve excellent performance generative task , such image super-resolution , but computational requirement make difficult deployment resource-constrained device . knowledge distillation be promising research direction gan compression , effectively train small student generator be challenge capacity mismatch student generator and teacher discriminator . work , propose student discriminator assisted knowledge distillation ( sdakd ) , novel gan distillation methodology introduce student discriminator to mitigate capacity mismatch . sdakd follow three-stage training strategy , and integrate adapt feature map distillation approach last two training stage . evaluate sdakd two well-performing super-resolution gan , gcfsr and real-esrgan . experiment demonstrate consistent improvement baseline and sota gan knowledge distillation method . sdakd source code will be make openly available acceptance paper .",Computer Vision and Pattern Recognition,04/10/2025
10.48550/arXiv.2510.03869,explore challenge and value deep learning automated skin disease diagnosis,"Runhao Liu, Ziming Chen, Peng Zhang","skin cancer be one most prevalent and deadly form cancer worldwide , highlight critical importance early detection and diagnosis improve patient outcome . deep learning ( dl ) have show significant promise enhance accuracy and efficiency automate skin disease diagnosis , particularly detect and evaluate skin lesion and classification . however , be still several challenge dl-base skin cancer diagnosis , include complex feature , image noise , intra-class variation , inter-class similarity , and data imbalance . synthesize recent research , review discuss innovative approach to cope challenge , such datum augmentation , hybrid model , and feature fusion , etc . furthermore , review highlight integration dl model clinical workflow , offer insight potential deep learning to revolutionize skin disease diagnosis and improve clinical decision-making . article follow comprehensive methodology base prisma framework and emphasize need continue advancement to fully unlock transformative potential dl dermatological care .",Computer Vision and Pattern Recognition,04/10/2025
10.48550/arXiv.2510.05052,proactive defense llm jailbreak,"Weiliang Zhao, Jinjun Peng, Daniel Ben-Levi, Zhou Yu, Junfeng Yang","proliferation powerful large language model ( llms ) have necessitate robust safety alignment , yet model remain vulnerable evolve adversarial attack , include multi-turn jailbreak iteratively search successful query . current defense , primarily reactive and static , often fail to counter search-based attack . paper , introduce proact , novel proactive defense framework design to disrupt and mislead autonomous jailbreaking process . core idea be to intentionally provide adversary "" spurious response "" appear to be result successful jailbreak attack but contain actual harmful content . misleading response provide false signal attacker ’s internal optimization loop , cause adversarial search to terminate prematurely and effectively jailbreake jailbreak . conduct extensive experiment state-of-the-art llms , jailbreake framework , and safety benchmark , method consistently and significantly reduce attack success rate to 92 % . combine other defense framework , far reduce success rate late attack strategy 0 % . proact represent orthogonal defense strategy can serve additional guardrail to enhance llm safety most effective jailbreaking attack .",Cryptography and Security,06/10/2025
10.48550/arXiv.2510.04987,natgvd : natural adversarial example attack graph-based vulnerability detection,"Avilash Rath, Weiliang Qi, Youpeng Li, Xinda Wang","graph-based model learn rich code graph structural information and present superior performance various code analysis task . however , robustness model adversarial example attack context vulnerability detection remain open question . paper propose natgvd , novel attack methodology generate natural adversarial vulnerable code to circumvent gnn-base and graph-aware transformer-based vulnerability detector . natgvd employ set code transformation modify graph structure preserve code semantic . instead inject dead or unrelated code previous work , natgvd consider naturalness requirement : generate example should not be easily recognize human or program analysis tool . extensive evaluation natgvd state-of-the-art vulnerability detection system , result reveal 53 . 04 % evasion rate gnn-based detector and graph-aware transformer-based detector . also explore potential defense strategy to enhance robustness system natgvd .",Cryptography and Security,06/10/2025
10.48550/arXiv.2510.04885,rl be hammer and llm be nail : simple reinforcement learning recipe strong prompt injection,"Yuxin Wen, Arman Zharmagambetov, Ivan Evtimov, Narine Kokhlikyan, Tom Goldstein, Kamalika Chaudhuri, Chuan Guo","prompt injection pose serious threat reliability and safety llm agent . recent defense prompt injection , such instruction hierarchy and secalign , have show notable robustness static attack . however , to more thoroughly evaluate robustness defense , be arguably necessary to employ strong attack such automate red-teaming . end , introduce rl-hammer , simple recipe training attacker model automatically learn to perform strong prompt injection and jailbreak reinforcement learning . rl-hammer require warm-up datum and can be train entirely scratch . to achieve high asr industrial-level model defense , propose set practical technique enable highly effective , universal attack . use pipeline , rl-hammer reach 98%98\% asr gpt-4o and 72%72\% asr gpt-5 instruction hierarchy defense . far discuss challenge achieve high diversity attack , highlight attacker model tend to "" reward-hack "" diversity objective . finally , show rl-hammer can evade multiple prompt injection detector . hope work advance automatic red-teaming and motivate development strong , more principled defense . code be available https://github.com/facebookresearch/rl-injector .",Cryptography and Security,06/10/2025
10.48550/arXiv.2510.04882,enhance treepir single-server setting resampling,Elian Morel,nan,Cryptography and Security,06/10/2025
10.48550/arXiv.2510.04652,modeling and managing temporal obligations gucon use sparql-star and rdf-star,"Ines Akaichi, Giorgos Flouris, Irini Fundulaki, Sabrina Kirrane","digital age , datum frequently cross organizational and jurisdictional boundary , make effective governance essential . usage control policy have emerge key paradigm regulate datum usage , safeguard privacy , protect intellectual property , and ensure compliance regulation . central mechanism usage control be handling obligation , arise side effect use and share datum . effective monitoring obligation require capture usage trace and account temporal aspect such start time and deadline , obligation may evolve time different state , such fulfil , violate , or expire . several solution have be propose obligation monitoring , often lack formal semantic or provide limited support reasoning obligation state . to address limitation , extend gucon , policy framework ground formal semantic spaqrl graph pattern , to explicitly model temporal aspect obligation . extension enable expressing temporal obligation and support continuous monitoring evolve state base usage trace store temporal knowledge graph . demonstrate extended model can be represent use rdf-star and sparql-star and propose obligation state manager monitor obligation state and assess compliance respect usage trace . finally , evaluate both extended model and prototype implementation .",Cryptography and Security,06/10/2025
10.48550/arXiv.2510.04619,pos-copor : proof-of-stake consensus protocol native onion routing provide scalability and dos-resistance,"Ivan Homoliak, Martin Perešíni, Marek Tamaškovič, Timotej Ponek, Lukáš Hellebrandt, Kamil Malinka","proof-of-stake ( pos ) consensus protocol often face trade-off performance and security . protocol pre-elect leader subsequent round be vulnerable denial-of-service ( dos ) attack , can disrupt network and compromise liveness . work , present pos-copor , single-chain pos consensus protocol mitigate vulnerability integrate native onion route mechanism consensus protocol . pos-copor combine stake-weighte probabilistic leader election anonymization layer conceal network identity next block proposer . approach prevent target dos attack leader produce block , thus enhance network resilience . implement and evaluate pos-copor , demonstrate ability to achieve throughput to 110 tx/s 6 node , even overhead anonymization layer . result show native anonymization can provide robust dos resistance only modest impact performance , offer solution to build secure and scalable pos blockchain .",Cryptography and Security,06/10/2025
10.48550/arXiv.2510.04529,computational certified deletion property magic square game and application classical secure key leasing,"Yuki Takeuchi, Duo Xu","present first construction computational certified deletion property ( cdp ) achievable classical communication , derive compilation non-local magic square game ( msg ) . leverage klvy compiler to transform non-local msg 2-round interactive protocol , rigorously demonstrate compilation preserve game-specific cdp . previously , quantum value and rigidity compile game be investigate . emphasize be first to investigate cdp ( local randomness [ fu and miller , phys . rev. 97 , 032324 ( 2018 ) ] ) compile game . then , combine cdp framework [ kitagawa , morimae , and yamakawa , eurocrypt 2025 ] to construct secure key leasing classical lessor ( cskl ) . skl enable lessor to lease secret key lessee and verify quantum lessee have indeed delete key . paper , realize cskl pke , prf , and digital signature . compare prior work cskl , realize cskl prf and digital signature first time . addition , succeed weaken assumption need to construct cskl .",Cryptography and Security,06/10/2025
10.48550/arXiv.2510.04528,"unified threat detection and mitigation framework ( utdmf ): combat prompt injection , deception , and bias enterprise-scale transformer",Santhosh KumarRavindran,"rapid adoption large language model ( llms ) enterprise system expose vulnerability prompt injection attack , strategic deception , and biased output , threaten security , trust , and fairness . extend adversarial activation patch framework ( arxiv : 2507 . 09406 ) , induce deception toy network 23 . 9 % rate , introduce unified threat detection and mitigation framework ( utdmf ) , scalable , real-time pipeline enterprise-grade model llama-3 . 1 ( 405b ) , gpt-4o , and claude-3 . 5 . 700 + experiment model , utdmf achieve : ( 1 ) 92 % detection accuracy prompt injection ( e.g. , jailbreaking ) ; ( 2 ) 65 % reduction deceptive output enhanced patching ; and ( 3 ) 78 % improvement fairness metric ( e.g. , demographic bias ) . novel contribution include generalized patching algorithm multi-threat detection , three groundbreake hypothesis threat interaction ( e.g. , threat chain enterprise workflow ) , and deployment-ready toolkit api enterprise integration . draw recent 2024-2025 peer-reviewed reference arxiv , acl anthology , acm , nature , pnas , and ieee , utdmf offer reproducible solution secure , fair , and responsible ai , open-source code and dataset immediate enterprise adoption .",Cryptography and Security,06/10/2025
10.48550/arXiv.2510.04503,p2p : poison-to-poison remedy reliable backdoor defense llms,"Shuai Zhao, Xinyi Wu, Shiqian Zhao, Xiaobao Wu, Zhongliang Guo, Yanhao Jia, Anh Tuan Luu","fine-tuning , large language model ( llms ) be increasingly vulnerable data-poisoning backdoor attack , compromise reliability and trustworthiness . however , exist defense strategy suffer limited generalization : only work specific attack type or task setting . study , propose poison-to-poison ( p2p ) , general and effective backdoor defense algorithm . p2p inject benign trigger safe alternative label subset training sample and fine-tune model re-poisone dataset leverage prompt-based learning . enforce model to associate trigger-induced representation safe output , thereby override effect original malicious trigger . thank robust and generalizable trigger-based fine-tuning , p2p be effective task setting and attack type . theoretically and empirically , show p2p can neutralize malicious backdoor preserve task performance . conduct extensive experiment classification , mathematical reasoning , and summary generation task , involve multiple state-of-the-art llms . result demonstrate p2p algorithm significantly reduce attack success rate compare baseline model . hope p2p can serve guideline defend backdoor attack and foster development secure and trustworthy llm community .",Cryptography and Security,06/10/2025
10.48550/arXiv.2510.04397,mulvuln : enhance pre-trained lm shared and language-specific knowledge multilingual vulnerability detection,"Van Nguyen, Surya Nepal, Xingliang Yuan, Tingmin Wu, Fengchao Chen, Carsten Rudolph","software vulnerability ( svs ) pose critical threat safety-critical system , drive adoption ai-based approach such machine learning and deep learning software vulnerability detection . promise result , most exist method be limit single programming language . be problematic give multilingual nature modern software , be often complex and write multiple language . current approach often face challenge capture shared and language-specific knowledge source code , can limit performance diverse programming language and real-world codebase . to address gap , propose mulvuln , novel multilingual vulnerability detection approach learn source code multiple language . mulvuln capture share knowledge generalize language and language-specific knowledge reflect unique coding convention . integrate aspect , achieve more robust and effective detection vulnerability real-world multilingual software system . rigorous and extensive experiment real-world and diverse reef dataset , consist 4 , 466 cf 30 , 987 patch seven programming language , demonstrate superiority mulvuln thirteen effective and state-of-the-art baseline . notably , mulvuln achieve substantially high f1-score , improvement range 1 . 45 % 23 . 59 % compare baseline method .",Cryptography and Security,05/10/2025
10.48550/arXiv.2510.04261,vortexpia : indirect prompt injection attack llms efficient extraction user privacy,"Yu Cui, Sicheng Pan, Yifei Liu, Haibin Zhang, Cong Zuo","large language model ( llms ) have be widely deploy conversational ai ( cai ) , expose privacy and security threat . recent research show llm-base cai can be manipulate to extract private information human user , pose serious security threat . however , method propose study rely white-box setting adversary can directly modify system prompt . condition be unlikely to hold real-world deployment . limitation raise critical question : can unprivileged attacker still induce such privacy risk practical llm-integrated application ? to address question , propose vortexpia , novel indirect prompt injection attack induce privacy extraction llm-integrated application black-box setting . inject token-efficient datum contain false memory , vortexpia mislead llm to actively request private information batch . prior method , vortexpia allow attacker to flexibly define multiple category sensitive datum . evaluate vortexpia six llm , cover both traditional and reason llms , four benchmark dataset . result show significantly outperform baseline and achieve state-of-the-art ( sota ) performance . also demonstrate efficient privacy request , reduce token consumption , and enhance robustness defense mechanism . far validate vortexpia multiple realistic open-source llm-integrated application , demonstrate practical effectiveness .",Cryptography and Security,05/10/2025
10.48550/arXiv.2510.04257,agenttypo : adaptive typographic prompt injection attacks black-box multimodal agents,"Yanjie Li, Yiming Cao, Dong Wang, Bin Xiao","multimodal agent build large vision–language model ( lvlm ) be increasingly deploy open-world setting but remain highly vulnerable prompt injection , especially visual input . introduce agenttypo , black-box red-teame framework mount adaptive typographic prompt injection embed optimize text webpage image . automatic typographic prompt injection ( atpi ) algorithm maximize prompt reconstruction substitute captioner minimize human detectability stealth loss , tree-structured parzen estimator guiding black-box optimization text placement , size , and color . to far enhance attack strength , develop agenttypo-pro , multi-llm system iteratively refine injection prompt use evaluation feedback and retrieve successful past example continual learning . effective prompt be abstract generalizable strategy and store strategy repository , enable progressive knowledge accumulation and reuse future attack . experiment vwa-adv benchmark classifieds , shopping , and reddit scenario show agenttypo significantly outperform late image-based attack such agentattack . gpt-4o agent , image-only attack raise success rate 23 % to 45 % , consistent result gpt-4v , gpt-4o-mini , gemini 1 . 5 pro , and claude 3 opus . image+text setting , agenttypo achieve 68 % asr , also outperform late baseline . finding reveal agenttypo pose practical and potent threat multimodal agent and highlight urgent need effective defense .",Cryptography and Security,05/10/2025
10.48550/arXiv.2510.04153,obclip : oblivious cloud-device hybrid image generation privacy preservation,"Haoqi Wu, Wei Dai, Ming Xu, Li Wang, Qiang Yan","diffusion models have gain significant popularity remarkable capability image generation , cost intensive computation requirement . meanwhile , widespread deployment inference service such midjourney , concern potential leakage sensitive information uploaded user prompt have arise . exist solution either lack rigorous privacy guarantee or fail to strike effective balance utility and efficiency . to bridge gap , propose obclip , plug-and-play safeguard enable oblivious cloud-device hybrid generation . oblivious , input prompt be transform set semantically similar candidate prompt differ only sensitive attribute ( e.g. , gender , ethnicity ) . cloud server process candidate prompt know one be real one , thus prevent prompt leakage . to mitigate server cost , only small portion denoise step be perform large cloud model . intermediate latent be then send back client , select targeted latent and complete remain denoising use small device model . additionally , analyze and incorporate several cache-based acceleration leverage temporal and batch redundancy , effectively reduce computation cost minimal utility degradation . extensive experiment multiple dataset demonstrate obclip provide rigorous privacy and comparable utility to cloud model slightly increase server cost .",Cryptography and Security,05/10/2025
10.48550/arXiv.2510.04118,cyber warfare operation sindoor : malware campaign analysis and detection framework,"Prakhar Paliwal, Atul Kabra, Manjesh Kumar Hanawal","rapid digitization critical infrastructure have make cyberwarfare one important dimension modern conflict . attack critical infrastructure be attractive pre-emptive proposition adversary can be do remotely cross border . such attack disturb support system opponent to launch offensive activity , cripple fighting capability . cyberattack cyberwarfare can not only be use to steal information , but also to spread disinformation to bring morale opponent . recent war europe , africa , and asia have demonstrate scale and sophistication war nation have deploy to take early upper hand . work , focus military action launch india , code-named operation sindoor , to dismantle terror infrastructure emanating pakistan and cyberattack launch pakistan . particular , study malware use pakistan apt group to deploy remote access trojans indian system . provide detail tactic and technique use rat deployment and develop telemetry framework to collect necessary event log use osquery custom extension . finally , develop detection rule can be readily deploy to detect presence rat or exploitation perform malware .",Cryptography and Security,05/10/2025
10.48550/arXiv.2510.04056,real-vulllm : llm base assessment framework wild,"Rijha Safdar, Danyail Mateen, Syed Taha Ali, Wajahat Hussain","artificial intelligence ( ai ) and more specifically large language models ( llms ) have demonstrate exceptional progress multiple area include software engineering , however , capability vulnerability detection wild scenario and corresponding reasoning remain underexplored . prompt pre-trained llm effective way offer computationally effective and scalable solution . contribution be ( i)varie prompt design vulnerability detection and corresponding reasoning wild . ( ii)a real-world vector datum store construct national vulnerability database , will provide real time context vulnerability detection framework , and ( iii)a scoring measure combine measurement accuracy and reasoning quality . contribution aim to examine llms be ready wild deployment , thus enable reliable use llms strong development secure software ’s .",Cryptography and Security,05/10/2025
10.48550/arXiv.2510.03996,fheon : configurable framework develop privacy-preserve neural networks use homomorphic encryption,"Nges Brian Njungle, Eric Jahns, Michel A. Kinsy","widespread adoption machine learning service raise critical privacy and security concern , particularly datum confidentiality and trust cloud provider and machine learning model . homomorphic encryption ( he ) have emerge promising solution problem , allow computation encrypt datum decryption . potential , exist approach to integrate neural network be often limit specific architecture , leave wide gap provide framework easy development he-friendly privacy-preserving neural network model similar have broad field machine learning .",Cryptography and Security,05/10/2025
10.48550/arXiv.2510.03995,privspike : employ homomorphic encryption private inference deep spiking neural networks,"Nges Brian Njungle, Eric Jahns, Milan Stojkov, Michel A. Kinsy","deep learning have become cornerstone modern machine learning . rely heavily vast dataset and significant computational resource high performance . datum often contain sensitive information , make privacy major concern deep learning . spike neural networks ( snns ) have emerge energy-efficient alternative conventional deep learning approach . nevertheless , snn still depend large volume datum , inherit privacy challenge deep learning . homomorphic encryption address challenge allow computation to be perform encrypt datum , ensure datum confidentiality entire processing pipeline .",Cryptography and Security,05/10/2025
10.48550/arXiv.2510.03992,quantifying distributional robustness agentic tool-selection,"Jehyeok Yeon, Isha Chaudhary, Gagandeep Singh","large language model ( llms ) be increasingly deploy agentic system map user intent relevant external tool to fulfill task . critical step process be tool selection , retriever first surface top-n slate candidate tool large pool , llm select most appropriate one to fulfill task . pipeline present underexplored attack surface error selection can lead severe outcome unauthorized data access or denial service , all modify agent ’s model or code . existing evaluation measure task performance benign setting , overlook specific vulnerability tool selection mechanism adversarial condition . to address gap , introduce toolcert , first statistical framework formally certify tool selection robustness . toolcert model tool selection bernoulli success process and evaluate strong , adaptive attacker introduce adversarial tool misleading metadata , and be iteratively refine base agent ’s previous choice . sample adversarial interaction , toolcert produce high-confidence lower bind accuracy , formally quantify agent ’s worst-case performance . evaluation toolcert uncover severe fragility sota llm agent tool selection . attack inject deceptively appeal tool or saturate retrieval result , certify lower bind accuracy drop close zero . represent average performance drop 60 % compare non-adversarial setting . attack target retrieval and selection stage , certify accuracy bind plummet less 20 % just single round adversarial adaptation . toolcert thus reveal previously unexamine security threat inherent tool selection and provide principled method to quantify agent ’s robustness such threat , necessary step safe deployment agentic system .",Cryptography and Security,05/10/2025
10.48550/arXiv.2510.03831,pilot contamination attacks detection machine learning multi-user massive mimo,"Pedro Ivo da Cruz, Dimitri Silva, Tito Spadini, Ricardo Suyama, Murilo Bellezoni Loiola","massive multiple-input multiple-output ( mmimo ) be essential modern wireless communication system , 5 g and 6 g , but be vulnerable active eavesdropping attack . one type such attack be pilot contamination attack ( pca ) , malicious user copy pilot signal authentic user uplink , intentionally interfere base station ’s ( bs ) channel estimation accuracy . work , propose to use decision tree ( dt ) algorithm pca detection bs multi-us system . present methodology to generate training datum dt classifier and select good dt accord depth . then , simulate different scenario could be encounter practice and compare dt classical technique base likelihood ratio testing ( lrt ) submit same scenario . result reveal dt only one level depth be sufficient to outperform lrt . dt show good performance regard probability detection noisy scenario and malicious user transmit low power , case lrt fail to detect pca . also show reason good performance dt be ability to compute threshold separate pca datum non-pca datum well lrt ’s threshold . moreover , dt do not necessitate prior knowledge noise power or assumption regard signal power malicious user , prerequisite typically essential lrt and other hypothesis testing methodology .",Cryptography and Security,04/10/2025
10.48550/arXiv.2510.03819,security analysis ponzi schemes ethereum smart contracts,"Chunyi Zhang, Qinghong Wei, Xiaoqi Li","rapid advancement blockchain technology have precipitate widespread adoption ethereum and smart contract variety sector . however , have also give rise numerous fraudulent activity , many speculator embed ponzi scheme smart contract , result significant financial loss investor . currently , be lack effective method identify and analyze such new type fraudulent activity . paper categorize scam four structural type and explore intrinsic characteristic ponzi scheme contract source code program analysis perspective . mythril tool be employ to conduct static and dynamic analysis representative case , thereby reveal vulnerability and operational mechanism . furthermore , paper employ shell script and command pattern to conduct batch detection open-source smart contract code , thereby unveil common characteristic ponzi scheme smart contract .",Cryptography and Security,04/10/2025
10.48550/arXiv.2510.03770,complex domain approach reversible data hiding and homomorphic encryption : general framework and application dispersed datum,David Megias,"ensure trustworthiness datum distribute and resource-constrained environment , such wireless sensor networks or iot device , be critical . exist reversible data hiding ( rdh ) method scalar datum suffer low embed capacity and poor intrinsic mixing host datum and watermark . paper introduce hide imaginary domain data encryption ( h[i][i]dden ) , novel framework base complex number arithmetic simultaneous information embed and encryption . h[i][i]dden framework offer perfect reversibility , in-principle unlimited watermark size , and intrinsic data-watermark mixing . paper far introduce two protocol : h[i][i]dden-eg , joint reversible datum hiding and encryption , and h[i][i]dden-aggp , privacy-preserve aggregation watermarke datum , base partially homomorphic encryption . protocol provide efficient and resilient solution datum integrity , provenance and confidentiality , serve foundation new scheme base algebraic property complex domain .",Cryptography and Security,04/10/2025
10.48550/arXiv.2510.03761,have be latexpose : systematic analysis information leakage preprint archives use large language model,"Richard A. Dubniczky, Bertalan Borsos, Tihanyi Norbert","widespread use preprint repository such have accelerate communication scientific result but also introduce overlook security risk . pdfs , platform provide unrestricted access original source material , include latex source , auxiliary code , figure , and embed comment . absence sanitization , submission may disclose sensitive information adversary can harvest use open-source intelligence . work , present first large-scale security audit preprint archive , analyze more 1 . 2 tb source datum 100 , 000 arxiv submission . introduce latexposed , four-stage framework integrate pattern matching , logical filtering , traditional harvesting technique , and large language model ( llms ) to uncover hide disclosure non-referenced file and latex comment . to evaluate llm ' secret-detection capability , introduce llmsec-db , benchmark test 25 state-of-the-art model . analysis uncover thousand pii leak , gps-tagge exif file , publicly available google drive and dropbox folder , editable private sharepoint link , expose github and google credential , and cloud api key . also uncover confidential author communication , internal disagreement , and conference submission credential , expose information pose serious reputational risk researcher and institution . urge research community and repository operator to take immediate action to close hide security gap . to support open science , release script and method study but withhold sensitive finding could be misuse , line ethical principle . source code and related material be available project website : https://github.com/latexposed",Cryptography and Security,04/10/2025
10.48550/arXiv.2510.03752,public-key encryption minrank problem,"Rohit Chatterjee, Changrui Mu, Prashant Nalini Vasudevan",construct public-key encryption scheme hardness ( plant ) minrank problem uniformly random instance . correspond hardness decode random linear rank-metric code . exist construction public-key encryption such problem require hardness structured instance arise masking efficiently decodable code . central construction be development new notion duality rank-metric code .,Cryptography and Security,04/10/2025
10.48550/arXiv.2510.03737,secure operating systems fine-graine kernel access limitation iot systems,"Dongyang Zhan, Zhaofeng Yu, Xiangzhan Yu, Hongli Zhang, Lin Ye, Likun Liu","development internet thing ( iot ) , be gain lot attention . be important to secure embed system low overhead . linux seccomp be widely use developer to secure kernel block access unused syscall , introduce less overhead . however , be systematic seccomp configuration approach iot application help developer . addition , exist seccomp configuration approach be coarse-grained , can not analyze and limit syscall argument . paper , novel static dependent syscall analysis approach embed application be propose , can obtain possible dependent syscall and correspond argument target application . so , fine-grained kernel access limitation can be perform iot application . end , mapping dynamic library api and syscall accord argument be build , analyze control flow graph and data dependency relationship dynamic library . good knowledge , be first work to generate fine-grained seccomp profile embed application .",Cryptography and Security,04/10/2025
10.48550/arXiv.2510.03720,shrink kernel attack surface static and dynamic syscall limitation,"Dongyang Zhan, Zhaofeng Yu, Xiangzhan Yu, Hongli Zhang, Lin Ye","linux seccomp be widely use program developer and system maintainer to secure operating system , can block unused syscall different application and container to shrink attack surface operating system . however , be difficult to configure whitelist container or application help program developer . docker container block only 50 syscall default , and lot unblocked useless syscall introduce big kernel attack surface . to obtain dependent syscall , dynamic tracking be straight-forward approach but can not get full syscall list . static analysis can construct over-approximated syscall list , but list contain many false positive . paper , systematic dependent syscall analysis approach , sysverify , be propose combine static analysis and dynamic verification together to shrink kernel attack surface . semantic gap binary executable and syscall be bridge analyze binary and source code , build mapping library api and syscall systematically . to far reduce attack surface good effort , propose dynamic verification approach to intercept and analyze security invocation indirect-call-related or rarely invoke syscall low overhead .",Cryptography and Security,04/10/2025
10.48550/arXiv.2510.03705,backdoor-powere prompt injection attacks nullify defense methods,"Yulin Chen, Haoran Li, Yuan Sui, Yangqiu Song, Bryan Hooi","development technology , large language model ( llms ) have dominate downstream natural language processing ( nlp ) task . however , llms ' instruction-following ability and inability to distinguish instruction data content , such web page search engine , llm be vulnerable prompt injection attack . attack trick llms deviate original input instruction and execute attacker ’ target instruction . recently , various instruction hierarchy defense strategy be propose to effectively defend prompt injection attack fine-tuning . paper , explore more vicious attack nullify prompt injection defense method , even instruction hierarchy : backdoor-powered prompt injection attack , attacker utilize backdoor attack prompt injection attack purpose . specifically , attacker poison supervised fine-tuning sample and insert backdoor model . trigger be activate , backdoore model execute inject instruction surround trigger . construct benchmark comprehensive evaluation . experiment demonstrate backdoor-powered prompt injection attack be more harmful previous prompt injection attack , nullify exist prompt injection defense method , even instruction hierarchy technique . 111code be publicly available https://github.com/lukechen-go/backdoor-powered-pia .",Cryptography and Security,04/10/2025
10.48550/arXiv.2510.03697,time-bound signature scheme blockchains,"Benjamin Marsh, Paolo Serafino","introduce modify schnorr signature scheme to allow time-bound signature transaction fee auction bidding and smart contract purpose blockchain context , ensure honest producer can only validate signature give block height . immutable blockchain be use source universal time signature scheme . show use signature scheme lead to low mev revenue builder . then apply time-bound signature ethereum ’s eip-1559 and show can be use to mitigate effect mev predicted equilibrium strategy .",Cryptography and Security,04/10/2025
10.48550/arXiv.2510.03631,qpadl : post-quantum private spectrum access verified location and dos resilience,"Saleh Darzi, Saif Eddine Nouma, Kiarash Sedghighadikolaei, Attila Altay","advance wireless communication and grow spectrum scarcity , spectrum access systems ( sas ) offer opportunistic solution but face significant security challenge . regulation require disclosure location coordinate and transmission detail , expose user privacy and anonymity spectrum query , database operation permit denial-of-service ( dos ) attack . location-based service , sas be also vulnerable compromised or malicious user conduct spoof attack . threat be far amplify give quantum computing advancement . thus , propose qpadl , first post-quantum ( pq ) secure framework simultaneously ensure privacy , anonymity , location verification , and dos resilience maintain efficiency large-scale spectrum access system . qpadl introduce sas-tailore private information retrieval location privacy , pq-variant tor anonymity , and employ advanced signature construction location verification client puzzle protocol and rate-limiting technique dos defense . formally assess security and conduct comprehensive performance evaluation , incorporate gpu parallelization and optimization strategy to demonstrate practicality and scalability .",Cryptography and Security,04/10/2025
10.48550/arXiv.2510.03625,limit consensus dynamic availability and reconfiguration,"Joachim Neu, Javier Nieto, Ling Ren","proof-of-stake blockchain require consensus protocol support dynamic availability and reconfiguration ( so-calle dar setting ) , former mean consensus protocol should remain live even large number node temporarily crash , and latter mean should be possible to change set operating node time . state-of-the-art protocol dar setting , such ethereum , cardano ’s ouroboros , or snow white , require unrealistic additional assumption , such social consensus , or key evolution be perform even node be not participate . paper , identify necessary and sufficient adversarial condition consensus can be achieve dar setting additional assumption . then introduce new and realistic additional assumption : honest node dispose cryptographic key moment express intent to exit set operating node . to add reconfiguration dynamically available consensus protocol , provide bootstrapping gadget be particularly simple and efficient common optimistic case few reconfiguration and double-spending attempt .",Cryptography and Security,04/10/2025
10.48550/arXiv.2510.03623,explainable but vulnerable : adversarial attacks xai explanation cybersecurity applications,"Maraz Mia, Mir Mehedi A. Pritom","explainable artificial intelligence ( xai ) have aid machine learning ( ml ) researcher power scrutinize decision black-box model . xai method enable look deep model ' behavior , eventually generate explanation perceive trust and transparency . however , depend specific xai method , level trust can vary . be evident xai method can be victim post-adversarial attack manipulate expect outcome explanation module . such attack tactic , fairwashe explanation ( fe ) , manipulation explanation ( me ) , and backdoor-enabled manipulation attack ( bd ) be notable one . paper , try to understand adversarial attack technique , tactic , and procedure ( ttps ) explanation alteration and thus effect model ’s decision . have explore total six different individual attack procedure post-hoc explanation method such shap ( shapley additive explanation ) , lime ( local interpretable model-agnostic explanation ) , and ig ( integrated gradients ) , and investigate adversarial attack cybersecurity application scenario such phishing , malware , intrusion , and fraudulent website detection . experimental study reveal actual effectiveness attack , thus provide urgency immediate attention to enhance resiliency xai method and application .",Cryptography and Security,04/10/2025
10.48550/arXiv.2510.03610,pentestmcp : toolkit agentic penetration testing,"Zachary Ezetta, Wu-chang Feng","agentic ai be transform security automate many task be perform manually . initial agentic approach employ monolithic architecture , model-context-protocol have now enable remote-procedure call ( rpc ) paradigm agentic application , allow flexible construction and composition multi-function agent . paper describe pentestmcp , library mcp server implementation support agentic penetration testing . support common penetration testing task such network scanning , resource enumeration , service fingerprinting , vulnerability scanning , exploitation , and post-exploitation , pentestmcp allow developer to customize multi-agent workflow perform penetration test .",Cryptography and Security,04/10/2025
10.48550/arXiv.2510.03565,cryptoracle : modular framework to characterize fully homomorphic encryption,"Cory Brynds, Parker McLeod, Lauren Caccamise, Asmita Pal, Dewan Saiham, Sazadur Rahman, Joshua San Miguel, Di Wu","privacy-preserve machine learning have become important long-term pursuit era artificial intelligence ( ai ) . fully homomorphic encryption ( fhe ) be uniquely promising solution , offer provable privacy and security guarantee . unfortunately , computational cost be impede mass adoption . modern solution be up to six order magnitude slow plaintext execution . understand and reduce overhead be essential advancement fhe , particularly underlie algorithm evolve rapidly . paper present detailed characterization openfhe , comprehensive open-source library fhe , particular focus ckk scheme significant potential ai and machine learning application . introduce cryptoracle , modular evaluation framework comprise ( 1 ) benchmark suite , ( 2 ) hardware profiler , and ( 3 ) predictive performance model . benchmark suite encompass openfhe kernel three abstraction level : workload , microbenchmark , and primitive . profiler be compatible standard and user-specified security parameter . cryptoracle monitor application performance , capture microarchitectural event , and log power and energy usage amd and intel system . metric be consume modeling engine to estimate runtime and energy efficiency different configuration scenario , error geomean −7 . 02%∼8 . 40%\mst@varfam@dot\mst@varfam@slash-7 . 02\%\sim 8 . 40\% runtime and −9 . 74%∼15 . 67%\mst@varfam@dot\mst@varfam@slash-9 . 74\%\sim 15 . 67\% energy . cryptoracle be open source , fully modular , and serve shared platform to facilitate collaborative advancement application , algorithm , software , and hardware fhe . cryptoracle code can be access github repository .",Cryptography and Security,03/10/2025
10.48550/arXiv.2510.03559,privacymotiv : speculative persona journeys empathic and motivating privacy reviews ux design,"Zeya Chen, Jianing Wen, Ruth Schmidt, Yaxing Yao, Toby Jia-Jun Li, Tianshi Li","ux professional routinely conduct design review , yet privacy concern be often overlooked—not only limited tool , but more critically low intrinsic motivation . limited privacy knowledge , weak empathy unexpectedly affected user , and low confidence identify harm make difficult to address risk . present privacymotiv , llm-powered system support privacy-oriented design diagnosis generate speculative persona ux user journey center individual vulnerable privacy risk . draw narrative strategy , system construct relatable and attention-drawe scenario show ordinary design choice may cause unintended harm , expand scope privacy reflection ux . within-subjects study professional ux practitioner ( n=16 ) , compare participant ' self-proposed method privacymotiv two privacy review task . result show significant improvement empathy , intrinsic motivation , and perceive usefulness . work contribute promising privacy review approach address motivational barrier privacy-aware ux .",Cryptography and Security,03/10/2025
10.48550/arXiv.2510.03417,nexus : network exploration exploiting unsafe sequences multi-turn llm jailbreaks,"Javad Rafiei Asl, Sidhant Narula, Mohammad Ghasemigol, Eduardo Blanco, Daniel Takabi","large language models ( llms ) have revolutionize natural language processing , yet remain vulnerable jailbreak attacks—particularly multi-turn jailbreak distribute malicious intent benign exchange , thereby bypass alignment mechanism . exist approach often suffer limited exploration adversarial space , rely hand-crafted heuristic , or lack systematic query refinement . propose nexus ( network exploration exploiting unsafe sequences ) , modular framework constructing , refining , and execute optimize multi-turn attack . nexus comprise : ( 1 ) thoughtnet , hierarchically expand harmful intent structured semantic network topic , entity , and query chain ; ( 2 ) feedback-driven simulator iteratively refine and prune chain attacker–victim–judge llm collaboration use harmfulness and semantic-similarity benchmark ; and ( 3 ) network traverser adaptively navigate refined query space real-time attack . pipeline systematically uncover stealthy , high-success adversarial path llms . experimental result several closed-source and open-source llms show nexus can achieve high attack success rate , 2 . 1 % and 19 . 4 % , compare state-of-the-art approach . source code be available github.com/inspire-lab/nexus .",Cryptography and Security,03/10/2025
10.48550/arXiv.2510.03407,security analysis and threat modeling research management applications [ extended version ],"Boniface M. Sindala, Ragib Hasan","research management application ( rma ) be widely use clinical research environment to collect , transmit , analyze , and store sensitive datum . data be so valuable make rma susceptible security threat . analysis , analyze rma ' security , focus research electronic data capture ( redcap ) example . explore strength and vulnerability rma evaluate architecture , datum flow , and security feature . identify and assess potential risk use mitre att&ck framework and stride model . assess redcap ’s defense common attack vector focus security to provide confidentiality , integrity , availability , non-repudiation , and authentication . conclude propose recommendation enhance security rma , ensure critical research datum remains protect compromise usability . research aim to contribute more secure framework manage sensitive information research-intensive environment .",Cryptography and Security,03/10/2025
10.48550/arXiv.2510.03320,"attack logic , not output : efficient robustification deep neural network falsify concept-based property","Raik Dankworth, Gesina Schwalbe","deep neural network ( nn ) computer vision be vulnerable adversarial attack , i.e. , miniscule malicious change input may induce unintuitive output . one key approach to verify and mitigate such robustness issue be to falsify expect output behavior . allow , e.g. , locally proof security , or to ( re)train nn obtain adversarial input example . black-box nature nn , current attack only falsify class final output , such flip stop_sign ¬stop_sign\neg\text{{stop\_sign } } . short position paper generalize to search generally illogical behavior , consider nn verification : falsify constraint ( concept-based property ) involve further human-interpretable concept , red∧octogonal→stop_sign\text{{red}}\wedge\text{{octogonal}}\rightarrow\text{{stop\_sign } } . , easy implementation concept-based property already train nn be propose use technique explainable artificial intelligence . far , sketch theoretical proof attack concept-based property be expect to have reduce search space compare simple class falsification , arguably be more align intuitive robustness target . outlook work progress hypothesize approach have potential to efficiently and simultaneously improve logical compliance and robustness .",Cryptography and Security,01/10/2025
10.48550/arXiv.2510.03319,svdefense : effective defense gradient inversion attacks singular value decomposition,"Chenxiang Luo, David K.Y. Yau, Qun Song","federated learning ( fl ) enable collaborative model training share raw datum but be vulnerable gradient inversion attack ( gia ) , adversary reconstruct private datum share gradient . exist defense either incur impractical computational overhead embed platform or fail to achieve privacy protection and good model utility same time . moreover , many defense can be easily bypass adaptive adversary have obtain defense detail . to address limitation , propose svdefense , novel defense framework gia leverage truncated singular value decomposition ( svd ) to obfuscate gradient update . svdefense introduce three key innovation , self-adaptive energy threshold adapt client vulnerability , channel-wise weighted approximation selectively preserve essential gradient information effective model training enhance privacy protection , and layer-wise weighted aggregation effective model aggregation class imbalance . extensive evaluation show svdefense outperform exist defense multiple application , include image classification , human activity recognition , and keyword spotting , offer robust privacy protection minimal impact model accuracy . furthermore , svdefense be practical deployment various resource-constrained embed platform . will make code publicly available paper acceptance .",Cryptography and Security,01/10/2025
10.48550/arXiv.2510.05068,multi-agent distribute optimization feasible set privacy,"Shreya Meel, Sennur Ulukus","consider problem decentralize constrained optimization multiple agent e1 , … , ene_{1} , \ldot , e_{n } jointly wish to learn optimal solution set keep feasible set 𝒫1 , … , 𝒫n\mathcal{p}_{1} , \ldot , \mathcal{p}_{n } private other . assume objective function ff be know agent and feasible set be collection point universal alphabet 𝒫a​l​p​h\mathcal{p}_{alph } . designated agent ( leader ) start communication remain ( non-leader ) agent , and be first to retrieve solution set . leader search solution send query and receive answer non-leader , such information individual feasible set reveal leader should be more nominal , i.e. , be reveal learn solution set alone . develop achievable scheme obtain solution set nominal information leakage , and characterize communication cost two communication setup agent . work , focus two kind network setup : i ) ring , agent communicate two adjacent agent , and ii ) star , only leader communicate remain agent . show , leader first learn joint feasible set exist private set intersection ( psi ) protocol and then deduce solution set , information leak leader be great nominal . moreover , draw connection scheme to threshold psi ( thpsi ) , be psi-variant intersection be reveal only cardinality be large threshold value . finally , various realization ff map uniformly random fix range value , scheme be more communication-efficient high probability compare retrieve entire feasible set psi .",Cryptography and Security,06/10/2025
10.48550/arXiv.2510.05028,"cryptography and distribution verification , application quantum advantage","Bruno Cavalar, Eli Goldin, Matthew Gray, Taiga Hiroka, Tomoyuki Morimae","one most fundamental problem field hypothesis testing be identity testing problem : sample unknown distribution 𝒢\mathcal{g } be actually explicit distribution 𝒟\mathcal{d } . be know distribution 𝒟\mathcal{d } have support [ n][n ] , optimal sample complexity identity testing problem be roughly } ) . however , many distribution interest , include can be sample efficiently , have exponential support size , and therefore optimal identity tester also require exponential sample . paper , bypass lower bind consider restrict setting . } ) sample complexity identity tester be construct be not fool ( even inefficiently-sampled ) distribution . however , most application , distribution consideration be efficiently sampleable , and therefore be enough to consider only identity tester be not fool efficiently-sampled distribution . case , can focus efficient verification efficient identity tester . investigate relation efficient verification classical/quantum distribution and classical/quantum cryptography , and show follow result .",Cryptography and Security,06/10/2025
10.48550/arXiv.2510.05025,imperceptible jailbreaking large language model,"Kuofeng Gao, Yiming Li, Chao Du, Xin Wang, Xingjun Ma, Shu-Tao Xia, Tianyu Pang","jailbreake attack vision modality typically rely imperceptible adversarial perturbation , attack textual modality be generally assume to require visible modification ( e.g. , non-semantic suffix ) . paper , introduce imperceptible jailbreak exploit class unicode character call variation selector . append invisible variation selector malicious question , jailbreak prompt appear visually identical original malicious question screen , tokenization be "" secretly "" alter . propose chain-of-search pipeline to generate such adversarial suffix to induce harmful response . experiment show imperceptible jailbreak achieve high attack success rate four align llm and generalize prompt injection attack , all produce visible modification write prompt . code be available https://github.com/sail-sg/imperceptible-jailbreak .",Cryptography and Security,06/10/2025
10.48550/arXiv.2510.04979,federated computation roc and pr curve,"Xuefeng Xu, Graham Cormode","receiver operate characteristic ( roc ) and precision-recall ( pr ) curve be fundamental tool evaluate machine learn classifier , offer detailed insight trade-off true positive rate false positive rate ( roc ) or precision recall ( pr ) . however , federated learning ( fl ) scenario , datum be distribute multiple client , compute curve be challenge privacy and communication constraint . specifically , server can not access raw prediction score and class label , be use to compute roc and pr curve centralized setting . paper , propose novel method approximate roc and pr curve federate setting estimate quantile prediction score distribution distribute differential privacy . provide theoretical bound area error ( ae ) true and estimated curve , demonstrate trade-off approximation accuracy , privacy , and communication cost . empirical result real-world dataset demonstrate method achieve high approximation accuracy minimal communication and strong privacy guarantee , make practical privacy-preserving model evaluation federate system .",Cryptography and Security,06/10/2025
10.48550/arXiv.2510.04465,autonomy matter : study personalization-privacy dilemma llm agents,"Zhiping Zhang, Yi Evie Zhang, Freda Shi, Tianshi Li","large language model ( llm ) agent require personal information personalization order to well act user ' behalf daily task , but raise privacy concern and personalization-privacy dilemma . agent ’s autonomy introduce risk and opportunity , yet effect remain unclear . to well understand , conduct 3×\times3 between-subjects experiment ( n=450n=450 ) to study agent ’s autonomy level and personalization influence user ' privacy concern , trust and willingness to use , as well underlie psychological process . find personalization consider user ' privacy preference increase privacy concern and decrease trust and willingness to use . autonomy moderate effect : intermediate autonomy flatten impact personalization compare no- and full-autonomy condition . result suggest rather aim perfect model alignment output generation , balance autonomy agent ’s action and user control offer promising path to mitigate personalization-privacy dilemma .",Cryptography and Security,06/10/2025
10.48550/arXiv.2510.04448,quantum cryptography and hardness non-collapsing measurement,"Tomoyuki Morimae, Yuki Shirakawa, Takashi Yamakawa","one-way puzzle ( owpuzzs ) introduce khurana and tomer [ stoc 2024 ] be natural quantum analogue one-way function ( owf ) , and one most fundamental primitive "" microcrypt "" owf do not exist but quantum cryptography be possible . owpuzz be imply almost quantum cryptographic primitive , and imply several important application such non-interactive commitment and multi-party computation . significant goal field quantum cryptography be to base owpuzz plausible assumption will not imply owf . paper , base owpuzz hardness non-collapsing measurement . end , introduce new complexity class , 𝐒𝐚𝐦𝐩𝐏𝐃𝐐𝐏\mathbf{samppdqp } , be sample version decision class 𝐏𝐃𝐐𝐏\mathbf{pdqp } introduce [ aaronson , bouland , fitzsimons , and lee , itcs 2016 ] . show 𝐒𝐚𝐦𝐩𝐏𝐃𝐐𝐏\mathbf{samppdqp } be hard average quantum polynomial time , then owpuzz exist . also show 𝐒𝐚𝐦𝐩𝐏𝐃𝐐𝐏⊈𝐒𝐚𝐦𝐩𝐁𝐐𝐏\mathbf{samppdqp}\not\subseteq\mathbf{sampbqp } , then auxiliary-input owpuzz exist . 𝐒𝐚𝐦𝐩𝐏𝐃𝐐𝐏\mathbf{samppdqp } be class sampling problem can be solve classical polynomial-time deterministic algorithm can make single query non-collapsing measurement oracle , be "" magical "" oracle can sample measurement result quantum state collapse state . such non-collapsing measurement be highly unphysical operation should be hard to realize quantum polynomial-time , and therefore assumption owpuzz be base seem extremely plausible . moreover , assumption do not seem to imply owf , possibility invert classical function would not be helpful to realize quantum non-collapsing measurement . also study upperbound hardness 𝐒𝐚𝐦𝐩𝐏𝐃𝐐𝐏\mathbf{samppdqp } . introduce new primitive , distributional collision-resistant puzzle ( dcrpuzz ) , be natural quantum analogue distributional collision-resistant hashing [ dubrov and ishai , stoc 2006 ] . show dcrpuzz imply average-case hardness 𝐒𝐚𝐦𝐩𝐏𝐃𝐐𝐏\mathbf{samppdqp } ( and therefore owpuzz as well ) . also show two-message honest-statistically-hiding commitment classical communication and one-shot message authentication code ( macs ) , be privately-verifiable version one-shot signature [ amos , georgiou , kiayias , zhandry , stoc 2020 ] , imply dcrpuzz .",Cryptography and Security,06/10/2025
10.48550/arXiv.2510.04159,proof quantum memory,"Minki Hhan, Tomoyuki Morimae, Yasuaki Okinaka, Takashi Yamakawa","rapid advance quantum computer architecture and emerge prospect large-scale quantum memory , be become essential to classically verify remote device genuinely allocate promise quantum memory specify number qubit and coherence time . paper , introduce new concept , proof quantum memory ( poqm ) . poqm be interactive protocol classical probabilistic polynomial-time ( ppt ) verifier and quantum polynomial-time ( qpt ) prover classical channel verifier can verify prover have possess quantum memory certain number qubit specified period time . poqm generalize notion proof quantumness ( poq ) [ brakerski , christiano , mahadev , vazirani , and vidick , jacm 2021 ] . main contribution be formal definition poqm and construction base hardness lwe . specifically , give two construction poqm . first be four-round and have negligible soundness error subexponential-hardness lwe . second be polynomial-round and have inverse-polynomial soundness error polynomial-hardness lwe . lowerbound poqm , also show poqm imply one-way puzzle . moreover , certain restrict version poqm imply quantum computation classical communication ( qccc ) key exchange .",Cryptography and Security,05/10/2025
10.48550/arXiv.2510.04027,multi-class support vector machine differential privacy,"Jinseong Park, Yujin Choi, Jaewook Lee","increase need to safeguard datum privacy machine learning model , differential privacy ( dp ) be one major framework to build privacy-preserving model . support vector machines ( svms ) be widely use traditional machine learning model robust margin guarantee and strong empirical performance binary classification . however , apply dp multi-class svms be inadequate , standard one-versus-rest ( ovr ) and one-versus-one ( ovo ) approach repeatedly query datum sample build multiple binary classifier , thus consume privacy budget proportionally number class . to overcome limitation , explore all-in-one svm approach dp , access datum sample only once to construct multi-class svm boundary margin maximization property . propose novel differentially private multi-class svm ( pmsvm ) weight and gradient perturbation method , provide rigorous sensitivity and convergence analysis to ensure dp all-in-one svm . empirical result demonstrate approach surpass exist dp-svm method multi-class scenario .",Cryptography and Security,05/10/2025
10.48550/arXiv.2510.03969,quantifying risk multi-turn conversation large language model,"Chengxiao Wang, Isha Chaudhary, Qian Hu, Weitong Ruan, Rahul Gupta, Gagandeep Singh",warn : paper may contain harmful model output .,Cryptography and Security,04/10/2025
10.48550/arXiv.2510.03636,theory practice : evaluate data poisoning attacks and defense in-context learning social media health discourse,"Rabeya Amin Jhuma, Mostafa Mohaimen Akand Faisal","study explore context learning ( icl ) large language model can be disrupt datum poisoning attack setting public health sentiment analysis . use tweet human metapneumovirus ( hmpv ) , small adversarial perturbation such synonym replacement , negation insertion , and randomize perturbation be introduce support example . even minor manipulation cause major disruption , sentiment label flip to 67 % case . to address , spectral signature defense be apply , filter poison example keep datum ’s meaning and sentiment intact . defense , icl accuracy remain steady 46 . 7 % , and logistic regression validation reach 100 % accuracy , show defense successfully preserve dataset ’s integrity . overall , finding extend prior theoretical study icl poisoning practical , high stake set public health discourse analysis , highlight risk and potential defense robust llm deployment . study also highlight fragility icl attack and value spectral defense make ai system more reliable health relate social medium monitoring .",Cryptography and Security,04/10/2025
10.48550/arXiv.2510.03612,cross-modal content optimization steering web agent preference,"Tanqiu Jiang, Min Bai, Nikolaos Pappas, Yanjun Qi, Sandesh Swamy","vision–language model ( vlm)-base web agent increasingly power high-stakes selection task content recommendation or product rank combine multimodal perception preference reasoning . recent study reveal agent be vulnerable attacker can bias selection outcome preference manipulation use adversarial pop-up , image perturbation , or content tweak . exist work , however , either assume strong white-box access , limited single-modal perturbation , or use impractical setting . paper , demonstrate , first time , joint exploitation visual and textual channel yield significantly more powerful preference manipulation realistic attacker capability . introduce cross-modal preference steering ( cps ) jointly optimize imperceptible modification item ’s visual and natural language description , exploit clip-transferable image perturbation and rlhf-induced linguistic bias to steer agent decision . contrast prior study assume gradient access , or control webpage , or agent memory , adopt realistic black-box threat setup : non-privileged adversary can edit only own listing ’s image and textual metadata , insight agent ’s model internal . evaluate cps agent power state-of-the-art proprietary and open source vlm include gpt-4 . 1 , qwen-2 . 5vl and pixtral-large movie selection and e-commerce task . result show cps be significantly more effective lead baseline method . instance , result show cps consistently outperform baseline model maintain 70 % low detection rate , demonstrate effectiveness and stealth . finding highlight urgent need robust defense agentic system play increasingly consequential role society .",Cryptography and Security,04/10/2025
10.48550/arXiv.2510.03567,machine unlearning meet adversarial robustness constrained interventions llms,"Fatmazohra Rezkellah, Ramzi Dakhmouche","increase adoption large language models ( llms ) , more customization be need to ensure privacy-preserving and safe generation . address objective two critical aspect : unlearning sensitive information and robustness jail-breaking attack . investigate various constrain optimization formulation address aspect unified manner , find small possible intervention llm weight either make give vocabulary set unreachable or embe llm robustness tailor attack shift part weight safe region . unify two key property , approach contrast previous work do not require oracle classifier be typically not available or represent computational overhead . surprisingly , find simple point-wise constraint-based intervention propose lead well performance max-min intervention , have low computational cost . comparison state-of-the-art defense method demonstrate superior performance propose approach .",Cryptography and Security,03/10/2025
10.48550/arXiv.2510.03513,lightweight federated learning approach privacy-preserve botnet detection iot,"Taha M. Mahmoud, Naima Kaabouch","rapid growth internet thing ( iot ) have expand opportunity innovation but also increase exposure botnet-driven cyberattack . conventional detection method often struggle scalability , privacy , and adaptability resource-constrained iot environment . to address challenge , present lightweight and privacy-preserving botnet detection framework base federate learning . approach enable distribute device to collaboratively train model exchange raw datum , thus maintain user privacy preserve detection accuracy . communication-efficient aggregation strategy be introduce to reduce overhead , ensure suitability constrained iot network . experiment benchmark iot botnet dataset demonstrate framework achieve high detection accuracy substantially reduce communication cost . finding highlight federate learning practical path scalable , secure , and privacy-aware intrusion detection iot ecosystem .",Cryptography and Security,03/10/2025
10.48550/arXiv.2510.03489,"quantum-secure voting framework use qkd , dual-key symmetric encryption , and verifiable receipts","Taha M. Mahmoud, Naima Kaabouch","electronic voting system face grow risk cyberattack and data breach , be expect to intensify advent quantum computing . to address challenge , introduce quantum-secure voting framework integrate quantum key distribution ( qkd ) , dual-key symmetric encryption , and verifiable receipt mechanism to strengthen privacy , integrity , and reliability voting process . framework enable voter to establish encryption key securely , cast encrypt ballot , and verify vote receipt-based confirmation , all expose vote content . to evaluate performance , simulate both quantum and classical communication channel use message queuing telemetry transport ( mqtt ) protocol . result demonstrate system can process large number vote efficiently low latency and minimal error rate . approach offer scalable and practical path secure , transparent , and verifiable electronic voting quantum era .",Cryptography and Security,03/10/2025
10.48550/arXiv.2510.03461,repair leaks resource wrappers,"Sanjay Malakar, Michael D. Ernst, Martin Kellogg, Manu Sridharan","resource leak occur program fail to release finite resource socket , file descriptor or database connection . sound static analysis tool can detect leak , automatically repair remain challenge . prior work take output detection tool and attempt to repair only leak hard-coded list library resource type . approach limit scope repairable leak : real-world code use resource wrapper store resource field and must be close .",Cryptography and Security,03/10/2025
10.48550/arXiv.2510.03405,legalsim : multi-agent simulation legal systems discovering procedural exploits,Sanket Badhe,"present legalsim , modular multi-agent simulation adversarial legal proceeding explore ai system can exploit procedural weakness codify rule . plaintiff and defendant agent choose constrain action space ( example , discovery request , motion , meet-and-conf , sanction ) govern json rule engine , stochastic judge model calibrate grant rate , cost allocation , and sanction tendency resolve outcome . compare four policy : ppo , contextual bandit llm , direct llm policy , and hand-crafted heuristic ; instead optimize binary case outcome , agent be train and evaluate use effective win rate and composite exploit score combine opponent-cost inflation , calendar pressure , settlement pressure low merit , and rule-compliance margin . configurable regime ( e.g. , bankruptcy stay , inter partes review , tax procedure ) and heterogeneous judge , observe emergent "" exploit chain "" , such cost-inflating discovery sequence and calendar-pressure tactic remain procedurally valid yet systemically harmful . evaluation cross-play and bradley-terry rating show , ppo win more often , bandit be most consistently competitive opponent , llm trail , and heuristic be weak . result be stable judge setting , and simulation reveal emergent exploit chain , motivate red-teame legal rule system addition model-level testing .",Cryptography and Security,03/10/2025
10.48550/arXiv.2510.03285,warex : web agent reliability evaluation exist benchmark,"Su Kara, Fazle Faisal, Suman Nath","recent advance browser-based llm agent have show promise automate task range simple form fill hotel booking or online shopping . current benchmark measure agent performance control environment , such container or stable network , website behave deterministically . however , real world , user access website network and https connection introduce instability multiple source : client-side , server-side issue or broad system failure . moreover , live website be prone web attack such cross-site scripting , as well general site modification can cause unexpected or malicious pop-up or improper functionality . to address gap , present warex111web agent reliability evaluation existing benchmark . name u . s . army ’s warriorexercise ( warex ) , immerse military unit realistic combat scenario to prepare deployment . , plug-and-play tool integrate exist web agent benchmark simulate common website failure . measure impact warex three popular benchmark : webarena , webvoyager , and real . experiment show introduce warex lead significant drop task success rate , highlight limited robustness state-of-the-art agent .",Cryptography and Security,28/09/2025
10.48550/arXiv.2510.03254,adversarial training restricted datum manipulation,"David Benfield, Stefano Coniglio, Phan Tu Vuong, Alain Zemkoho","adversarial machine learn concern situation learner face attack active adversary . such scenario arise application such spam email filtering , malware detection and fake-image generation , security method must be actively update to keep ever-improving generation malicious datum . pessimistic bilevel optimisation have be show to be effective method train resilient classifier such adversary . model scenario game learner and adversary , anticipate adversary will modify datum and then train resilient classifier accordingly . however , exist pessimistic bilevel approach feature unrestricted adversary , model be vulnerable become overly pessimistic and unrealistic . find optimal solution defeat classifier , ’ possible adversary ’s datum become nonsensical and lose intended nature . adversary will not properly reflect reality , and consequently , will lead poor classifier performance implement real-world datum . construct constrain pessimistic bilevel optimisation model , restrict adversary ’s movement and identify solution well reflect reality . demonstrate experiment model perform , average , well exist approach .",Cryptography and Security,26/09/2025
10.48550/arXiv.2510.03219,tpm-base continuous remote attestation and integrity verification 5 g vnf kubernete,"Al Nahian Bin Emran, Rajendra Upadhyay, Rajendra Paudyal, Lisa Donnan, Duminda Wijesekera","rapidly evolve landscape 5 g technology , adoption cloud-based infrastructure deployment 5 g service have become increasingly common . use service-based architecture , critical 5 g component , such access and mobility management function ( amf ) , session management function ( smf ) , and user plane function ( upf ) , now run containerize pod kubernetes cluster . approach improve scalability , flexibility , and resilience , also introduce new security challenge , particularly to ensure integrity and trustworthiness component . current 5 g security specification ( example , 3gpp ts 33 . 501 [ 1 ] ) focus communication security and assume network function remain trustworthy authentication , consequently lack mechanism to continuously validate integrity nvf runtime . to close gap , and to align zero trust principle "" never trust , always verify "" , present tpm 2 . 0-based continuous remote attestation solution core 5 g component deploy kubernetes . approach use linux integrity measurement architecture ( ima ) and trusted platform module ( tpm ) to provide hardware-based runtime validation . integrate open-source keylime framework ( natively provide node-level attestation ) custom ima template isolate pod-level measurement , allow per-pod integrity verification [ 2 ] . prototype k3s cluster [ 3 ] ( lightweight cncf-certified kubernetes distribution consist 1 master , 2 worker node ) be implement to attest core function , include amf , smf and upf . experimental result show system detect unauthorized modification real time , label pod ’s trust state , and generate detailed audit log . work provide hardware-based continuous attestation cloud native and edge deployment , strengthen resilience 5 g critical infrastructure multi-vendor and mission-critical scenario 5g .",Cryptography and Security,03/10/2025
10.48550/arXiv.2510.03035,protect persona biometric data : case facial privacy,"Lambert Hogenhout, Rinzin Wangmo",nan,Cryptography and Security,03/10/2025
10.48550/arXiv.2510.02999,untargeted jailbreak attack,"Xinzhe Huang, Wenjing Hu, Tianhang Zheng, Kedong Xiu, Xiaojun Jia, Di Wang, Zhan Qin, Kui Ren","exist gradient-based jailbreak attack large language models ( llms ) , such greedy coordinate gradient ( gcg ) and cold-attack , typically optimize adversarial suffix to align llm output predefine target response . however , restrict optimization objective induce predefine target , method inherently constrain adversarial search space , limit overall attack efficacy . furthermore , exist method typically require large number optimization iteration to fulfill large gap fix target and original model response , result low attack efficiency .",Cryptography and Security,03/10/2025
10.48550/arXiv.2510.02964,external data extraction attacks retrieval-augmented large language model,"Yu He, Yifei Chen, Yiming Li, Shuo Shao, Leyi Qi, Boheng Li, Dacheng Tao, Zhan Qin","recent year , retrieval-augmented generation ( rag ) have emerge key paradigm enhance large language model ( llms ) . integrate externally retrieve information , rag alleviate issue outdated knowledge and , crucially , insufficient domain expertise . effective , rag introduce new risk external data extraction attack ( edea ) , sensitive or copyright datum knowledge base may be extract verbatim adversary . risk be particularly acute rag be use to customize specialized llm application private knowledge basis . initial study explore risk , often lack formalize framework , robust attack performance , and comprehensive evaluation , leave critical question real-world edea feasibility unanswered .",Cryptography and Security,03/10/2025
10.48550/arXiv.2510.02947,sok : preconfirmation,"Aikaterini-Panagiota Stouka, Conor McMenamin, Demetris Kyriacou, Lin Oshitani, Quentin Botha","recent year , significant research effort have focus improve blockchain throughput and confirmation speed compromise security . decrease time take transaction to be include blockchain ledger enhance user experience , fundamental delay still remain transaction be issue user and inclusion be confirm blockchain ledger . delay limit user experience gain confirmation uncertainty bring user . inherent delay conventional blockchain protocol have lead emergence preconfirmation protocol – protocol provide user early guarantee eventual transaction confirmation .",Cryptography and Security,03/10/2025
10.48550/arXiv.2510.02944,improve search-to-decision reduction random local functions,"Kel Zin Tan, Prashant Nalini Vasudevan","random local function define dd-ary predicate pp be one output bit be compute apply pp to dd randomly choose bit input . represent natural distribution instance constraint satisfaction problem . be put forward goldreich [ gol11 ] candidate low-complexity one-way function , and have subsequently be widely study also potential pseudo-random generator .",Cryptography and Security,03/10/2025
10.48550/arXiv.2510.02833,attack overfitting : 10-shot benign fine-tuning jailbreak llms,"Zhixin Xie, Xurui Song, Jun Luo","substantial effort safety alignment , recent research indicate large language models ( llms ) remain highly susceptible jailbreak attack . attack , finetuning-based one compromise llms ' safety alignment fine-tune stand stable jailbreak performance . particular , recent study indicate fine-tune as few 10 harmful question-answer ( qa ) pair can lead successful jailbreake various harmful question . however , such malicious fine-tuning attack be readily detectable and hence thwart moderation model . paper , demonstrate llms can be jailbroken fine-tune only 10 benign qa pair ; attack exploit increase sensitivity llms fine-tune datum be overfitte . specifically , fine-tuning process start overfitte llm fine-tune benign qa pair involve identical refusal answer . further fine-tuning be then perform standard benign answer , cause overfitte llm to forget refusal attitude and thus provide compliant answer regardless harmfulness question . implement attack ten llms and compare five exist baseline . experiment demonstrate method achieve significant advantage attack effectiveness and attack stealth . finding expose previously unreported security vulnerability current llm and provide new perspective understand llms ' security be compromise , even benign fine-tuning . code be available https://github.com/zhixinxie/ten_benign.git .",Cryptography and Security,03/10/2025
10.48550/arXiv.2510.02707,statistical method attack-agnostic adversarial attack detection compressive sensing comparison,"Chinthana Wimalasuriya, Spyros Tragoudas","adversarial attack present significant threat modern machine learning system . yet , exist detection method often lack ability to detect unseen attack or detect different attack type high level accuracy . work , propose statistical approach establish detection baseline neural network ’s deployment , enable effective real-time adversarial detection . generate metric adversarial presence compare behavior compressed/uncompresse neural network pair . method have be test state-of-the-art technique , and achieve near-perfect detection wide range attack type . moreover , significantly reduce false positive , make both reliable and practical real-world application .",Cryptography and Security,03/10/2025
10.48550/arXiv.2510.02694,malf : multi-agent llm framework intelligent fuzzing industrial control protocols,"Bowei Ning, Xuejun Zong, Kan He","industrial control system ( ics ) be vital modern infrastructure but increasingly vulnerable cybersecurity threat , particularly weakness communication protocol . paper present malf ( multi-agent llm fuzzing framework ) , advanced fuzzing solution integrate large language model ( llms ) multi-agent coordination to identify vulnerability industrial control protocol ( icps ) . leverage retrieval-augmented generation ( rag ) domain-specific knowledge and qlora fine-tune protocol-aware input generation , malf enhance fuzz testing precision and adaptability . multi-agent framework optimize seed generation , mutation strategy , and feedback-driven refinement , lead improved vulnerability discovery . experiment protocol modbus/tcp , s7comm , and ethernet/ip demonstrate malf surpass traditional method , achieve test case pass rate ( tcpr ) 88–92 % and generate more exception trigger ( etn ) . malf also maintain 90 % seed coverage and shannon entropy value 4 . 2 and 4 . 6 bit , ensure diverse , protocol-compliant mutation . deploy real-world industrial attack-defense range power plant , malf identify critical vulnerability , include three zero-day flaw , confirm and register cnvd . result validate malf ’s effectiveness real-world fuzzing application . research highlight transformative potential multi-agent llm ics cybersecurity , offer scalable , automate framework set new standard vulnerability discovery and strengthen critical infrastructure security emerge threat .",Cryptography and Security,03/10/2025
10.48550/arXiv.2510.02643,use preformed resistive random access memory to create strong physically unclonable function,"Jack Garrard, John F. Hardy II, Carlo daCunha, Mayank Bakshi","physically unclonable functions ( pufs ) be promising solution identity verification and asymmetric encryption . paper , new resistive random access memory ( reram ) puf-base protocol be present to create physical reram puf large challenge space . protocol use differential read unformed reram method response generation . lastly , paper also provide experimental hardware demonstration protocol physical reram device , provide notable result puf , excellent performance characteristic .",Cryptography and Security,03/10/2025
10.48550/arXiv.2510.02563,be wear ? ear canal biometric key extraction user authentication wireless earbuds,"Chenpei Huang, Lingfeng Yao, Hui Zhong, Kyu In Lee, Lan Zhang, Xiaoyong Yuan, Tomoaki Ohtsuki, Miao Pan","ear canal scanning/sense ( ecs ) have emerge novel biometric authentication method mobile device pair wireless earbud . exist study have demonstrate uniqueness ear canal training and test machine learn classifier ecs datum . however , implement practical ecs-based authentication require prevent raw biometric datum leakage and design computationally efficient protocol suitable resource-constrained earbud . to address challenge , propose ear canal key extraction protocol , earid . rely classifier , earid extract unique binary key directly earbud authentication . key far allow use privacy-preserve fuzzy commitment scheme verify wearer ’s key mobile device . evaluation result demonstrate earid achieve 98 . 7 % authentication accuracy , comparable machine learning classifier . mobile enrollment time ( 160 ms ) and earbud processing time ( 226 ms ) be negligible term wearer ’s experience . moreover , approach be robust and attack-resistant , maintain false acceptance rate 1 % adversarial scenario . believe propose earid offer practical and secure solution next-generation wireless earbuds .",Cryptography and Security,02/10/2025
10.48550/arXiv.2510.02554,tooltweak : attack tool selection llm-based agent,"Jonathan Sneh, Ruomei Yan, Jialin Yu, Philip Torr, Yarin Gal, Sunando Sengupta, Eric Sommerlade, Alasdair Paren, Adel Bibi","llm increasingly power agent interact external tool , tool use have become essential mechanism extend capability . agent typically select tool grow database or marketplace to solve user task , create implicit competition tool provider and developer visibility and usage . paper , show selection process harbor critical vulnerability : iteratively manipulate tool name and description , adversary can systematically bias agent select specific tool , gain unfair advantage equally capable alternative . present tooltweak , lightweight automatic attack increase selection rate baseline 20 % as high 81 % , strong transferability open-source and closed-source model . individual tool , show such attack cause distributional shift tool usage , reveal risk fairness , competition , and security emerge tool ecosystem . to mitigate risk , evaluate two defense : paraphrasing and perplexity filtering , reduce bias and lead agent to select functionally similar tool more equally . code will be open-sourced acceptance .",Cryptography and Security,02/10/2025
10.48550/arXiv.2510.02519,tlora : implement tls lora secure http communication iot,"Atonu Ghosh, Akhilesh Mohanasundaram, Srishivanth R F, Sudip Misra","present tlora , end-to-end architecture https communication lora integrate tcp tunneling and complete tls 1 . 3 handshake . enable seamless and secure communication channel wifi-enable end device and internet lora use end hub ( eh ) and net relay ( nr ) . eh tether wifi hotspot and captive portal user device to connect and request url . eh forward request url nr use secure tunnel lora . nr , act server-side proxy , receive and resolve request internet-based server . then relay back encrypt response server same secure tunnel . tlora operate three phase setup , secure tunneling , and render . first phase , manage tcp socket and initiate tls handshake . second , create secure tunnel and transfer encrypt tls datum lora . finally , deliver url content user . tlora also implement lightweight tls record reassembly layer and queue mechanism session multiplexing . evaluate tlora real hardware use multiple access web api . result indicate provide practical solution successfully establish tls session lora 9 . 9 second and take 3 . 58 second to fulfill api request . good knowledge , be first work to comprehensively design , implement , and evaluate performance https access lora use full tls .",Cryptography and Security,02/10/2025
10.48550/arXiv.2510.02475,rigorous evaluation microarchitectural side-channels statistical model checking,"Weihang Li, Pete Crowley, Arya Tschand, Yu Wang, Miroslav Pajic, Daniel Sorin","rigorous quantitative evaluation microarchitectural side channel be challenge two reason . first , processor , attack , and defense often exhibit probabilistic behavior . probabilistic behavior arise natural noise system ( e.g. , co-running process ) , probabilistic side channel attack , and probabilistic obfuscation defense . second , microprocessor be extremely complex . previous evaluation method have rely abstract or simplified model , be necessarily less detailed real system or cycle-by-cycle simulator , and model may miss important phenomenon . simple model may suffice estimate performance , security issue frequently manifest detail .",Cryptography and Security,02/10/2025
10.48550/arXiv.2510.02424,adaptive deception framework behavioral analysis enhanced cybersecurity defense,Basil Abdullah AL-Zahrani,"paper present cadl ( cognitive-adaptive deception layer ) , adaptive deception framework achieve 99 . 88 % detection rate 0 . 13 % false positive rate cicids2017 dataset . framework employ ensemble machine learning ( random forest , xgboost , neural networks ) combine behavioral profiling to identify and adapt response network intrusion . coordinate signal bus architecture , security component share real-time intelligence , enable collective decision-making . system profile attacker base temporal pattern and deploy customize deception strategy five escalation level . evaluation 50 , 000 cicids2017 test sample demonstrate cadl significantly outperform traditional intrusion detection system ( snort : 71 . 2 % , suricata : 68 . 5 % ) maintain production-ready false positive rate . framework ’s behavioral analysis achieve 89 % accuracy classify attacker profile . provide open-source implementation and transparent performance metric , offer accessible alternative commercial deception platform cost $ 150-400 host annually .",Cryptography and Security,02/10/2025
10.48550/arXiv.2510.02422,dynamic target attack,"Kedong Xiu, Churui Zeng, Tianhang Zheng, Xinzhe Huang, Xiaojun Jia, Di Wang, Puning Zhao, Zhan Qin, Kui Ren","exist gradient-based jailbreak attack typically optimize adversarial suffix to induce fix affirmative response , e.g. , "" sure , here be … "" . however , fix target usually reside extremely low-density region safety-aligned llm ’s output distribution condition diverse harmful input . substantial discrepancy target and original output , exist attack require numerous iteration to optimize adversarial prompt , might still fail to induce low-probability target response target llm . paper , propose dynamic target attack ( dta ) , new jailbreake framework rely target llm ’s own response target to optimize adversarial prompt . optimization round , dta iteratively sample multiple candidate response directly output distribution condition current prompt , and select most harmful response temporary target prompt optimization . contrast exist attack , dta significantly reduce discrepancy target and output distribution , substantially ease optimization process to search effective adversarial prompt .",Cryptography and Security,02/10/2025
10.48550/arXiv.2510.02395,polylink : blockchain base decentralized edge ai platform llm inference,"Hongbo Liu, Jiannong Cao, Bo Yang, Dongbin Bai, Yinfeng Cao, Xiaoming Shen, Yinan Zhang, Jinwen Liang, Shan Jiang, Mingjin Zhang","rapid advancement large language model ( llms ) recent year have revolutionize ai landscape . however , deployment model and usage llm service remain highly centralized , create significant trust issue and cost end user and developer . to address issue , propose polylink , blockchain-based decentralize ai platform decentralize llm development and inference . specifically , polylink introduce decentralized crowdsourcing architecture support single-device and cross-device model deployment and inference heterogeneous device edge . moreover , to ensure inference integrity , design tiqe protocol , combine lightweight cross-encoder model and llm-as-a-judge high-accuracy inference evaluation . lastly , integrate comprehensive token-based incentive model dynamic pricing and reward mechanism participant . have deploy polylink and conduct extensive real-world evaluation geo-distributed deployment heterogeneous device . result indicate inference and verification latency be practical . security analysis demonstrate system be resistant to model degradation attack and validator corruption . polylink be now available https://github.com/imcl-polylink/polylink .",Cryptography and Security,01/10/2025
10.48550/arXiv.2510.02386,fragility benchmark contamination detection reasoning models,"Han Wang, Haoyu Li, Brian Ko, Huan Zhang","leaderboard large reasoning model ( lrms ) have turn evaluation competition , incentivize developer to optimize directly benchmark suite . shortcut achieve high ranking be to incorporate evaluation benchmark training datum , thereby yield inflated performance , know benchmark contamination . numerous contamination detection approach have be propose , surprisingly , study find evade contamination detection lrms be alarmingly easy . focus two scenario contamination may occur practice : ( i ) base model evolve lrm supervised fine-tuning ( sft ) and reinforcement learning ( rl ) , find contamination sft can be originally identify contamination detection method . yet , even brief group relative policy optimization ( grpo ) training can markedly conceal contamination signal most detection method rely . further empirical experiment and theoretical analysis indicate proximal policy optimization ( ppo ) style importance sampling and clip objective be root cause detection concealment , indicate broad class rl method may inherently exhibit similar concealment capability ; ( ii ) sft contamination cot be apply advanced lrms final stage , most contamination detection method perform random guess . exposure non-member , contaminate lrms would still have more confidence respond unseen sample share similar distribution training set , and thus , evade exist memorization-based detection method . together , finding reveal unique vulnerability lrms evaluation : model developer could easily contaminate lrm to achieve inflated leaderboard performance leave minimal trace contamination , thereby strongly undermine fairness evaluation and threaten integrity public leaderboard . underscore urgent need advanced contamination detection method and trustworthy evaluation protocol tailor lrms . code be available https://github.com/astral-group/lrm_conta_detection_arena.git .",Cryptography and Security,30/09/2025
10.48550/arXiv.2510.02384,secure and robust watermarking ai-generated images : comprehensive survey,"Jie Cao, Qi Li, Zelin Zhang, Jianbing Ni","rapid advancement generative artificial intelligence ( gen-ai ) have facilitate effortless creation high-quality image , simultaneously raise critical concern regard intellectual property protection , authenticity , and accountability . watermarking have emerge promising solution challenge distinguish ai-generate image natural content , ensure provenance , and foster trustworthy digital ecosystem . paper present comprehensive survey current state ai-generate image watermarking , address five key dimension : ( 1 ) formalization image watermarking system ; ( 2 ) overview and comparison diverse watermarking technique ; ( 3 ) evaluation methodology respect visual quality , capacity , and detectability ; ( 4 ) vulnerability malicious attack ; and ( 5 ) prevail challenge and future direction . survey aim to equip researcher holistic understanding ai-generate image watermarking technology , thereby promote continue development .",Cryptography and Security,30/09/2025
10.48550/arXiv.2510.02383,selmer-inspire elliptic curve generation,Awnon Bhowmik,"elliptic curve cryptography ( ecc ) be foundational modern secure communication , yet exist standard curve have face scrutiny opaque parameter-generation practice . work introduce selmer-inspired framework construct elliptic curve be transparent and auditable . draw 22- and 33-descent method , derive binary quartic and ternary cubic classical invariant deterministically yield candidate ( c4 , c6)(c_{4} , c_{6 } ) parameter . local solubility check , model selmer admissibility , filter candidate prior reconciliation short-weierstrass form prime field . then apply establish cryptographic validation , include group-order factorization , cofactor bound , twist security , and embedding-degree heuristic . proof-of-concept implementation demonstrate pipeline function retry-until-success las vegas algorithm , complete transcript enable independent verification . seed-based or purely efficiency-driven design , approach embed arithmetic structure parameter selection remain compatible constant-time , side-channel resistant implementation . work broaden design space elliptic curve , show descent technique arithmetic geometry can underpin trust-enhancing , standardization-ready construction .",Cryptography and Security,30/09/2025
10.48550/arXiv.2510.02378,apply bayes theorem to optimize ivr authentication process,"Jingrong Xie, Yumin Li","paper introduce bayesian approach to improve interactive voice response ( ivr ) authentication process use financial institution . traditional ivr system authenticate user static sequence credential , assume uniform effectiveness . however , fraudster exploit predictability , selectively bypass strong credential . study apply bayes ' theorem and conditional probability modeling to evaluate fraud risk dynamically and adapt credential verification path . simulation experiment use real-world-inspired datum , develop algorithm to identify most effective credential combination give certain condition and propose dynamic selection available credential . finding suggest optimize , adaptive authentication flow balance fraud detection user convenience , provide road map bank to enhance security automate channel .",Cryptography and Security,30/09/2025
10.48550/arXiv.2510.02376,scale homomorphic applications deployment,"Ryan Marinelli, Angelica Chowdhury","endeavor , proof-of-concept homomorphic application be develop to determine production readiness encryption ecosystem . movie recommendation app be implement purpose and productionize containerization and orchestration . tune deployment configuration , computational limitation fully homomorphic encryption ( fhe ) be mitigate additional infrastructure optimization .",Cryptography and Security,30/09/2025
10.48550/arXiv.2510.02374,hybrid captcha combining generative ai keystroke dynamics enhanced bot detection,Ayda Aghaei Nia,"completely automate public ture test to tell computers and humans apart ( captcha ) be foundational component web security , yet traditional implementation suffer trade-off usability and resilience ai-powered bot . paper introduce novel hybrid captcha system synergize cognitive challenge pose large language models ( llms ) behavioral biometric analysis keystroke dynamic . approach generate dynamic , unpredictable question be trivial human but non-trivial automated agent , simultaneously analyze user ’s type rhythm to distinguish human pattern robotic input . present system ’s architecture , formalize feature extraction methodology keystroke analysis , and report experimental evaluation . result indicate dual-layered approach achieve high degree accuracy bot detection , successfully thwart paste-based and script-based simulation attack , maintain high usability score human participant . work demonstrate potential combine cognitive and behavioral test to create new generation more secure and user-friendly captcha .",Cryptography and Security,29/09/2025
10.48550/arXiv.2510.02373,a-memguard : proactive defense framework llm-based agent memory,"Qianshan Wei, Tengchao Yang, Yaochen Wang, Xinfeng Li, Lijun Li, Zhenfei Yin, Yi Zhan, Thorsten Holz, Zhiqiang Lin, XiaoFeng Wang","large language model ( llm ) agent use memory to learn past interaction , enable autonomous planning and decision-make complex environment . however , reliance memory introduce critical security risk : adversary can inject seemingly harmless record agent ’s memory to manipulate future behavior . vulnerability be characterize two core aspect : first , malicious effect inject record be only activate specific context , make hard to detect individual memory entry be audit isolation . second , once trigger , manipulation can initiate self-reinforcing error cycle : corrupted outcome be store precedent , not only amplify initial error but also progressively lower threshold similar attack future . to address challenge , introduce a-memguard ( agent-memory guard ) , first proactive defense framework llm agent memory . core idea work be insight memory must become self-checking and self-correcting . modify agent ’s core architecture , a-memguard combine two mechanism : ( 1 ) consensus-based validation , detect anomaly compare reasoning path derive multiple relate memory and ( 2 ) dual-memory structure , detect failure be distil "" lesson "" store separately and consult future action , break error cycle and enable adaptation . comprehensive evaluation multiple benchmark show a-memguard effectively cut attack success rate 95 % incur minimal utility cost . work shift llm memory security static filtering proactive , experience-driven model defense strengthen time . code be available https://github.com/tangciuyueng/amemguard",Cryptography and Security,29/09/2025
10.48550/arXiv.2510.02371,federated spatiotemporal graph learning passive attack detection smart grids,"Bochra Al Agha, Razane Tajeddine","smart grid be expose passive eavesdropping , attacker listen silently communication link . data be actively alter , such reconnaissance can reveal grid topology , consumption pattern , and operational behavior , create gateway more severe target attack . detect threat be difficult signal produce be faint , short-lived , and often disappear traffic be examine single node or single timeline . paper introduce graph-centric , multimodal detector fuse physical-layer ( channel state information ( csi ) , signal-to-noise ratio ( snr ) ) and behavioral ( latency , packet error rate ( per ) , event context ) indicator ego-centric star subgraph and short temporal window to detect passive attack . to capture stealthy perturbation , two-stage encoder be introduce : graph convolution aggregate spatial context ego-centric star subgraph , bidirectional gru model short-term temporal dependency . encoder transform heterogeneous feature unified spatio-temporal representation suitable classification . training occur federated learning setup fedprox , improve robustness heterogeneous local raw datum and contribute trustworthiness decentralized training ; raw measurement remain client device . synthetic , standards-informed dataset be generate to emulate heterogeneous han/nan/wan111han : in-premise device ; nan : neighborhood-level aggregation gateway ; wan : utility backhaul substation and control center . communication wireless-only passive perturbation , event co-occurrence , and leak-safe split . model achieve testing accuracy 98 . 32 % per-timestep ( f1attack=0 . 972 ) and 93 . 35 % per-sequence 0 . 15 % fpr use simple decision rule run-length m=2m=2 and threshold τ=0 . 55\tau=0 . 55 . result demonstrate combine spatial and temporal context enable reliable detection stealthy reconnaissance maintain low false-positive rate , make approach suitable non-iid federate smart-grid deployment .",Cryptography and Security,29/09/2025
10.48550/arXiv.2510.02365,bootstrappe morphism : arithmetic geometry approach asymptotically faster homomorphic encryption,Dongfang Zhao,"fully homomorphic encryption ( fhe ) provide powerful paradigm secure computation , but practical adoption be severely hinder prohibitive computational cost bootstrapping procedure . complexity current bootstrappe method be fundamentally tie multiplicative depth decryption circuit , denote ld​e​cl_{dec } , make primary performance bottleneck . paper introduce new approach bootstrappe completely bypass traditional circuit evaluation model . apply tool modern arithmetic geometry to reframe bootstrapping operation direct geometric projection . framework model space ciphertext affine scheme and rigorously define loci decryptable and fresh ciphertext distinct closed subscheme . bootstrapping transformation be then realize morphism two space . computationally , projection be equivalent solve specific closest vector problem ( cvp ) instance highly structure ideal lattice , show can be do efficiently use technique call algebraic folding . primary result work be complete and provably correct bootstrappe algorithm computational complexity o​(d⋅poly​(log⁡q))o(d\cdot\text{poly}(\log q ) ) , dd be ring dimension and qq be ciphertext modulus . significance result lie complete elimination factor ld​e​cl_{dec } complexity , represent fundamental asymptotic improvement state art . geometric perspective offer new and promising pathway achieve truly practical and high-performance fhe .",Cryptography and Security,29/09/2025
10.48550/arXiv.2510.02356,measure physical-world privacy awareness large language model : evaluation benchmark,"Xinjie Shen, Mufei Li, Pan Li","deployment large language models ( llms ) embody agent create urgent need to measure privacy awareness physical world . exist evaluation method , however , be confine natural language base scenario . to bridge gap , introduce eaprivacy , comprehensive evaluation benchmark design to quantify physical-world privacy awareness llm-powered agent . eaprivacy utilize procedurally generate scenario four tier to test agent ’s ability to handle sensitive object , adapt change environment , balance task execution privacy constraint , and resolve conflict social norm . measurement reveal critical deficit current model . top-performing model , gemini 2 . 5 pro , achieve only 59 % accuracy scenario involve change physical environment . furthermore , task be accompany privacy request , model prioritize completion constraint to 86 % case . high-stakes situation pit privacy critical social norm , lead model gpt-4o and claude-3 . 5-haiku disregard social norm 15 % time . finding , demonstrate benchmark , underscore fundamental misalignment llms regard physically ground privacy and establish need more robust , physically-aware alignment .",Cryptography and Security,27/09/2025
10.48550/arXiv.2510.02349,investigation performance non-contrastive self-supervised learning methods network intrusion detection,"Hamed Fard, Tobias Schalau, Gerhard Wunder","network intrusion detection , well-explored cybersecurity field , have predominantly rely supervised learning algorithm past two decade . however , limitation detect only know anomaly prompt exploration alternative approach . motivate success self-supervised learning computer vision , be rise interest adapt paradigm network intrusion detection . prior research mainly delve contrastive self-supervised method , efficacy non-contrastive method , conjunction encoder architecture serve representation learn backbone and augmentation strategy determine be learn , remain unclear effective attack detection . paper compare performance five non-contrastive self-supervised learning method use three encoder architecture and six augmentation strategy . ninety experiment be systematically conduct two network intrusion detection dataset , unsw-nb15 and 5g-nidd . self-supervised model , combination encoder architecture and augmentation method yield high average precision , recall , f1-score , and aucroc be report . furthermore , compare best-performe model two unsupervised baseline , deepsvdd , and autoencoder , showcase competitiveness non-contrastive method attack detection . code : https://github.com/renje4z335jh4/non_contrastive_ssl_nids",Cryptography and Security,27/09/2025
10.48550/arXiv.2510.02342,catmark : context-aware thresholde framework robust cross-task watermarking large language model,"Yu Zhang, Shuliang Liu, Xu Yang, Xuming Hu","watermarke algorithm large language models ( llms ) effectively identify machine-generated content embed and detect hide statistical feature text . however , such embed lead decline text quality , especially low-entropy scenario performance need improvement . exist method rely entropy threshold often require significant computational resource tuning and demonstrate poor adaptability unknown or cross-task generation scenario . propose context-aware threshold watermarking ( catmark ) , novel framework dynamically adjust watermarke intensity base real-time semantic context . catmark partition text generation semantic state use logit cluster , establish context-aware entropy threshold preserve fidelity structured content embed robust watermark . crucially , require pre-defined threshold or task-specific tuning . experiment show catmark improve text quality cross-task sacrifice detection accuracy .",Cryptography and Security,27/09/2025
10.48550/arXiv.2510.02325,"agentic-ai healthcare : multilingual , privacy-first framework mcp agent",Mohammed A. Shehab,"paper introduce agentic-ai healthcare , privacy-aware , multilingual , and explainable research prototype develop single-investigator project . system leverage emerge model context protocol ( mcp ) to orchestrate multiple intelligent agent patient interaction , include symptom checking , medication suggestion , and appointment scheduling .",Cryptography and Security,25/09/2025
10.48550/arXiv.2510.02319,model attack : detect ai-generate text quantifying adversarial perturbations,"Lekkala Sai Teja, Annepaka Yadagiri, Sangam Sai Anish, Siva Gopala Krishna Nuthakki, Partha Pakray","growth highly advanced large language models ( llms ) constitute huge dual-use problem , make necessary to create dependable ai-generate text detection system . modern detector be notoriously vulnerable adversarial attack , paraphrase stand effective evasion technique foil statistical detection . paper present comparative study adversarial robustness , first quantify limitation standard adversarial training and then introduce novel , significantly more resilient detection framework : perturbation-invariant feature engineering ( pife ) , framework enhance detection first transform input text standardized form use multi-stage normalization pipeline , then quantify transformation ’s magnitude use metric levenshtein distance and semantic similarity , feed signal directly classifier . evaluate both conventionally harden transformer and pife-augmente model hierarchical taxonomy character- , word- , and sentence-level attack . finding first confirm conventional adversarial training , resilient syntactic noise , fail semantic attack , effect term "" semantic evasion threshold "" , true positive rate strict 1 % false positive rate plummet 48 . 8 % . stark contrast , pife model , explicitly engineer feature discrepancy text and canonical form , overcome limitation . maintain remarkable 82 . 6 % tpr same condition , effectively neutralize most sophisticated semantic attack . superior performance demonstrate explicitly model perturbation artifact , rather merely train , be more promising path achieve genuine robustness adversarial arm race .",Cryptography and Security,22/09/2025
10.48550/arXiv.2510.02317,hybrid horizons : policy post-quantum security,Anais Jaikissoon,"age artificial intelligence be here . 2025 , be few regulation govern artificial intelligence . expansion artificial intelligence be go relatively good direction , be risk can be misuse . misuse technology be new and will continue to happen . lack regulation artificial intelligence be necessary raise question can move forward know limit be . artificial intelligence dominate technology industry , new technology be start to emerge . quantum cryptography be expect to replace classical cryptography ; however , transition classical quantum cryptography be expect to occur next 10 year . ability to transition classical quantum cryptography require hybrid cryptography . hybrid cryptography can be use now ; however , similar artificial intelligence , be regulation or support regulatory infrastructure regard hybrid machine . paper will explore regulatory gap hybrid cryptography . paper will also offer solution to fix gap and ensure transition classical quantum cryptography be safely and effectively complete .",Cryptography and Security,06/09/2025
10.48550/arXiv.2510.02915,wavinwav : time-domain speech hiding invertible neural network,"Wei Fan, Kejiang Chen, Xiangkun Wang, Weiming Zhang, Nenghai Yu","datum hide be essential secure communication digital medium , and recent advance deep neural networks ( dnn ) provide enhance method embed secret information effectively . however , previous audio hiding method often result unsatisfactory quality recover secret audio , inherent limitation modeling time-frequency relationship . paper , explore limitation and introduce new dnn-based approach . use flow-based invertible neural network to establish direct link stego audio , cover audio , and secret audio , enhance reversibility embed and extract message . to address common issue time-frequency transformation degrade secret audio quality recovery , implement time-frequency loss time-domain signal . approach not only retain benefit time-frequency constraint but also enhance reversibility message recovery , be vital practical application . also add encryption technique to protect hide datum unauthorized access . experimental result vctk and librispeech dataset demonstrate method outperform previous approach term subjective and objective metric and exhibit robustness various type noise , suggest utility target secure communication scenario .",Cryptography and Security,03/10/2025
10.48550/arXiv.2510.02773,automated repair openid connect programs ( extended version ),"Tamjid Al Rahat, Yanju Chen, Yu Feng, Yuan Tian","openid connect have revolutionize online authentication base single sign-on ( sso ) provide secure and convenient method access multiple service single set credential . widespread adoption , critical security bug openid connect have result significant financial loss and security breach , highlight need robust mitigation strategy . automate program repair present promising solution generate candidate patch openid implementation . however , challenge such domain-specific complexity and necessity precise fault localization and patch verification must be address . propose authfix , counterexample-guided repair engine leverage llm automated openid bug fixing . authfix integrate three key component : fault localization , patch synthesis , and patch verification . employ novel petri-net-based model checker , authfix ensure correctness patch effectively modeling interaction . evaluation dataset openid bug demonstrate authfix successfully generate correct patch 17 23 bug ( 74 % ) , high proportion patch semantically equivalent developer-written fix .",Cryptography and Security,03/10/2025
10.48550/arXiv.2510.02503,bilevel optimization framework adversarial control gas pipeline operations,"Tejaswini Sanjay Katale, Lu Gao, Yunpeng Zhang, Alaa Senouci","cyberattack pipeline operational technology system pose grow risk energy infrastructure . study develop physics-informed simulation and optimization framework analyze cyber–physical threat petroleum pipeline network . model integrate networked hydraulic dynamic , scada-based state estimation , model predictive control ( mpc ) , and bi-level formulation stealthy false-data injection ( fdi ) attack . pipeline flow and pressure dynamic be model direct graph use nodal pressure evolution and edge-based weymouth-type relation , include control-aware equipment such valve and compressor . extended kalman filter estimate full network state partial scada telemetry . controller compute pressure-safe control input mpc actuator constraint and forecast demand . adversarial manipulation be formalize bi-level optimization problem attacker perturb sensor datum to degrade throughput remain undetected bad-data detector . attack-control interaction be solve karush–kuhn–tucker ( kkt ) reformulation , result tractable mixed-integer quadratic program . test gas pipeline case study demonstrate covert reduction service delivery attack . result show undetectable attack can cause sustained throughput loss minimal instantaneous deviation . reveal need integrated detection and control strategy cyber-physical infrastructure .",Cryptography and Security,02/10/2025
10.48550/arXiv.2510.02487,"interplay security , privacy and trust 6g-enabled intelligent transportation systems","Ahmed Danladi Abdullahi, Erfan Bahrami, Tooska Dargahi, Mohammed Al-Khalidi, Mohammad Hammoudeh","advancement 6 g technology have potential to revolutionize transportation sector and significantly improve travel . 6g-enable intelligent transportation systems ( its ) promise to offer high-speed , low-latency communication and advanced data analytic capability , support development safe , more efficient , and more sustainable transportation solution . however , various security and privacy challenge be identify literature must be address to enable safe and secure deployment 6g-it and ensure people ’s trust use technology . paper review opportunity and challenge 6g-its , particularly focus trust , security , and privacy , special attention quantum technology both enhance security quantum key distribution and introduce new vulnerability . discuss potential benefit 6 g technology transportation sector , include improved communication , device interoperability support , datum analytic capability , and increase automation different component , such transportation management and communication system . taxonomy different attack model 6g-its be propose , and comparison security threat 5g-its and 6g-its be provide , potential mitigating solution . research highlight urgent need comprehensive , multi-layered security framework span physical infrastructure protection , network protocol security , datum management safeguard , application security measure , and trust management system to effectively mitigate emerge security and privacy risk and ensure integrity and resilience future transportation ecosystem .",Cryptography and Security,02/10/2025
10.48550/arXiv.2510.02389,trace line : llm agent real-world oss vulnerability localization,"Haoran Xi, Minghao Shao, Brendan Dolan-Gavitt, Muhammad Shafique, Ramesh Karri","large language model show promise vulnerability discovery , yet prevail method inspect code isolation , struggle long contexts , and focus coarse function or file level detections—offere limited actionable guidance engineer need precise line-level localization and target patch real-world software development . present t2l-agent ( trace-to-line agent ) , project-level , end-to-end framework plan own analysis and progressively narrow scope module to exact vulnerable line . t2l-agent couple multi-round feedback agentic trace analyzer ( ata ) fuse runtime evidence—crash point , stack trace , and coverage delta ast-base code chunking , enable iterative refinement single pass prediction and translate symptom actionable , line-level diagnosis . to benchmark line-level vulnerability discovery , introduce , diverse , expert-verified 50-case benchmark span five crash family and real-world project . t2l-arvo be specifically design to support coarse-grained detection and fine-grained localization , enable rigorous evaluation system aim to move file-level prediction . t2l-arvo , t2l-agent achieve 58 . 0 % detection and 54 . 8 % line-level localization , substantially outperform baseline . together , framework and benchmark push llm-base vulnerability detection coarse identification deployable , robust , precision diagnostic reduce noise and accelerate patching open-source software workflow . framework and benchmark be publicly available open source https://github.com/haoranxi/t2lagent .",Cryptography and Security,30/09/2025
10.48550/arXiv.2510.02332,high-capacity and secure disambiguation algorithm neural linguistic steganography,"Yapei Feng, Feng Jiang, Shanhao Wu, Hua Zhong","neural linguistic steganography aim to embed information natural text preserve statistical undetectability . fundamental challenge field stem tokenization ambiguity modern tokenizer , can lead catastrophic decoding failure . recent method , syncpool , address ambiguity employ coarse-grained synchronization mechanism group ambiguous candidate . however , syncpool sacrifice embed capacity , utilize entire shannon entropy ambiguous group solely synchronization rather payload embed . propose method name look-ahead sync , overcome capacity limitation syncpool retain provable security guarantee . approach perform minimal synchronized sampling only truly indistinguishable token sequence , strategically preserve other discernible path to maximize embed capacity . provide theoretical proof security method and analyze gap achievable embed capacity and theoretical upper bind . experiment english ( use llama 3 ) and chinese ( use qwen 2 . 5 ) benchmark show method consistently approach theoretical capacity upper bind and significantly outperform syncpool . improvement embed rate exceed 160 % english and 25 % chinese , particularly setting large candidate pool . work represent significant step practical high-capacity provably secure linguistic steganography .",Cryptography and Security,26/09/2025
10.48550/arXiv.2510.02196,authentication security prf gnss range,Jason Anderson,"work derive authentication security pseudorandom function ( prf ) gnss range multiple gnss spoofing model , include security code estimation and replay ( scer ) spoofer . gnss range code derive prf utilize secret know only broadcaster , spoofer can not predict range code broadcast . therefore , prf ranging can be use to establish trust gnss pseudorange and result receiver position , navigation , and time ( pnt ) solution . apply method herein galileo ’s signal authentication service ( sas ) utilize encrypt galileo e6-c signal to compute , most , 400 ms galileo e6-c datum to assert 128-bit authentication security non-scer model . scer adversary , predict adversary ’s need receive radio equipment to break authentication security . can use work to design prf gnss range protocol to meet useful authentication security requirement compute probability miss detection .",Cryptography and Security,02/10/2025
10.48550/arXiv.2510.02162,nomod : non-modular attack module learning error,"Cristian Bassotto, Ermes Franch, Marina Krček, Stjepan Picek","advent quantum computing threaten classical public-key cryptography , motivate nist ’s adoption post-quantum scheme such base module learning errors ( module-lwe ) problem . present nomod ml-attack , hybrid white-box cryptanalytic method circumvent challenge model modular reduction treat wrap-around statistical corruption and cast secret recovery robust linear estimation . approach combine optimize lattice preprocessing—including reduced-vector saving and algebraic robust estimator train tukey ’s biweight loss . experiment show nomod achieve full recovery binary secret dimension n=350n=350 , recovery sparse binomial secret n=256n=256 , and successful recovery sparse secret crystals-kyber setting parameter ( n , k)=(128 , 3)(n , k)=(128 , 3 ) and ( 256 , 2)(256 , 2 ) . release implementation anonymous repository https://anonymous.4open.science/r/nomod-3bd4 .",Cryptography and Security,02/10/2025
10.48550/arXiv.2510.02158,"mirage fools ear , mute hide truth : precise target adversarial attacks polyphonic sound event detection systems","Junjie Su, Weifei Jin, Yuxin Cao, Derui Wang, Kai Ye, Jie Hao","sound event detection ( sed ) system be increasingly deploy safety-critical application such industrial monitoring and audio surveillance . however , robustness adversarial attack have not be well explore . exist audio adversarial attack target sed system , incorporate detection and localization capability , often lack effectiveness sed ’s strong contextual dependency or lack precision focus solely misclassifye target region target event , inadvertently affect non-target region . to address challenge , propose mirage and mute attack ( m2​a\text{m}^{2}\text{a } ) framework , be design target adversarial attack polyphonic sed system . optimization process , impose specific constraint non-target output , refer preservation loss , ensure attack do not alter model output non-target region , thus achieve precise attack . furthermore , introduce novel evaluation metric editing precison ( ep ) balance effectiveness and precision , enable method to simultaneously enhance . comprehensive experiment show m2​a\text{m}^{2}\text{a } achieve 94 . 56 % and 99 . 11 % ep two state-of-the-art sed model , demonstrate framework be sufficiently effective significantly enhance attack precision .",Cryptography and Security,02/10/2025
10.48550/arXiv.2510.01780,secure multi-modal data fusion federated digital health systems mcp,Aueaphum Aueawatthanaphisut,"secure and interoperable integration heterogeneous medical datum remain grand challenge digital health . current federated learning ( fl ) framework offer privacy-preserving model training but lack standardized mechanism to orchestrate multi-modal datum fusion distribute and resource-constrained environment . study introduce novel framework leverage model context protocol ( mcp ) interoperability layer secure , cross-agent communication multi-modal federate healthcare system . propose architecture unify three pillar : ( i ) multi-modal feature alignment clinical imaging , electronic medical record , and wearable iot datum ; ( ii ) secure aggregation differential privacy to protect patient-sensitive update ; and ( iii ) energy-aware scheduling to mitigate dropout mobile client . employ mcp schema-driven interface , framework enable adaptive orchestration ai agent and toolchain ensure compliance privacy regulation . experimental evaluation benchmark dataset and pilot clinical cohort demonstrate up to 9 . 8 % improvement diagnostic accuracy compare baseline fl , 54 % reduction client dropout rate , and clinically acceptable privacy–utility trade-off . result highlight mcp-enable multi-modal fusion scalable and trustworthy pathway equitable , next-generation federate health infrastructure .",Cryptography and Security,02/10/2025
10.48550/arXiv.2510.01720,construction efficiently implementable boolean functions provable nonlinearity/resiliency/algebraic immunity trade-off,Palash Sarkar,"describe several family efficiently implementable boolean function achieve provable trade-off resiliency , nonlinearity , and algebraic immunity . particular , follow statement hold function family propose . give integer m0≥0m_{0}\geq 0 , x0≥1x_{0}\geq 1 , and a0≥1a_{0}\geq 1 , be possible to construct nn-variable function have resiliency least m0m_{0 } , linear bias ( be equivalent method express nonlinearity ) most 2−x02^{-x_{0 } } and algebraic immunity least } ; far , nn be linear m0m_{0 } , x0x_{0 } and a0a_{0 } , and function can be implement use o​(n)o(n ) 2-input gate , be essentially optimal .",Cryptography and Security,02/10/2025
10.48550/arXiv.2510.01699,imperceptible adversarial defense : gradient-driven shield facial manipulations,"Yue Li, Linying Xue, Dongdong Lin, Qiushi Li, Hui Tian, Hongxia Wang","flourish prosperity generative model , manipulate facial image have become increasingly accessible , raise concern regard privacy infringement and societal trust . response , proactive defense strategy embed adversarial perturbation facial image to counter deepfake manipulation . however , exist method often face trade-off imperceptibility and defense effectiveness—strong perturbation may disrupt forgery but degrade visual fidelity . recent study have attempt to address issue introduce additional visual loss constraint , yet often overlook underlie gradient conflict loss , ultimately weaken defense performance . to bridge gap , propose gradient-projection-based adversarial proactive defense ( grasp ) method effectively counter facial deepfake minimize perceptual degradation . grasp be first approach to successfully integrate structural similarity loss and low-frequency loss to enhance perturbation imperceptibility . analyze gradient conflict defense effectiveness loss and visual quality loss , grasp pioneer design gradient-projection mechanism to mitigate conflict , enable balanced optimization preserve image fidelity sacrifice defensive performance . extensive experiment validate efficacy grasp , achieve psnr exceed 40 db , ssim 0 . 99 , and 100 % defense success rate facial attribute manipulation , significantly outperform exist approach visual quality .",Cryptography and Security,02/10/2025
10.48550/arXiv.2510.01676,evaluate robustness production malware detection system transferable adversarial attacks,"Milad Nasr, Yanick Fratantonio, Luca Invernizzi, Ange Albertini, Loua Farah, Alex Petit-Bianco, Andreas Terzis, Kurt Thomas, Elie Bursztein, Nicholas Carlini","deep learning model become widely deploy component large production system , individual shortcoming can create system-level vulnerability real-world impact . paper study adversarial attack target ml component can degrade or bypass entire production-grade malware detection system , perform case study analysis gmail ’s pipeline file-type identification rely ml model .",Cryptography and Security,02/10/2025
